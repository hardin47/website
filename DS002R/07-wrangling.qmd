# Data wrangling {#sec-data-wrang}

As with data visualization, data wrangling is a fundamental part of being able to accurately, reproducibly, and efficiently work with data.  The approach taken in the following chapter is based on the philosophy of tidy data and takes many of its precepts from database theory.  If you have done much work in SQL, the functionality and approach of tidy data will feel very familiar.  The more adept you are at data wrangling, the more effective you will be at data analysis.


```{r, include=FALSE, eval=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, 
                      fig.height=3, fig.width=5,  
                      cache=TRUE, fig.align = "center")

library(tidyverse)
```


>Information is what we want, but data are what we've got. [@Kaplan15]

**Embrace all the ways to get help!**

1. cheat sheets: https://www.rstudio.com/resources/cheatsheets/
2. tidyverse vignettes: https://www.tidyverse.org/articles/2019/09/tidyr-1-0-0/
3. pivoting: https://tidyr.tidyverse.org/articles/pivot.html
4. google what you need and include `R tidy` or `tidyverse`

## Coding Style

An important aspect of the data wrangling tools in this chapter includes best practices for writing code.
The tidyverse style of coding allows you to implement code that is clean and communicates ideas easily.
The more your code conforms to a style, the easier it will be to debug, and the fewer mistakes you will make.
Understanding the rules of programming discourse is part of what makes excellent coders. [@soloway1984]

> Good coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread. <a href = "https://style.tidyverse.org/" target = "_blank">The tidyverse style guide</a>

### Why do style and format matter?

Consistency and communication are very important aspects of coding.
While the computer does not usually care about code style, the computer is not the only entity working in the coding space.
Humans play a huge role in making code work, and they absolutely do better in situations where style is consistent and clear.

In chess, experienced players have excellent memories for recall of specific games and positions they have seen previously.  However, recall is substantially better for situations with regular patterns as opposed to remembering random positions. [@gobet1996] The related psychological idea, <a href = "https://en.wikipedia.org/wiki/Chunking_(psychology)" target = "_blank">chunking</a>, states that small pieces of information improve long-term retention of the material. When code is random or unwieldy, the coder has to use more brainpower to process the intent of the code.

In particular, good code style:

* highlights where the errors are.
* makes it easier to fix errors.
* focuses the reader's eye on what the code is doing (bad style obscures the information into the code itself).
* helps the future reader of the code (which is likely you in the future!) understand what the code does.
* follows the rules that specify conventions in programming.

### Best practices for writing good code.

A style guide is a set of rules and best practices that help coders write code.  There are no absolute *truths* when it comes to style, but consistency is important for being able to communicate your work.

1. Use a style guide.  For example, try <a href = "https://style.tidyverse.org/" target = "_blank">The tidyverse style guide</a> 
2. Use the same guide that your collaborators are using -- remember, communication is key!




## Structure of Data {#datastruc}

For plotting, analyses, model building, etc., it's important that the data be structured in a very particular way.   Hadley Wickham provides a thorough discussion and advice for cleaning up the data in @Wickham14.

* *Tidy Data*: rows (cases/observational units) and columns (variables).  The key is that *every* row is a case and *every} column is a variable.  No exceptions.
* Creating tidy data is not trivial.  We work with objects (often data tables), functions, and arguments (often variables).


The Active Duty data are not tidy!  What are the cases?  How are the data not tidy?  What might the data look like in tidy form?  Suppose that the case was "an individual in the armed forces."  What variables would you use to capture the information in the following table?

https://docs.google.com/spreadsheets/d/1Ow6Cm4z-Z1Yybk3i352msulYCEDOUaOghmo9ALajyHo/edit#gid=1811988794

![](images/activedutyTidy.png)

**Problem:** totals and different sheets

**Better for R:** longer format with columns - grade, gender, status, service, count (case is still the total pay grade)

**Case is individual (?)**:  grade, gender, status, service (no count because each row does the counting)

### Building Tidy Data

Within R (really within any type of computing language, Python, SQL, Java, etc.), we need to understand how to build data using the patterns of the language.  Some things to consider:


* `object_name = function_name(arguments)` is a way of using a function to create a new object.
* `object_name = data_table |> function_name(arguments)` uses chaining syntax as an extension of the ideas of functions.  In chaining, the value on the left side of `|>` becomes the *first argument* to the function on the right side.


``` 
object_name = data_table |>
function_name(arguments) |> 
function_name(arguments)
```
is extended chaining.  `|>` is never at the front of the line, it is always connecting one idea with the continuation of that idea on the next line.
* In R, all functions take arguments in round parentheses (as opposed to subsetting observations or variables from data objects which happen with square parentheses).  Additionally, the spot to the left of `|>` is always a data table.
* The pipe syntax should be read as *then*, `|>`.

### Examples of Chaining

The pipe syntax (`|>`) takes a data frame (or data table) and sends it to the argument of a function.  The mapping goes to the first available argument in the function.  For example:

`x |> f()` is the same as `f(x)`

`x |> f(y)` is the same as `f(x, y)`


#### Little Bunny Foo Foo

From Hadley Wickham, how to think about tidy data.

> Little bunny Foo Foo
> Went hopping through the forest
> Scooping up the field mice
> And bopping them on the head

The nursery rhyme could be created by a series of steps where the output from each step is saved as an object along the way.

```
foo_foo <- little_bunny()
foo_foo_1 <- hop(foo_foo, through = forest)
foo_foo_2 <- scoop(foo_foo_2, up = field_mice)
foo_foo_3 <- bop(foo_foo_2, on = head)
```

Another approach is to concatenate the functions so that there is only one output.  

```
bop(
   scoop(
      hop(foo_foo, through = forest),
      up = field_mice),
   on = head)
```

Or even worse, as one line:

```
bop(scoop(hop(foo_foo, through = forest), up = field_mice), on = head)))
```

Instead, the code can be written using the pipe in the **order** in which the function is evaluated:

```
foo_foo |>
   hop(through = forest) |>
       scoop(up = field_mice) |>
           bop(on = head)
```

**babynames**  Each year, the US Social Security Administration publishes a list of the most popular names given to babies.  In 2014, http://www.ssa.gov/oact/babynames/#ht=2 shows Emma and Olivia leading for girls, Noah and Liam for boys.

The `babynames` data table in the `babynames` package comes from the Social Security Administration's listing of the names givens to babies in each year, and the number of babies of each sex given that name. (Only names with 5 or more babies are published by the SSA.)

### Data Verbs (on single data frames)

> Super important resource:  The RStudio **dplyr** cheat sheet: https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf

**Data verbs take data tables as input and give data tables as output (that's how we can use the chaining syntax!).**  We will use the R package **dplyr** to do much of our data wrangling.  Below is a list of verbs which will be helpful in wrangling many different types of data.  See the Data Wrangling cheat sheet from RStudio for additional help.   https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf

 * `sample_n()` take a random row(s)
 * `head()`  grab the first few rows
 * `tail()` grab the last few rows
 * `filter()`  removes unwanted *cases*
 *  `arrange()` reorders the cases
 *  `select()` removes unwanted *variables*   (and `rename()` )
 *  `distinct()` returns the unique values in a table
 * `mutate()` transforms the variable (and `transmute()` like mutate, returns only new variables)
 *  `group_by()` tells R that SUCCESSIVE functions keep in mind that there are groups of items.  So `group_by()` only makes sense with verbs later on (like `summarize()`).
 *  `summarize()`  collapses a data frame to a single row.  Some functions that are used within `summarize()` include:

     * `min(), max(), mean(), sum(), sd(), median()`, and `IQR()`
     * `n()`: number of observations in the current group
     * `n_distinct(x)`: count the number of unique values in `x`
     * `first_value(x), last_value(x)` and `nth_value(x, n)`: work similarly to `x[1], x[length(x)]`, and `x[n]` 



<!--
The following Shiny app ("Visualizing data manipulation operations") is for demonstrating how to work with dplyr/tidyr data manipulation.  It includes tabs for data selection, `filter` and `select`, `mutate`, `group_by` and `summarize`, `group_by` and `mutate`, and `join`.   http://rstudio.calvin.edu:3838/rpruim/dataOps/
-->

## R examples, basic verbs

  
### Datasets


`starwars` is from **dplyr** , although originally from SWAPI, the Star Wars API, http://swapi.co/.

`NHANES` From `?NHANES`:  NHANES is survey data collected by the US National Center for Health Statistics (NCHS) which has conducted a series of health and nutrition surveys since the early 1960's. Since 1999 approximately 5,000 individuals of all ages are interviewed in their homes every year and complete the health examination component of the survey. The health examination is conducted in a mobile examination center (MEC).

`babynames`  Each year, the US Social Security Administration publishes a list of the most popular names given to babies.  In 2018, http://www.ssa.gov/oact/babynames/#ht=2 shows Emma and Olivia leading for girls, Noah and Liam for boys. (Only names with 5 or more babies are published by the SSA.)

  
### Examples of Chaining


```{r}
library(babynames)
babynames |> nrow()
babynames |> names()
babynames |> glimpse()
babynames |> head()
babynames |> tail()
babynames |> sample_n(size=5)
```


### Data Verbs

Taken from the dplyr tutorial: http://dplyr.tidyverse.org/

#### Starwars
```{r}
library(dplyr)

starwars |> dim()
starwars |> names()
starwars |> head()

starwars |> 
  dplyr::filter(species == "Droid")


starwars |> 
  dplyr::select(name, ends_with("color"))


starwars |> 
  dplyr::mutate(name, bmi = mass / ((height / 100)  ^ 2)) |>
  dplyr::select(name:mass, bmi)

starwars |> 
  dplyr::arrange(desc(mass))


starwars |>
  dplyr::group_by(species) |>
  dplyr::summarize(
    num = n(),
    mass = mean(mass, na.rm = TRUE)
  ) |>
  dplyr::filter(num > 1)
```


#### NHANES
```{r}
require(NHANES)
names(NHANES)

# find the sleep variables
NHANESsleep <- NHANES |> select(Gender, Age, Weight, Race1, Race3, 
                                 Education, SleepTrouble, SleepHrsNight, 
                                 TVHrsDay, TVHrsDayChild, PhysActive)
names(NHANESsleep)
dim(NHANESsleep)

# subset for college students
NHANESsleep <- NHANESsleep |> filter(Age %in% c(18:22)) |> 
  mutate(Weightlb = Weight*2.2)

names(NHANESsleep)
dim(NHANESsleep)

NHANESsleep |> ggplot(aes(x=Age, y=SleepHrsNight, color=Gender)) + 
  geom_point(position=position_jitter(width=.25, height=0) ) + 
  facet_grid(SleepTrouble ~ TVHrsDay) 
```
  
### `summarize` and `group_by`
```{r}
# number of people (cases) in NHANES
NHANES |> summarize(n())

# total weight of all the people in NHANES (silly)
NHANES |> mutate(Weightlb = Weight*2.2) |> summarize(sum(Weightlb, na.rm=TRUE))

# mean weight of all the people in NHANES
NHANES |> mutate(Weightlb = Weight*2.2) |> summarize(mean(Weightlb, na.rm=TRUE))


# repeat the above but for groups

# males versus females
NHANES |> group_by(Gender) |> summarize(n())

NHANES |> group_by(Gender) |> mutate(Weightlb = Weight*2.2) |> 
  summarize(mean(Weightlb, na.rm=TRUE))


# smokers and non-smokers
NHANES |> group_by(SmokeNow) |> summarize(n())
NHANES |> group_by(SmokeNow) |> mutate(Weightlb = Weight*2.2) |> 
  summarize(mean(Weightlb, na.rm=TRUE))

# people with and without diabetes
NHANES |> group_by(Diabetes) |> summarize(n())
NHANES |> group_by(Diabetes) |> mutate(Weightlb = Weight*2.2) |> 
  summarize(mean(Weightlb, na.rm=TRUE))

# break down the smokers versus non-smokers further, by sex
NHANES |> group_by(SmokeNow, Gender) |> summarize(n())
NHANES |> group_by(SmokeNow, Gender) |> mutate(Weightlb = Weight*2.2) |> 
  summarize(mean(Weightlb, na.rm=TRUE))

# break down the people with diabetes further, by smoking
NHANES |> group_by(Diabetes, SmokeNow) |> summarize(n())
NHANES |> group_by(Diabetes, SmokeNow) |> mutate(Weightlb = Weight*2.2) |> 
  summarize(mean(Weightlb, na.rm=TRUE))
```
  
### babynames

```{r}  
babynames |> group_by(sex) |>
  summarize(total=sum(n))

babynames |> group_by(year, sex) |>
  summarize(name_count = n_distinct(name)) |> head()

babynames |> group_by(year, sex) |>
  summarize(name_count = n_distinct(name)) |> tail()

babysamp <- babynames |> sample_n(size=50)
babysamp |> select(year) |> distinct() |> table()
babysamp |> distinct() |> select(year) |> table()


Frances <- babynames |>
  filter(name== "Frances") |>
  group_by(year, sex) |>
  summarize(yrTot = sum(n))

Frances |> ggplot(aes(x=year, y=yrTot)) +
  geom_point(aes(color=sex)) + 
  geom_vline(xintercept=2006) + scale_y_log10() +
  labs(y = "Yearly total on log10 scale",
       title = "Number of babies named Frances, over time")
```
  



## Higher Level Data Verbs {#highverb}

There are more complicated verbs which may be important for more sophisticated analyses.  See the RStudio **dplyr** cheat sheet,  https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf}.


* `pivot_longer` makes many columns into 2 columns: `pivot_longer(data, cols,  names_to = , value_to = )`
* `pivot_wider` makes one column into multiple columns: `pivot_wider(data, names_from = , values_from = )`
* `left_join` returns all rows from the left table, and any rows with matching keys from the right table.
* `inner_join` returns only the rows in which the left table have matching keys in the right table (i.e., matching rows in both sets).
* `full_join` returns all rows from both tables, join records from the left which have matching keys in the right table.


Good practice:  always specify the `by` argument when joining data frames.

![If you ever need to understand which join is the right join for you, try to find an image that will lay out what the function is doing.  I found this one that is quite good and is taken from Statistics Globe blog: https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti](images/join.png)


## R examples, higher level verbs

<!--
In class example on babynames via Nick  http://dtkaplan.github.io/CVC/Summer2015/Learn/BabyNames/WhatHappenedToJane.Rmd   http://dtkaplan.github.io/CVC/Summer2015/Learn/BabyNames/WhatHappenedToJane-answers.pdf
-->

**tidyr** 1.0.0 has just been released!  The new release means that you need to update **tidyr**.  You will know if you have the latest version if the following command works in the console (window below):

```
?tidyr::pivot_longer
```

If you are familiar with `spread` and `gather`, you should acquaint yourself with `pivot_longer()` and `pivot_wider()`.  The idea is to go from very wide dataframes to very long dataframes and vice versa.

### `pivot_longer()`

`pivot` the military pay grade to become longer? 

![https://docs.google.com/spreadsheets/d/1Ow6Cm4z-Z1Yybk3i352msulYCEDOUaOghmo9ALajyHo/edit#
  gid=1811988794](images/activedutyTidy.png)



```{r}
library(googlesheets4)
gs4_deauth()

navy_gs = read_sheet("https://docs.google.com/spreadsheets/d/1Ow6Cm4z-Z1Yybk3i352msulYCEDOUaOghmo9ALajyHo/edit#gid=1877566408", 
                     col_types = "ccnnnnnnnnnnnnnnn")
```

```{r}
glimpse(navy_gs)
names(navy_gs) = c("X","pay.grade", "male.sing.wo", "female.sing.wo",
                   "tot.sing.wo", "male.sing.w", "female.sing.w", 
                   "tot.sing.w", "male.joint.NA", "female.joint.NA",
                   "tot.joint.NA", "male.civ.NA", "female.civ.NA",
                   "tot.civ.NA", "male.tot.NA", "female.tot.NA", 
                   "tot.tot.NA")
navy = navy_gs[-c(1:8), -1]
dplyr::glimpse(navy)

# get rid of total columns & rows:

navyWR = navy |> select(-contains("tot")) |>
   filter(substr(pay.grade, 1, 5) != "TOTAL" & 
                   substr(pay.grade, 1, 5) != "GRAND" ) |>
   pivot_longer(-pay.grade, 
                       values_to = "numPeople", 
                       names_to = "status") |>
   separate(status, into = c("sex", "marital", "kids"))

navyWR |> head()
```

Does a graph tell us if we did it right?  what if we had done it wrong...?
```{r}
navyWR |> ggplot(aes(x=pay.grade, y=numPeople, color=sex)) + 
  geom_point()  + 
  facet_grid(kids ~ marital) +
  theme_minimal() +
  scale_color_viridis_d() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   hjust = 1, size = rel(.5)))
```


Notice the difference between `facet_grid()` and `facet_wrap()`.

```{r}
navyWR |> ggplot(aes(x=pay.grade, y=numPeople, color=sex)) + 
  geom_point()  + 
  facet_wrap(kids ~ marital) +
  theme_minimal() +
  scale_color_viridis_d() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   hjust = 1, size = rel(.5)))
```

### `pivot_wider`

```{r}
library(babynames)
babynames |> dplyr::select(-prop) |>
   tidyr::pivot_wider(names_from = sex, values_from = n) 
```


```{r}
babynames |> 
  select(-prop) |> 
  pivot_wider(names_from = sex, values_from = n) |>
  filter(!is.na(F) & !is.na(M)) |>
  arrange(desc(year), desc(M))
```

```{r}
babynames |> 
  pivot_wider(names_from = sex, values_from = n) |>
  filter(!is.na(F) & !is.na(M)) |>
  arrange(desc(prop))
```

### `join` (use `join` to **merge** two datasets)

#### First get the data (GapMinder)

Both of the following datasets come from GapMinder.  The first represents country, year, and female literacy rate.  The second represents country, year, and GDP (in fixed 2000 US$).

```{r}
gs4_deauth()
litF = read_sheet("https://docs.google.com/spreadsheets/d/1hDinTIRHQIaZg1RUn6Z_6mo12PtKwEPFIz_mJVF6P5I/pub?gid=0")

litF = litF |> select(country=starts_with("Adult"), 
                              starts_with("1"), starts_with("2")) |>
  pivot_longer(-country, 
                      names_to = "year", 
                      values_to = "litRateF") |>
  filter(!is.na(litRateF))
```


```{r}
gs4_deauth()
GDP = read_sheet("https://docs.google.com/spreadsheets/d/1RctTQmKB0hzbm1E8rGcufYdMshRdhmYdeL29nXqmvsc/pub?gid=0")

GDP = GDP |> select(country = starts_with("Income"), 
                            starts_with("1"), starts_with("2")) |>
  pivot_longer(-country, 
                      names_to = "year", 
                      values_to = "gdp") |>
  filter(!is.na(gdp))
```
  
```{r}
head(litF)
head(GDP)

# left
litGDPleft = left_join(litF, GDP, by=c("country", "year"))
dim(litGDPleft)
sum(is.na(litGDPleft$gdp))
head(litGDPleft)

# right
litGDPright = right_join(litF, GDP, by=c("country", "year"))
dim(litGDPright)
sum(is.na(litGDPright$gdp))
head(litGDPright)

# inner
litGDPinner = inner_join(litF, GDP, by=c("country", "year"))
dim(litGDPinner)
sum(is.na(litGDPinner$gdp))
head(litGDPinner)

# full
litGDPfull = full_join(litF, GDP, by=c("country", "year"))
dim(litGDPfull)
sum(is.na(litGDPfull$gdp))
head(litGDPfull)
```



<!--
## Scraping Data

Need to talk about this!  Scraping from HTML. 

* Example / instructions:  Beginner's Guide on Web Scraping in R (using rvest) with hands-on example
by Saurav Kaushik   https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/
* Mine Dogucu at eCOTS18  https://www.causeweb.org/cause/ecots/ecots18/tech-talk/1
* La Quinta vs. Dennys (Colin Rundel & Mine Çetinkaya-Rundel )  https://github.com/rundel/Dennys_LaQuinta_Chance Webinar about the study:  https://www.rstudio.com/resources/webinars/data-science-case-study/  OR what if you look at Holiday Inn???)
-->


## **purrr** for functional programming

We will see the R package **purrr** in greater detail as we go, but for now, let's get a hint for how it works.  

We are going to focus on the `map` family of functions which will just get us started.  Lots of other good **purrr** functions like `pluck()` and `accumulate()`.

Much of below is taken from a [tutorial](https://www.rebeccabarter.com/blog/2019-08-19_purrr/) by Rebecca Barter.


The `map` functions are *named* by the **output** the produce.  For example: 

* `map(.x, .f)` is the main mapping function and returns a list

* `map_df(.x, .f)` returns a data frame

* `map_dbl(.x, .f)` returns a numeric (double) vector

* `map_chr(.x, .f)` returns a character vector

* `map_lgl(.x, .f)` returns a logical vector

Note that the first argument is always the data object and the second object is always the function you want to iteratively apply to each element in the input object.

The **input** to a `map` function is always either a *vector* (like a column), a *list* (which can be non-rectangular), or a *dataframe* (like a rectangle).

A list is a way to hold things which might be very different in shape:

```{r}
a_list <- list(a_number = 5,
                      a_vector = c("a", "b", "c"),
                      a_dataframe = data.frame(a = 1:3, 
                                               b = c("q", "b", "z"), 
                                               c = c("bananas", "are", "so very great")))

print(a_list)
```


Consider the following function:

```{r}
add_ten <- function(x) {
  return(x + 10)
  }
```

We can `map()` the `add_ten()` function across a vector.  Note that the output is a list (the default).

```{r}
library(tidyverse)
map(.x = c(2, 5, 10),
    .f = add_ten)
```

What if we use a different type of input?  The default behavior is to still return a list!

```{r}
data.frame(a = 2, b = 5, c = 10) |>
  map(add_ten)
```

What if we want a different type of output?  We use a different `map()` function, `map_df()`, for example.

```{r}
data.frame(a = 2, b = 5, c = 10) |>
  map_df(add_ten)
```


Shorthand lets us get away from pre-defining the function (which will be useful).  Use the tilde `~` to indicate that you have a function: 

```{r}
data.frame(a = 2, b = 5, c = 10) |>
  map_df(~{.x + 10})
```

Mostly, the tilde will be used for functions we already know:

```{r}
library(palmerpenguins)
library(broom)

penguins_split <- split(penguins, penguins$species)
penguins_split |>
  map(~ lm(body_mass_g ~ flipper_length_mm, data = .x)) |>
  map_df(tidy)  # map(tidy)

penguins |>
  group_by(species) |>
  group_map(~lm(body_mass_g ~ flipper_length_mm, data = .x)) |>
  map(tidy)  # map_df(tidy)
```


## <i class="fas fa-lightbulb"></i> Reflection questions  


## <i class="fas fa-balance-scale"></i> Ethics considerations 



