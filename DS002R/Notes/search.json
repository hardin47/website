[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Foundations of Data Science in R",
    "section": "",
    "text": "Welcome to Foundations of Data Science in R\nDaily class notes for Foundations of Data Science in R, by Jo Hardin, DS002R at Pomona College. Built on Modern Data Science with R by Baumer, Kaplan, and Horton, 3rd ed. and R for Data Science by Wickham, Çetinkaya-Rundel, and Grolemund, 2nd ed.\nYou are responsible for reading your texts. They are both free, excellent, and readable, so you should use them. That said, you should also make sure you are coming to class and asking lots of questions.\nMore information and course details can be found at the DS002R website.\n\nCopyright © 2024.\nVersion date: August 25, 2024.\nThe notes are available under a Creative Commons Attribution 4.0 United States License. License details are available at the Creative Commons website: https://creativecommons.org/licenses/by/4.0/.\nSource files for these notes can be found on GitHub at: https://github.com/hardin47/website/tree/gh-pages/DS002R.",
    "crumbs": [
      "Welcome to Foundations of Data Science in R"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  Introduction1",
    "section": "",
    "text": "1.1 Course Logistics\nWhat is Data Science?\nData science lives at the intersection between statistics, computer science, and discipline knowledge. It is generally the process by which we gain insight from data. Some statistical topics which intersect data science include data wrangling, data visualization, modeling, and statistical inference. Some statistical topics that aren’t usually considered data science include uncovering the convergence rates of particular algorithms. Computer science topics which intersect data science include search algorithms, data storage, and distributed computing. Some computer science topics that aren’t usually considered data science include operating systems, computer networks, computer architecture, and theory of computation. Regardless, it is vitally important to always keep in mind the disciplinary and ethical context in which data science problems are being applied.\nWhat is the content of DS 002R?\nThis class will cover all aspects of the data science process, from data acquisition to communication. Each of the aspects is important to the data science process, but we will not cover the topics linearly. We will work through acuiring data (e.g., web scraping and using SQL), data exploration (e.g., data wrangling, text analysis), data visualization, data conclusions (e.g., iteration, permutation tests), and data communication (e.g., reproducible workflow).\nBased on https://www.effectivedatastorytelling.com/post/a-deeper-dive-into-lego-bricks-and-data-stories, original source: https://www.linkedin.com/learning/instructors/bill-shander\nWho should take DS 002R?\nFoundations of Data Science will cover many of the concepts and tools for modern data analysis, and therefore the ideas are important for people who would like to do modern data analysis. The tools are particularly important for those who want to approach their own discipline through a quantitative lens.\nWhat are the prerequisites for DS 002R ?\nFoundations of Data Science has a formal prerequisite of some computer science. The prerequisite is there because we will move quickly with respect to programming, and students should be familiar with using software and command line programming. The class will use R, but there is no previous knowledge of R required.\nIs there overlap with other classes?\nThe first few weeks of Foundations of Data Science will get students up and running with the software R. The topics in the first few weeks will overlap with other classes, including Computational Statistics and some sections of Introductory Statistics. There are other data science courses at the 5Cs that cover many of the same topics covered in Foundations of Data Science.\nWhen should I take DS 002R?\nIf you are interested in data science, it is worth your while to take Foundations of Data Science as early as possible in your time at Pomona. It will help you frame the quantitative and computational aspects of the data science projects you will see in your own discipline.\nWhat is the workload for DS 002R?\nThere is one homework assignment per week, regular quizzes, and 5 mini-projects. Many students report working about 8-10 hours per week on this class.\nWhat software will we use? Will there be any real world applications? Will there be any mathematics? Will there be any CS?\nAll of the work will be done in R (using RStudio as a front end, called an integrated development environment, IDE). You will need to either download R and RStudio (both are free) onto your own computer or use them on Pomona’s server. All assignments will be posted to private repositories on GitHub. The class is a mix of many real world applications and case studies, some statistics, programming, and communication skills. The projects will allow you to be creative in answering questions of interest to you.",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction^[Much of this content was inspired by great educators who provide open source materials for educational use.  Many thanks to Mine Çetinkaya-Rundel (Duke), Ben Baumer (Smith), Brianna Heggeseth (Macalester), Leslie Myint (Macalester), Paul Roback (St Olaf) for sharing their materials.]</span>"
    ]
  },
  {
    "objectID": "01-intro.html#course-logistics",
    "href": "01-intro.html#course-logistics",
    "title": "1  Introduction1",
    "section": "",
    "text": "You may use R on the Pomona server: https://rstudio.pomona.edu/ (All Pomona students will be able to log in immediately. Non-Pomona students need to go to ITS at Pomona to get Pomona login information.)\nIf you want to use R on your own machine, you may. Please make sure all components are updated: R is freely available at http://www.r-project.org/ and is already installed on college computers. Additionally, installing R Studio is required https://posit.co/downloads/.\nAll assignments should be turned in using Quarto compiled to pdf.",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction^[Much of this content was inspired by great educators who provide open source materials for educational use.  Many thanks to Mine Çetinkaya-Rundel (Duke), Ben Baumer (Smith), Brianna Heggeseth (Macalester), Leslie Myint (Macalester), Paul Roback (St Olaf) for sharing their materials.]</span>"
    ]
  },
  {
    "objectID": "01-intro.html#course-content",
    "href": "01-intro.html#course-content",
    "title": "1  Introduction",
    "section": "1.2 Course Content",
    "text": "1.2 Course Content\nData Science includes the full pipeline for working with data. Some of the topics we will cover in DS 002R include:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDS workflow\nin DS002R\nbeyond DS002R\n\n\n\n\ndata acquisition\nweb scraping, SQL\ndatabases, APIs\n\n\ndata exploration\nwranging, strings\nnatural language processing\n\n\ndata visualization\nggplot\nanimations\n\n\ndata conclusions\npermutation tests, regular expressions\npredictive modeling, machine learning, AI\n\n\ndata communication\nyes!\nyes!\n\n\n\n\n\n\n\n\n\n1.2.1 Data\nWhat are data?\nOftentimes, the word data brings to mind a spreadsheet, like the one below, which is tidy.\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntidy data\n\n\n\n\neach row = a unit of observation (here, a penguin)\neach column = a measure on some variable of interest, either quantitative (numbers with units) or categorical (discrete possibilities or categories)\neach entry contains a single data value; no analysis, summaries, footnotes, comments, etc, and only one value per cell\n\n\n\nBut the definition of datum can be much broader:\n\n\n\n\n\n\n\n\n\nDefinition of datum from the Oxford English Dictionary\n\n\n\n\nEach of the following can be thought of as data. How would you wrangle such information into a tidy format?\nData examples:\n\nthe emails in your inbox\n\nsocial media texts\n\nimages\n\nvideos\n\naudio files\n\nFor each example, provide:\n\nthe observational units (what does a row represent)\n\nat least 4 possible variables (what might we record for each observation)\n\nwho might use such data?\n\n\n\n1.2.2 The Workflow\n\n\n\n\n\n\n\n\n\nA schematic of the typical workflow used in data analysis. Most statistics classes focus only on the left side. We will work to address all aspects (including those on the right side). (Baumer 2015)\n\n\n\n\n\n\n\n\n\n\n\n\n\nStitch Fix Algorithms Tour",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#repro",
    "href": "01-intro.html#repro",
    "title": "1  Introduction1",
    "section": "1.4 Reproducibility",
    "text": "1.4 Reproducibility\nReproducibility has long been considered an important topic for consideration in any research project. However, recently there has been increased press and available examples for understanding the impact that non-reproducible science can have.\nKitzes, Turek, and Deniz (2018) provide a full textbook on the structure of reproducible research as well as dozens of case studies to help hone skills and consider different aspects of the reproducible pipeline. Below are a handful of examples to get us thinking about reproducibility.\n\n1.4.1 Need for Reproducibility\n\n\n\n\n\n\n\n\n\nslide taken from Kellie Ottoboni https://github.com/kellieotto/useR2016\n\n\n\n\n\n\nExample 1\nScience retracts gay marriage paper without agreement of lead author LaCour\n\n\n\n\n\n\n\n\n\n\nIn May 2015 Science retracted a study of how canvassers can sway people’s opinions about gay marriage published just 5 months prior.\nScience Editor-in-Chief Marcia McNutt:\n\nOriginal survey data not made available for independent reproduction of results.\nSurvey incentives misrepresented.\nSponsorship statement false.\n\nTwo Berkeley grad students who attempted to replicate the study quickly discovered that the data must have been faked.\nMethods we’ll discuss can’t prevent this, but they can make it easier to discover issues.\nSource: http://news.sciencemag.org/policy/2015/05/science-retracts-gay-marriage-paper-without-lead-author-s-consent\n\n\n\nExample 2\nSeizure study retracted after authors realize data got “terribly mixed”\n\n\n\n\n\n\n\n\n\n\nFrom the authors of Low Dose Lidocaine for Refractory Seizures in Preterm Neonates:\n\n\nThe article has been retracted at the request of the authors. After carefully re-examining the data presented in the article, they identified that data of two different hospitals got terribly mixed. The published results cannot be reproduced in accordance with scientific and clinical correctness.\n\n\nSource: http://retractionwatch.com/2013/02/01/seizure-study-retracted-after-authors-realize-data-got-terribly-mixed/\n\n\n\nExample 3\nBad spreadsheet merge kills depression paper, quick fix resurrects it\n\n\n\n\n\n\n\n\n\n\nThe authors informed the journal that the merge of lab results and other survey data used in the paper resulted in an error regarding the identification codes. Results of the analyses were based on the data set in which this error occurred. Further analyses established the results reported in this manuscript and interpretation of the data are not correct.\n\n\nOriginal conclusion: Lower levels of CSF IL-6 were associated with current depression and with future depression …\n\n\nRevised conclusion: Higher levels of CSF IL-6 and IL-8 were associated with current depression …\n\n\nSource: http://retractionwatch.com/2014/07/01/bad-spreadsheet-merge-kills-depression-paper-quick-fix-resurrects-it/\n\n\n\nExample 4\nPNAS paper retracted due to problems with figure and reproducibility (April 2016): http://cardiobrief.org/2016/04/06/pnas-paper-by-prominent-cardiologist-and-dean-retracted/",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction^[Much of this content was inspired by great educators who provide open source materials for educational use.  Many thanks to Mine Çetinkaya-Rundel (Duke), Ben Baumer (Smith), Brianna Heggeseth (Macalester), Leslie Myint (Macalester), Paul Roback (St Olaf) for sharing their materials.]</span>"
    ]
  },
  {
    "objectID": "01-intro.html#data-examples",
    "href": "01-intro.html#data-examples",
    "title": "1  Introduction1",
    "section": "1.5 Data Examples",
    "text": "1.5 Data Examples\n\nWhat can/can’t Data Science Do?\n\nCan model the data at hand!\nCan find patterns & visualizations in large datasets.\nCan’t establish causation.\nCan’t represent data if it isn’t there.\n\n\n\nStats / Data Science / Math are not apolitical/agnostic\n\n“Inner city crime is reaching record levels” (Donald Trump, 8/30/16)\n“The unemployment rate for African-American youth is 59 percent” (Donald Trump 6/20/16)\n“Two million more Latinos are in poverty today than when President Obama took his oath of office less than eight years ago” (Donald Trump 8/25/16)\n“We are now, for the first time ever, energy independent” (Hillary Clinton 8/10/16)\n“If you look worldwide, the number of terrorist incidents have not substantially increased” (Barack Obama 10/13/16)\n“Illegal immigration is lower than it’s been in 40 years” (Barack Obama, 3/17/16)\n\nSource: http://www.politifact.com/truth-o-meter/statements/\n\n\n1.5.1 College Rankings Systems\nCheating\n\nBucknell University lied about SAT averages from 2006 to 2012, and Emory University sent in biased SAT scores and class ranks for at least 11 years, starting in 2000. Iona College admitted to fudging SAT scores, graduation rates, retention rates, acceptance rates, and student-to-faculty ratios in order to move from 50th place to 30th for nine years before it was discovered. ( Weapons of Math Destruction, O’Neil, https://weaponsofmathdestructionbook.com/ and http://www.slate.com/articles/business/moneybox/2016/09/how_big_data_made_applying_to_college_tougher_crueler_and_more_expensive.html)\n\nGaming the system\n\nPoint by point, senior staff members tackled different criteria, always with an eye to U.S. News’s methodology. Freeland added faculty, for instance, to reduce class size. “We did play other kinds of games,” he says. “You get credit for the number of classes you have under 20 [students], so we lowered our caps on a lot of our classes to 19 just to make sure.” From 1996 to the 2003 edition (released in 2002), Northeastern rose 20 spots. ( 14 Reasons Why US News College Rankings are Meaningless http://www.liberalartscolleges.com/us-news-college-rankings-meaningless/)\n\nNo way to measure “quality of education”\nWhat is “best”? A big part of the ranking system has to do with peer-assessed reputation (feedback loop!).\n\n\n1.5.2 Trump and Twitter\nAnalysis of Trump’s tweets with evidence that someone else tweets from his account using an iPhone.\n\nAug 9, 2016 http://varianceexplained.org/r/trump-tweets/\n\n\nMy analysis, shown below, concludes that the Android and iPhone tweets are clearly from different people, posting during different times of day and using hashtags, links, and retweets in distinct ways. What’s more, we can see that the Android tweets are angrier and more negative, while the iPhone tweets tend to be benign announcements and pictures.\n\n\nAug 9, 2017 http://varianceexplained.org/r/trump-followup/\n\n\nThere is a year of new data, with over 2700 more tweets. And quite notably, Trump stopped using the Android in March 2017. This is why machine learning approaches like http://didtrumptweetit.com/ are useful, since they can still distinguish Trump’s tweets from his campaign’s by training on the kinds of features I used in my original post.\n\n\nI’ve found a better dataset: in my original analysis, I was working quickly and used the twitteR package (https://cran.r-project.org/web/packages/twitteR/) to query Trump’s tweets. I since learned there’s a bug in the package that caused it to retrieve only about half the tweets that could have been retrieved, and in any case I was able to go back only to January 2016. I’ve since found the truly excellent Trump Twitter Archive (http://www.trumptwitterarchive.com/), which contains all of Trump’s tweets going back to 2009. Below I show some R code for querying it.\n\n\nI’ve heard some interesting questions that I wanted to follow up on: These come from the comments on the original post and other conversations I’ve had since. Two questions included what device Trump tended to use before the campaign, and what types of tweets tended to lead to high engagement.\n\n\n\n1.5.3 Can Twitter Predict Election Results?\n\nIn 2013, DiGrazia et al. (2013) published a provocative paper suggesting that polling could now be replaced by analyzing social media data. They analyzed 406 competitive US congressional races using over 3.5 billion tweets. In an article in The Washington Post one of the co-authors, Rojas, writes: “Anyone with programming skills can write a program that will harvest tweets, sort them for content and analyze the results. This can be done with nothing more than a laptop computer.” (Rojas 2013)\nWhat makes using Tweets to predict elections relevant to our class? (See Baumer (2015).)\n\nThe data come from neither an experiment nor a random sample - there must be careful thought applied to the question of to whom the analysis can be generalized. The data were also scraped from the internet.\nThe analysis was done combining domain knowledge (about congressional races) with a data source that seems completely irrelevant at the outset (tweets).\nThe dataset was quite large! 3.5 billion tweets were collected and a random sample of 500,000 tweets were analyzed.\nThe researchers were from sociology and computer science - a truly collaborative endeavor, and one that is often quite efficient at producing high quality analyses.\n\n\nActivity\nSpend a few minutes reading the Rojas editorial and skimming the actual paper. Be sure to consider Figure 1 and Table 1 carefully, and address the following questions.\n\nworking paper: http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2235423\npublished in PLoS ONE: http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079449 DiGrazia J, McKelvey K, Bollen J, Rojas F (2013) More Tweets, More Votes: Social Media as a Quantitative Indicator of Political Behavior. PLoS ONE 8 (11): e79449.\neditorial in The Washington Post by Rojas: http://www.washingtonpost.com/opinions/how-twitter-can-predict-an-election/2013/08/11/35ef885a-0108-11e3-96a8-d3b921c0924a_story.html\neditorial in the Huffington Post by Linkins: http://www.huffingtonpost.com/2013/08/14/twitter-predict-elections_n_3755326.html\neditorial blog by Gelman: http://andrewgelman.com/2013/04/24/the-tweets-votes-curve/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistics Hat\n\nWrite a sentence summarizing the findings of the paper.\nDiscuss Figure 1 with your neighbor. What is its purpose? What does it convey? Think critically about this data visualization. What would you do differently?\n\nshould be proportion for the response variable. The bizarre scaling could dramatically change the results\ndots could then be scaled in proportion to the number of tweets\nlinear fit may be questionable.\nHow would you improve the plot? I.e., annotate it to make it more convincing / communicative? Does it need enhancement?\n\nInterpret the coefficient of Republican Tweet Share in both models shown in Table 1. Be sure to include units.\nDiscuss with your neighbor the differences between the Bivariate model and the Full Model. Which one do you think does a better job of predicting the outcome of an election? Which one do you think best addresses the influence of tweets on an election?\n\n\\(R^2\\) is way higher after control variables are included, but duh!\nthe full model will likely do a better job of predicting\n\nWhy do you suppose that the coefficient of Republican Tweet Share is so much larger in the Bivariate model? How does this reflect on the influence of tweets in an election?\n\nAfter controlling for how many Republicans are in the district, most of the effect disappears\nWhile the coefficient of the main term is still statistically significant, the size of the coefficient\n(155 +/- 43 votes) is of little practical significance\n\nDo you think the study holds water? Why or why not? What are the shortcomings of this study?\n\nNot really. First of all, how many of these races are actually competitive? It’s not 406, it’s probably fewer than 100. If you redid the study on that sample, would the tweet share still be statistically significant in the full model?\n\n\n\n\nData Scientist Hat\nImagine that your boss, who does not have advanced technical skills or knowledge, asked you to reproduce the study you just read. Discuss the following with your neighbor.\n\nWhat steps are necessary to reproduce this study? Be as specific as you can! Try to list the subtasks that you would have to perform.\nWhat computational tools would you use for each task? Identify all the steps necessary to conduct the study. Could you do it given your current abilities & knowledge? What about the practical considerations? (1) How do you download from Twitter? (2) What is an API (Application Programming Interface), and how does R interface with APIs? (3) How hard is it to store 3.5 billion tweets? (4) How big is a tweet? (5) How do you know which congressional district the person who tweeted was in?\n\nHow much storage does it take to download 3.5 billion tweets? = 2000+ Gb = 2+ Tb (your hard drive is likely 1Tb, unless you have a small computer). Can you explain the billions of tweets stored at Indiana University? How would you randomly sample from the database? One tweet is about 2/3 of a Kb.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvantages\n\nCheap\nCan measure any political race (not just the wealthy ones).\n\n\n\nDisadvantages\n\nIs it really reflective of the voting populace? Who would it bias toward?\nDoes simple mention of a candidate always reflect voting patterns? When wouldn’t it?\nMargin of error of 2.7%. How is that number typically calculated in a poll? Note: \\(2 \\cdot \\sqrt{(1/2)(1/2)/1000} = 0.0316\\).\nTweets feel more free in terms of what you are able to say - is that a good thing or a bad thing with respect to polling?\nCan’t measure any demographic information.\n\n\n\nWhat could be done differently?\n\nGelman: look only at close races\nGelman: “It might make sense to flip it around and predict twitter mentions given candidate popularity. That is, rotate the graph 90 degrees, and see how much variation there is in tweet shares for elections of different degrees of closeness.”\nGelman: “And scale the size of each dot to the total number of tweets for the two candidates in the election.”\nGelman: Make the data publicly available so that others can try to reproduce the results\n\n\n\nTweeting and R\nThe twitter analysis requires a twitter password, and sorry, I won’t give you mine. If you want to download tweets, follow the instructions at http://stats.seandolinar.com/collecting-twitter-data-introduction/ or maybe one of these: https://www.credera.com/blog/business-intelligence/twitter-analytics-using-r-part-1-extract-tweets/ and http://davetang.org/muse/2013/04/06/using-the-r_twitter-package/ and ask me if you have any questions.",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction^[Much of this content was inspired by great educators who provide open source materials for educational use.  Many thanks to Mine Çetinkaya-Rundel (Duke), Ben Baumer (Smith), Brianna Heggeseth (Macalester), Leslie Myint (Macalester), Paul Roback (St Olaf) for sharing their materials.]</span>"
    ]
  },
  {
    "objectID": "01-intro.html#reflection-questions",
    "href": "01-intro.html#reflection-questions",
    "title": "1  Introduction1",
    "section": "1.6  Reflection questions",
    "text": "1.6  Reflection questions",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction^[Much of this content was inspired by great educators who provide open source materials for educational use.  Many thanks to Mine Çetinkaya-Rundel (Duke), Ben Baumer (Smith), Brianna Heggeseth (Macalester), Leslie Myint (Macalester), Paul Roback (St Olaf) for sharing their materials.]</span>"
    ]
  },
  {
    "objectID": "01-intro.html#ethics-considerations",
    "href": "01-intro.html#ethics-considerations",
    "title": "1  Introduction1",
    "section": "1.7  Ethics considerations",
    "text": "1.7  Ethics considerations\n\n\n\nBased on https://www.effectivedatastorytelling.com/post/a-deeper-dive-into-lego-bricks-and-data-stories, original source: https://www.linkedin.com/learning/instructors/bill-shander\nDefinition of datum from the Oxford English Dictionary\nTaken from Modern Drive: An introduction to statistical and data sciences via R, by Ismay and Kim\nJessica Ward, PhD student at Newcastle University\nhttps://xkcd.com/1597/\nslide taken from Kellie Ottoboni https://github.com/kellieotto/useR2016\n\n\n\nBaumer, Ben. 2015. “A Data Science Course for Undergraduates: Thinking with Data.” The American Statistician.\n\n\nDiGrazia, Joseph, Karissa McKelvey, Johan Bollen, and Fabio Rojas. 2013. “More Tweets, More Votes: Social Media as a Quantitative Indicator of Political Behavior.” PLoS ONE 8 (11): e79449.\n\n\nKitzes, Justin, Daniel Turek, and Fatma Deniz, eds. 2018. In The Practice of Reproducible Research: Case Studies and Lessons from the Data-Intensive Sciences. University of California Press.\n\n\nRojas, Fabio. 2013. “How Twitter Can Predict and Election.” The Washington Post.",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction^[Much of this content was inspired by great educators who provide open source materials for educational use.  Many thanks to Mine Çetinkaya-Rundel (Duke), Ben Baumer (Smith), Brianna Heggeseth (Macalester), Leslie Myint (Macalester), Paul Roback (St Olaf) for sharing their materials.]</span>"
    ]
  },
  {
    "objectID": "16-reprex.html",
    "href": "16-reprex.html",
    "title": "16  Reproducible examples",
    "section": "",
    "text": "16.1 reprex()\nIn order to create a reproducible example …\nStep 1. Copy code onto the clipboard\nStep 2. Type reprex() into the Console\nStep 3. Look at the Viewer to the right. Copy the Viewer output into GitHub, Piazza, an email, stackexchange, etc.\nSome places to learn more about reprex include",
    "crumbs": [
      "Data communication",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Reproducible examples</span>"
    ]
  },
  {
    "objectID": "16-reprex.html#reprex",
    "href": "16-reprex.html#reprex",
    "title": "16  Reproducible examples",
    "section": "",
    "text": "Help me help you\n\n\n\n\n\n\n\nA blog about it: https://teachdatascience.com/reprex/\nThe reprex vignette: https://reprex.tidyverse.org/index.html\n\nreprex dos and donts: https://reprex.tidyverse.org/articles/reprex-dos-and-donts.html\nJenny Bryan webinar on reprex: “Help me help you. Creating reproducible examples” https://resources.rstudio.com/webinars/help-me-help-you-creating-reproducible-examples-jenny-bryan\nSome advice: https://stackoverflow.com/help/minimal-reproducible-example\n\n\n16.1.0.1 reprex demo\nreprex(\n  jan31 + months(0:11) + days(31)\n)\nmultiple lines of code:\nreprex({\n  jan31 &lt;- ymd(\"2021-01-31\")\n  jan31 + months(0:11) + days(31)\n})\nreprex({\n  library(lubridate)\n  jan31 &lt;- ymd(\"2021-01-31\")\n  jan31 + months(0:11) + days(31)\n})",
    "crumbs": [
      "Data communication",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Reproducible examples</span>"
    ]
  },
  {
    "objectID": "16-reprex.html#reflection-questions",
    "href": "16-reprex.html#reflection-questions",
    "title": "16  Reproducible examples",
    "section": "\n16.2  Reflection questions",
    "text": "16.2  Reflection questions",
    "crumbs": [
      "Data communication",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Reproducible examples</span>"
    ]
  },
  {
    "objectID": "16-reprex.html#ethics-considerations",
    "href": "16-reprex.html#ethics-considerations",
    "title": "16  Reproducible examples",
    "section": "\n16.3  Ethics considerations",
    "text": "16.3  Ethics considerations",
    "crumbs": [
      "Data communication",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Reproducible examples</span>"
    ]
  },
  {
    "objectID": "15-R-tip-of-the-day.html",
    "href": "15-R-tip-of-the-day.html",
    "title": "15  R tip-of-the-day",
    "section": "",
    "text": "15.1  Reflection questions",
    "crumbs": [
      "Data communication",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>R tip-of-the-day</span>"
    ]
  },
  {
    "objectID": "15-R-tip-of-the-day.html#ethics-considerations",
    "href": "15-R-tip-of-the-day.html#ethics-considerations",
    "title": "15  R tip-of-the-day",
    "section": "\n15.2  Ethics considerations",
    "text": "15.2  Ethics considerations",
    "crumbs": [
      "Data communication",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>R tip-of-the-day</span>"
    ]
  },
  {
    "objectID": "14-version-control.html",
    "href": "14-version-control.html",
    "title": "14  Version control",
    "section": "",
    "text": "14.1  Reflection questions",
    "crumbs": [
      "Data communication",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Version control</span>"
    ]
  },
  {
    "objectID": "14-version-control.html#ethics-considerations",
    "href": "14-version-control.html#ethics-considerations",
    "title": "14  Version control",
    "section": "\n14.2  Ethics considerations",
    "text": "14.2  Ethics considerations",
    "crumbs": [
      "Data communication",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Version control</span>"
    ]
  },
  {
    "objectID": "13-permutation-tests.html",
    "href": "13-permutation-tests.html",
    "title": "13  Permutation tests",
    "section": "",
    "text": "13.1  Reflection questions",
    "crumbs": [
      "Data conclusions",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Permutation tests</span>"
    ]
  },
  {
    "objectID": "13-permutation-tests.html#ethics-considerations",
    "href": "13-permutation-tests.html#ethics-considerations",
    "title": "13  Permutation tests",
    "section": "\n13.2  Ethics considerations",
    "text": "13.2  Ethics considerations",
    "crumbs": [
      "Data conclusions",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Permutation tests</span>"
    ]
  },
  {
    "objectID": "12-iteration.html",
    "href": "12-iteration.html",
    "title": "12  Iteration",
    "section": "",
    "text": "12.1  Reflection questions",
    "crumbs": [
      "Data conclusions",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "12-iteration.html#ethics-considerations",
    "href": "12-iteration.html#ethics-considerations",
    "title": "12  Iteration",
    "section": "\n12.2  Ethics considerations",
    "text": "12.2  Ethics considerations",
    "crumbs": [
      "Data conclusions",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Iteration</span>"
    ]
  },
  {
    "objectID": "11-ggplot.html",
    "href": "11-ggplot.html",
    "title": "11  ggplot",
    "section": "",
    "text": "11.1 Deconstructing a graph",
    "crumbs": [
      "Data visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ggplot</span>"
    ]
  },
  {
    "objectID": "11-ggplot.html#examples",
    "href": "11-ggplot.html#examples",
    "title": "11  ggplot",
    "section": "",
    "text": "An aside\nGenerally, the better your graphics are, the better able you will be to communicate ideas broadly (that’s how you become rich and famous). By graphics I mean not only figures associated with analyses, but also power point presentations, posters, and information on your website provided for other scientists who might be interested in your work. Tufte is a master at understanding how to convey information visually, and I strongly recommend you look at his work. Start with Wikipedia where some of his main ideas are provided (e.g., “data-ink ratio”) and then check out his incredible texts. I have many of them in my office and am happy to let you peruse them. http://www.edwardtufte.com/tufte/books_vdqi\nAs mentioned in the booklet we are using, there are two main motivational steps to working with graphics as part of an argument (Tufte 1997).\n\n“An essential analytic task in making decisions based on evidence is to understand how things work.”\nMaking decisions based on evidence requires the appropriate display of that evidence.”\n\nBack to the examples…\n\n11.1.1 Cholera via Tufte\nIn September 1854, the worst outbreak of cholera in London occurred in a few block radius - within 10 days, there were more than 500 fatalities. John Snow recognized the clumping of deaths, and hypothesized that they were due to contamination of the Broad Street water pump. Despite testing the water from the pump and finding no suspicious impurities, he did notice that the water quality varies from data to day. More importantly, there seemed to be no other possible causal mechanism for the outbreak. Eight days after the outbreak began, Snow described his findings to the authorities, and the Board of Guardians of St. James’s Parish ordered the Broad Street pump handle removed. The epidemic ended soon after.\nWhy was John Snow successful at solving the problem? Some thoughts to consider (as reported in Tufte (1997)):\n\nThe bacterium Vibrio cholerae was not discovered until 1886, however Snow had myriad experience both as a medical doctor and in looking at patterns of of other outbreaks. He was the first to realized that cholera was transmitted through water instead of by air or other means.\nData in Context Snow thought carefully about how to present the data. Instead of simply looking at the data as counts or frequencies, he looked at the death spatially - on a map of the area.\nComparisons In order to isolate the pump as the cause of the outbreak, Snow needed to understand how the individuals who had died were different than the individuals who had survived. Snow found two other groups of individuals (brewers who drank only beer, and employees at a work house who had an on-site pump) who had not succumbed to the disease.\nAlternatives Whenever a theory is present, it is vitally important to contrast the theory against all possible alternative possibilities. In Snow’s case, he needed to consider all individuals who did not regularly use the Broad Street pump - he was able to understand the exceptions in every case.\nDid removing the pump handle really cause the outbreak to cease? Wasn’t it already on the decline?\nAssessment of the Graphic Did the individuals die at the place on the map? Live at the place on the map? Which (types of) individuals were missing from the graph? Missing at random? What decisions did he make in creating the graph (axes, binning of histogram bars, time over which data are plotted, etc.) that change the story needing to be told?\n\n11.1.2 Challenger via Tufte\nJohn Snow’s story of the successful graphical intervention in the cholera outbreak is contrasted with the fateful poor-graphical non-intervention of the Challenger disaster. On January 28, 1986, the space shuttle Challenger took off from Cape Canaveral, FL and immediately exploded, killing all seven astronauts aboard. We now know that the reason for the explosion was due to the failure of two rubber O-rings which malfunctioned due to the cold temperature of the day (\\(\\sim 29^\\circ\\) F).\nUnlike the cholera epidemic, those who understood the liability of a shuttle launch under cold conditions were unable to convince the powers that be to postpone the launch (there was much political momentum going forward to get the shuttle off the ground, including the first teacher in space, Christa McAuliffe). As seen in the Tufte chapter, the evidence was clear but not communicated!\nThe biggest problem (existing in many of the bullet points below) is that the engineers failed to as the important question about the data: in relation to what??\n\n\nThe engineers who understood the problem created tables and engineering graphs which were\n\nNot visually appealing.\nNot decipherable to the layman (e.g., “At about \\(50^\\circ\\) F blow-by could be experienced in case joints”)\nThere was also no authorship (reproducibility!). Figures should always have both accountability and reproducibility.\n\n\n\nThe information provided included very relevant points (about temperature) and superfluous information unrelated to temperature. The univariate analysis was insufficient because the story the data were trying to tell was about the bivariate relationship between temperature and o-ring failure.\nMissing data created an illusion of lack of evidence, when in fact, the true story was quite strong given the full set of information. (92% of the temperature data was missing from some of the most vital tables.)\nAnecdotal evidence was misconstrued: SRM-15 at 57F had the most damage, but SRM-22 at 75F had the second most damage.\nIn the end, the shuttle launched on a day which was an extrapolation from the model suggested by the data. They had never launched a shuttle at temperatures of \\(26^\\circ-29^\\circ\\)F.\nTufte goes on to describe many ways which the final presentation by the engineers to the administrators was inadequate: disappearing legend (labels), chartjunk, lack of clarity depicting cause and effect, and wrong order.\n\nAs with the cholera outbreak, a persuasive argument could have been made if the visualizations had\n\nbeen in context plot data versus temperature not time!,\nused appropriate comparisons: as compared with what?,\nconsider alternative scenarios when else did O-rings fail? What is the science behind O-ring failure?, and\nthe graphics had been assessed what is all of the extra noise? are the words being used accessible to non-engineers?.\n\nTufte (Tufte 1997) created the graphic below which should have been used before the launch to convince others to postpone. As you can see, the graphic is extremely convincing. An aside: the O-ring data are well suited for an analysis using logistic regression. Today, most scientists believe that the temperature caused the O-ring failure, however, the data do not speak to the causal relationship because they were not collected using a randomized experiment. That is, there could have been other confounding variables (e.g., humidity) which were possible causal mechanisms.\n\n\n\n\n\n\n\nThe graphic the engineers should have led with in trying to persuade the administrators not to launch. It is evident that the number of O-ring failures is quite highly associated with the ambient temperature. Note the vital information on the x-axis associated with the large number of launches at warm temperatures that had zero O-ring failures. (Tufte 1997)",
    "crumbs": [
      "Data visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ggplot</span>"
    ]
  },
  {
    "objectID": "11-ggplot.html#thoughts",
    "href": "11-ggplot.html#thoughts",
    "title": "11  ggplot",
    "section": "\n11.2 Thoughts on Plotting",
    "text": "11.2 Thoughts on Plotting\n\n11.2.1 Advice\n\nBasic plotting\n\nAvoid having other graph elements interfere with data\nUse visually prominent symbols\nAvoid over-plotting (One way to avoid over plotting: Jitter the values)\nDifferent values of data may obscure each other\nInclude all or nearly all of the data\nFill data region\n\n\nEliminate superfluous material\n\nChart junk & stuff that adds no meaning, e.g. butterflies on top of barplots, background images\nExtra tick marks and grid lines\nUnnecessary text and arrows\nDecimal places beyond the measurement error or the level of difference\n\n\nFacilitate Comparisons\n\nPut juxtaposed plots on same scale\nMake it easy to distinguish elements of superposed plots (e.g. color)\nEmphasizes the important difference\nComparison: volume, area, height (be careful, volume can seem bigger than you mean it to)\n\n\nChoosing the Scale (n.b., some of the principles may go counter to one another, use your judgment.)\n\nKeep scales on x and y axes the same for both plots to facilitate the comparison\nZoom in to focus on the region that contains the bulk of the data\nKeep the scale the same throughout the plot (i.e. don’t change it mid-axis)\nOrigin need not be on the scale\nChoose a scale that improves resolution\nAvoid jiggling the baseline\n\n\nHow to make a plot information rich\n\nDescribe what you see in the caption\nAdd context with reference markers (lines and points) including text\nAdd legends and labels\nUse color and plotting symbols to add more information\nPlot the same thing more than once in different ways/scales\nReduce clutter\n\n\nCaptions should\n\nBe comprehensive\nSelf-contained\nDescribe what has been graphed\nDraw attention to important features\nDescribe conclusions drawn from graph\n\n\nGood Plot Making Practice\n\nPut major conclusions in graphical form\nProvide reference information\nProof read for clarity and consistency\nGraphing is an iterative process\nMultiplicity is OK, i.e. two plots of the same variable may provide different messages\nMake plots data rich\n\n\n\nCreating a statistical graphic is an iterative process of discovery and fine tuning. We try to model the process of creating visualizations in the course by dedicating class time to an iterative creation of a plot. We begin either with a plot that screams for correction, and we transform it step-by-step, always thinking about the goal of a graph that is data rich and presents a clear vision of the important features of the data.\n\n11.2.2 An example from Information is Beautiful\n(See HW2 for details on R code)\nConsider the plot at http://www.informationisbeautiful.net/visualizations/caffeine-and-calories/. Note that the origin is at the point (150,150). While we can get over the hurdle, it is not what is expected when looking at a graph.\n\n\n\n\n\n\n\nhttp://infobeautiful3.s3.amazonaws.com/2013/01/1276_buzz_v_bulge.png\n\n\n\nI have removed the vertical and horizontal lines which detracted from the idea of an origin. I have also added additional information (color) to describe the chain from which the drink comes from. Notice that an additional difference between my plot and the original plot is that I have many more observations.\n\n\n\n\n\n\n\nCalories and Caffeine for drinks from various drinks and other items. Data source is: World Cancer Research Fund, Starbucks Beverage Nutrition Guide, Calorie Counter Database. Seemingly, the observational units (rows) are not a random sample of anything. As such, we should be careful of summarizing the data in any way - what would the ‘average’ calories even mean? Note, from the entire dataset give, the average calories is 179.8 and the average caffeine is 134.43. How do those numbers compare to the original plot?\n\n\n\nData retrieved from: https://docs.google.com/spreadsheets/d/1KYMUjrCulPtpUHwep9bVvsBvmVsDEbucdyRZ5uHCDxw/edit?hl=en_GB#gid=0\n\n11.2.2.1 Fonts Matter\nAt RStudio::conf 2020, The Glamour of Graphics, Will Chase makes some very important points about how and why making good graphics matters. The talk might be summarized by the plot below: fonts matter.\n\n\n\n\n\n\n\n\n\n11.2.3 Assessing Graphics (and Other Analyses)\n\n\n\n\n\n\n\n\nCritical Task\nNeeds Improvement\nBasic\nSurpassed\n\n\n\n\nComputation Perform computations\nComputations contain errors and extraneous code\nComputations are correct but contain extraneous / unnecessary computations\nComputations are correct and properly identified and labeled\n\n\n\nAnalysis Choose and carry out analysis appropriate for data and content(s)\nChoice of analysis is overly simplistic, irrelevant, or missing key component\nAnalysis appropriate, but incomplete, or not important features and assumptions not made explicit\nAnalysis appropriate, complete, advanced, relevant, and informative\n\n\n\nSynthesis Identify key features of the analysis, and interpret results (including context)\nConclusions are missing, incorrect, or not made based on results of analysis\nConclusions reasonable, but is partially correct or partially complete\nMake relevant conclusions explicitly connect to analysis and to context\n\n\n\nVisual presentation Communicate findings graphically clearly, precisely, and concisely\nInappropriate choice of plots; poorly labeled plots; plots missing\nPlots convey information correctly but lack context for interpretation\nPlots convey information correctly with adequate / appropriate reference information\n\n\n\nWritten Communicate findings clearly, precisely, and concisely\nExplanation is illogical, incorrect, or incoherent\nExplanation is partially correct but incomplete or unconvincing\nExplanation is correct, complete, and convincing\n\n\n\nA rubric for assessing analysis and corresponding visualization. Note that there can be a large amount of information gained in moving from basic competency to surpassed competency. Table taken from Nolan and Perrett (2016).",
    "crumbs": [
      "Data visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ggplot</span>"
    ]
  },
  {
    "objectID": "11-ggplot.html#deconstruct",
    "href": "11-ggplot.html#deconstruct",
    "title": "11  ggplot",
    "section": "",
    "text": "11.1.1 The Grammar of Graphics (gg)\nYau (2013) and Wickham (2014) have come up with a taxonomy and a grammar for thinking about the parts of a figure just like we conceptualize the parts of a body or the parts of a sentence.\nOne great way of thinking of the new process: it is no longer necessary to talk about the name of the graph (e.g., boxplot). Instead we now think in glyphs (geoms), and so we can put whatever we want on the plot. Note also that the transition leads you from a passive consumer (I need to make plot XXX because everyone else does, so I just plug in the data) into an active participant (what do I want my data to say? and how can I put that information onto my graphic?)\nThe most important questions you can ask with respect to creating figures are:\n\nWhat do we want R to do? (What is the goal?)\nWhat does R need to know?\n\nYau (2013) gives us nine visual cues, and Wickham (2014) translates them into a language using ggplot2. (The items below are from Baumer, Kaplan, and Horton (2021), chapter 2.)\n\nVisual Cues: the aspects of the figure where we should focus.Position (numerical) where in relation to other things?Length (numerical) how big (in one dimension)?Angle (numerical) how wide? parallel to something else?Direction (numerical) at what slope? In a time series, going up or down?Shape (categorical) belonging to what group?Area (numerical) how big (in two dimensions)? Beware of improper scaling!Volume (numerical) how big (in three dimensions)? Beware of improper scaling!Shade (either) to what extent? how severely?Color (either) to what extent? how severely? Beware of red/green color blindness.\nCoordinate System: rectangular, polar, geographic, etc.\nScale: numeric (linear? logarithmic?), categorical (ordered?), time\nContext: in comparison to what (think back to ideas from Tufte)\n\n\n\n\n\n\n\n\n\nOrder Matters\n\n\n\n\n\n\n\n\nCues Together\n\n\n\n\n\n\n\n\nWhat are the visual cues on the plot?\n\n\n\n\n\n\n\n\n\nposition?\nlength?\nshape?\narea/volume?\nshade/color?\ncoordinate System?\n\nscale?\nWhat are the visual cues on the plot?\n\n\n\n\n\n\n\n\n\nposition?\nlength?\nshape?\narea/volume?\nshade/color?\ncoordinate System?\n\nscale?\nWhat are the visual cues on the plot?\n\n\n\n\n\n\n\n\n\nposition?\nlength?\nshape?\narea/volume?\nshade/color?\ncoordinate System?\n\nscale?\n\n11.1.1.1 The grammar of graphics in ggplot2\n\ngeom: the geometric “shape” used to display data\n\nbar, point, line, ribbon, text, etc.\n\naesthetic: an attribute controlling how geom is displayed with respect to variables\n\nx position, y position, color, fill, shape, size, etc.\n\nscale: adjust information in the aesthetic to map onto the plot\n\n\nparticular assignment of colors, shapes, sizes, etc.; making axes continuous or constrained to a particular range of values.\n\nguide: helps user convert visual data back into raw data (legends, axes)\nstat: a transformation applied to data before geom gets it\n\nexample: histograms work on binned data\n\n11.1.2 ggplot2\n\nIn ggplot2, an aesthetic refers to a mapping between a variable and the information it conveys on the plot. Further information about plotting and visualizing information is given in chapter 2 (Data visualization) of Baumer, Kaplan, and Horton (2021). Much of the data in the presentation represents all births from 1978 in the US: the date, the day of the year, and the number of births.\n\nGoals\nWhat I will try to do\n\ngive a tour of ggplot2\nexplain how to think about plots the ggplot2 way\nprepare/encourage you to learn more later\n\nWhat I can’t do in one session\n\nshow every bell and whistle\nmake you an expert at using ggplot2\nGetting help\n\nOne of the best ways to get started with ggplot is to Google what you want to do with the word ggplot. Then look through the images that come up. More often than not, the associated code is there. There are also ggplot galleries of images, one of them is here: https://plot.ly/ggplot2/\nggplot2 cheat sheet: https://rstudio.github.io/cheatsheets/html/data-visualization.html\nLook at the end of the presentation. More help options there.\n\n\n\n\n\n\n\n\n\n\nrequire(mosaic)    # where Births78 lives\ndata(Births78)     # restore fresh version of Births78\n\n\nhead(Births78, 3)\n\n\n\n\n\n\n\n\ndate\nbirths\nwday\nyear\nmonth\nday_of_year\nday_of_month\nday_of_week\n\n\n\n1978-01-01\n7701\nSun\n1978\n1\n1\n1\n1\n\n\n1978-01-02\n7527\nMon\n1978\n1\n2\n2\n2\n\n\n1978-01-03\n8825\nTue\n1978\n1\n3\n3\n3\n\n\n\n\n\n\n\nHow can we make the plot?\n\n\n\n\n\n\n\n\nTwo Questions:\n\nWhat do we want R to do? (What is the goal?)\n\nWhat does R need to know?\n\ndata source: Births78\n\naesthetics:\n\ndate -&gt; x\nbirths -&gt; y\npoints (!)\n\n\n\n\n\nGoal: scatterplot = a plot with points\n\nggplot() + geom_point()\n\n\n\nWhat does R need to know?\n\ndata source: data = Births78\naesthetics: aes(x = date, y = births)\n\n\nHow can we make the plot?\n\n\n\n\n\n\n\n\nWhat has changed?\n\nnew aesthetic: mapping color to day of week\nAdding day of week to the data set\n\nggplot(data = Births78) +\n  geom_point(aes(x = date, y = births, color = wday)) +\n  ggtitle(\"US Births in 1978\")\n\n\n\n\n\n\n\nHow can we make the plot?\n\n\n\n\n\n\n\n\nNow we use lines instead of dots\n\nggplot(data = Births78) +\n  geom_line(aes(x = date, y = births, color = wday)) +\n  ggtitle(\"US Births in 1978\")\n\nHow can we make the plot?\n\n\n\n\n\n\n\n\nNow we have two layers, one with points and one with lines\n\nggplot(data = Births78, \n       aes(x = date, y = births, color = wday)) + \n  geom_point() +  \n  geom_line() +\n  ggtitle(\"US Births in 1978\")\n\n\nThe layers are placed one on top of the other: the points are below and the lines are above.\ndata and aes specified in ggplot() affect all geoms\nAlternative Syntax\n\nggplot(data = Births78,\n         aes(x = date, y = births, color = wday)) + \n  geom_point() + \n  geom_line() +\n  ggtitle(\"US Births in 1978\")\n\n\n\n\n\n\n\nWhat does adding the color argument do?\n\nggplot(data = Births78, \n       aes(x = date, y = births, color = \"navy\")) + \n  geom_point()  +\n  ggtitle(\"US Births in 1978\")\n\n\n\n\n\n\n\n\n\nBecause there is no variable, we have mapped the color aesthetic to a new variable with only one value (“navy”). So all the dots get set to the same color, but it’s not navy.\nSetting vs. Mapping\nIf we want to set the color to be navy for all of the dots, we do it outside the aesthetic, without a dataset variable:\n\nggplot(data = Births78, \n       aes(x = date, y = births)) +   # map x & y \n  geom_point(color = \"navy\")   +     # set color\n  ggtitle(\"US Births in 1978\")\n\n\n\n\n\n\n\n\nNote that color = \"navy\" is now outside of the aesthetics list. That’s how ggplot2 distinguishes between mapping and setting.\nHow can we make the plot?\n\n\n\n\n\n\n\n\n\nggplot(data = Births78, \n       aes(x = date, y = births)) + \n  geom_line(aes(color = wday)) +       # map color here\n  geom_point(color = \"navy\") +          # set color here\n  ggtitle(\"US Births in 1978\")\n\n\nggplot() establishes the default data and aesthetics for the geoms, but each geom may change the defaults.\ngood practice: put into ggplot() the things that affect all (or most) of the layers; rest in geom_blah()\nSetting vs. Mapping (again)\nInformation gets passed to the plot via:\n\nmap the variable information inside the aes (aesthetic) command\nset the non-variable information outside the aes (aesthetic) command\nOther geoms\n\napropos(\"^geom_\")\n\n [1] \"geom_abline\"            \"geom_area\"              \"geom_ash\"              \n [4] \"geom_bar\"               \"geom_bin_2d\"            \"geom_bin2d\"            \n [7] \"geom_blank\"             \"geom_boxplot\"           \"geom_col\"              \n[10] \"geom_contour\"           \"geom_contour_filled\"    \"geom_count\"            \n[13] \"geom_crossbar\"          \"geom_curve\"             \"geom_density\"          \n[16] \"geom_density_2d\"        \"geom_density_2d_filled\" \"geom_density2d\"        \n[19] \"geom_density2d_filled\"  \"geom_dotplot\"           \"geom_errorbar\"         \n[22] \"geom_errorbarh\"         \"geom_freqpoly\"          \"geom_function\"         \n[25] \"geom_hex\"               \"geom_histogram\"         \"geom_hline\"            \n[28] \"geom_jitter\"            \"geom_label\"             \"geom_line\"             \n[31] \"geom_linerange\"         \"geom_lm\"                \"geom_map\"              \n[34] \"geom_path\"              \"geom_point\"             \"geom_pointrange\"       \n[37] \"geom_polygon\"           \"geom_qq\"                \"geom_qq_line\"          \n[40] \"geom_quantile\"          \"geom_raster\"            \"geom_rect\"             \n[43] \"geom_ribbon\"            \"geom_rug\"               \"geom_segment\"          \n[46] \"geom_sf\"                \"geom_sf_label\"          \"geom_sf_text\"          \n[49] \"geom_smooth\"            \"geom_spline\"            \"geom_spoke\"            \n[52] \"geom_step\"              \"geom_text\"              \"geom_tile\"             \n[55] \"geom_violin\"            \"geom_vline\"            \n\n\nhelp pages will tell you their aesthetics, default stats, etc.\n\n?geom_area             # for example\n\nLet’s try geom_area\n\n\nggplot(data = Births78, \n       aes(x = date, y = births, fill = wday)) + \n  geom_area() +\n  ggtitle(\"US Births in 1978\")\n\n\n\n\n\n\n\nUsing area does not produce a good plot\n\nover plotting is hiding much of the data\nextending y-axis to 0 may or may not be desirable.\nSide note: what makes a plot good?\nMost (all?) graphics are intended to help us make comparisons\n\nHow does something change over time?\nDo my treatments matter? How much?\nDo men and women respond the same way?\n\nKey plot metric: Does my plot make the comparisons I am interested in\n\neasily, and\naccurately?\nTime for some different data\nHELPrct: Health Evaluation and Linkage to Primary care randomized clinical trial\n\nhead(HELPrct) \n\n\n\n\n\n\n\n\nage\nanysubstatus\nanysub\ncesd\nd1\ndaysanysub\ndayslink\ndrugrisk\ne2b\nfemale\nsex\ng1b\nhomeless\ni1\ni2\nid\nindtot\nlinkstatus\nlink\nmcs\npcs\npss_fr\nracegrp\nsatreat\nsexrisk\nsubstance\ntreat\navg_drinks\nmax_drinks\nhospitalizations\n\n\n\n37\n1\nyes\n49\n3\n177\n225\n0\nNA\n0\nmale\nyes\nhoused\n13\n26\n1\n39\n1\nyes\n25.111990\n58.41369\n0\nblack\nno\n4\ncocaine\nyes\n13\n26\n3\n\n\n37\n1\nyes\n30\n22\n2\nNA\n0\nNA\n0\nmale\nyes\nhomeless\n56\n62\n2\n43\nNA\nNA\n26.670307\n36.03694\n1\nwhite\nno\n7\nalcohol\nyes\n56\n62\n22\n\n\n26\n1\nyes\n39\n0\n3\n365\n20\nNA\n0\nmale\nno\nhoused\n0\n0\n3\n41\n0\nno\n6.762923\n74.80633\n13\nblack\nno\n2\nheroin\nno\n0\n0\n0\n\n\n39\n1\nyes\n15\n2\n189\n343\n0\n1\n1\nfemale\nno\nhoused\n5\n5\n4\n28\n0\nno\n43.967880\n61.93168\n11\nwhite\nyes\n4\nheroin\nno\n5\n5\n2\n\n\n32\n1\nyes\n39\n12\n2\n57\n0\n1\n0\nmale\nno\nhomeless\n10\n13\n5\n38\n1\nyes\n21.675755\n37.34558\n10\nblack\nno\n6\ncocaine\nno\n10\n13\n12\n\n\n47\n1\nyes\n6\n1\n31\n365\n0\nNA\n1\nfemale\nno\nhoused\n4\n4\n6\n29\n0\nno\n55.508991\n46.47521\n5\nblack\nno\n5\ncocaine\nyes\n4\n4\n1\n\n\n\n\n\n\n\nSubjects admitted for treatment for addiction to one of three substances.\nWho are the people in the study?\n\nggplot(data = HELPrct,\n       aes(x = substance)) + \n  geom_bar() +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\n\nHmm. What’s up with y?\n\n\nstat_bin() is being applied to the data before the geom_bar() gets to do its thing. Binning creates the y values.\n\n\nWho are the people in the study?\n\nggplot(data = HELPrct,\n       aes(x = substance, fill = sex)) + \n  geom_bar() +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nWho are the people in the study?\n\nlibrary(scales)\nggplot(data = HELPrct,\n       aes(x = substance, fill = sex)) + \n  geom_bar() +\n  scale_y_continuous(labels = percent) +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nWho are the people in the study?\n\nggplot(data = HELPrct,\n       aes(x = substance, fill = sex)) + \n  geom_bar(position=\"fill\") +\n  scale_y_continuous(\"actually, percent\") +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nHow old are people in the HELP study?\n\nggplot(data = HELPrct,\n       aes(x = age)) + \n  geom_histogram() +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nNotice the messages\n\nstat_bin: Histograms are not mapping the raw data but binned data.stat_bin() performs the data transformation.\nbinwidth: a default binwidth has been selected, but we should really choose our own.\nSetting the binwidth manually\n\nggplot(data = HELPrct,\n       aes(x = age)) + \n  geom_histogram(binwidth = 2) +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nHow old are people in the HELP study? – Other geoms\n\nggplot(data = HELPrct,\n       aes(x = age)) + \n  geom_freqpoly(binwidth = 2) +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\nggplot(data = HELPrct,\n       aes(x = age)) + \n  geom_density() +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nSelecting stat and geom manually\nEvery geom comes with a default stat\n\nfor simple cases, the stat is stat_identity() which does nothing\nwe can mix and match geoms and stats however we like\n\n\nggplot(data = HELPrct,\n       aes(x = age)) + \n  geom_line(stat = \"density\") +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nSelecting stat and geom manually\nEvery stat comes with a default geom, every geom with a default stat\n\nwe can specify stats instead of geom, if we prefer\nwe can mix and match geoms and stats however we like\n\n\nggplot(data = HELPrct,\n       aes(x = age)) + \n  stat_density(geom = \"line\") +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nMore combinations\n\nggplot(data = HELPrct,\n       aes(x = age)) + \n  geom_point(stat = \"bin\", binwidth = 3) + \n  geom_line(stat = \"bin\", binwidth = 3)  +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\nggplot(data = HELPrct,\n       aes(x = age)) + \n  geom_area(stat = \"bin\", binwidth = 3) +\n  ggtitle(\"HELP clinical trial at detoxification unit\") \n\n\n\n\n\n\n\n\nggplot(data = HELPrct,\n       aes(x = age)) + \n  geom_point(stat = \"bin\", binwidth = 3, \n             aes(size=..count..)) +\n  geom_line(stat = \"bin\", binwidth = 3) +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nHow much do they drink? (i1)\n\nggplot(data = HELPrct,\n       aes(x = i1)) + geom_histogram() +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\nggplot(data = HELPrct,\n       aes(x = i1)) + \n  geom_density() +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\nggplot(data = HELPrct,\n       aes(x = i1)) + \n  geom_area(stat = \"density\") +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nCovariates: Adding in more variables\nUsing color and linetype:\n\nggplot(data = HELPrct,\n       aes(x = i1, color = substance, linetype = sex)) + \n  geom_line(stat = \"density\") +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nUsing color and facets\n\nggplot(data = HELPrct,\n       aes(x = i1, color = substance)) + \n  geom_line(stat = \"density\") + \n  facet_grid( . ~ sex ) +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\nggplot(data = HELPrct,\n       aes(x = i1, color = substance)) + \n  geom_line(stat = \"density\") + \n  facet_grid( sex ~ . ) +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nBoxplots\nBoxplots use stat_quantile() which computes a five-number summary (roughly the five quartiles of the data) and uses them to define a “box” and “whiskers”.\nThe quantitative variable must be y, and there must be an additional x variable.\n\nggplot(data = HELPrct,\n       aes(x = substance, y = age, color = sex)) + \n  geom_boxplot() +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nHorizontal boxplots\nHorizontal boxplots are obtained by flipping the coordinate system:\n\nggplot(data = HELPrct,\n       aes(x = substance, y = age, color = sex)) + \n  geom_boxplot() +\n  coord_flip() +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\n\ncoord_flip() may be used with other plots as well to reverse the roles of x and y on the plot.\nAxes scaling with boxplots\nWe can scale the continuous axis\n\nggplot(data = HELPrct,\n       aes(x = substance, y = age, color = sex)) + \n  geom_boxplot() +\n  coord_trans(y = \"log\") +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nGive me some space\nWe’ve triggered a new feature: dodge (for dodging things left/right). We can control how much if we set the dodge manually.\n\nggplot(data = HELPrct,\n       aes(x = substance, y = age, color = sex)) + \n  geom_boxplot(position = position_dodge(width = 1)) +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nIssues with bigger data\n\nrequire(NHANES)\ndim(NHANES)\n\n[1] 10000    76\n\nggplot(data = NHANES,\n       aes(x = Height, y = Weight)) +\n  geom_point() + \n  facet_grid( Gender ~ PregnantNow ) +\n  ggtitle(\"National Health and Nutrition Examination Survey\")\n\n\n\n\n\n\n\n\nAlthough we can see a generally positive association (as we would expect), the over plotting may be hiding information.\nUsing alpha (opacity)\nOne way to deal with over plotting is to set the opacity low.\n\nggplot(data = NHANES,\n       aes(x = Height, y = Weight)) +\n  geom_point(alpha = 0.01) + \n  facet_grid( Gender ~ PregnantNow ) +\n  ggtitle(\"National Health and Nutrition Examination Survey\")\n\n\n\n\n\n\n\ngeom_density2d\nAlternatively (or simultaneously) we might prefer a different geom altogether.\n\nggplot(data = NHANES,\n       aes(x = Height, y = Weight)) +\n  geom_density2d() + \n  facet_grid( Gender ~ PregnantNow ) +\n  ggtitle(\"National Health and Nutrition Examination Survey\")\n\n\n\n\n\n\n\nMultiple layers\n\nggplot(data = HELPrct, \n       aes(x = sex, y = age)) +\n  geom_boxplot(outlier.size = 0) +\n  geom_jitter(alpha = .6, width = 0.2) + \n  coord_flip() +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nMultiple layers\n\nggplot(data = HELPrct, \n       aes(x = sex, y = age)) +\n  geom_boxplot(outlier.size = 0) +\n  geom_point(alpha = .6, \n             position = position_jitter(width = .1, height = 0)) +\n  coord_flip() +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nThings I haven’t mentioned (much)\n\ncoords (coord_flip() is good to know about)\nthemes (for customizing appearance)\nposition (position_dodge(), position_jitterdodge(), position_stack(), etc.)\ntransforming axes\n\n\nrequire(ggthemes)\nggplot(Births78, \n       aes(x = date, y = births)) + \n  geom_point() + \n  theme_wsj()\n\n\n\n\n\n\n\n\nggplot(data = HELPrct, \n       aes(x = substance, y = age, color = sex)) +\n  geom_boxplot(coef = 10, position = position_dodge()) +\n  geom_point(aes(color = sex, fill = sex), \n             position = position_jitterdodge()) +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nA little bit of everything\n\nggplot(data = HELPrct, \n       aes(x = substance, y = age, color = sex)) +\n  geom_boxplot(coef = 10, \n               position = position_dodge(width = 1)) +\n  geom_point(aes(fill = sex), alpha = .5, \n             position = position_jitterdodge(dodge.width = 1)) + \n  facet_wrap(~homeless) +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nWhat else can we do?\nshiny\n\ninteractive graphics / modeling\nhttps://shiny.posit.co/\n\nplotly\n\nPlotly is an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js. The plotly R library contains the ggplotly function , which will convert ggplot2 figures into a Plotly object. Furthermore, you have the option of manipulating the Plotly object with the style function.\n\n\nhttps://plot.ly/ggplot2/getting-started/\n\nDynamic documents\n\ncombination of Quarto, ggvis, and shiny",
    "crumbs": [
      "Data visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ggplot</span>"
    ]
  },
  {
    "objectID": "11-ggplot.html#reflection-questions",
    "href": "11-ggplot.html#reflection-questions",
    "title": "11  ggplot",
    "section": "\n11.2  Reflection questions",
    "text": "11.2  Reflection questions\n\nWhat do you want R to do? What does R need to know in order to do that thing?\nHow can you break down a plot into visual cues? What are the visual cues?\nWhich visual cues are most accurate? Does that mean only such cues should be used?\nDoes the order of layers in a ggplot matter? When does it change the plot and when does it not change the plot?",
    "crumbs": [
      "Data visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ggplot</span>"
    ]
  },
  {
    "objectID": "11-ggplot.html#ethics-considerations",
    "href": "11-ggplot.html#ethics-considerations",
    "title": "11  ggplot",
    "section": "\n11.3  Ethics considerations",
    "text": "11.3  Ethics considerations\n\nWhy might you want to avoid overplotting?\n\n\n\n\n\n\nBaumer, Ben, Daniel Kaplan, and Nicholas Horton. 2021. Modern Data Science with r. CRC Press. https://mdsr-book.github.io/mdsr2e/.\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal of Statistical Software 59 (10). http://www.jstatsoft.org/v59/i10/paper.\n\n\nYau, Nathan. 2013. Data Points: Visualization That Means Something. Wiley.",
    "crumbs": [
      "Data visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ggplot</span>"
    ]
  },
  {
    "objectID": "10-grammar-graphics.html",
    "href": "10-grammar-graphics.html",
    "title": "10  Graphics",
    "section": "",
    "text": "10.1 Examples\nThe first two examples are taken from a book by Edward Tufte who is arguably a master at visualizations. The book is Visual and Statistical Thinking: Displays of Evidence for Making decisions. The book can be purchased at http://www.edwardtufte.com/tufte/books_textb, though there may be online versions of it that you can download.",
    "crumbs": [
      "Data visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Graphics</span>"
    ]
  },
  {
    "objectID": "10-grammar-graphics.html#examples",
    "href": "10-grammar-graphics.html#examples",
    "title": "10  Graphics",
    "section": "",
    "text": "An aside\nGenerally, the better your graphics are, the better able you will be to communicate ideas broadly (that’s how you become rich and famous). By graphics I mean not only figures associated with analyses, but also power point presentations, posters, and information on your website provided for other scientists who might be interested in your work. Tufte is a master at understanding how to convey information visually, and I strongly recommend you look at his work. Start with Wikipedia where some of his main ideas are provided (e.g., “data-ink ratio”) and then check out his incredible texts. I have many of them in my office and am happy to let you peruse them. http://www.edwardtufte.com/tufte/books_vdqi\nAs mentioned in the booklet we are using, there are two main motivational steps to working with graphics as part of an argument (Tufte 1997).\n\n“An essential analytic task in making decisions based on evidence is to understand how things work.”\nMaking decisions based on evidence requires the appropriate display of that evidence.”\n\nBack to the examples…\n\n10.1.1 Cholera via Tufte\nIn September 1854, the worst outbreak of cholera in London occurred in a few block radius - within 10 days, there were more than 500 fatalities. John Snow recognized the clumping of deaths, and hypothesized that they were due to contamination of the Broad Street water pump. Despite testing the water from the pump and finding no suspicious impurities, he did notice that the water quality varies from data to day. More importantly, there seemed to be no other possible causal mechanism for the outbreak. Eight days after the outbreak began, Snow described his findings to the authorities, and the Board of Guardians of St. James’s Parish ordered the Broad Street pump handle removed. The epidemic ended soon after.\nWhy was John Snow successful at solving the problem? Some thoughts to consider (as reported in Tufte (1997)):\n\nThe bacterium Vibrio cholerae was not discovered until 1886, however Snow had myriad experience both as a medical doctor and in looking at patterns of of other outbreaks. He was the first to realized that cholera was transmitted through water instead of by air or other means.\nData in Context Snow thought carefully about how to present the data. Instead of simply looking at the data as counts or frequencies, he looked at the death spatially - on a map of the area.\nComparisons In order to isolate the pump as the cause of the outbreak, Snow needed to understand how the individuals who had died were different than the individuals who had survived. Snow found two other groups of individuals (brewers who drank only beer, and employees at a work house who had an on-site pump) who had not succumbed to the disease.\nAlternatives Whenever a theory is present, it is vitally important to contrast the theory against all possible alternative possibilities. In Snow’s case, he needed to consider all individuals who did not regularly use the Broad Street pump - he was able to understand the exceptions in every case.\nDid removing the pump handle really cause the outbreak to cease? Wasn’t it already on the decline?\nAssessment of the Graphic Did the individuals die at the place on the map? Live at the place on the map? Which (types of) individuals were missing from the graph? Missing at random? What decisions did he make in creating the graph (axes, binning of histogram bars, time over which data are plotted, etc.) that change the story needing to be told?\n\n10.1.2 Challenger via Tufte\nJohn Snow’s story of the successful graphical intervention in the cholera outbreak is contrasted with the fateful poor-graphical non-intervention of the Challenger disaster. On January 28, 1986, the space shuttle Challenger took off from Cape Canaveral, FL and immediately exploded, killing all seven astronauts aboard. We now know that the reason for the explosion was due to the failure of two rubber O-rings which malfunctioned due to the cold temperature of the day (\\(\\sim 29^\\circ\\) F).\nUnlike the cholera epidemic, those who understood the liability of a shuttle launch under cold conditions were unable to convince the powers that be to postpone the launch (there was much political momentum going forward to get the shuttle off the ground, including the first teacher in space, Christa McAuliffe). As seen in the Tufte chapter, the evidence was clear but not communicated!\nThe biggest problem (existing in many of the bullet points below) is that the engineers failed to as the important question about the data: in relation to what??\n\n\nThe engineers who understood the problem created tables and engineering graphs which were\n\nNot visually appealing.\nNot decipherable to the layman (e.g., “At about \\(50^\\circ\\) F blow-by could be experienced in case joints”)\nThere was also no authorship (reproducibility!). Figures should always have both accountability and reproducibility.\n\n\n\nThe information provided included very relevant points (about temperature) and superfluous information unrelated to temperature. The univariate analysis was insufficient because the story the data were trying to tell was about the bivariate relationship between temperature and o-ring failure.\nMissing data created an illusion of lack of evidence, when in fact, the true story was quite strong given the full set of information. (92% of the temperature data was missing from some of the most vital tables.)\nAnecdotal evidence was misconstrued: SRM-15 at 57F had the most damage, but SRM-22 at 75F had the second most damage.\nIn the end, the shuttle launched on a day which was an extrapolation from the model suggested by the data. They had never launched a shuttle at temperatures of \\(26^\\circ-29^\\circ\\)F.\nTufte goes on to describe many ways which the final presentation by the engineers to the administrators was inadequate: disappearing legend (labels), chartjunk, lack of clarity depicting cause and effect, and wrong order.\n\nAs with the cholera outbreak, a persuasive argument could have been made if the visualizations had\n\nbeen in context plot data versus temperature not time!,\nused appropriate comparisons: as compared with what?,\nconsider alternative scenarios when else did O-rings fail? What is the science behind O-ring failure?, and\nthe graphics had been assessed what is all of the extra noise? are the words being used accessible to non-engineers?.\n\nTufte (Tufte 1997) created the graphic below which should have been used before the launch to convince others to postpone. As you can see, the graphic is extremely convincing. An aside: the O-ring data are well suited for an analysis using logistic regression. Today, most scientists believe that the temperature caused the O-ring failure, however, the data do not speak to the causal relationship because they were not collected using a randomized experiment. That is, there could have been other confounding variables (e.g., humidity) which were possible causal mechanisms.\n\n\n\n\n\n\n\nThe graphic the engineers should have led with in trying to persuade the administrators not to launch. It is evident that the number of O-ring failures is quite highly associated with the ambient temperature. Note the vital information on the x-axis associated with the large number of launches at warm temperatures that had zero O-ring failures. (Tufte 1997)",
    "crumbs": [
      "Data visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Graphics</span>"
    ]
  },
  {
    "objectID": "10-grammar-graphics.html#thoughts",
    "href": "10-grammar-graphics.html#thoughts",
    "title": "10  Graphics",
    "section": "\n10.2 Thoughts on Plotting",
    "text": "10.2 Thoughts on Plotting\n\n10.2.1 Advice\n\nThink carefully about the basic plot\n\nAvoid having other graph elements interfere with data\nUse visually prominent symbols\nAvoid over-plotting (One way to avoid over plotting: Jitter the values)\nDifferent values of data may obscure each other\nInclude all or nearly all of the data\nFill data region\n\n\nEliminate superfluous material\n\nChart junk & stuff that adds no meaning, e.g. butterflies on top of barplots, background images\nExtra tick marks and grid lines\nUnnecessary text and arrows\nDecimal places beyond the measurement error or the level of difference\n\n\nFacilitate Comparisons\n\nPut juxtaposed plots on same scale\nMake it easy to distinguish elements of superposed plots (e.g. color)\nEmphasizes the important difference\nComparison: volume, area, height (be careful, volume can seem bigger than you mean it to)\n\n\nChoose the scale well (n.b., some of the principles may go counter to one another, use your judgment.)\n\nKeep scales on x and y axes the same for both plots to facilitate the comparison\nZoom in to focus on the region that contains the bulk of the data\nKeep the scale the same throughout the plot (i.e. don’t change it mid-axis)\nOrigin need not be on the scale\nChoose a scale that improves resolution\nAvoid jiggling the baseline\n\n\nHow to make a plot information rich\n\nDescribe what you see in the caption\nAdd context with reference markers (lines and points) including text\nAdd legends and labels\nUse color and plotting symbols to add more information\nPlot the same thing more than once in different ways/scales\nReduce clutter\n\n\nCreate good captions\n\nBe comprehensive\nSelf-contained\nDescribe what has been graphed\nDraw attention to important features\nDescribe conclusions drawn from graph\n\n\nFollow good plot making practice\n\nPut major conclusions in graphical form\nProvide reference information\nProof read for clarity and consistency\nGraphing is an iterative process\nMultiplicity is OK, i.e. two plots of the same variable may provide different messages\nMake plots data rich\n\n\n\nCreating a statistical graphic is an iterative process of discovery and fine tuning. We try to model the process of creating visualizations in the course by dedicating class time to an iterative creation of a plot. We begin either with a plot that screams for correction, and we transform it step-by-step, always thinking about the goal of a graph that is data rich and presents a clear vision of the important features of the data.\n\n10.2.2 An example from Information is Beautiful\nConsider the plot at http://www.informationisbeautiful.net/visualizations/caffeine-and-calories/. Note that the origin is at the point (150,150). While we can get over the hurdle, it is not what is expected when looking at a graph.\n\n\n\n\n\n\n\nhttp://infobeautiful3.s3.amazonaws.com/2013/01/1276_buzz_v_bulge.png\n\n\n\nI have removed the vertical and horizontal lines which detracted from the idea of an origin. I have also added additional information (color) to describe the chain from which the drink comes from. Notice that an additional difference between my plot and the original plot is that I have many more observations.\n\n\n\n\n\n\n\nCalories and Caffeine for drinks from various drinks and other items. Data source is: World Cancer Research Fund, Starbucks Beverage Nutrition Guide, Calorie Counter Database. Seemingly, the observational units (rows) are not a random sample of anything. As such, we should be careful of summarizing the data in any way - what would the ‘average’ calories even mean? Note, from the entire dataset give, the average calories is 179.8 and the average caffeine is 134.43. How do those numbers compare to the original plot?\n\n\n\nData retrieved from: https://docs.google.com/spreadsheets/d/1KYMUjrCulPtpUHwep9bVvsBvmVsDEbucdyRZ5uHCDxw/edit?hl=en_GB#gid=0\n\n10.2.2.1 Fonts Matter\nAt RStudio::conf 2020, The Glamour of Graphics, Will Chase makes some very important points about how and why making good graphics matters. The talk might be summarized by the plot below: fonts matter.\n\n\n\n\n\n\n\n\n\n10.2.3 Assessing Graphics (and Other Analyses)\n\n\n\n\n\n\n\n\nCritical Task\nNeeds Improvement\nBasic\nSurpassed\n\n\n\n\nComputation Perform computations\nComputations contain errors and extraneous code\nComputations are correct but contain extraneous / unnecessary computations\nComputations are correct and properly identified and labeled\n\n\n\nAnalysis Choose and carry out analysis appropriate for data and content(s)\nChoice of analysis is overly simplistic, irrelevant, or missing key component\nAnalysis appropriate, but incomplete, or not important features and assumptions not made explicit\nAnalysis appropriate, complete, advanced, relevant, and informative\n\n\n\nSynthesis Identify key features of the analysis, and interpret results (including context)\nConclusions are missing, incorrect, or not made based on results of analysis\nConclusions reasonable, but is partially correct or partially complete\nMake relevant conclusions explicitly connect to analysis and to context\n\n\n\nVisual presentation Communicate findings graphically clearly, precisely, and concisely\nInappropriate choice of plots; poorly labeled plots; plots missing\nPlots convey information correctly but lack context for interpretation\nPlots convey information correctly with adequate / appropriate reference information\n\n\n\nWritten Communicate findings clearly, precisely, and concisely\nExplanation is illogical, incorrect, or incoherent\nExplanation is partially correct but incomplete or unconvincing\nExplanation is correct, complete, and convincing\n\n\n\nA rubric for assessing analysis and corresponding visualization. Note that there can be a large amount of information gained in moving from basic competency to surpassed competency. Table taken from Nolan and Perrett (2016).",
    "crumbs": [
      "Data visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Graphics</span>"
    ]
  },
  {
    "objectID": "10-grammar-graphics.html#deconstruct",
    "href": "10-grammar-graphics.html#deconstruct",
    "title": "10  Grammar of graphics",
    "section": "\n10.3 Deconstructing a graph",
    "text": "10.3 Deconstructing a graph\n\n10.3.1 The Grammar of Graphics (gg)\nYau (2013) and Wickham (2014) have come up with a taxonomy and a grammar for thinking about the parts of a figure just like we conceptualize the parts of a body or the parts of a sentence.\nOne great way of thinking of the new process: it is not longer necessary to talk about the name of the graph (e.g., boxplot). Instead we now think in glyphs (geoms), and so we can put whatever we want on the plot. Note also that the transition leads you from a passive consumer (I need to make plot XXX because everyone else does, so I just plug in the data) into an active participant (what do I want my data to say? and how can I put that information onto my graphic?)\nThe most important questions you can ask with respect to creating figures are:\n\nWhat do we want R to do? (What is the goal?)\nWhat does R need to know?\n\nYau (2013) gives us nine visual cues, and Wickham (2014) translates them into a language using ggplot2. (The items below are from Baumer, Kaplan, and Horton (2021), chapter 2.)\n\nVisual Cues: the aspects of the figure where we should focus.Position (numerical) where in relation to other things?Length (numerical) how big (in one dimension)?Angle (numerical) how wide? parallel to something else?Direction (numerical) at what slope? In a time series, going up or down?Shape (categorical) belonging to what group?Area (numerical) how big (in two dimensions)? Beware of improper scaling!Volume (numerical) how big (in three dimensions)? Beware of improper scaling!Shade (either) to what extent? how severely?Color (either) to what extent? how severely? Beware of red/green color blindness.\nCoordinate System: rectangular, polar, geographic, etc.\nScale: numeric (linear? logarithmic?), categorical (ordered?), time\nContext: in comparison to what (think back to ideas from Tufte)\n\n\n\n\n\n\n\n\n\nOrder Matters\n\n\n\n\n\n\n\n\nCues Together\n\n\n\n\n\n\n\n\nWhat are the visual cues on the plot?\n\n\n\n\n\n\n\n\n\nposition?\nlength?\nshape?\narea/volume?\nshade/color?\ncoordinate System?\n\nscale?\nWhat are the visual cues on the plot?\n\n\n\n\n\n\n\n\n\nposition?\nlength?\nshape?\narea/volume?\nshade/color?\ncoordinate System?\n\nscale?\nWhat are the visual cues on the plot?\n\n\n\n\n\n\n\n\n\nposition?\nlength?\nshape?\narea/volume?\nshade/color?\ncoordinate System?\n\nscale?\n\n10.3.1.1 The grammar of graphics in ggplot2\n\ngeom: the geometric “shape” used to display data\n\nbar, point, line, ribbon, text, etc.\n\naesthetic: an attribute controlling how geom is displayed with respect to variables\n\nx position, y position, color, fill, shape, size, etc.\n\nscale: adjust information in the aesthetic to map onto the plot\n\n\nparticular assignment of colors, shapes, sizes, etc.; making axes continuous or constrained to a particular range of values.\n\nguide: helps user convert visual data back into raw data (legends, axes)\nstat: a transformation applied to data before geom gets it\n\nexample: histograms work on binned data\n\n10.3.2 ggplot2\n\nIn ggplot2, an aesthetic refers to a mapping between a variable and the information it conveys on the plot. Further information about plotting and visualizing information is given in chapter 2 (Data visualization) of Baumer, Kaplan, and Horton (2021). Much of the data in the presentation represents all births from 1978 in the US: the date, the day of the year, and the number of births.\n\nGoals\nWhat I will try to do\n\ngive a tour of ggplot2\nexplain how to think about plots the ggplot2 way\nprepare/encourage you to learn more later\n\nWhat I can’t do in one session\n\nshow every bell and whistle\nmake you an expert at using ggplot2\nGetting help\n\nOne of the best ways to get started with ggplot is to google what you want to do with the word ggplot. Then look through the images that come up. More often than not, the associated code is there. There are also ggplot galleries of images, one of them is here: https://plot.ly/ggplot2/\nggplot2 cheat sheet: https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf\nLook at the end of the presentation. More help options there.\n\n\n\n\n\n\n\n\n\n\nrequire(mosaic)\nrequire(lubridate) # package for working with dates\ndata(Births78)     # restore fresh version of Births78\nhead(Births78, 3)\n\n        date births wday year month day_of_year day_of_month day_of_week\n1 1978-01-01   7701  Sun 1978     1           1            1           1\n2 1978-01-02   7527  Mon 1978     1           2            2           2\n3 1978-01-03   8825  Tue 1978     1           3            3           3\n\n\nHow can we make the plot?\n\n\n\n\n\n\n\n\nTwo Questions:\n\nWhat do we want R to do? (What is the goal?)\n\nWhat does R need to know?\n\ndata source: Births78\n\naesthetics:\n\ndate -&gt; x\nbirths -&gt; y\npoints (!)\n\n\n\n\n\nGoal: scatterplot = a plot with points\n\nggplot() + geom_point()\n\n\n\nWhat does R need to know?\n\ndata source: data = Births78\naesthetics: aes(x = date, y = births)\n\n\nHow can we make the plot?\n\n\n\n\n\n\n\n\nWhat has changed?\n\nnew aesthetic: mapping color to day of week\nAdding day of week to the data set\nThe wday() function in the lubridate package computes the day of the week from a date.\n\nBirths78 &lt;-  \n  Births78 %&gt;% \n  mutate(wday = lubridate::wday(date, label=TRUE))\n\n\nggplot(data=Births78) +\n  geom_point(aes(x=date, y=births, color=wday))+\n  ggtitle(\"US Births in 1978\")\n\n\n\n\n\n\n\nHow can we make the plot?\n\n\n\n\n\n\n\n\nNow we use lines instead of dots\n\nggplot(data=Births78) +\n  geom_line(aes(x=date, y=births, color=wday)) +\n  ggtitle(\"US Births in 1978\")\n\nHow can we make the plot?\n\n\n\n\n\n\n\n\nNow we have two layers, one with points and one with lines\n\nggplot(data=Births78, \n       aes(x=date, y=births, color=wday)) + \n  geom_point() +  geom_line()+\n  ggtitle(\"US Births in 1978\")\n\n\nThe layers are placed one on top of the other: the points are below and the lines are above.\ndata and aes specified in ggplot() affect all geoms\nAlternative Syntax\n\nBirths78 %&gt;% \n  ggplot(aes(x=date, y=births, color=wday)) + \n  geom_point() + \n  geom_line()+\n  ggtitle(\"US Births in 1978\")\n\n\n\n\n\n\n\nWhat does adding the color argument do?\n\nBirths78 %&gt;%\n  ggplot(aes(x=date, y=births, color=\"navy\")) + \n  geom_point()  +\n  ggtitle(\"US Births in 1978\")\n\n\n\n\n\n\n\n\n\nBecause there is no variable, we have mapped the color aesthetic to a new variable with only one value (“navy”). So all the dots get set to the same color, but it’s not navy.\nSetting vs. Mapping\nIf we want to set the color to be navy for all of the dots, we do it outside the aesthetic, without a dataset variable:\n\nBirths78 %&gt;%\n  ggplot(aes(x=date, y=births)) +   # map x & y \n  geom_point(color = \"navy\")   +     # set color\n  ggtitle(\"US Births in 1978\")\n\n\n\n\n\n\n\n\nNote that color = \"navy\" is now outside of the aesthetics list. That’s how ggplot2 distinguishes between mapping and setting.\nHow can we make the plot?\n\n\n\n\n\n\n\n\n\nBirths78 %&gt;%\n  ggplot(aes(x=date, y=births)) + \n  geom_line(aes(color=wday)) +       # map color here\n  geom_point(color=\"navy\") +          # set color here\n  ggtitle(\"US Births in 1978\")\n\n\nggplot() establishes the default data and aesthetics for the geoms, but each geom may change the defaults.\ngood practice: put into ggplot() the things that affect all (or most) of the layers; rest in geom_blah()\nSetting vs. Mapping (again)\nInformation gets passed to the plot via:\n\nmap the variable information inside the aes (aesthetic) command\nset the non-variable information outside the aes (aesthetic) command\nOther geoms\n\napropos(\"^geom_\")\n\n [1] \"geom_abline\"            \"geom_area\"              \"geom_ash\"              \n [4] \"geom_bar\"               \"geom_bin_2d\"            \"geom_bin2d\"            \n [7] \"geom_blank\"             \"geom_boxplot\"           \"geom_col\"              \n[10] \"geom_contour\"           \"geom_contour_filled\"    \"geom_count\"            \n[13] \"geom_crossbar\"          \"geom_curve\"             \"geom_density\"          \n[16] \"geom_density_2d\"        \"geom_density_2d_filled\" \"geom_density2d\"        \n[19] \"geom_density2d_filled\"  \"geom_dotplot\"           \"geom_errorbar\"         \n[22] \"geom_errorbarh\"         \"geom_freqpoly\"          \"geom_function\"         \n[25] \"geom_hex\"               \"geom_histogram\"         \"geom_hline\"            \n[28] \"geom_jitter\"            \"geom_label\"             \"geom_line\"             \n[31] \"geom_linerange\"         \"geom_lm\"                \"geom_map\"              \n[34] \"geom_path\"              \"geom_point\"             \"geom_pointrange\"       \n[37] \"geom_polygon\"           \"geom_qq\"                \"geom_qq_line\"          \n[40] \"geom_quantile\"          \"geom_raster\"            \"geom_rect\"             \n[43] \"geom_ribbon\"            \"geom_rug\"               \"geom_segment\"          \n[46] \"geom_sf\"                \"geom_sf_label\"          \"geom_sf_text\"          \n[49] \"geom_smooth\"            \"geom_spline\"            \"geom_spoke\"            \n[52] \"geom_step\"              \"geom_text\"              \"geom_tile\"             \n[55] \"geom_violin\"            \"geom_vline\"            \n\n\nhelp pages will tell you their aesthetics, default stats, etc.\n\n?geom_area             # for example\n\nLet’s try geom_area\n\n\nBirths78 %&gt;%\n  ggplot(aes(x=date, y=births, fill=wday)) + \n  geom_area()+\n  ggtitle(\"US Births in 1978\")\n\n\n\n\n\n\n\nUsing area does not produce a good plot\n\nover plotting is hiding much of the data\nextending y-axis to 0 may or may not be desirable.\nSide note: what makes a plot good?\nMost (all?) graphics are intended to help us make comparisons\n\nHow does something change over time?\nDo my treatments matter? How much?\nDo men and women respond the same way?\n\nKey plot metric: Does my plot make the comparisons I am interested in\n\neasily, and\naccurately?\nTime for some different data\nHELPrct: Health Evaluation and Linkage to Primary care randomized clinical trial\n\nhead(HELPrct)\n\n  age anysubstatus anysub cesd d1 daysanysub dayslink drugrisk e2b female\n1  37            1    yes   49  3        177      225        0  NA      0\n2  37            1    yes   30 22          2       NA        0  NA      0\n3  26            1    yes   39  0          3      365       20  NA      0\n4  39            1    yes   15  2        189      343        0   1      1\n5  32            1    yes   39 12          2       57        0   1      0\n6  47            1    yes    6  1         31      365        0  NA      1\n     sex g1b homeless i1 i2 id indtot linkstatus link       mcs      pcs pss_fr\n1   male yes   housed 13 26  1     39          1  yes 25.111990 58.41369      0\n2   male yes homeless 56 62  2     43         NA &lt;NA&gt; 26.670307 36.03694      1\n3   male  no   housed  0  0  3     41          0   no  6.762923 74.80633     13\n4 female  no   housed  5  5  4     28          0   no 43.967880 61.93168     11\n5   male  no homeless 10 13  5     38          1  yes 21.675755 37.34558     10\n6 female  no   housed  4  4  6     29          0   no 55.508991 46.47521      5\n  racegrp satreat sexrisk substance treat avg_drinks max_drinks\n1   black      no       4   cocaine   yes         13         26\n2   white      no       7   alcohol   yes         56         62\n3   black      no       2    heroin    no          0          0\n4   white     yes       4    heroin    no          5          5\n5   black      no       6   cocaine    no         10         13\n6   black      no       5   cocaine   yes          4          4\n  hospitalizations\n1                3\n2               22\n3                0\n4                2\n5               12\n6                1\n\n\nSubjects admitted for treatment for addiction to one of three substances.\nWho are the people in the study?\n\nHELPrct %&gt;% \n  ggplot(aes(x=substance)) + \n  geom_bar()+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\n\nHmm. What’s up with y?\n\n\nstat_bin() is being applied to the data before the geom_bar() gets to do its thing. Binning creates the y values.\n\n\nWho are the people in the study?\n\nHELPrct %&gt;% \n  ggplot(aes(x=substance, fill=sex)) + \n  geom_bar()+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nWho are the people in the study?\n\nlibrary(scales)\nHELPrct %&gt;% \n  ggplot(aes(x=substance, fill=sex)) + \n  geom_bar() +\n  scale_y_continuous(labels = percent)+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nWho are the people in the study?\n\nHELPrct %&gt;% \n  ggplot(aes(x=substance, fill=sex)) + \n  geom_bar(position=\"fill\") +\n  scale_y_continuous(\"actually, percent\")+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nHow old are people in the HELP study?\n\nHELPrct %&gt;% \n  ggplot(aes(x=age)) + \n  geom_histogram()+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nNotice the messages\n\nstat_bin: Histograms are not mapping the raw data but binned data.stat_bin() performs the data transformation.\nbinwidth: a default binwidth has been selected, but we should really choose our own.\nSetting the binwidth manually\n\nHELPrct %&gt;% \n  ggplot(aes(x=age)) + \n  geom_histogram(binwidth=2)+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nHow old are people in the HELP study? – Other geoms\n\nHELPrct %&gt;% \n  ggplot(aes(x=age)) + \n  geom_freqpoly(binwidth=2)+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\nHELPrct %&gt;% \n  ggplot(aes(x=age)) + \n  geom_density()+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nSelecting stat and geom manually\nEvery geom comes with a default stat\n\nfor simple cases, the stat is stat_identity() which does nothing\nwe can mix and match geoms and stats however we like\n\n\nHELPrct %&gt;% \n  ggplot(aes(x=age)) + \n  geom_line(stat=\"density\")+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nSelecting stat and geom manually\nEvery stat comes with a default geom, every geom with a default stat\n\nwe can specify stats instead of geom, if we prefer\nwe can mix and match geoms and stats however we like\n\n\nHELPrct %&gt;% \n  ggplot(aes(x=age)) + \n  stat_density( geom=\"line\")+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nMore combinations\n\nHELPrct %&gt;% \n  ggplot(aes(x=age)) + \n  geom_point(stat=\"bin\", binwidth=3) + \n  geom_line(stat=\"bin\", binwidth=3)  +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\nHELPrct %&gt;% \n  ggplot(aes(x=age)) + \n  geom_area(stat=\"bin\", binwidth=3) +\n  ggtitle(\"HELP clinical trial at detoxification unit\") \n\n\n\n\n\n\n\n\nHELPrct %&gt;% \n  ggplot(aes(x=age)) + \n  geom_point(stat=\"bin\", binwidth=3, aes(size=..count..)) +\n  geom_line(stat=\"bin\", binwidth=3) +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nHow much do they drink? (i1)\n\nHELPrct %&gt;% \n  ggplot(aes(x=i1)) + geom_histogram()+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\nHELPrct %&gt;% \n  ggplot(aes(x=i1)) + geom_density()+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\nHELPrct %&gt;% \n  ggplot(aes(x=i1)) + geom_area(stat=\"density\")+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nCovariates: Adding in more variables\nUsing color and linetype:\n\nHELPrct %&gt;% \n  ggplot(aes(x=i1, color=substance, linetype=sex)) + \n  geom_line(stat=\"density\")+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nUsing color and facets\n\nHELPrct %&gt;% \n  ggplot(aes(x=i1, color=substance)) + \n  geom_line(stat=\"density\") + facet_grid( . ~ sex )+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\nHELPrct %&gt;% \n  ggplot(aes(x=i1, color=substance)) + \n  geom_line(stat=\"density\") + facet_grid( sex ~ . )+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nBoxplots\nBoxplots use stat_quantile() which computes a five-number summary (roughly the five quartiles of the data) and uses them to define a “box” and “whiskers”.\nThe quantitative variable must be y, and there must be an additional x variable.\n\nHELPrct %&gt;% \n  ggplot(aes(x=substance, y=age, color=sex)) + \n  geom_boxplot()+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nHorizontal boxplots\nHorizontal boxplots are obtained by flipping the coordinate system:\n\nHELPrct %&gt;% \n  ggplot(aes(x=substance, y=age, color=sex)) + \n  geom_boxplot() +\n  coord_flip()+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\n\n\ncoord_flip() may be used with other plots as well to reverse the roles of x and y on the plot.\nAxes scaling with boxplots\nWe can scale the continuous axis\n\nHELPrct %&gt;% \n  ggplot(aes(x=substance, y=age, color=sex)) + \n  geom_boxplot() +\n  coord_trans(y=\"log\")+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nGive me some space\nWe’ve triggered a new feature: dodge (for dodging things left/right). We can control how much if we set the dodge manually.\n\nHELPrct %&gt;% \n  ggplot(aes(x=substance, y=age, color=sex)) + \n  geom_boxplot(position=position_dodge(width=1)) +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nIssues with bigger data\n\nrequire(NHANES)\ndim(NHANES)\n\n[1] 10000    76\n\nNHANES %&gt;%  ggplot(aes(x=Height, y=Weight)) +\n  geom_point() + facet_grid( Gender ~ PregnantNow ) +\n  ggtitle(\"National Health and Nutrition Examination Survey\")\n\n\n\n\n\n\n\n\nAlthough we can see a generally positive association (as we would expect), the over plotting may be hiding information.\nUsing alpha (opacity)\nOne way to deal with over plotting is to set the opacity low.\n\nNHANES %&gt;% \n  ggplot(aes(x=Height, y=Weight)) +\n  geom_point(alpha=0.01) + facet_grid( Gender ~ PregnantNow ) +\n  ggtitle(\"National Health and Nutrition Examination Survey\")\n\n\n\n\n\n\n\ngeom_density2d\nAlternatively (or simultaneously) we might prefer a different geom altogether.\n\nNHANES %&gt;% \n  ggplot(aes(x=Height, y=Weight)) +\n  geom_density2d() + facet_grid( Gender ~ PregnantNow ) +\n  ggtitle(\"National Health and Nutrition Examination Survey\")\n\n\n\n\n\n\n\nMultiple layers\n\nggplot( data=HELPrct, aes(x=sex, y=age)) +\n  geom_boxplot(outlier.size=0) +\n  geom_jitter(alpha=.6) +\n  coord_flip()+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nMultiple layers\n\nggplot( data=HELPrct, aes(x=sex, y=age)) +\n  geom_boxplot(outlier.size=0) +\n  geom_point(alpha=.6, position=position_jitter(width=.1, height=0)) +\n  coord_flip()+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nThings I haven’t mentioned (much)\n\ncoords (coord_flip() is good to know about)\nthemes (for customizing appearance)\nposition (position_dodge(), position_jitterdodge(), position_stack(), etc.)\ntransforming axes\n\n\nrequire(ggthemes)\nggplot(Births78, aes(x=date, y=births)) + geom_point() + \n          theme_wsj()\n\n\n\n\n\n\n\n\nggplot(data=HELPrct, aes(x=substance, y=age, color=sex)) +\n  geom_boxplot(coef = 10, position=position_dodge()) +\n  geom_point(aes(color=sex, fill=sex), position=position_jitterdodge()) +\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nA little bit of everything\n\nggplot( data=HELPrct, aes(x=substance, y=age, color=sex)) +\n  geom_boxplot(coef = 10, position=position_dodge(width=1)) +\n  geom_point(aes(fill=sex), alpha=.5, \n             position=position_jitterdodge(dodge.width=1)) + \n  facet_wrap(~homeless)+\n  ggtitle(\"HELP clinical trial at detoxification unit\")\n\n\n\n\n\n\n\nWant to learn more?\n\ndocs.ggplot2.org/\nWinston Chang’s: R Graphics Cookbook\n\n\n\n\n\n\n\n\n\nWhat else can we do?\nshiny\n\ninteractive graphics / modeling\nhttps://shiny.rstudio.com/\n\nplotly\n\nPlotly is an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js. The plotly R library contains the ggplotly function , which will convert ggplot2 figures into a Plotly object. Furthermore, you have the option of manipulating the Plotly object with the style function.\n\n\nhttps://plot.ly/ggplot2/getting-started/\n\nDynamic documents\n\ncombination of quarto, ggvis, and shiny",
    "crumbs": [
      "Data visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Grammar of graphics</span>"
    ]
  },
  {
    "objectID": "10-grammar-graphics.html#reflection-questions",
    "href": "10-grammar-graphics.html#reflection-questions",
    "title": "10  Graphics",
    "section": "\n10.3  Reflection questions",
    "text": "10.3  Reflection questions\n\nWhat different aspects deconstruct a plot?\nProvide some of the guidelines which lead to improved visualizations.\nConsider the comparison of interest, does your plot make that comparison easily and accurately?",
    "crumbs": [
      "Data visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Graphics</span>"
    ]
  },
  {
    "objectID": "10-grammar-graphics.html#ethics-considerations",
    "href": "10-grammar-graphics.html#ethics-considerations",
    "title": "10  Graphics",
    "section": "\n10.4  Ethics considerations",
    "text": "10.4  Ethics considerations\n\nWhat are you trying to communicate with your plot? Is that what your graph communicates?\nDid you add alt text to your images? (see Writing Alt Text for Data Visualizations)\nIs your plot accessible to those who are color blind or looking at the image in black and white?\n\n\n\n\nThe graphic the engineers should have led with in trying to persuade the administrators not to launch. It is evident that the number of O-ring failures is quite highly associated with the ambient temperature. Note the vital information on the x-axis associated with the large number of launches at warm temperatures that had zero O-ring failures. (Tufte 1997)\nhttp://infobeautiful3.s3.amazonaws.com/2013/01/1276_buzz_v_bulge.png\nCalories and Caffeine for drinks from various drinks and other items. Data source is: World Cancer Research Fund, Starbucks Beverage Nutrition Guide, Calorie Counter Database. Seemingly, the observational units (rows) are not a random sample of anything. As such, we should be careful of summarizing the data in any way - what would the ‘average’ calories even mean? Note, from the entire dataset give, the average calories is 179.8 and the average caffeine is 134.43. How do those numbers compare to the original plot?\n\n\n\nGelman, Andrew. 2011. “Rejoinder.” Journal of Computational and Graphical Statistics 20: 36–40. http://arxiv.org/abs/1503.00781.\n\n\nNolan, Deborah, and Jamis Perrett. 2016. “Teaching and Learning Data Visualization: Ideas and Assignments.” The American Statistician.\n\n\nTufte, Edward. 1997. “Visual Explanations: Images and Quantities, Evidence and Narrative.” In, 27–54. Graphics Press, LLC. www.edwardtufte.com.",
    "crumbs": [
      "Data visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Graphics</span>"
    ]
  },
  {
    "objectID": "08-text-analysis.html",
    "href": "08-text-analysis.html",
    "title": "8  Text analysis",
    "section": "",
    "text": "8.1  Reflection questions",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Text analysis</span>"
    ]
  },
  {
    "objectID": "08-text-analysis.html#ethics-considerations",
    "href": "08-text-analysis.html#ethics-considerations",
    "title": "8  Text analysis",
    "section": "\n8.2  Ethics considerations",
    "text": "8.2  Ethics considerations",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Text analysis</span>"
    ]
  },
  {
    "objectID": "06-sql-joins.html",
    "href": "06-sql-joins.html",
    "title": "6  Combining tables in SQL",
    "section": "",
    "text": "6.1 Subqueries\nA SQL subquery is a query used as a data source in the FROM clause, instead of the usual table. There was a subquery in Table 5.6 when the task required a function of the results set within the SELECT clause.\nWe could do something similar if we wanted to transform the variables in the select column. The example is a little bit forced, and there are other ways to obtain the same results. But hopefully the idea of a subquery is becoming more clear. Again, a subquery is just a query that becomes the data source for FROM.\nChapter 9 will cover regular expressions in some detail. Here we use the function REGEXP_REPLACE to remove any characters which are not letters, comma, or space. The function LOWER converts any upper case letters to lower case.\nSELECT name,\n       name_clean,\n       SUBSTRING_INDEX(name_clean, ',', 1) AS last_name,\n       SUBSTRING_INDEX(name_clean, ',', -1) AS first_name\nFROM (\nSELECT LOWER(REGEXP_REPLACE(name, '[^a-z,. ]', '')) AS name_clean,\n       name,\n       id, person_id\nFROM aka_name) AS temp_subquery\nLIMIT 0, 30;\nTable 6.3: A subquery is used so that the variable in the subquery can be used and transformed in the SELECT clause.\n\n\n\n\n\nname\nname_clean\nlast_name\nfirst_name\n\n\n\nSmith, Jessica Noel\nsmith, jessica noel\nsmith\njessica noel\n\n\nPain, L. $ham\npain, l. ham\npain\nl. ham\n\n\nBoy, $hutter\nboy, hutter\nboy\nhutter\n\n\nDollasign, Ty\ndollasign, ty\ndollasign\nty\n\n\nSign, Ty Dolla\nsign, ty dolla\nsign\nty dolla\n\n\nMoore, Brandon\nmoore, brandon\nmoore\nbrandon\n\n\n$torm, Country\ntorm, country\ntorm\ncountry\n\n\n'Hooper', Simon P.J. Kelly\nhooper, simon p.j. kelly\nhooper\nsimon p.j. kelly\n\n\nHooper\nhooper\nhooper\nhooper\n\n\nKelly, Simon P.J.\nkelly, simon p.j.\nkelly\nsimon p.j.\n\n\nAbdul-Hamid, Jaffar\nabdulhamid, jaffar\nabdulhamid\njaffar\n\n\nAl-Hamid, Jaffar Abd\nalhamid, jaffar abd\nalhamid\njaffar abd\n\n\nSvensson, Acke\nsvensson, acke\nsvensson\nacke\n\n\nViera, Michael 'Power'\nviera, michael power\nviera\nmichael power\n\n\nBuguelo\nbuguelo\nbuguelo\nbuguelo\n\n\n'El Burro' Rankin', Jorge Van\nel burro rankin, jorge van\nel burro rankin\njorge van\n\n\nBurro, El\nburro, el\nburro\nel\n\n\nVan Rankin, Jorge 'Burro'\nvan rankin, jorge burro\nvan rankin\njorge burro\n\n\nVan Rankin, Jorge\nvan rankin, jorge\nvan rankin\njorge\n\n\nvan Rankin, Jorge 'El Burro'\nvan rankin, jorge el burro\nvan rankin\njorge el burro\n\n\nSeigal, Jason\nseigal, jason\nseigal\njason\n\n\nKaufman, Murray\nkaufman, murray\nkaufman\nmurray\n\n\n'Knoccout'Madison, Kareim\nknoccoutmadison, kareim\nknoccoutmadison\nkareim\n\n\nStarks, Johnny\nstarks, johnny\nstarks\njohnny\n\n\nKraemer, 'Logan' Howard\nkraemer, logan howard\nkraemer\nlogan howard\n\n\nGee, Emm\ngee, emm\ngee\nemm\n\n\nCusick, Maura\ncusick, maura\ncusick\nmaura\n\n\nMaura, Maude Cusick\nmaura, maude cusick\nmaura\nmaude cusick\n\n\nWheeler, Mackenzie\nwheeler, mackenzie\nwheeler\nmackenzie\n\n\nMonkey\nmonkey\nmonkey\nmonkey",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combining tables in SQL</span>"
    ]
  },
  {
    "objectID": "06-sql-joins.html#all-the-joins",
    "href": "06-sql-joins.html#all-the-joins",
    "title": "6  Combining tables in SQL",
    "section": "\n6.2 All the JOINs",
    "text": "6.2 All the JOINs\nRecall that SQL is a query language that works on relational databases. One of its major strengths is being able to efficiently store information in separate tables that can be easily connected as needed. The syntax for tying together information from multiple tables is done with a JOIN clause.\nEach JOIN clause needs four specific pieces of information:\n\nThe name of the first table you want to JOIN.\nThe type of JOIN being used.\nThe name of the second table you want to JOIN.\nThe condition(s) under which you want the records in the first table to match records in the second table.\n\nSome types of JOINs available in MySQL include the following, which are represented as Venn diagrams in Figure 6.1.\n\n\nJOIN: include all of the rows that exist in both tables (similar to inner_join() in R, the intersection of the two tables). INNER JOIN is alternative, and identical, function to JOIN.\n\nLEFT JOIN: include all of the rows in the first table. Connect them, as much as possible, to the rows in the second table. Rows that have no match in the second table will have a value of NULL for the new “second table” variables.\n\nRIGHT JOIN: include all of the rows in the second table. Connect them, as much as possible, to the rows in the first table. Rows that have no match in the first table will have a value of NULL for the new “first table” variables. A RIGHT JOIN with the tables in the opposite order is the same as a LEFT JOIN with the tables in the original order.\n\nFULL OUTER JOIN: include all rows in either table. Rows that have no match in the other table will have a value of NULL for the other table variables. (similar to full_join() in R, the union of the two tables). The functionality doesn’t exist in MySQL but can be created using joins and UNION.\n\nCROSS JOIN: match each row of the first table with each row in the second table.\n\nFigure 6.1 shows Venn diagrams of the different types of joins. Figure 6.2 shows four of the JOIN functions with mini data tables. Note that in SQL the missing values will be labeled as NULL (not NA).\n\n\n\n\n\n\n\nFigure 6.1: Venn diagrams describing different JOINs, image credit: phoenixNAP https://phoenixnap.com/kb/mysql-join\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.2: Mini data tables describing different JOINs, image credit: Statistics Globe blog, https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti\n\n\n\n\n\n6.2.1 A toy example\nWe will head to R for just a minute so as to understand joins using a small toy dataset on rock bands from the 60s, The Beatles and The Rolling Stones. The function sqldf() in the sqldf R package allows for SQL commands on R objects.\nConsider the following datasets which are available in the dplyr package.\n\nband_members\n\n# A tibble: 3 × 2\n  name  band   \n  &lt;chr&gt; &lt;chr&gt;  \n1 Mick  Stones \n2 John  Beatles\n3 Paul  Beatles\n\nband_instruments\n\n# A tibble: 3 × 2\n  name  plays \n  &lt;chr&gt; &lt;chr&gt; \n1 John  guitar\n2 Paul  bass  \n3 Keith guitar\n\n\nInner join\nAn inner join combines two datasets returning only the observations that exist in both of the original datasets.\n\nsqldf::sqldf(\"SELECT star.name,\n                     star.band,\n                     inst.plays\n              FROM band_members AS star\n              JOIN band_instruments AS inst ON star.name = inst.name\")\n\n  name    band  plays\n1 John Beatles guitar\n2 Paul Beatles   bass\n\n\nFull join\nA full join combines two datasets returning every observation that exists in either one of the original datasets. Note that in the results, Mick’s instrument is missing, and Keith’s band is missing.\nThe full_join() function does not have an equivalent in MySQL. See Section 6.3.1.1 for using JOINs and UNIONs to produce a full join.\n\nband_members |&gt;\n  full_join(band_instruments)\n\n# A tibble: 4 × 3\n  name  band    plays \n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 Mick  Stones  &lt;NA&gt;  \n2 John  Beatles guitar\n3 Paul  Beatles bass  \n4 Keith &lt;NA&gt;    guitar\n\n\nLeft join\nA left join combines two datasets returning every observation that exists in the left (or first) original dataset. Note that in the results, Mick’s instrument is missing.\n\nsqldf::sqldf(\"SELECT star.name,\n                     star.band,\n                      inst.plays\n              FROM band_members AS star\n              LEFT JOIN band_instruments AS inst \n              ON star.name = inst.name\")\n\n  name    band  plays\n1 Mick  Stones   &lt;NA&gt;\n2 John Beatles guitar\n3 Paul Beatles   bass\n\n\nRight join\nA right join combines two datasets returning every observation that exists in the right (or second) original dataset. Note that in the results, Keith’s band is missing.\n\nsqldf::sqldf(\"SELECT inst.name,\n                     star.band,\n                      inst.plays\n              FROM band_members AS star\n              RIGHT JOIN band_instruments AS inst \n              ON star.name = inst.name\")\n\n   name    band  plays\n1  John Beatles guitar\n2  Paul Beatles   bass\n3 Keith    &lt;NA&gt; guitar\n\n\n\n6.2.2 JOIN\n\nIn the imdb database, the title table includes information about the 4,626,322 titles in the database, including the id, title, kind_id (indicator for the kind of ID it is), and production_year. It does not, however, include the review of the title. See Table 6.4.\n\nSELECT * FROM title LIMIT 0, 10;\n\n\n\n\nTable 6.4: SELECT to glance at the title table in the imdb database.\n\n\n\n\n\nid\ntitle\nimdb_index\nkind_id\nproduction_year\nimdb_id\nphonetic_code\nepisode_of_id\nseason_nr\nepisode_nr\nseries_years\nmd5sum\n\n\n\n78460\nAdults Recat to the Simpsons (30th Anniversary)\n\n7\n2017\n\nA3432\n78406\n\n\n\n2ae09eed7d576cc2c24774fed5b18168\n\n\n70273\n(2016-05-18)\n\n7\n2016\n\n\n68058\n\n\n\n511dfc14cfff7589d29a95abb30cd66a\n\n\n60105\n(2014-04-11)\n\n7\n2014\n\n\n59138\n\n\n\nc6cdce7e667e07713e431805c407feed\n\n\n32120\n(2008-05-01)\n\n7\n2008\n\n\n32060\n\n\n\n100df65742caf5afd092b2e0ead67d8e\n\n\n97554\nSchmÃ¶lders Traum\n\n7\n2001\n\nS2543\n97302\n10\n1\n\n46862a2f96f9fb2d59e8c9a11ecfdd28\n\n\n57966\n(#1.1)\n\n7\n2013\n\n\n57965\n1\n1\n\n409c37703766c4b24f8a86162fd9cf85\n\n\n76391\nAnniversary\n\n7\n1971\n\nA5162\n76385\n4\n9\n\n5e12ce73fac1d1dcf94136b6e9acd8f8\n\n\n11952\nAngus Black/Lester Barrie/DC Curry\n\n7\n2009\n\nA5214\n11937\n4\n7\n\n9c38b9e5601dc154444b73b518034aa1\n\n\n1554\nNew Orleans\n\n7\n2003\n\nN6452\n1508\n2\n11\n\n621bea735740a547e862e4a3226f35d2\n\n\n58442\nKiss Me Kate\n\n7\n2011\n\nK2523\n58436\n1\n10\n\n293e8c75c7f35a4035abf617962be5a9\n\n\n\n\n\n\n\n\n\nThe movie_info_idx table does not contain much information about each particular film. It does, however, have an indicator for the movie ID (given by movie_id) as well as the number of votes (given by info where type_id = 100). See Table 6.5.\n\nSELECT * FROM movie_info_idx LIMIT 0, 6;\n\n\n\n\nTable 6.5: SELECT to glance at the movie_info_idx table in the imdb database.\n\n\n\n\n\nid\nmovie_id\ninfo_type_id\ninfo\nnote\n\n\n\n1\n1\n99\n31.2.1..2.\n\n\n\n2\n1\n100\n9\n\n\n\n3\n1\n101\n4.1\n\n\n\n4\n2\n99\n1000000102\n\n\n\n5\n2\n100\n61\n\n\n\n6\n2\n101\n6.4\n\n\n\n\n\n\n\n\n\n\nLet’s say we want to combine the titles with the number of votes so that each title with user votes is included. That is, only keep the titles that have a corresponding votes. And also, only keep the votes if there is an associated title (which means we use INNER JOIN or just plain JOIN).\nRemember that WHERE will work on the raw variables, and HAVING works on the results set.\nSome aspects of the query are worth pointing out:\n* The variables in the output are given in the SELECT clause. The id and title (both from the title table) and the info from the movie_info_idx which represents the number of IMDb votes. * The variables are preceded by the table from which they came. While not always necessary, it is good practice so as to avoid confusion. * The JOIN happens by linking the id variable in the title table with the movie_id variable in the movie_info_idx table. * The LIMIT wasn’t necessary (there are only 12 observations), but it’s good practice so that we don’t end up with unwieldy query results. * The WHERE clause happens before the JOIN action, despite being written after. * In the WHERE clause, we keep only movies, only 2015 production year, and only at least 150,000 votes.\n\nSELECT title.id,\n       title.title,\n       movie_info_idx.info\nFROM title\nJOIN movie_info_idx ON title.id = movie_info_idx.movie_id \nWHERE title.production_year = 2015 \n    AND title.kind_id = 1                  # movies only\n    AND movie_info_idx.info_type_id = 100  # info_type is votes\n    AND movie_info_idx.info &gt; 150000       # at least 150,000 votes\nORDER BY movie_info_idx.info DESC\nLIMIT 0, 20;\n\n\n\n\nTable 6.6: Movies from 2015 that have at least 150,000 votes in the imdb database.\n\n\n\n\n\nid\ntitle\ninfo\n\n\n\n4260166\nStar Wars: Episode VII - The Force Awakens\n691691\n\n\n3915213\nMad Max: Fury Road\n666484\n\n\n4389619\nThe Martian\n583987\n\n\n3313672\nAvengers: Age of Ultron\n540606\n\n\n4414139\nThe Revenant\n526189\n\n\n3787790\nJurassic World\n471237\n\n\n3752999\nInside Out\n443051\n\n\n3292159\nAnt-Man\n390965\n\n\n4364483\nThe Hateful Eight\n363199\n\n\n4251736\nSpectre\n319875\n\n\n3630368\nFurious Seven\n310970\n\n\n4255450\nSpotlight\n290362\n\n\n3961438\nMission: Impossible - Rogue Nation\n266759\n\n\n4321769\nThe Big Short\n262598\n\n\n4221220\nSicario\n260996\n\n\n3600120\nFifty Shades of Grey\n250962\n\n\n4164324\nRoom\n244210\n\n\n3379559\nBridge of Spies\n229440\n\n\n4368666\nThe Hunger Games: Mockingjay - Part 2\n214569\n\n\n4387967\nThe Man from U.N.C.L.E.\n213754\n\n\n\n\n\n\n\n\n\nLet’s say we also want to obtain information about the actors and actresses in each of the movies. In the cast_info table, there is a person_id, a movie_id, and person_role_id is 1 if actor and 2 if actress.\n\nSELECT * FROM cast_info LIMIT 0, 10;\n\n\n\n\nTable 6.7: SELECT to glance at the cast_info table in the imdb database.\n\n\n\n\n\nid\nperson_id\nmovie_id\nperson_role_id\nnote\nnr_order\nrole_id\n\n\n\n1\n1\n3432997\n1\n\n31\n1\n\n\n2\n2\n1901690\n2\n\n\n1\n\n\n3\n3\n4027567\n2\n\n25\n1\n\n\n4\n3\n4282876\n3\n\n22\n1\n\n\n5\n4\n3542672\n\n\n12\n1\n\n\n6\n5\n3331520\n4\n(as $hutter Boy)\n10\n1\n\n\n7\n5\n4027191\n2\n(as $hutter Boy)\n1\n1\n\n\n8\n5\n4195731\n5\n(uncredited)\n\n1\n\n\n9\n5\n4263956\n6\n(uncredited)\n\n1\n\n\n10\n5\n4267787\n7\n(uncredited)\n\n1\n\n\n\n\n\n\n\n\n\nWe also want the name of the actress which is in the table aka_name. Note that there is no movie information in the aka_name table!\n\nSELECT * FROM aka_name LIMIT 0, 10;\n\n\n\n\nTable 6.8: SELECT to glance at the aka_name table in the imdb database.\n\n\n\n\n\nid\nperson_id\nname\nimdb_index\nname_pcode_cf\nname_pcode_nf\nsurname_pcode\nmd5sum\n\n\n\n1\n6188450\nSmith, Jessica Noel\n\nS5325\nJ2542\nS53\n25c9d464e3ff2957533546aa92b397ed\n\n\n2\n5125059\nPain, L. $ham\n\nP545\nL515\nP5\n569b1e885ccb51211c01753f0dad9b2c\n\n\n3\n5\nBoy, $hutter\n\nB36\nH361\nB\n35092b5604ce378fc48c8a6fc0038a49\n\n\n4\n4152053\nDollasign, Ty\n\nD4253\nT3425\nD425\n0f565a2d8027cfb8ed6c5f4bba719fcd\n\n\n5\n4152053\nSign, Ty Dolla\n\nS2534\nT3425\nS25\n2eded1b021b96333b4b74e0fec959650\n\n\n6\n6\nMoore, Brandon\n\nM6165\nB6535\nM6\n193a6f5adf4756320f622162d2475608\n\n\n7\n8\n$torm, Country\n\nT6525\nC5363\nT65\n1654400b707d34323ea392b87060e6cc\n\n\n8\n19\n'Hooper', Simon P.J. Kelly\n\nH1625\nS5124\nH16\n3fd8885372c23f8c74e583da91d1fd05\n\n\n9\n19\nHooper\n\nH16\n\n\n24ddc68ab605ee95857ad45b65ffa2d8\n\n\n10\n19\nKelly, Simon P.J.\n\nK4251\nS5124\nK4\n33d976f22e276b73c61513bc5f6e72a6\n\n\n\n\n\n\n\n\n\nConnecting the most popular movies of 2015 with the actresses in those movies requires a series of JOINs. Note that to make the code less onerous, the title table has been aliased by t, the movie_info_idx table has been aliased by idx, the cast_info table has been aliased by a, and the aka_name table has been aliased by n.\nThere is a lot of data cleaning to do as some of the person_id values are one to many!! That is, the person_id matches multiple names in the aka_name database.\n\nSELECT t.title,\n       idx.info,\n       a.person_id,\n       n.name\nFROM title AS t\nJOIN movie_info_idx AS idx ON t.id = idx.movie_id \nJOIN cast_info AS a ON idx.movie_id = a.movie_id\nJOIN aka_name AS n ON a.person_id = n.person_id\nWHERE t.production_year = 2015 \n    AND t.kind_id = 1           # movies only\n    AND idx.info_type_id = 100  # info_type is votes\n    AND idx.info &gt; 150000       # at least 150,000 votes\n    AND a.role_id = 2           # actresses only\nORDER BY idx.info DESC\nLIMIT 0, 50;\n\n\n\n\nTable 6.9: Movies from 2015 that have at least 150,000 votes in the imdb database with the actress name joined.\n\n\n\n\n\ntitle\ninfo\nperson_id\nname\n\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n2698188\nSam\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n2806101\nGillespie, Hilary Catherine\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n2959609\nCuzner, Natalie\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3089483\nFisher, Carrie Frances\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3150880\nClass, Clare\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3150880\nGlass, Claire\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3231758\nHenwick, Jessica Yu Li\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3265686\nHui, Karen\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3305561\nKamen, Hannah John\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3462940\nBilly\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3462940\nLourd, Billie Catherine\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3569409\nFran\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3649948\nNyongo, Lupita\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3649948\nNyong'o, Lupita Amondi\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3785240\nRidley, Daisy Jazz Isobel\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3835377\nGiagrande, Meredith J.\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3835377\nSalinger, Meredith\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3835377\nSalenger, Meredith Dawn\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3850834\nPhi\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3875581\nFox, Claudia\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3879039\nArti\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3907812\nSlade, Sandy\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3907812\nSandy\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3907812\nSandy Slade\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3938795\nRyan, Karol Lesley\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3970637\nStevens, Cat\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3970637\nTaber, Cat\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3970637\nTabor, Cat\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3970637\nCat\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3970637\nStevens, Cat\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3970637\nTaber, Cat\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3970637\nTabor, Cat\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n3970637\nCat\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n4073883\nWalter, Dame Harriet\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n4073883\nWalter, Harriet Mary\n\n\nStar Wars: Episode VII - The Force Awakens\n691691\n4094732\nWhite, Kelsey Marie\n\n\nMad Max: Fury Road\n666484\n2681098\nMichelle, Debra\n\n\nMad Max: Fury Road\n666484\n2782138\nAli\n\n\nMad Max: Fury Road\n666484\n2873752\nCardona, Helena\n\n\nMad Max: Fury Road\n666484\n2873752\nCardona, Helene\n\n\nMad Max: Fury Road\n666484\n2873752\nCardona, HÃ©lÃ¨ne Vania\n\n\nMad Max: Fury Road\n666484\n2957052\nCunico, Lillie\n\n\nMad Max: Fury Road\n666484\n3087531\nFinlay, Sandi 'Hotrod'\n\n\nMad Max: Fury Road\n666484\n3087531\nFinlay, Sandi 'Hotrod'\n\n\nMad Max: Fury Road\n666484\n3146859\nGilles, Coco Jack\n\n\nMad Max: Fury Road\n666484\n3146859\nGillies, Coco\n\n\nMad Max: Fury Road\n666484\n3268456\nRose\n\n\nMad Max: Fury Road\n666484\n3268456\nHuntington-Whiteley, Rosie Alice\n\n\nMad Max: Fury Road\n666484\n3343489\nKellerman, Antoinette\n\n\nMad Max: Fury Road\n666484\n3348513\nRiley\n\n\n\n\n\n\n\n\n\n\n6.2.3 Other JOINs\nConsider the following two tables. The first has seven movies in it (from 2015 with at least 400,000 IMDb votes). The second consists of almost 3 million actresses (person_role_id = 2). In order to find a subset of actresses, the person_id &gt; 3900000 was set arbitrarily (in order to have a smaller group with which to work).\nmovies:\n\nSELECT t.id,\n       t.title,\n       idx.info,\n       (SELECT COUNT(*)\n       FROM title AS t\n       JOIN movie_info_idx AS idx ON idx.movie_id = t.id\n       WHERE t.production_year = 2015  \n             AND t.kind_id = 1\n             AND idx.info_type_id = 100\n             AND idx.info &gt; 400000) AS row_count\nFROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1             # movies only\n    AND idx.info_type_id = 100    # info_type is votes\n    AND idx.info &gt; 400000         # at least 400,000 votes\nORDER BY idx.info DESC\n\n\n\n\nTable 6.10: Movies from 2015 that have at least 400,000 votes in the imdb database.\n\n\n\n\n\nid\ntitle\ninfo\nrow_count\n\n\n\n4260166\nStar Wars: Episode VII - The Force Awakens\n691691\n7\n\n\n3915213\nMad Max: Fury Road\n666484\n7\n\n\n4389619\nThe Martian\n583987\n7\n\n\n3313672\nAvengers: Age of Ultron\n540606\n7\n\n\n4414139\nThe Revenant\n526189\n7\n\n\n3787790\nJurassic World\n471237\n7\n\n\n3752999\nInside Out\n443051\n7\n\n\n\n\n\n\n\n\n\nactresses:\n\nSELECT a.person_id,\n       a.movie_id,\n       n.name,\n       (SELECT COUNT(*)\n       FROM cast_info AS a\n       JOIN aka_name AS n ON a.person_id = n.person_id\n       WHERE a.person_role_id = 2  \n             AND a.person_id &gt; 390000) AS row_count\nFROM cast_info AS a\nJOIN aka_name AS n ON a.person_id = n.person_id\n       WHERE a.person_role_id = 2  \n             AND a.person_id &gt; 3900000\nLIMIT 0, 20;\n\n\n\n\nTable 6.11: Actresses whose person_id is greater than 400000. Note that some actresses have different spelling or phrasing of their names.\n\n\n\n\n\nperson_id\nmovie_id\nname\nrow_count\n\n\n\n3900141\n759802\nSimons, Rita Joanne\n2904759\n\n\n3902258\n4365829\nSinger, Rabbi Tovia\n2904759\n\n\n3902699\n3109788\nSingh, Sabine Erika\n2904759\n\n\n3903035\n3215866\nVal\n2904759\n\n\n3904831\n2468067\nMasha\n2904759\n\n\n3904928\n3654347\nFei, Siu Yin\n2904759\n\n\n3904928\n3654347\nHsiao, Yen-fei\n2904759\n\n\n3904928\n3654347\nSiu, Yinfei\n2904759\n\n\n3904928\n3654347\nXiao, Yanfei\n2904759\n\n\n3904928\n3654347\nYin-Fai, Siu\n2904759\n\n\n3905289\n115191\nCoso, Cosondra\n2904759\n\n\n3905289\n115191\nSjostrom, Cossondra\n2904759\n\n\n3905289\n115191\nCoso\n2904759\n\n\n3909355\n2939100\nSlovÃ¡ckovÃ¡, Anna Julie\n2904759\n\n\n3911826\n4379610\nMeador, Constance June\n2904759\n\n\n3912134\n2675144\nDJ\n2904759\n\n\n3912134\n2675144\nSmith, DJ\n2904759\n\n\n3912134\n2675144\nSmith, Dujonette\n2904759\n\n\n3912134\n2675144\nDJ Smith\n2904759\n\n\n3913519\n1678444\nKeely, Dorothy Jacqueline\n2904759\n\n\n\n\n\n\n\n\n\nUsing subqueries, we can JOIN the two datasets using different JOIN techniques.\nInner JOIN\n\nWith an inner JOIN, there are 32 rows corresponding to all the actresses in the seven 2015 films with the most votes. Because the JOIN is an intersection of the two tables, only the actresses with person_id above 3900000 are included.\n\n\nSELECT * FROM\n(SELECT t.id,\n       t.title\nFROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               # movies only\n    AND idx.info_type_id = 100      # info_type is votes\n    AND idx.info &gt; 400000) AS movs  # at least 400,000 votes     \nINNER JOIN (SELECT a.person_id,\n       a.movie_id,\n       n.name\n    FROM cast_info AS a\n    JOIN aka_name AS n ON a.person_id = n.person_id\n    WHERE a.role_id = 2             # acresses only\n        AND a.person_id &gt; 3900000) AS acts ON acts.movie_id = movs.id\nLIMIT 0, 300;\n\n\n\n\nTable 6.12: Inner JOIN of movies and actresses.\n\n\n\n\n\n\n\n\n\nRIGHT JOIN\nWith a RIGHT JOIN, there are more than 300 rows (the LIMIT clause keeps us from knowing how many rows, but there are a LOT!) corresponding to all the actresses whose person_id above 3900000 are included. Those actresses who acted in one of the seven top 2015 films are also included in the full results table, but they don’t happen to be in the truncated output here.\n\n\nSELECT * FROM\n(SELECT t.id,\n       t.title\nFROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               # movies only\n    AND idx.info_type_id = 100      # info_type is votes\n    AND idx.info &gt; 400000) AS movs  # at least 400,000 votes     \nRIGHT JOIN (SELECT a.person_id,\n       a.movie_id,\n       n.name\n    FROM cast_info AS a\n    JOIN aka_name AS n ON a.person_id = n.person_id\n    WHERE a.role_id = 2             # acresses only\n        AND a.person_id &gt; 3900000) AS acts ON acts.movie_id = movs.id\nLIMIT 0, 300;\n\n\n\n\nTable 6.13: RIGHT JOIN of movies and actresses.\n\n\n\n\n\n\n\n\n\nLEFT JOIN\nWith a LEFT JOIN, there are 33 rows corresponding to the actresses in the seven top 2015 movies. Only The Revenant did not have any actresses whose person_id is greater than 3900000.\n\n\nSELECT * FROM\n(SELECT t.id,\n       t.title\nFROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               # movies only\n    AND idx.info_type_id = 100      # info_type is votes\n    AND idx.info &gt; 400000) AS movs  # at least 400,000 votes     \nLEFT JOIN (SELECT a.person_id,\n       a.movie_id,\n       n.name\n    FROM cast_info AS a\n    JOIN aka_name AS n ON a.person_id = n.person_id\n    WHERE a.role_id = 2             # acresses only\n        AND a.person_id &gt; 3900000) AS acts ON acts.movie_id = movs.id\nLIMIT 0, 300;\n\n\n\n\nTable 6.14: LEFT JOIN of movies and actresses.\n\n\n\n\n\n\n\n\n\nCounting repeat actresses\nWe might, for example, want to know how many names / spellings of a name with a specific person_id (above 3900000) exist for each person_id in each of the top voted seven films of 2015.\nIn Table 6.15 why isn’t there a column indicating the name of the actress? (There can’t be such a column. Why not?)\n\nSELECT acts.person_id, \n       COUNT(*) AS num_repeat_names\nFROM (SELECT t.id,\n       t.title\nFROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               # movies only\n    AND idx.info_type_id = 100      # info_type is votes\n    AND idx.info &gt; 400000) AS movs  # at least 400,000 votes\nJOIN (SELECT a.person_id,\n       a.movie_id,\n       n.name\n    FROM cast_info AS a\n    JOIN aka_name AS n ON a.person_id = n.person_id\n    WHERE a.role_id = 2             # acresses only\n        AND a.person_id &gt; 3900000) AS acts ON acts.movie_id = movs.id\nGROUP BY acts.person_id;\n\n\n\n\nTable 6.15: For each person_id (&gt; 3900000) in the seven top voted 2015 films, how many names / spellings are associated with the person_id?\n\n\n\n\n\nperson_id\nnum_repeat_names\n\n\n\n3916648\n1\n\n\n4122876\n1\n\n\n3938423\n2\n\n\n3950111\n1\n\n\n4079047\n2\n\n\n4084626\n3\n\n\n4099458\n1\n\n\n3958614\n1\n\n\n3990819\n2\n\n\n4081131\n2\n\n\n3907812\n3\n\n\n3938795\n1\n\n\n3970637\n8\n\n\n4073883\n2\n\n\n4094732\n1\n\n\n4098918\n1\n\n\n\n\n\n\n\n\n\nCounting number of actresses per film\nWe might, for example, want to know how many actresses with a specific person_id (above 3900000) are in each of the top voted seven films of 2015.\n\nSELECT movs.id, \n       movs.title,\n       COUNT(*) AS num_actress\nFROM (SELECT t.id,\n       t.title\nFROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               # movies only\n    AND idx.info_type_id = 100      # info_type is votes\n    AND idx.info &gt; 400000) AS movs  # at least 400,000 votes\nJOIN (SELECT a.person_id,\n       a.movie_id,\n       n.name\n    FROM cast_info AS a\n    JOIN aka_name AS n ON a.person_id = n.person_id\n    WHERE a.role_id = 2             # acresses only\n        AND a.person_id &gt; 3900000) AS acts ON acts.movie_id = movs.id\nGROUP BY movs.id;\n\n\n\n\nTable 6.16: Number of actresses (with person_id &gt; 3900000) in each of the seven top voted films of 2015. Recall that The Revenant had no actresses with person_id &gt; 3900000, so there are only six movies listed.\n\n\n\n\n\nid\ntitle\nnum_actress\n\n\n\n3313672\nAvengers: Age of Ultron\n1\n\n\n3752999\nInside Out\n1\n\n\n3787790\nJurassic World\n9\n\n\n3915213\nMad Max: Fury Road\n5\n\n\n4260166\nStar Wars: Episode VII - The Force Awakens\n15\n\n\n4389619\nThe Martian\n1",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combining tables in SQL</span>"
    ]
  },
  {
    "objectID": "06-sql-joins.html#unioning",
    "href": "06-sql-joins.html#unioning",
    "title": "6  Combining tables in SQL",
    "section": "\n6.3 UNIONing",
    "text": "6.3 UNIONing\nIn SQL a UNION clause combines two different tables by their rows (whereas JOIN combines two tables by columns). Think about UNION similarly to the bind_rows() command in R.\n\n\n\n\n\n\n\nFigure 6.3: UNION binds rows while JOIN appends columns, image credit: Jane Williams https://blog.devart.com/mysql-union-tutorial-html.html\n\n\n\n\n\n6.3.1 UNIONs\nUNION does not check the names of the columns to make sure they match. UNION requires that the number of columns be the same and that the variable type be the same for all columns in the two tables being combined.\nTable 6.17 contains a silly example. The first table has 1 as bar and the second table has 20 as bar. But when the tables are UNIONed, the bar column contains c(1, 10). SQL took the column names from the first table and appended the second table without considering the variable names.\n\nSELECT \n    1 AS bar,\n    2 AS foo\n\nUNION\n\nSELECT \n    10 AS foo,\n    20 AS bar;\n\n\n\n\nTable 6.17: The variable names are chosen from the first table. The names and order of the variables in the second table are ignored when using UNION.\n\n\n\n\n\nbar\nfoo\n\n\n\n1\n2\n\n\n10\n20\n\n\n\n\n\n\n\n\n\nUNION is specifically designed to bind rows from two different SELECT queries where the variables have been selected in the same order. If the two SELECT clauses are done from the same table with the same order of variables, you do not need to worry about the order of the variables matching up in the UNION. If you are UNIONing two very different subqueries, you do need to worry about the variables and their order.\nUNION\nLet’s say we want to combine the top voted movies from 2015 with the top voted movies from 2019. However, to account for time, we require the movies from 2015 to have more votes (400,000) than the movies from 2017 (200,000). That is, the WHERE clause is different for the two subqueries.\n\n(SELECT t.title, \n        t.production_year, \n        idx.info AS num_votes\n    FROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               \n    AND idx.info_type_id = 100      \n    AND idx.info &gt; 400000)\n\nUNION\n\n(SELECT t.title, \n        t.production_year, \n        idx.info AS num_votes\n    FROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2017  \n    AND t.kind_id = 1               \n    AND idx.info_type_id = 100      \n    AND idx.info &gt; 200000)\nLIMIT 0, 100;\n   \n\n\n\n\nTable 6.18: The variable names are chosen from the first table. The names and order of the variables in the second table are ignored when using UNION.\n\n\n\n\n\ntitle\nproduction_year\nnum_votes\n\n\n\nAvengers: Age of Ultron\n2015\n540606\n\n\nInside Out\n2015\n443051\n\n\nJurassic World\n2015\n471237\n\n\nMad Max: Fury Road\n2015\n666484\n\n\nStar Wars: Episode VII - The Force Awakens\n2015\n691691\n\n\nThe Martian\n2015\n583987\n\n\nThe Revenant\n2015\n526189\n\n\nDunkirk\n2017\n229089\n\n\nGuardians of the Galaxy Vol. 2\n2017\n281845\n\n\nLogan\n2017\n397056\n\n\nSpider-Man: Homecoming\n2017\n209930\n\n\nWonder Woman\n2017\n306611\n\n\n\n\n\n\n\n\n\nUNION ALL\nUNION does check, however, to see if any of the rows in the two tables are identical. If the goal is to include duplicates across two tables, use UNION ALL instead of UNION.\nLet’s say that the first table is all movies with production year after 2012 and number of votes greater than 500,000. The second table is movies with production year equal to 2015 and number of votes greater than 400,000. Even though the Martian would have been in both tables, the results table lists The Marian only once in Table 6.19.\n\n(SELECT t.title,\n        t.production_year, \n        idx.info AS num_votes\n    FROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year &gt; 2012  \n    AND t.kind_id = 1               \n    AND idx.info_type_id = 100      \n    AND idx.info &gt; 500000)\n\nUNION\n\n(SELECT t.title, \n        t.production_year, \n        idx.info AS num_votes\n    FROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               \n    AND idx.info_type_id = 100      \n    AND idx.info &gt; 400000)\nORDER BY production_year DESC, num_votes;\n\n\n\n\nTable 6.19: Using UNION to combine movies from table 1: later than 2012 and at least 500,000 votes with movies from table 2: 2015 and at least 400,000 votes.\n\n\n\n\n\ntitle\nproduction_year\nnum_votes\n\n\n\nBatman v Superman: Dawn of Justice\n2016\n500037\n\n\nDeadpool\n2016\n673887\n\n\nInside Out\n2015\n443051\n\n\nJurassic World\n2015\n471237\n\n\nThe Revenant\n2015\n526189\n\n\nAvengers: Age of Ultron\n2015\n540606\n\n\nThe Martian\n2015\n583987\n\n\nMad Max: Fury Road\n2015\n666484\n\n\nStar Wars: Episode VII - The Force Awakens\n2015\n691691\n\n\nInterstellar\n2014\n1102826\n\n\nWhiplash\n2014\n507827\n\n\nThe Imitation Game\n2014\n550521\n\n\nThe Grand Budapest Hotel\n2014\n553558\n\n\nCaptain America: The Winter Soldier\n2014\n562419\n\n\nX-Men: Days of Future Past\n2014\n567780\n\n\nGone Girl\n2014\n664035\n\n\nGuardians of the Galaxy\n2014\n795151\n\n\n12 Years a Slave\n2013\n506640\n\n\nNow You See Me\n2013\n507519\n\n\nWorld War Z\n2013\n509285\n\n\nThe Hobbit: The Desolation of Smaug\n2013\n526001\n\n\nThe Hunger Games: Catching Fire\n2013\n537678\n\n\nMan of Steel\n2013\n592427\n\n\nIron Man Three\n2013\n607323\n\n\nGravity\n2013\n640900\n\n\nThe Wolf of Wall Street\n2013\n900450\n\n\n\n\n\n\n\n\n\nWhen UNION ALL is applied in the same context, The Martian is listed twice in the results table given in Table 6.20.\n\n(SELECT t.title,\n        t.production_year, \n        idx.info AS num_votes\n    FROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year &gt; 2012  \n    AND t.kind_id = 1               \n    AND idx.info_type_id = 100      \n    AND idx.info &gt; 500000)\n\nUNION ALL\n\n(SELECT t.title, \n        t.production_year, \n        idx.info AS num_votes\n    FROM title AS t\nJOIN movie_info_idx AS idx ON idx.movie_id = t.id\nWHERE t.production_year = 2015  \n    AND t.kind_id = 1               \n    AND idx.info_type_id = 100      \n    AND idx.info &gt; 400000)\nORDER BY production_year DESC, num_votes;\n\n\n\n\nTable 6.20: Using UNION ALL to combine movies from table 1: later than 2012 and at least 500,000 votes with movies from table 2: 2015 and at least 400,000 votes.\n\n\n\n\n\ntitle\nproduction_year\nnum_votes\n\n\n\nBatman v Superman: Dawn of Justice\n2016\n500037\n\n\nDeadpool\n2016\n673887\n\n\nInside Out\n2015\n443051\n\n\nJurassic World\n2015\n471237\n\n\nThe Revenant\n2015\n526189\n\n\nThe Revenant\n2015\n526189\n\n\nAvengers: Age of Ultron\n2015\n540606\n\n\nAvengers: Age of Ultron\n2015\n540606\n\n\nThe Martian\n2015\n583987\n\n\nThe Martian\n2015\n583987\n\n\nMad Max: Fury Road\n2015\n666484\n\n\nMad Max: Fury Road\n2015\n666484\n\n\nStar Wars: Episode VII - The Force Awakens\n2015\n691691\n\n\nStar Wars: Episode VII - The Force Awakens\n2015\n691691\n\n\nInterstellar\n2014\n1102826\n\n\nWhiplash\n2014\n507827\n\n\nThe Imitation Game\n2014\n550521\n\n\nThe Grand Budapest Hotel\n2014\n553558\n\n\nCaptain America: The Winter Soldier\n2014\n562419\n\n\nX-Men: Days of Future Past\n2014\n567780\n\n\nGone Girl\n2014\n664035\n\n\nGuardians of the Galaxy\n2014\n795151\n\n\n12 Years a Slave\n2013\n506640\n\n\nNow You See Me\n2013\n507519\n\n\nWorld War Z\n2013\n509285\n\n\nThe Hobbit: The Desolation of Smaug\n2013\n526001\n\n\nThe Hunger Games: Catching Fire\n2013\n537678\n\n\nMan of Steel\n2013\n592427\n\n\nIron Man Three\n2013\n607323\n\n\nGravity\n2013\n640900\n\n\nThe Wolf of Wall Street\n2013\n900450\n\n\n\n\n\n\n\n\n\n\n6.3.1.1 FULL OUTER JOIN via UNION\n\nMySQL doesn’t have a FULL OUTER JOIN (although other implementations of SQL do have full join functionality). However, we can mimic a full join using right and left joins with UNION.\nRecall the ideas of RIGHT JOIN (which keeps all observations in the right table) and LEFT JOIN (which keeps all observations in the left table). By UNIONing the right and left joins, all of the observations are obtained (i.e., a full join). Using the function sqldf() in the sqldf R package, the full join will be demonstrated using the 1960s rock bands.\nNotice that in the RIGHT JOIN the name column must come from the right table (not the left table).\nAlso notice that UNION ALL keeps the duplicate rows which is probably not what we want.\n\nsqldf::sqldf(\"SELECT star.name, star.band, inst.plays \n      FROM band_members AS star\n      LEFT JOIN band_instruments AS inst ON star.name = inst.name\")\n\n  name    band  plays\n1 Mick  Stones   &lt;NA&gt;\n2 John Beatles guitar\n3 Paul Beatles   bass\n\nsqldf::sqldf(\"SELECT inst.name, star.band, inst.plays \n      FROM band_members AS star\n      RIGHT JOIN band_instruments AS inst ON star.name = inst.name\")\n\n   name    band  plays\n1  John Beatles guitar\n2  Paul Beatles   bass\n3 Keith    &lt;NA&gt; guitar\n\nsqldf::sqldf(\"SELECT star.name, star.band, inst.plays \n      FROM band_members AS star\n      LEFT JOIN band_instruments AS inst ON star.name = inst.name\nUNION\n      SELECT inst.name, star.band, inst.plays \n      FROM band_members AS star\n      RIGHT JOIN band_instruments AS inst ON star.name = inst.name \")\n\n   name    band  plays\n1  John Beatles guitar\n2 Keith    &lt;NA&gt; guitar\n3  Mick  Stones   &lt;NA&gt;\n4  Paul Beatles   bass\n\nsqldf::sqldf(\"SELECT star.name, star.band, inst.plays \n      FROM band_members AS star\n      LEFT JOIN band_instruments AS inst ON star.name = inst.name\nUNION ALL\n      SELECT inst.name, star.band, inst.plays \n      FROM band_members AS star\n      RIGHT JOIN band_instruments AS inst ON star.name = inst.name \")\n\n   name    band  plays\n1  Mick  Stones   &lt;NA&gt;\n2  John Beatles guitar\n3  Paul Beatles   bass\n4  John Beatles guitar\n5  Paul Beatles   bass\n6 Keith    &lt;NA&gt; guitar",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combining tables in SQL</span>"
    ]
  },
  {
    "objectID": "06-sql-joins.html#best-practice",
    "href": "06-sql-joins.html#best-practice",
    "title": "6  Combining tables in SQL",
    "section": "\n6.4 Best practice",
    "text": "6.4 Best practice\nIt is always a good idea to terminate the SQL connection when you are done with it.\n\ndbDisconnect(con_imdb, shutdown = TRUE)",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combining tables in SQL</span>"
    ]
  },
  {
    "objectID": "06-sql-joins.html#reflection-questions",
    "href": "06-sql-joins.html#reflection-questions",
    "title": "6  Combining tables in SQL",
    "section": "\n6.5  Reflection questions",
    "text": "6.5  Reflection questions\n\nWhat are the different types of joins? Which data from which table gets kept and which gets removed for each type of join?\nWhat is the difference between a join and a union?\nWhen working with multiple tables, how (and why) is a variable linked to its table?\nConsider a RIGHT JOIN. If there are records in the right table that are not in the left table, what will the value of the left table variable be for those records?",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combining tables in SQL</span>"
    ]
  },
  {
    "objectID": "06-sql-joins.html#ethics-considerations",
    "href": "06-sql-joins.html#ethics-considerations",
    "title": "6  Combining tables in SQL",
    "section": "\n6.6  Ethics considerations",
    "text": "6.6  Ethics considerations\n\nWhat can happen if a UNION is done without carefully matching up the columns of the two tables being UNIONed?\nHow will you know if JOINing removed some records? What if the JOIN produced missing values for some of the variables? How should we deal with missing data or arbitrarily removed records?\n\n\n\n\nFigure 6.1: Venn diagrams describing different JOINs, image credit: phoenixNAP https://phoenixnap.com/kb/mysql-join\nFigure 6.2: Mini data tables describing different JOINs, image credit: Statistics Globe blog, https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti\nFigure 6.3: UNION binds rows while JOIN appends columns, image credit: Jane Williams https://blog.devart.com/mysql-union-tutorial-html.html",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combining tables in SQL</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html",
    "href": "05-sql-verbs.html",
    "title": "5  SQL clauses",
    "section": "",
    "text": "5.1 Looking at the tables in the database\nConsider a database of taxi rides from the Yellow Cab company in NYC in March of 2014.\nlibrary(mdsr)\ncon_taxi &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"nyctaxi\",\n  host = Sys.getenv(\"MDSR_HOST\"),\n  user = Sys.getenv(\"MDSR_USER\"),\n  password = Sys.getenv(\"MDSR_PWD\")\n)\nSHOW TABLES;\nTable 5.1: SHOW all the TABLES in the nyctaxi database.\nThere is only one table in the nyctaxi database, called yellow_old.\nDESCRIBE yellow_old;\nTable 5.2: DESCRIBE variables in the yellow_old table.\nSimilarly, the DESCRIBE command shows the 18 field names (variables) in the yellow_old table. Some of the variables are characters (text) and some are numeric (either double or bigint)\nMost engagements with SQL are done through queries. Queries in SQL start with the SELECT keyword and consist of several clauses, which must be written in the following order:1",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html#looking-at-the-tables-in-the-database",
    "href": "05-sql-verbs.html#looking-at-the-tables-in-the-database",
    "title": "5  SQL clauses",
    "section": "",
    "text": "Watch out!\n\n\n\nSQL clauses must be written in the following order.\n\n\n\n\n\nSELECT allows you to list the columns, or functions operating on columns, that you want to retrieve. This is an analogous operation to the select() verb in dplyr, potentially combined with mutate() or summarize().\n\nFROM specifies the table where the data are.\n\nJOIN allows you to stitch together two or more tables using a key. This is analogous to the inner_join() and left_join() commands in dplyr. More details of JOIN are given in Chapter 6.\n\nWHERE allows you to filter the records according to some criteria and is an analogous operation to the filter() verb in dplyr. Note, even though the WHERE clause is written after SELECT and JOIN, it is actually evaluated before the SELECT or JOIN clauses (which is why WHERE only works on the original data, not the results set).\n\nGROUP BY allows you to aggregate the records according to some shared value and is an analogous operation to the group_by() verb in dplyr.\n\nHAVING is like a WHERE clause that operates on the result set—not the records themselves and is analogous to applying a second filter() command in dplyr, after the rows have already been aggregated.\n\nORDER BY is exactly what it sounds like—it specifies a condition for ordering the rows of the result set and is analogous to the arrange() verb in dplyr.\n\nLIMIT restricts the number of rows in the output and is similar to the R commands head() and slice().",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html#sec-select",
    "href": "05-sql-verbs.html#sec-select",
    "title": "5  SQL clauses",
    "section": "\n5.2 SELECT … FROM",
    "text": "5.2 SELECT … FROM\n\n\n\n\n\n\nR function: select()\n\n\n\nA SQL query starts with a SELECT command and has a corresponding FROM to indicate the table being queried. Columns may be specified, or the * will indicate that every column in the table should be returned.\nThe shortest SQL query is the following SELECT command. Do not run this command!!! The yellow_old table has 15 million rows, and we do not want to look at them simultaneously.\n\nDO NOT RUN:  SELECT * FROM yellow_old;\n\n\n\n\n\n\n\n Watch out!\n\n\n\nDo not run the following command unless you are certain that the table from which you are querying is small enough so that the query results fit easily into your memory.\nSELECT * FROM table;\n\n\nInstead, to look at the top of the table, SELECT the first few rows. The LIMIT command specifies which rows to select: the first number is the number of rows to skip (0 rows skipped), the second number is the number of rows to print up to (up to row 14).\n\nSELECT * FROM yellow_old LIMIT 0, 14;\n\n\n\nTable 5.3: SELECT the first 14 rows of the table.\n\n\n\n\n\nSpeaking of which, how many rows are there in the yellow_old table? That is, how many taxi rides are recorded? Now SELECT is used with a summary function, COUNT(). Instead of using a separate summary function (like mutate() or summarize()), all the work is done inside the SELECT call.\n\nSELECT COUNT(*) FROM yellow_old;\n\n\n\nTable 5.4: COUNT(*) the number of rows in the entire yellow_old table.\n\n\n\n\n\nYikes, more than 15 million taxi rides!!!!\nYou might have noticed that the yellow_old table has two different datetime variables (one for pickup, the other for drop-off). We can use the information to assess the length of each ride (in time, not distance). However, the variables are stored in SQL as character strings instead of in a DateTime format (even though they look like they are stored in a DateTime format!), see Table 5.2. Fortunately for us, SQL has functionality to convert a text Type into DateTime type (POSIXct is a special type of DateTime formatting).\n\nSELECT\n      pickup_datetime, dropoff_datetime,\n      STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\") AS pickup,\n      STR_TO_DATE(dropoff_datetime, \"%Y-%m-%d %T\") AS dropoff\n   FROM yellow_old\n   LIMIT 0, 10;\n\n\n\nTable 5.5: Convert the pickup and drop-off times to date objects using STR_TO_DATE.\n\n\n\n\n\nNow that the variables are no longer strings, we can subtract them to figure out the number of minutes for each taxi ride. Unfortunately, the following code won’t run because neither of the variables pickup or dropoff are in the table yellow_old.\n\nSELECT\n      pickup_datetime, dropoff_datetime,\n      STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\") AS pickup,\n      STR_TO_DATE(dropoff_datetime, \"%Y-%m-%d %T\") AS dropoff.\n      TIMEDIFF(pickup, dropoff) AS length_time\n   FROM yellow_old\n   LIMIT 0, 10;\n\nInstead, we need two layers of SELECT commands so that the first SELECT (i.e., inside) layer creates the new variables, and the second SELECT (i.e., outside) layer subtracts the two times.\n\nSELECT \n   pickup,\n   dropoff, \n   TIMEDIFF(pickup, dropoff) AS length_time \nFROM (\n   SELECT\n      STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\") AS pickup,\n      STR_TO_DATE(dropoff_datetime, \"%Y-%m-%d %T\") AS dropoff\n   FROM yellow_old)\n   AS subquery_table\nLIMIT 0, 20;\n\n\n\nTable 5.6: Use TIMEDIFF to find the length (time) of the ride.\n\n\n\n\n\nAlternatively, the STR_TO_DATE() function can be applied inside the TIMEDIFF() function so that the full (now only) SELECT command is being used only on variables that are in the original table.\n\nSELECT \n   pickup_datetime,\n   dropoff_datetime, \n   TIMEDIFF(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\"), \n            STR_TO_DATE(dropoff_datetime, \"%Y-%m-%d %T\")) AS length_time \nFROM yellow_old\nLIMIT 0, 20;\n\n\n\nTable 5.7: Alternative method to find the length (time) of the ride.\n\n\n\n\n\nKeep in mind that there is a distinction between clauses that operate on the variables of the original table versus those that operate on the variables of the results set. The variables pickup_datetime and dropoff_datetime are columns in the original table - they are written to disk on the SQL server. The variables pickup, dropoff, and length_time exist only in the results set, which is passed from the server (SQL server) to the client (e.g., RStudio or DBeaver) and is not written to disk.",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html#select-distinct",
    "href": "05-sql-verbs.html#select-distinct",
    "title": "5  SQL clauses",
    "section": "\n5.3 SELECT DISTINCT",
    "text": "5.3 SELECT DISTINCT\nSELECT DISTINCT returns only unique rows. That is, it filters out all the duplicates of a variable or a combination of variables. Note that I have a larger limit on the query that I needed, just to make sure I got all the levels.\n\nSELECT DISTINCT payment_type\nFROM yellow_old\nLIMIT 0, 20;\n\n\n\nTable 5.8: The distinct values of payment types. CRD is credit card; CSH is cash; NOC is no charge; DIS is dispute.\n\n\n\n\n\n\nSELECT DISTINCT vendor_id, payment_type\nFROM yellow_old\nLIMIT 0, 20;\n\n\n\nTable 5.9: The distinct values of vendor ID and payment types, combined. VTS is Verifone Transportation Systems and CMT is Mobile Knowledge Systems Inc. CRD is credit card; CSH is cash; NOC is no charge; DIS is dispute.",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html#where",
    "href": "05-sql-verbs.html#where",
    "title": "5  SQL clauses",
    "section": "\n5.4 WHERE",
    "text": "5.4 WHERE\n\n\n\n\n\n\nR function: filter()\n\n\n\nThe WHERE clause is analogous to the filter() function in dplyr. However, keep in mind that there are two SQL commands that resemble the dplyr filter() function. WHERE operates on the original data in the table and HAVING operates on the result set. See below for examples using HAVING.\nWhat was the fare for those taxi rides where the tip_amount was more than $10 and the person used cash? (Note that in SQL the equality logical is = and in R the equality logical is ==.)\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE tip_amount &gt; 10\n   AND payment_type = \"CSH\"\nLIMIT 0, 10;\n\n\n\nTable 5.10: WHERE to subset the queried rows.\n\n\n\n\n\nBETWEEN can be used to specify a range of values for a numeric value. BETWEEN is inclusive.\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE tip_amount BETWEEN 10 and 12\n   AND payment_type = \"CSH\"\nLIMIT 0, 10;\n\n\n\nTable 5.11: BETWEEN in the WHERE clause.\n\n\n\n\n\nIN is similar to the dplyr %in% function which specifies distinct values for the variable.\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE tip_amount IN (10, 12)\n   AND payment_type = \"CSH\"\nLIMIT 0, 10;\n\n\n\nTable 5.12: IN in the WHERE clause.\n\n\n\n\n\nThe WHERE clause can be established by a number of logical commands combined using either AND or OR. Usually it is important to use parentheses with OR logicals to make sure the desired query is return. Consider the difference between the following queries. In SQL (as in many programming languages), AND takes precedent over OR in the order of operations, when there are no parentheses. (I was taught to remember order of operations using “please excuse my dear aunt Sally.”) The order of operations on the first query groups the second two conditions into one because AND take precedence over OR (as if the query was tip_amount BETWEEN 10 and 12 OR (total_amount BETWEEN 100 and 112 AND payment_type = \"CSH\")).\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE tip_amount BETWEEN 10 and 12 OR \n      total_amount BETWEEN 100 and 112 AND \n      payment_type = \"CSH\"\nLIMIT 0, 10;\n\n\n\nTable 5.13: OR and AND without parentheses.\n\n\n\n\n\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE (tip_amount BETWEEN 10 and 12 OR \n      total_amount BETWEEN 100 and 112 ) AND \n      payment_type = \"CSH\"\nLIMIT 0, 10;\n\n\n\nTable 5.14: OR and AND with parentheses.\n\n\n\n\n\n\n5.4.1 NULL in WHERE\nSQL considers NULL values to be unknown. Therefore, when searching for a NULL value, you need to ask SQL if the value IS NULL. Asking if the value is equal to NULL doesn’t work because NULL values don’t equal anything (they are unknown). To keep all values that are not NULL values, use IS NOT NULL in the WHERE clause.\n\n\n\n\n\n\n Watch out!\n\n\n\nIn order to find the records that are NULL use WHERE variable IS NULL.\n\n\n\n5.4.1.1 A NULL example2\n\nThe logic of NULL:\n\nIf you do anything with NULL, you’ll just get NULL. For instance if \\(x\\) is NULL, then \\(x &gt; 3\\), \\(1 = x\\), and \\(x + 4\\) all evaluate to NULL. Even \\(x =\\) NULL evaluates to NULL! if you want to check whether \\(x\\) is NULL, use x IS NULL or x IS NOT NULL.\n\nNULL short-circuits with boolean operators. That means a boolean expression involving NULL will evaluate to:\n\nTRUE, if it’d evaluate to TRUE regardless of whether the NULL value is really TRUE or FALSE.\nFALSE, if it’d evaluate to FALSE regardless of whether the NULL value is really TRUE or FALSE.\nOr NULL, if it depends on the NULL value.\n\n\n\nConsider the following table and SQL query:\n\nSELECT * FROM (\n   SELECT 'Ace' AS name, 20 AS age, 4 as num_dogs\n   UNION\n   SELECT 'Ada' AS name, NULL AS age, 3 as num_dogs   \n   UNION\n   SELECT 'Ben' AS name, NULL AS age, NULL as num_dogs\n   UNION\n   SELECT 'Cho' AS name, 27 AS age, NULL as num_dogs\n   ) AS temptable;\n\n\nSELECT * FROM (\n   SELECT 'Ace' AS name, 20 AS age, 4 as num_dogs\n   UNION\n   SELECT 'Ada' AS name, NULL AS age, 3 as num_dogs   \n   UNION\n   SELECT 'Ben' AS name, NULL AS age, NULL as num_dogs\n   UNION\n   SELECT 'Cho' AS name, 27 AS age, NULL as num_dogs\n   ) AS temptable\nWHERE age &lt;= 20 OR num_dogs = 3;\n\nWhere does the WHERE clause do? It tells us that we only want to keep the rows satisfying the age &lt;= 20 OR num_dogs = 3. Let’s consider each row one at a time:\n\nFor Ace, age &lt;= 20 evaluates to TRUE so the claim is satisfied.\nFor Ada, age &lt;= 20 evaluates to NULL but num_dogs = 3 evaluates to TRUE so the claim is satisfied.\nFor Ben, age &lt;= 20 evaluates to NULL and num_dogs = 3 evaluates to NULL so the overall expression is NULL which has a FALSE value.\nFor Cho, age &lt;= 20 evaluates to FALSE and num_dogs = 3 evaluates to NULL so the overall expression evaluates to NULL (because it depends on the value of the NULL).\n\nThus we keep only Ace and Ada.\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE payment_type IS NULL\nLIMIT 0, 10;\n\n\n\nTable 5.15: There is ONE record with a NULL value for payment_type. Note that the way to find NULL values is via IS NULL.\n\n\n\n\n\n\nSELECT payment_type, fare_amount, tip_amount, total_amount\nFROM yellow_old\nWHERE payment_type = NULL\nLIMIT 0, 10;\n\n\n\nTable 5.16: NO rows are selected when the WHERE command is specified to indicate if the variable equals NULL.",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html#group-by",
    "href": "05-sql-verbs.html#group-by",
    "title": "5  SQL clauses",
    "section": "\n5.5 GROUP BY",
    "text": "5.5 GROUP BY\n\n\n\n\n\n\nR function: group_by()\n\n\n\nThe GROUP BY clause will direct SQL to carry out the query separately for each category in the grouped variable. Using GROUP BY is particularly important when aggregating multiple rows into a single number. Some aggregate functions include COUNT(), SUM(), MAX(), MIN(), and AVG().\nNote that SUM(1) adds (sums) the number 1 for each row. Which is the same as counting the number of rows. SUM(2) adds (sums) the number 2 for each row which returns twice as many transactions.\n\nSELECT COUNT(*) AS num_transactions, \n       SUM(1) AS num_transactions_also,\n       SUM(2) AS double_transactions,\n       payment_type \nFROM yellow_old\nWHERE tip_amount BETWEEN 10 and 20\nGROUP BY payment_type;\n\n\n\nTable 5.17: GROUP BY on payment_type.\n\n\n\n\n\nFor those people who tipped between $10 and $20, what was the lowest and highest fare for each of the types of payments?\n\nSELECT COUNT(*) AS num_transactions, \n       MIN(fare_amount) AS lowest_fare,\n       MAX(fare_amount) AS highest_fare,\n       payment_type \nFROM yellow_old\nWHERE tip_amount BETWEEN 10 and 20\nGROUP BY payment_type;\n\n\n\nTable 5.18: GROUP BY with aggregate functions.\n\n\n\n\n\nGROUP BY will work applied to multiple columns. Let’s tabulate the same results, now broken down by payment_type and day of week. Except that we don’t have a day of week variable! We need to convert the pickup_datetime variable to a DateTime object and then pull out the day of the week, using DAYNAME. (Note: DAYOFWEEK will give you the day of the week as an integer. Use your internet sleuthing skills if you are looking for functions that might help your desired query.)\n\n\nSELECT COUNT(*) AS num_transactions, \n       MIN(fare_amount) AS lowest_fare,\n       MAX(fare_amount) AS highest_fare,\n       payment_type,\n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old\nGROUP BY payment_type, wday;\n\n\n\nTable 5.19: GROUP BY with payment_type and wday.",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html#order-by",
    "href": "05-sql-verbs.html#order-by",
    "title": "5  SQL clauses",
    "section": "\n5.6 ORDER BY",
    "text": "5.6 ORDER BY\n\n\n\n\n\n\nR function: arrange()\n\n\n\nThe ORDER BY command can be used with or without the GROUP BY and aggregation commands. It allows us to look at interesting aspects of the data by sorting the data.\n\nSELECT COUNT(*) AS num_transactions, \n       MIN(fare_amount) AS lowest_fare,\n       MAX(fare_amount) AS highest_fare,\n       payment_type,\n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old\nGROUP BY payment_type, wday\nORDER BY lowest_fare ASC;\n\n\n\nTable 5.20: ORDER BY lowest_fare, ascending.\n\n\n\n\n\nWHAT?!?!! How in the world was one of the fares -$612.40? It doesn’t make any sense that a fare would be negative. Some additional inquiry into the observation corresponding to a fare of -$612.40 is absolutely warranted. If the observation is found to be a typo, it would need to be removed from the data set. If the observation is somehow legitimate, it would need to be included in the analysis, with the information provided about its legitimacy.\n\nSELECT COUNT(*) AS num_transactions, \n       MIN(fare_amount) AS lowest_fare,\n       MAX(fare_amount) AS highest_fare,\n       payment_type,\n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old\nGROUP BY payment_type, wday\nORDER BY highest_fare DESC;\n\n\n\nTable 5.21: ORDER BY highest_fare, descending\n\n\n\n\n\n$950 is a lot to pay for a cab ride! But in NYC, I’d believe it.\n\nSELECT COUNT(*) AS num_transactions, \n       MIN(fare_amount) AS lowest_fare,\n       MAX(fare_amount) AS highest_fare,\n       payment_type,\n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old\nGROUP BY payment_type, wday\nORDER BY wday, payment_type;\n\n\n\nTable 5.22: ORDER BY wday and payment_type.\n\n\n\n\n\n\n\n\n\n\n\nNote that both GROUP BY and ORDER BY evaluate the data after it has been retrieved. Therefore, the functions operate on the results set, not the original rows of the data.\n\n\n\nAs above, we were able to GROUP BY and ORDER BY on the new variables we had created, wday.",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html#having",
    "href": "05-sql-verbs.html#having",
    "title": "5  SQL clauses",
    "section": "\n5.7 HAVING",
    "text": "5.7 HAVING\n\n\n\n\n\n\nR function: filter()\n\n\n\nRecall that WHERE acts only on the original data. If we are interested in rides that took place on Friday, we need to use the derived variable wday instead of the raw variable pickup_datetime. Fortunately, HAVING works on the results set. Note that SQL uses '' for strings, not \"\". In SQL, \"\" is used to identify variables (not values of variables), like R’s &grave;&grave;.\n\nSELECT COUNT(*) AS num_transactions, \n       MIN(fare_amount) AS lowest_fare,\n       MAX(fare_amount) AS highest_fare,\n       payment_type,\n       DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old\nGROUP BY payment_type, wday\nHAVING wday = 'Friday';\n\n\n\nTable 5.23: HAVING to filter only Friday rides.\n\n\n\n\n\nWhile it worked out quite well for us that HAVING was able to filter the data based on the results set, the use of HAVING was quite onerous because the entire data set was considered before the filter was applied. That is, if the filter can be done on the original data using WHERE, the query will be much faster and more efficient.\nNote: HAVING requires a GROUP BY clause. And the variable(s) used in HAVING must also be part of the GROUP BY clause.\n\n\n\n\n\n\nWhenever possible, use WHERE instead of HAVING to make your queries as efficient as possible.",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html#limit",
    "href": "05-sql-verbs.html#limit",
    "title": "5  SQL clauses",
    "section": "\n5.8 LIMIT",
    "text": "5.8 LIMIT\n\n\n\n\n\n\nR function: head() or slice()\n\n\n\nAs we’ve seen, LIMIT truncates the query to specified rows. The LIMIT command specifies which rows to select: the first number is the number of rows to skip (0 rows skipped), the second number is the number of rows to print up to (up to row 14). The query below shows the last 10 rows of the entire data set.\n\nSELECT * FROM yellow_old LIMIT 15428118, 10;\n\n\n\nTable 5.24: LIMIT on the last 10 rows of the table.",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html#saving-sql-queries-as-r-objects",
    "href": "05-sql-verbs.html#saving-sql-queries-as-r-objects",
    "title": "5  SQL clauses",
    "section": "\n5.9 Saving SQL queries as R objects",
    "text": "5.9 Saving SQL queries as R objects\nIf you are working in R to run SQL commands, you may want to use the query output for further analysis or visualizations. In that case, use #|output.var: \"name_of_variable\" inside the {sql} chunk. The variable called name_of_variable will then be available to be used in the R environment.\n\n```{sql}\n#| connection: con_taxi\n#| label: new-table\n#| output.var: \"new_table\"\n#| eval: false\n\nSELECT *, DAYNAME(STR_TO_DATE(pickup_datetime, \"%Y-%m-%d %T\")) AS wday\nFROM yellow_old \nLIMIT 0, 1000;\n\n```\n\n\n\nTable 5.25: New data.frame saved to R called new_table.\n\n\n\n\n\n\n```{r}\n#| eval: false\n\nnew_table |&gt;\n  drop_na(wday) |&gt;\n  ggplot(aes(x = fare_amount, y = tip_amount, color = wday)) + \n  geom_point() \n```",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html#best-practice",
    "href": "05-sql-verbs.html#best-practice",
    "title": "5  SQL clauses",
    "section": "\n5.10 Best practice",
    "text": "5.10 Best practice\nIt is always a good idea to terminate the SQL connection when you are done with it.\n\ndbDisconnect(con_taxi, shutdown = TRUE)",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html#reflection-questions",
    "href": "05-sql-verbs.html#reflection-questions",
    "title": "5  SQL clauses",
    "section": "\n5.11  Reflection questions",
    "text": "5.11  Reflection questions\n\nWhy don’t we usually want to run the query: SELECT * FROM table;?\nWhat is the difference between the original table and the results set?\nIn SQL does the WHERE clause use = or == to indicate equality?\nDoes BETWEEN work only on numeric variables or also on character strings?\nWhat syntax is used to direct ORDER BY to sort by biggest to smallest or smallest to biggest?\nWhat is the difference between WHERE and HAVING?",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html#ethics-considerations",
    "href": "05-sql-verbs.html#ethics-considerations",
    "title": "5  SQL clauses",
    "section": "\n5.12  Ethics considerations",
    "text": "5.12  Ethics considerations\n\nWhat are different ways to look at the dataset to identify possible typos or rogue values?\nWhy are such tasks so much harder with large datasets (versus small datasets)?\nWhy are such tasks to much more important with large datasets (versus small datasets)?",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "05-sql-verbs.html#footnotes",
    "href": "05-sql-verbs.html#footnotes",
    "title": "5  SQL clauses",
    "section": "",
    "text": "Taken directly from Modern Data Science with R↩︎\ntaken from: https://cs186berkeley.net/notes/note1/#filtering-null-values↩︎",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>SQL clauses</span>"
    ]
  },
  {
    "objectID": "04-sql-in-R.html",
    "href": "04-sql-in-R.html",
    "title": "4  SQL in R and DBeaver",
    "section": "",
    "text": "4.1 Translating dplyr code into SQL\nLet’s go back to the airlines database to try out some things that we already know how to do in R. Recall that we need the DBI and RMariaDB packages to connect to R; we need the dbplyr package to translate SQL code into R.\nlibrary(DBI)\nlibrary(RMariaDB)\nlibrary(dbplyr)\n\ncon_air &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"airlines\",\n  host = Sys.getenv(\"MDSR_HOST\"),\n  user = Sys.getenv(\"MDSR_USER\"),\n  password = Sys.getenv(\"MDSR_PWD\")\n)\nThe function dbListTables() in the DBI package will tell us what tables exist in the airlines database.\nDBI::dbListTables(con_air)\n\n[1] \"planes\"          \"carriers\"        \"airports\"        \"flights_summary\"\n[5] \"flights\"        \n\nflights &lt;- tbl(con_air, \"flights\")\ncarriers &lt;- tbl(con_air, \"carriers\")\nLet’s ask a few questions about the data set using data wrangling techniques that should already be familiar.\nTo start, let’s write the commands using tidy dplyr code.\nyrs &lt;- flights |&gt;\n  summarize(min_year = min(year), max_year = max(year))\n\nyrs\n\n# Source:   SQL [1 x 2]\n# Database: mysql  [mdsr_public@mdsr.cdc7tgkkqd0n.us-east-1.rds.amazonaws.com:3306/airlines]\n  min_year max_year\n     &lt;int&gt;    &lt;int&gt;\n1     2013     2015\nBecause flights is not actually a data.frame in R (but instead a tbl in SQL), the work that was done above was actually performed in SQL. To see the SQL code, we can use the function show_query.\nshow_query(yrs)\n\n&lt;SQL&gt;\nSELECT MIN(`year`) AS `min_year`, MAX(`year`) AS `max_year`\nFROM `flights`\nNote the similarity between the R code and the SQL code. We can see SELECT and MIN and MAX which are familiar. The AS function is new, but maybe it that AS does the job of assigning a new name to the output columns. FROM is also new and does the job of piping in a data set to use.\nla_bos &lt;- flights |&gt;\n  filter(year == 2012 & ((origin == \"LAX\" & dest == \"BOS\") | \n           (origin == \"BOS\" & dest == \"LAX\"))) \n\n\nla_bos\n\n# Source:   SQL [0 x 21]\n# Database: mysql  [mdsr_public@mdsr.cdc7tgkkqd0n.us-east-1.rds.amazonaws.com:3306/airlines]\n# ℹ 21 variables: year &lt;int&gt;, month &lt;int&gt;, day &lt;int&gt;, dep_time &lt;int&gt;,\n#   sched_dep_time &lt;int&gt;, dep_delay &lt;int&gt;, arr_time &lt;int&gt;,\n#   sched_arr_time &lt;int&gt;, arr_delay &lt;int&gt;, carrier &lt;chr&gt;, tailnum &lt;chr&gt;,\n#   flight &lt;int&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;int&gt;, distance &lt;int&gt;,\n#   cancelled &lt;int&gt;, diverted &lt;int&gt;, hour &lt;int&gt;, minute &lt;int&gt;, time_hour &lt;dttm&gt;\nshow_query(la_bos)\n\n&lt;SQL&gt;\nSELECT `flights`.*\nFROM `flights`\nWHERE (`year` = 2012.0 AND ((`origin` = 'LAX' AND `dest` = 'BOS') OR (`origin` = 'BOS' AND `dest` = 'LAX')))\nThe WHERE function in SQL acts as filter() did in R; & has been translated to AND, and | has been translated to OR.\nAs might be expected, dbplyr doesn’t translate every R command into SQL. After all, SQL is not a statistical software and doesn’t, for example, have a mechanism for creating data visualizations. To track which R commands are connected to SQL see the dbplyr reference sheet.\nBecause the data set has been subsetted substantially, we could pull it into R to create an R object. Note that now R is aware of the size of the entire data frame (7064 rows and 21 columns). The la_bos object now exists in the R environment and can be explored through the IDE.\nla_bos &lt;- la_bos |&gt;\n  collect()\n\nla_bos\n\n# A tibble: 0 × 21\n# ℹ 21 variables: year &lt;int&gt;, month &lt;int&gt;, day &lt;int&gt;, dep_time &lt;int&gt;,\n#   sched_dep_time &lt;int&gt;, dep_delay &lt;int&gt;, arr_time &lt;int&gt;,\n#   sched_arr_time &lt;int&gt;, arr_delay &lt;int&gt;, carrier &lt;chr&gt;, tailnum &lt;chr&gt;,\n#   flight &lt;int&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;int&gt;, distance &lt;int&gt;,\n#   cancelled &lt;int&gt;, diverted &lt;int&gt;, hour &lt;int&gt;, minute &lt;int&gt;, time_hour &lt;dttm&gt;\nChapter 5 will explore more SQL queries and using SQL verbs. For now, let’s continue learning about the different ways R can talk to SQL.\nAlways a good idea to terminate the SQL connection when you are done with it.\ndbDisconnect(con_air, shutdown = TRUE)",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>SQL in R and DBeaver</span>"
    ]
  },
  {
    "objectID": "04-sql-in-R.html#sec-dplyr-seq",
    "href": "04-sql-in-R.html#sec-dplyr-seq",
    "title": "4  SQL in R and DBeaver",
    "section": "",
    "text": "Over what years is the flights data taken?\n\n\n\n\n\n\n\nCreate a data set containing only flights between LAX and BOS in 2012.\n\n\n\n\n\n\n\n\n\n\n\n\n Watch out!\n\n\n\nBe careful with collect(). Don’t use collect() on large data frames that won’t fit in an R environment.",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>SQL in R and DBeaver</span>"
    ]
  },
  {
    "objectID": "04-sql-in-R.html#sql-queries-through-the-dbi-package",
    "href": "04-sql-in-R.html#sql-queries-through-the-dbi-package",
    "title": "4  SQL in R and DBeaver",
    "section": "\n4.2 SQL queries through the DBI package",
    "text": "4.2 SQL queries through the DBI package\nUsing R as a wrapper, we can send actual SQL code to query data from the connection. It is okay if you aren’t yet able to write SQL commands from scratch, but try to figure out what the command is asking for. As mentioned above, we will start from scratch to learn SQL commands in Chapter 5.\nStart by setting up the SQL connection in the same way.\n\ncon_air &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"airlines\",\n  host = Sys.getenv(\"MDSR_HOST\"),\n  user = Sys.getenv(\"MDSR_USER\"),\n  password = Sys.getenv(\"MDSR_PWD\")\n)\n\n\nLook at the first few rows of the flights data.\n\nBecause the flights data is not an R object, we can’t open it in R to explore the variables. If we want to see a small bit of the data, we can SELECT everything (i.e, *) from the flights table but LIMIT the query to only the first eight observations.\nNote that the code in the dbGetQuery() R function is written in SQL not in R.\nA semicolon (;) is typically used to indicate the termination of a SQL statement. They are not always required (particularly when only one statement is being sent), however, it is good practice to use a semicolon at the end of each SQL statement. (Indeed, some SQL dialects require the semicolon at the end of every statement, regardless of whether or not there are more statements following.)\n\nDBI::dbGetQuery(con_air,\n                \"SELECT * FROM flights LIMIT 8;\")\n\n  year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n1 2013    10   1        2             10        -8      453            505\n2 2013    10   1        4           2359         5      730            729\n3 2013    10   1       11             15        -4      528            530\n4 2013    10   1       14           2355        19      544            540\n5 2013    10   1       16             17        -1      515            525\n6 2013    10   1       22             20         2      552            554\n7 2013    10   1       29             35        -6      808            816\n8 2013    10   1       29             35        -6      449            458\n  arr_delay carrier tailnum flight origin dest air_time distance cancelled\n1       -12      AA  N201AA   2400    LAX  DFW      149     1235         0\n2         1      FL  N344AT    710    SFO  ATL      247     2139         0\n3        -2      AA  N3KMAA   1052    SFO  DFW      182     1464         0\n4         4      AA  N3ENAA   2392    SEA  ORD      191     1721         0\n5       -10      UA  N38473   1614    LAX  IAH      157     1379         0\n6        -2      UA  N458UA    291    SFO  IAH      188     1635         0\n7        -8      US  N551UW    436    LAX  CLT      256     2125         0\n8        -9      AS  N402AS    108    ANC  SEA      181     1448         0\n  diverted hour minute           time_hour\n1        0    0     10 2013-10-01 00:10:00\n2        0   23     59 2013-10-01 23:59:00\n3        0    0     15 2013-10-01 00:15:00\n4        0   23     55 2013-10-01 23:55:00\n5        0    0     17 2013-10-01 00:17:00\n6        0    0     20 2013-10-01 00:20:00\n7        0    0     35 2013-10-01 00:35:00\n8        0    0     35 2013-10-01 00:35:00\n\n\n\nHow many flights per year are in the flights table?\n\n\ndbGetQuery(con_air, \n  \"SELECT year, count(*) AS num_flights FROM flights GROUP BY year ORDER BY num_flights;\")\n\n  year num_flights\n1 2015     5819079\n2 2014     5819811\n3 2013     6369482\n\n\nNote that we’ve now SELECTed two variables: year and num_flights (which we created along the way using count(*) which is written as n() in R) FROM the flights table. Then we GROUP BY the year variable which retroactively acts on the count(*) function. And last, we ORDER BY (which is similar to arrange()) the new num_flights variable.\nAlways a good idea to terminate the SQL connection when you are done with it.\n\ndbDisconnect(con_air, shutdown = TRUE)",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>SQL in R and DBeaver</span>"
    ]
  },
  {
    "objectID": "04-sql-in-R.html#direct-sql-queries-through-a-sql-chunk",
    "href": "04-sql-in-R.html#direct-sql-queries-through-a-sql-chunk",
    "title": "4  SQL in R and DBeaver",
    "section": "\n4.3 Direct SQL queries through a sql chunk",
    "text": "4.3 Direct SQL queries through a sql chunk\nNotice that the formatting of the next few chunks is slightly different. Instead of reporting only the inside / code of the chunk, the entire chunk is printed. The SQL chunks are given by {sql} instead of {r} and each SQL chunk is required to connect to a particular database (through the con_air connection).\nThe same queries have been run.\nStart by setting up the SQL connection in the same way.\n\n```{r}\ncon_air &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"airlines\",\n  host = Sys.getenv(\"MDSR_HOST\"),\n  user = Sys.getenv(\"MDSR_USER\"),\n  password = Sys.getenv(\"MDSR_PWD\")\n)\n```\n\n\n```{sql}\n#| connection: con_air\n\nSELECT * FROM flights LIMIT 8;\n```\n\n\n8 records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\ntailnum\nflight\norigin\ndest\nair_time\ndistance\ncancelled\ndiverted\nhour\nminute\ntime_hour\n\n\n\n2013\n10\n1\n2\n10\n-8\n453\n505\n-12\nAA\nN201AA\n2400\nLAX\nDFW\n149\n1235\n0\n0\n0\n10\n2013-10-01 00:10:00\n\n\n2013\n10\n1\n4\n2359\n5\n730\n729\n1\nFL\nN344AT\n710\nSFO\nATL\n247\n2139\n0\n0\n23\n59\n2013-10-01 23:59:00\n\n\n2013\n10\n1\n11\n15\n-4\n528\n530\n-2\nAA\nN3KMAA\n1052\nSFO\nDFW\n182\n1464\n0\n0\n0\n15\n2013-10-01 00:15:00\n\n\n2013\n10\n1\n14\n2355\n19\n544\n540\n4\nAA\nN3ENAA\n2392\nSEA\nORD\n191\n1721\n0\n0\n23\n55\n2013-10-01 23:55:00\n\n\n2013\n10\n1\n16\n17\n-1\n515\n525\n-10\nUA\nN38473\n1614\nLAX\nIAH\n157\n1379\n0\n0\n0\n17\n2013-10-01 00:17:00\n\n\n2013\n10\n1\n22\n20\n2\n552\n554\n-2\nUA\nN458UA\n291\nSFO\nIAH\n188\n1635\n0\n0\n0\n20\n2013-10-01 00:20:00\n\n\n2013\n10\n1\n29\n35\n-6\n808\n816\n-8\nUS\nN551UW\n436\nLAX\nCLT\n256\n2125\n0\n0\n0\n35\n2013-10-01 00:35:00\n\n\n2013\n10\n1\n29\n35\n-6\n449\n458\n-9\nAS\nN402AS\n108\nANC\nSEA\n181\n1448\n0\n0\n0\n35\n2013-10-01 00:35:00\n\n\n\n\n\n\n```{sql}\n#| connection: con_air\n\nSELECT year, count(*) AS num_flights FROM flights GROUP BY year ORDER BY num_flights;\n```\n\n\n3 records\n\nyear\nnum_flights\n\n\n\n2015\n5819079\n\n\n2014\n5819811\n\n\n2013\n6369482\n\n\n\n\n\nAlways a good idea to terminate the SQL connection when you are done with it.\n\ndbDisconnect(con_air, shutdown = TRUE)",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>SQL in R and DBeaver</span>"
    ]
  },
  {
    "objectID": "04-sql-in-R.html#dbeaver",
    "href": "04-sql-in-R.html#dbeaver",
    "title": "4  SQL in R and DBeaver",
    "section": "\n4.4 DBeaver",
    "text": "4.4 DBeaver\nDBeaver is a free SQL client that supports MySQL (as well as other dialects like MariaDB, PostgreSQL, and SQLite). While writing SQL code in R has some benefits (e.g., piping results tables into ggplot2 for visualizations), using a SQL client that is designed for SQL queries has benefits as well. In order to use DBeaver, download the client onto your computer and open it from your Applications.\n\n4.4.1 New database connection\nUsing the pull-down menus, navigate to a new database connection (Database -&gt; New Database Connection). Click on the MySQL icon (and click next). You should see an image similar to Figure 4.1.\n\n\n\n\n\n\n\nFigure 4.1: Connection settings for a MySQL connection via DBeaver.\n\n\n\n\n\nKeep the Host radio button toggled (don’t click on URL)\nWhere currently it says Server Host: localhost change localhost to the URL for the MySQL server to which you want to connect.\nChange the Username to the appropriate username for the server.\nChange the Password to the appropriate password for the server.\nOptional: in the Database: box, include the database you will query.\nClick Finish.\n\nOnce the connection is established, you should be able to navigate through the databases and their tables on the left side of the DBeaver window.\n\n4.4.2 Writing SQL queries\nPull up a SQL script by clicking ont he SQL button as seen in Figure 4.2.\n\n\n\n\n\n\n\nFigure 4.2: Click on SQL to initiate a SQL script.\n\n\n\n\nWrite SQL code. Click on the orange triangle to run the code.\nEach lab should be saved as a .sql files that can be turned in. The SQL queries (in the .sql file) should be able to be run by someone else. Use the hashtag (#) to comment out lines so that you can identify particular problems or comment on the query results.\nIf you did not specify which database to use when you set up the connection, the database can be specified at the top of the .sql file as USE database; (for example, you might want USE airlines;, with the semi-colon, before running your lines of SQL code).\nTo write text use /* write text here ... */, the slash and asterisk, for any commenting in the .sql file.",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>SQL in R and DBeaver</span>"
    ]
  },
  {
    "objectID": "04-sql-in-R.html#reflection-questions",
    "href": "04-sql-in-R.html#reflection-questions",
    "title": "4  SQL in R and DBeaver",
    "section": "\n4.5  Reflection questions",
    "text": "4.5  Reflection questions\n\nWhat are the three main ways to write a SQL query using the RStudio interface?\nHow is DBeaver similar and/or different from writing queries using **R*?\nWhy can’t you use collect() to pull the flights data into your R session?",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>SQL in R and DBeaver</span>"
    ]
  },
  {
    "objectID": "04-sql-in-R.html#ethics-considerations",
    "href": "04-sql-in-R.html#ethics-considerations",
    "title": "4  SQL in R and DBeaver",
    "section": "\n4.6  Ethics considerations",
    "text": "4.6  Ethics considerations\n\nHow / why is Sys.getenv() used to protect the username and password for the SQL connection?\nIf SQL databases are expensive to maintain, who will then have access to important data? Does it matter?\n\n\n\n\nFigure 4.1: Connection settings for a MySQL connection via DBeaver.\nFigure 4.2: Click on SQL to initiate a SQL script.",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>SQL in R and DBeaver</span>"
    ]
  },
  {
    "objectID": "03-rvest.html",
    "href": "03-rvest.html",
    "title": "3  Web scraping",
    "section": "",
    "text": "3.1  Reflection questions",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Web scraping</span>"
    ]
  },
  {
    "objectID": "03-rvest.html#ethics-considerations",
    "href": "03-rvest.html#ethics-considerations",
    "title": "3  Web scraping",
    "section": "\n3.2  Ethics considerations",
    "text": "3.2  Ethics considerations",
    "crumbs": [
      "Data acquisition",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Web scraping</span>"
    ]
  },
  {
    "objectID": "02-github.html",
    "href": "02-github.html",
    "title": "2  GitHub",
    "section": "",
    "text": "3 Working on assignments with GitHub and Gradescope\nIn DS002R, we will use GitHub + Gradescope to access and submit assignments. Here is the basic structure of how it will work:\nThe following diagram lays out the process, and the rest of the document provides a more detailed set of instructions.\nFlowchart of assignment process.",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GitHub</span>"
    ]
  },
  {
    "objectID": "02-github.html#ethics-considerations",
    "href": "02-github.html#ethics-considerations",
    "title": "2  GitHub",
    "section": "\n8.4  Ethics considerations",
    "text": "8.4  Ethics considerations\n\n\n\nimage credit: https://xkcd.com/1597/,\nFlowchart of assignment process.\nThe more you read Happy Git with R, the better your life will be.\nThe course organization which lists all of the assignment repositories. Click on the repository associated with the specific week’s HW assignment.\nCopy the HTTPS URL, and use it to create a new project in RStudio.\nAlways pull before you start. pull-work-save-commit-push\nAlways pull before you start. pull-work-render-commit-push\npull-work-render-commit-push\npull-work-render-commit-push\nCheck that your changes are correct.\nChange your Gradescope account settings.\nLinking GitHub to Gradescope.\nAuthorizing Gradescope to talk to GitHub.\nSuccessful integration of GitHub and Gradescope\nSubmitting HW from GitHub to Gradescope.",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GitHub</span>"
    ]
  },
  {
    "objectID": "p5-data-communicate.html",
    "href": "p5-data-communicate.html",
    "title": "Regular expressions",
    "section": "",
    "text": "Regular expressions are sequences of characters that define search patterns. Symbolic notation is used to find particular sequences of interest. Regular expressions are used in many different contexts including SQL queries, web scraping, and data wrangling. 9  Regular expressions covers regular expressions within R, but the syntax for pattern matching is identical across almost all platforms and programming languages. One thing to note is that to escape a metacharacter in R, two backslashes are needed. For example, \\\\d is the correct syntax to denote a digit.",
    "crumbs": [
      "Regular expressions"
    ]
  },
  {
    "objectID": "p1-data-acquire.html",
    "href": "p1-data-acquire.html",
    "title": "Data acquisition",
    "section": "",
    "text": "Databases are a powerful structure for holding huge amounts of data that can easily be accessed. Databases are made up of tables which are efficiently stored using indexing and avoiding unnecessary replication of information.\n?sec-db covers details of databases and reviews R functionality (mostly through the dplyr package) for working with data frames that mimics SQL queries for working with tables.\n4  SQL in R and DBeaver covers three different ways to run SQL queries in R. R code can be translated into SQL; the DBI package can send SQL queries through an r chunk; and SQL queries can be sent directly to a SQL server through a sql chunk. Additionally, DBeaver is introduced as a SQL client which supports MySQL.\nSQL code is written as a series of statements. Later in the text, ?sec-create-db and ?sec-change-db cover statements like CREATE for defining new tables and INSERT for adding data. In this part, 5  SQL clauses covers SELECT statements, which are arguably the most useful statements for data scientists. SELECT statements are also called queries because they query table(s), with particular characteristics, from databases.\nA query is made up of clauses. Every query must have a SELECT and FROM clause. Other clauses include WHERE, GROUP BY, HAVING, and ORDER BY, all of which will be covered in 5  SQL clauses.\nBecause of the efficiency of data storage in SQL databases, it is often necessary to combine information held across two or more tables. 6  Combining tables in SQL covers combining tables via JOIN (combining columns) and via UNION (combining rows).",
    "crumbs": [
      "Data acquisition"
    ]
  },
  {
    "objectID": "p2-data-explore.html",
    "href": "p2-data-explore.html",
    "title": "Data exploration",
    "section": "",
    "text": "Regular expressions are sequences of characters that define search patterns. Symbolic notation is used to find particular sequences of interest. Regular expressions are used in many different contexts including SQL queries, web scraping, and data wrangling. 9  Regular expressions covers regular expressions within R, but the syntax for pattern matching is identical across almost all platforms and programming languages. One thing to note is that to escape a metacharacter in R, two backslashes are needed. For example, \\\\d is the correct syntax to denote a digit.",
    "crumbs": [
      "Data exploration"
    ]
  },
  {
    "objectID": "p0-data-intro.html",
    "href": "p0-data-intro.html",
    "title": "Introduction to data science",
    "section": "",
    "text": "Databases are a powerful structure for holding huge amounts of data that can easily be accessed. Databases are made up of tables which are efficiently stored using indexing and avoiding unnecessary replication of information.\n?sec-db covers details of databases and reviews R functionality (mostly through the dplyr package) for working with data frames that mimics SQL queries for working with tables.\n4  SQL in R and DBeaver covers three different ways to run SQL queries in R. R code can be translated into SQL; the DBI package can send SQL queries through an r chunk; and SQL queries can be sent directly to a SQL server through a sql chunk. Additionally, DBeaver is introduced as a SQL client which supports MySQL.",
    "crumbs": [
      "Introduction to data science"
    ]
  },
  {
    "objectID": "07-wrangling.html",
    "href": "07-wrangling.html",
    "title": "7  Data wrangling",
    "section": "",
    "text": "7.1 Structure of Data\nFor plotting, analyses, model building, etc., it’s important that the data be structured in a very particular way. Hadley Wickham provides a thorough discussion and advice for cleaning up the data in Wickham (2014).\nThe Active Duty data are not tidy! What are the cases? How are the data not tidy? What might the data look like in tidy form? Suppose that the case was “an individual in the armed forces.” What variables would you use to capture the information in the following table?\nhttps://docs.google.com/spreadsheets/d/1Ow6Cm4z-Z1Yybk3i352msulYCEDOUaOghmo9ALajyHo/edit#gid=1811988794\nProblem: totals and different sheets\nBetter for R: longer format with columns - grade, gender, status, service, count (case is still the total pay grade)\nCase is individual (?): grade, gender, status, service (no count because each row does the counting)",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "07-wrangling.html#datastruc",
    "href": "07-wrangling.html#datastruc",
    "title": "7  Data wrangling",
    "section": "",
    "text": "Tidy Data: rows (cases/observational units) and columns (variables). The key is that every row is a case and *every} column is a variable. No exceptions.\nCreating tidy data is not trivial. We work with objects (often data tables), functions, and arguments (often variables).\n\n\n\n\n\n\n\n\n7.1.1 Building Tidy Data\nWithin R (really within any type of computing language, Python, SQL, Java, etc.), we need to understand how to build data using the patterns of the language. Some things to consider:\n\nobject_name = function_name(arguments) is a way of using a function to create a new object.\nobject_name = data_table %&gt;% function_name(arguments) uses chaining syntax as an extension of the ideas of functions. In chaining, the value on the left side of %&gt;% becomes the first argument to the function on the right side.\n\nobject_name = data_table %&gt;%\nfunction_name(arguments) %&gt;% \nfunction_name(arguments)\nis extended chaining. %&gt;% is never at the front of the line, it is always connecting one idea with the continuation of that idea on the next line. * In R, all functions take arguments in round parentheses (as opposed to subsetting observations or variables from data objects which happen with square parentheses). Additionally, the spot to the left of %&gt;% is always a data table. * The pipe syntax should be read as then, %&gt;%.\n\n\n7.1.2 Examples of Chaining\nThe pipe syntax (%&gt;%) takes a data frame (or data table) and sends it to the argument of a function. The mapping goes to the first available argument in the function. For example:\nx %&gt;% f(y) is the same as f(x, y)\ny %&gt;% f(x, ., z) is the same as f(x,y,z)\n\n7.1.2.1 Little Bunny Foo Foo\nFrom Hadley Wickham, how to think about tidy data.\n\nLittle bunny Foo Foo Went hopping through the forest Scooping up the field mice And bopping them on the head\n\nThe nursery rhyme could be created by a series of steps where the output from each step is saved as an object along the way.\nfoo_foo &lt;- little_bunny()\nfoo_foo_1 &lt;- hop(foo_foo, through = forest)\nfoo_foo_2 &lt;- scoop(foo_foo_2, up = field_mice)\nfoo_foo_3 &lt;- bop(foo_foo_2, on = head)\nAnother approach is to concatenate the functions so that there is only one output.\nbop(\n   scoop(\n      hop(foo_foo, through = forest),\n      up = field_mice),\n   on = head)\nOr even worse, as one line:\nbop(scoop(hop(foo_foo, through = forest), up = field_mice), on = head)))\nInstead, the code can be written using the pipe in the order in which the function is evaluated:\nfoo_foo %&gt;%\n   hop(through = forest) %&gt;%\n       scoop(up = field_mice) %&gt;%\n           bop(on = head)\nbabynames Each year, the US Social Security Administration publishes a list of the most popular names given to babies. In 2014, http://www.ssa.gov/oact/babynames/#ht=2 shows Emma and Olivia leading for girls, Noah and Liam for boys.\nThe babynames data table in the babynames package comes from the Social Security Administration’s listing of the names givens to babies in each year, and the number of babies of each sex given that name. (Only names with 5 or more babies are published by the SSA.)\n\n\n\n7.1.3 Data Verbs (on single data frames)\n\nSuper important resource: The RStudio dplyr cheat sheet: https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf\n\nData verbs take data tables as input and give data tables as output (that’s how we can use the chaining syntax!). We will use the R package dplyr to do much of our data wrangling. Below is a list of verbs which will be helpful in wrangling many different types of data. See the Data Wrangling cheat sheet from RStudio for additional help. https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf\n\nsample_n() take a random row(s)\nhead() grab the first few rows\ntail() grab the last few rows\nfilter() removes unwanted cases\narrange() reorders the cases\nselect() removes unwanted variables (and rename() )\ndistinct() returns the unique values in a table\nmutate() transforms the variable (and transmute() like mutate, returns only new variables)\ngroup_by() tells R that SUCCESSIVE functions keep in mind that there are groups of items. So group_by() only makes sense with verbs later on (like summarize()).\nsummarize() collapses a data frame to a single row. Some functions that are used within summarize() include:\n\nmin(), max(), mean(), sum(), sd(), median(), and IQR()\nn(): number of observations in the current group\nn_distinct(x): count the number of unique values in x\nfirst_value(x), last_value(x) and nth_value(x, n): work similarly to x[1], x[length(x)], and x[n]",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "07-wrangling.html#r-examples-basic-verbs",
    "href": "07-wrangling.html#r-examples-basic-verbs",
    "title": "7  Data wrangling",
    "section": "7.2 R examples, basic verbs",
    "text": "7.2 R examples, basic verbs\n\n7.2.1 Datasets\nstarwars is from dplyr , although originally from SWAPI, the Star Wars API, http://swapi.co/.\nNHANES From ?NHANES: NHANES is survey data collected by the US National Center for Health Statistics (NCHS) which has conducted a series of health and nutrition surveys since the early 1960’s. Since 1999 approximately 5,000 individuals of all ages are interviewed in their homes every year and complete the health examination component of the survey. The health examination is conducted in a mobile examination center (MEC).\nbabynames Each year, the US Social Security Administration publishes a list of the most popular names given to babies. In 2018, http://www.ssa.gov/oact/babynames/#ht=2 shows Emma and Olivia leading for girls, Noah and Liam for boys. (Only names with 5 or more babies are published by the SSA.)\n\n\n7.2.2 Examples of Chaining\n\nlibrary(babynames)\nbabynames %&gt;% nrow()\n\n[1] 1924665\n\nbabynames %&gt;% names()\n\n[1] \"year\" \"sex\"  \"name\" \"n\"    \"prop\"\n\nbabynames %&gt;% glimpse()\n\nRows: 1,924,665\nColumns: 5\n$ year &lt;dbl&gt; 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880, 1880,…\n$ sex  &lt;chr&gt; \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", …\n$ name &lt;chr&gt; \"Mary\", \"Anna\", \"Emma\", \"Elizabeth\", \"Minnie\", \"Margaret\", \"Ida\",…\n$ n    &lt;int&gt; 7065, 2604, 2003, 1939, 1746, 1578, 1472, 1414, 1320, 1288, 1258,…\n$ prop &lt;dbl&gt; 0.07238359, 0.02667896, 0.02052149, 0.01986579, 0.01788843, 0.016…\n\nbabynames %&gt;% head()\n\n# A tibble: 6 × 5\n   year sex   name          n   prop\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;  &lt;dbl&gt;\n1  1880 F     Mary       7065 0.0724\n2  1880 F     Anna       2604 0.0267\n3  1880 F     Emma       2003 0.0205\n4  1880 F     Elizabeth  1939 0.0199\n5  1880 F     Minnie     1746 0.0179\n6  1880 F     Margaret   1578 0.0162\n\nbabynames %&gt;% tail()\n\n# A tibble: 6 × 5\n   year sex   name       n       prop\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;int&gt;      &lt;dbl&gt;\n1  2017 M     Zyhier     5 0.00000255\n2  2017 M     Zykai      5 0.00000255\n3  2017 M     Zykeem     5 0.00000255\n4  2017 M     Zylin      5 0.00000255\n5  2017 M     Zylis      5 0.00000255\n6  2017 M     Zyrie      5 0.00000255\n\nbabynames %&gt;% sample_n(size=5)\n\n# A tibble: 5 × 5\n   year sex   name         n       prop\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;int&gt;      &lt;dbl&gt;\n1  2007 M     Mateusz     59 0.0000267 \n2  2014 F     Malaia      14 0.00000717\n3  2013 F     Genelle     14 0.00000728\n4  1936 F     Rossetta     6 0.00000557\n5  2010 F     Brynlea      5 0.00000255\n\nbabynames %&gt;% mosaic::favstats(n ~ sex, data = .)\n\n  sex min Q1 median Q3   max     mean       sd       n missing\n1   F   5  7     11 31 99686 151.4294 1180.557 1138293       0\n2   M   5  7     12 33 94756 223.4940 1932.338  786372       0\n\n\n\n\n7.2.3 Data Verbs\nTaken from the dplyr tutorial: http://dplyr.tidyverse.org/\n\n7.2.3.1 Starwars\n\nlibrary(dplyr)\n\nstarwars %&gt;% dim()\n\n[1] 87 14\n\nstarwars %&gt;% names()\n\n [1] \"name\"       \"height\"     \"mass\"       \"hair_color\" \"skin_color\"\n [6] \"eye_color\"  \"birth_year\" \"sex\"        \"gender\"     \"homeworld\" \n[11] \"species\"    \"films\"      \"vehicles\"   \"starships\" \n\nstarwars %&gt;% head()\n\n# A tibble: 6 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Luke Sky…    172    77 blond      fair       blue            19   male  mascu…\n2 C-3PO        167    75 &lt;NA&gt;       gold       yellow         112   none  mascu…\n3 R2-D2         96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n4 Darth Va…    202   136 none       white      yellow          41.9 male  mascu…\n5 Leia Org…    150    49 brown      light      brown           19   fema… femin…\n6 Owen Lars    178   120 brown, gr… light      blue            52   male  mascu…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\nstarwars %&gt;%\n  mosaic::favstats(mass~gender, data = .)\n\n     gender min   Q1 median   Q3  max      mean         sd  n missing\n1  feminine  45 50.0     55 56.2   75  54.68889   8.591921  9       8\n2 masculine  15 74.5     80 87.5 1358 106.51489 188.924092 47      19\n\nstarwars %&gt;% \n  dplyr::filter(species == \"Droid\")\n\n# A tibble: 6 × 14\n  name   height  mass hair_color skin_color  eye_color birth_year sex   gender  \n  &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   \n1 C-3PO     167    75 &lt;NA&gt;       gold        yellow           112 none  masculi…\n2 R2-D2      96    32 &lt;NA&gt;       white, blue red               33 none  masculi…\n3 R5-D4      97    32 &lt;NA&gt;       white, red  red               NA none  masculi…\n4 IG-88     200   140 none       metal       red               15 none  masculi…\n5 R4-P17     96    NA none       silver, red red, blue         NA none  feminine\n6 BB8        NA    NA none       none        black             NA none  masculi…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\nstarwars %&gt;% \n  dplyr::filter(species != \"Droid\") %&gt;%\n  mosaic::favstats(mass~gender, data = .)\n\n     gender min Q1 median   Q3  max      mean         sd  n missing\n1  feminine  45 50     55 56.2   75  54.68889   8.591921  9       7\n2 masculine  15 76     80 87.5 1358 109.93488 196.887934 43      18\n\nstarwars %&gt;% \n  dplyr::select(name, ends_with(\"color\"))\n\n# A tibble: 87 × 4\n   name               hair_color    skin_color  eye_color\n   &lt;chr&gt;              &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;    \n 1 Luke Skywalker     blond         fair        blue     \n 2 C-3PO              &lt;NA&gt;          gold        yellow   \n 3 R2-D2              &lt;NA&gt;          white, blue red      \n 4 Darth Vader        none          white       yellow   \n 5 Leia Organa        brown         light       brown    \n 6 Owen Lars          brown, grey   light       blue     \n 7 Beru Whitesun Lars brown         light       blue     \n 8 R5-D4              &lt;NA&gt;          white, red  red      \n 9 Biggs Darklighter  black         light       brown    \n10 Obi-Wan Kenobi     auburn, white fair        blue-gray\n# ℹ 77 more rows\n\nstarwars %&gt;% \n  dplyr::mutate(name, bmi = mass / ((height / 100)  ^ 2)) %&gt;%\n  dplyr::select(name:mass, bmi)\n\n# A tibble: 87 × 4\n   name               height  mass   bmi\n   &lt;chr&gt;               &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Luke Skywalker        172    77  26.0\n 2 C-3PO                 167    75  26.9\n 3 R2-D2                  96    32  34.7\n 4 Darth Vader           202   136  33.3\n 5 Leia Organa           150    49  21.8\n 6 Owen Lars             178   120  37.9\n 7 Beru Whitesun Lars    165    75  27.5\n 8 R5-D4                  97    32  34.0\n 9 Biggs Darklighter     183    84  25.1\n10 Obi-Wan Kenobi        182    77  23.2\n# ℹ 77 more rows\n\nstarwars %&gt;% \n  dplyr::arrange(desc(mass))\n\n# A tibble: 87 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Jabba D…    175  1358 &lt;NA&gt;       green-tan… orange         600   herm… mascu…\n 2 Grievous    216   159 none       brown, wh… green, y…       NA   male  mascu…\n 3 IG-88       200   140 none       metal      red             15   none  mascu…\n 4 Darth V…    202   136 none       white      yellow          41.9 male  mascu…\n 5 Tarfful     234   136 brown      brown      blue            NA   male  mascu…\n 6 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…\n 7 Bossk       190   113 none       green      red             53   male  mascu…\n 8 Chewbac…    228   112 brown      unknown    blue           200   male  mascu…\n 9 Jek Ton…    180   110 brown      fair       blue            NA   &lt;NA&gt;  &lt;NA&gt;  \n10 Dexter …    198   102 none       brown      yellow          NA   male  mascu…\n# ℹ 77 more rows\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\nstarwars %&gt;%\n  dplyr::group_by(species) %&gt;%\n  dplyr::summarize(\n    num = n(),\n    mass = mean(mass, na.rm = TRUE)\n  ) %&gt;%\n  dplyr::filter(num &gt; 1)\n\n# A tibble: 9 × 3\n  species    num  mass\n  &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt;\n1 Droid        6  69.8\n2 Gungan       3  74  \n3 Human       35  81.3\n4 Kaminoan     2  88  \n5 Mirialan     2  53.1\n6 Twi'lek      2  55  \n7 Wookiee      2 124  \n8 Zabrak       2  80  \n9 &lt;NA&gt;         4  81  \n\n\n\n\n7.2.3.2 NHANES\n\nrequire(NHANES)\nnames(NHANES)\n\n [1] \"ID\"               \"SurveyYr\"         \"Gender\"           \"Age\"             \n [5] \"AgeDecade\"        \"AgeMonths\"        \"Race1\"            \"Race3\"           \n [9] \"Education\"        \"MaritalStatus\"    \"HHIncome\"         \"HHIncomeMid\"     \n[13] \"Poverty\"          \"HomeRooms\"        \"HomeOwn\"          \"Work\"            \n[17] \"Weight\"           \"Length\"           \"HeadCirc\"         \"Height\"          \n[21] \"BMI\"              \"BMICatUnder20yrs\" \"BMI_WHO\"          \"Pulse\"           \n[25] \"BPSysAve\"         \"BPDiaAve\"         \"BPSys1\"           \"BPDia1\"          \n[29] \"BPSys2\"           \"BPDia2\"           \"BPSys3\"           \"BPDia3\"          \n[33] \"Testosterone\"     \"DirectChol\"       \"TotChol\"          \"UrineVol1\"       \n[37] \"UrineFlow1\"       \"UrineVol2\"        \"UrineFlow2\"       \"Diabetes\"        \n[41] \"DiabetesAge\"      \"HealthGen\"        \"DaysPhysHlthBad\"  \"DaysMentHlthBad\" \n[45] \"LittleInterest\"   \"Depressed\"        \"nPregnancies\"     \"nBabies\"         \n[49] \"Age1stBaby\"       \"SleepHrsNight\"    \"SleepTrouble\"     \"PhysActive\"      \n[53] \"PhysActiveDays\"   \"TVHrsDay\"         \"CompHrsDay\"       \"TVHrsDayChild\"   \n[57] \"CompHrsDayChild\"  \"Alcohol12PlusYr\"  \"AlcoholDay\"       \"AlcoholYear\"     \n[61] \"SmokeNow\"         \"Smoke100\"         \"Smoke100n\"        \"SmokeAge\"        \n[65] \"Marijuana\"        \"AgeFirstMarij\"    \"RegularMarij\"     \"AgeRegMarij\"     \n[69] \"HardDrugs\"        \"SexEver\"          \"SexAge\"           \"SexNumPartnLife\" \n[73] \"SexNumPartYear\"   \"SameSex\"          \"SexOrientation\"   \"PregnantNow\"     \n\n# find the sleep variables\nNHANESsleep &lt;- NHANES %&gt;% select(Gender, Age, Weight, Race1, Race3, \n                                 Education, SleepTrouble, SleepHrsNight, \n                                 TVHrsDay, TVHrsDayChild, PhysActive)\nnames(NHANESsleep)\n\n [1] \"Gender\"        \"Age\"           \"Weight\"        \"Race1\"        \n [5] \"Race3\"         \"Education\"     \"SleepTrouble\"  \"SleepHrsNight\"\n [9] \"TVHrsDay\"      \"TVHrsDayChild\" \"PhysActive\"   \n\ndim(NHANESsleep)\n\n[1] 10000    11\n\n# subset for college students\nNHANESsleep &lt;- NHANESsleep %&gt;% filter(Age %in% c(18:22)) %&gt;% \n  mutate(Weightlb = Weight*2.2)\n\nnames(NHANESsleep)\n\n [1] \"Gender\"        \"Age\"           \"Weight\"        \"Race1\"        \n [5] \"Race3\"         \"Education\"     \"SleepTrouble\"  \"SleepHrsNight\"\n [9] \"TVHrsDay\"      \"TVHrsDayChild\" \"PhysActive\"    \"Weightlb\"     \n\ndim(NHANESsleep)\n\n[1] 655  12\n\nNHANESsleep %&gt;% ggplot(aes(x=Age, y=SleepHrsNight, color=Gender)) + \n  geom_point(position=position_jitter(width=.25, height=0) ) + \n  facet_grid(SleepTrouble ~ TVHrsDay) \n\n\n\n\n\n\n\n\n\n\n\n7.2.4 summarize and group_by\n\n# number of people (cases) in NHANES\nNHANES %&gt;% summarize(n())\n\n# A tibble: 1 × 1\n  `n()`\n  &lt;int&gt;\n1 10000\n\n# total weight of all the people in NHANES (silly)\nNHANES %&gt;% mutate(Weightlb = Weight*2.2) %&gt;% summarize(sum(Weightlb, na.rm=TRUE))\n\n# A tibble: 1 × 1\n  `sum(Weightlb, na.rm = TRUE)`\n                          &lt;dbl&gt;\n1                      1549419.\n\n# mean weight of all the people in NHANES\nNHANES %&gt;% mutate(Weightlb = Weight*2.2) %&gt;% summarize(mean(Weightlb, na.rm=TRUE))\n\n# A tibble: 1 × 1\n  `mean(Weightlb, na.rm = TRUE)`\n                           &lt;dbl&gt;\n1                           156.\n\n# repeat the above but for groups\n\n# males versus females\nNHANES %&gt;% group_by(Gender) %&gt;% summarize(n())\n\n# A tibble: 2 × 2\n  Gender `n()`\n  &lt;fct&gt;  &lt;int&gt;\n1 female  5020\n2 male    4980\n\nNHANES %&gt;% group_by(Gender) %&gt;% mutate(Weightlb = Weight*2.2) %&gt;% \n  summarize(mean(Weightlb, na.rm=TRUE))\n\n# A tibble: 2 × 2\n  Gender `mean(Weightlb, na.rm = TRUE)`\n  &lt;fct&gt;                           &lt;dbl&gt;\n1 female                           146.\n2 male                             167.\n\n# smokers and non-smokers\nNHANES %&gt;% group_by(SmokeNow) %&gt;% summarize(n())\n\n# A tibble: 3 × 2\n  SmokeNow `n()`\n  &lt;fct&gt;    &lt;int&gt;\n1 No        1745\n2 Yes       1466\n3 &lt;NA&gt;      6789\n\nNHANES %&gt;% group_by(SmokeNow) %&gt;% mutate(Weightlb = Weight*2.2) %&gt;% \n  summarize(mean(Weightlb, na.rm=TRUE))\n\n# A tibble: 3 × 2\n  SmokeNow `mean(Weightlb, na.rm = TRUE)`\n  &lt;fct&gt;                             &lt;dbl&gt;\n1 No                                 186.\n2 Yes                                177.\n3 &lt;NA&gt;                               144.\n\n# people with and without diabetes\nNHANES %&gt;% group_by(Diabetes) %&gt;% summarize(n())\n\n# A tibble: 3 × 2\n  Diabetes `n()`\n  &lt;fct&gt;    &lt;int&gt;\n1 No        9098\n2 Yes        760\n3 &lt;NA&gt;       142\n\nNHANES %&gt;% group_by(Diabetes) %&gt;% mutate(Weightlb = Weight*2.2) %&gt;% \n  summarize(mean(Weightlb, na.rm=TRUE))\n\n# A tibble: 3 × 2\n  Diabetes `mean(Weightlb, na.rm = TRUE)`\n  &lt;fct&gt;                             &lt;dbl&gt;\n1 No                                155. \n2 Yes                               202. \n3 &lt;NA&gt;                               21.6\n\n# break down the smokers versus non-smokers further, by sex\nNHANES %&gt;% group_by(SmokeNow, Gender) %&gt;% summarize(n())\n\n# A tibble: 6 × 3\n# Groups:   SmokeNow [3]\n  SmokeNow Gender `n()`\n  &lt;fct&gt;    &lt;fct&gt;  &lt;int&gt;\n1 No       female   764\n2 No       male     981\n3 Yes      female   638\n4 Yes      male     828\n5 &lt;NA&gt;     female  3618\n6 &lt;NA&gt;     male    3171\n\nNHANES %&gt;% group_by(SmokeNow, Gender) %&gt;% mutate(Weightlb = Weight*2.2) %&gt;% \n  summarize(mean(Weightlb, na.rm=TRUE))\n\n# A tibble: 6 × 3\n# Groups:   SmokeNow [3]\n  SmokeNow Gender `mean(Weightlb, na.rm = TRUE)`\n  &lt;fct&gt;    &lt;fct&gt;                           &lt;dbl&gt;\n1 No       female                           167.\n2 No       male                             201.\n3 Yes      female                           167.\n4 Yes      male                             185.\n5 &lt;NA&gt;     female                           138.\n6 &lt;NA&gt;     male                             151.\n\n# break down the people with diabetes further, by smoking\nNHANES %&gt;% group_by(Diabetes, SmokeNow) %&gt;% summarize(n())\n\n# A tibble: 8 × 3\n# Groups:   Diabetes [3]\n  Diabetes SmokeNow `n()`\n  &lt;fct&gt;    &lt;fct&gt;    &lt;int&gt;\n1 No       No        1476\n2 No       Yes       1360\n3 No       &lt;NA&gt;      6262\n4 Yes      No         267\n5 Yes      Yes        106\n6 Yes      &lt;NA&gt;       387\n7 &lt;NA&gt;     No           2\n8 &lt;NA&gt;     &lt;NA&gt;       140\n\nNHANES %&gt;% group_by(Diabetes, SmokeNow) %&gt;% mutate(Weightlb = Weight*2.2) %&gt;% \n  summarize(mean(Weightlb, na.rm=TRUE))\n\n# A tibble: 8 × 3\n# Groups:   Diabetes [3]\n  Diabetes SmokeNow `mean(Weightlb, na.rm = TRUE)`\n  &lt;fct&gt;    &lt;fct&gt;                             &lt;dbl&gt;\n1 No       No                                183. \n2 No       Yes                               175. \n3 No       &lt;NA&gt;                              143. \n4 Yes      No                                204. \n5 Yes      Yes                               204. \n6 Yes      &lt;NA&gt;                              199. \n7 &lt;NA&gt;     No                                193. \n8 &lt;NA&gt;     &lt;NA&gt;                               19.1\n\n\n\n\n7.2.5 babynames\n\nbabynames %&gt;% group_by(sex) %&gt;%\n  summarize(total=sum(n))\n\n# A tibble: 2 × 2\n  sex       total\n  &lt;chr&gt;     &lt;int&gt;\n1 F     172371079\n2 M     175749438\n\nbabynames %&gt;% group_by(year, sex) %&gt;%\n  summarize(name_count = n_distinct(name)) %&gt;% head()\n\n# A tibble: 6 × 3\n# Groups:   year [3]\n   year sex   name_count\n  &lt;dbl&gt; &lt;chr&gt;      &lt;int&gt;\n1  1880 F            942\n2  1880 M           1058\n3  1881 F            938\n4  1881 M            997\n5  1882 F           1028\n6  1882 M           1099\n\nbabynames %&gt;% group_by(year, sex) %&gt;%\n  summarize(name_count = n_distinct(name)) %&gt;% tail()\n\n# A tibble: 6 × 3\n# Groups:   year [3]\n   year sex   name_count\n  &lt;dbl&gt; &lt;chr&gt;      &lt;int&gt;\n1  2015 F          19074\n2  2015 M          14024\n3  2016 F          18817\n4  2016 M          14162\n5  2017 F          18309\n6  2017 M          14160\n\nbabysamp &lt;- babynames %&gt;% sample_n(size=50)\nbabysamp %&gt;% select(year) %&gt;% distinct() %&gt;% table()\n\nyear\n1885 1893 1897 1929 1934 1937 1945 1946 1948 1952 1958 1960 1963 1964 1967 1975 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1976 1981 1983 1984 1985 1986 1987 1990 1991 1992 1996 1997 1998 1999 2003 2004 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n2007 2008 2009 2011 2015 \n   1    1    1    1    1 \n\nbabysamp %&gt;% distinct() %&gt;% select(year) %&gt;% table()\n\nyear\n1885 1893 1897 1929 1934 1937 1945 1946 1948 1952 1958 1960 1963 1964 1967 1975 \n   1    1    1    1    1    1    1    2    1    2    1    1    1    1    2    1 \n1976 1981 1983 1984 1985 1986 1987 1990 1991 1992 1996 1997 1998 1999 2003 2004 \n   2    1    2    1    1    1    1    2    1    2    1    2    1    1    2    2 \n2007 2008 2009 2011 2015 \n   4    1    1    1    1 \n\nFrances &lt;- babynames %&gt;%\n  filter(name== \"Frances\") %&gt;%\n  group_by(year, sex) %&gt;%\n  summarize(yrTot = sum(n))\n\nFrances %&gt;% ggplot(aes(x=year, y=yrTot)) +\n  geom_point(aes(color=sex)) + \n  geom_vline(xintercept=2006) + scale_y_log10() +\n  ylab(\"Yearly total on log10 scale\")",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "07-wrangling.html#highverb",
    "href": "07-wrangling.html#highverb",
    "title": "7  Data wrangling",
    "section": "7.3 Higher Level Data Verbs",
    "text": "7.3 Higher Level Data Verbs\nThere are more complicated verbs which may be important for more sophisticated analyses. See the RStudio dplyr cheat sheet, https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf}.\n\npivot_longer makes many columns into 2 columns: pivot_longer(data, cols,  names_to = , value_to = )\npivot_wider makes one column into multiple columns: pivot_wider(data, names_from = , values_from = )\nleft_join returns all rows from the left table, and any rows with matching keys from the right table.\ninner_join returns only the rows in which the left table have matching keys in the right table (i.e., matching rows in both sets).\nfull_join returns all rows from both tables, join records from the left which have matching keys in the right table.\n\nGood practice: always specify the by argument when joining data frames.\n\n\n\nIf you ever need to understand which join is the right join for you, try to find an image that will lay out what the function is doing. I found this one that is quite good and is taken from Statistics Globe blog: https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "07-wrangling.html#r-examples-higher-level-verbs",
    "href": "07-wrangling.html#r-examples-higher-level-verbs",
    "title": "7  Data wrangling",
    "section": "7.4 R examples, higher level verbs",
    "text": "7.4 R examples, higher level verbs\n\ntidyr 1.0.0 has just been released! The new release means that you need to update tidyr. You will know if you have the latest version if the following command works in the console (window below):\n?tidyr::pivot_longer\nIf you are familiar with spread and gather, you should acquaint yourself with pivot_longer() and pivot_wider(). The idea is to go from very wide dataframes to very long dataframes and vice versa.\n\n7.4.1 pivot_longer()\npivot the military pay grade to become longer?\n\n\n\nhttps://docs.google.com/spreadsheets/d/1Ow6Cm4z-Z1Yybk3i352msulYCEDOUaOghmo9ALajyHo/edit# gid=1811988794\n\n\n\nlibrary(googlesheets4)\ngs4_deauth()\n\nnavy_gs = read_sheet(\"https://docs.google.com/spreadsheets/d/1Ow6Cm4z-Z1Yybk3i352msulYCEDOUaOghmo9ALajyHo/edit#gid=1877566408\", \n                     col_types = \"ccnnnnnnnnnnnnnnn\")\n\n\nglimpse(navy_gs)\n\nRows: 38\nColumns: 17\n$ ...1                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ `Active Duty Family` &lt;chr&gt; NA, \"Marital Status Report\", NA, \"Data Reflect Se…\n$ ...3                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 31229, 53094, 131…\n$ ...4                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 5717, 8388, 21019…\n$ ...5                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 36946, 61482, 152…\n$ ...6                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 563, 1457, 4264, …\n$ ...7                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 122, 275, 1920, 4…\n$ ...8                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 685, 1732, 6184, …\n$ ...9                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 139, 438, 3579, 8…\n$ ...10                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 141, 579, 4902, 9…\n$ ...11                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 280, 1017, 8481, …\n$ ...12                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 5060, 12483, 5479…\n$ ...13                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 719, 1682, 6641, …\n$ ...14                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 5779, 14165, 6143…\n$ ...15                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 36991, 67472, 193…\n$ ...16                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 6699, 10924, 3448…\n$ ...17                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 43690, 78396, 228…\n\nnames(navy_gs) = c(\"X\",\"pay.grade\", \"male.sing.wo\", \"female.sing.wo\",\n                   \"tot.sing.wo\", \"male.sing.w\", \"female.sing.w\", \n                   \"tot.sing.w\", \"male.joint.NA\", \"female.joint.NA\",\n                   \"tot.joint.NA\", \"male.civ.NA\", \"female.civ.NA\",\n                   \"tot.civ.NA\", \"male.tot.NA\", \"female.tot.NA\", \n                   \"tot.tot.NA\")\nnavy = navy_gs[-c(1:8), -1]\ndplyr::glimpse(navy)\n\nRows: 30\nColumns: 16\n$ pay.grade       &lt;chr&gt; \"E-1\", \"E-2\", \"E-3\", \"E-4\", \"E-5\", \"E-6\", \"E-7\", \"E-8\"…\n$ male.sing.wo    &lt;dbl&gt; 31229, 53094, 131091, 112710, 57989, 19125, 5446, 1009…\n$ female.sing.wo  &lt;dbl&gt; 5717, 8388, 21019, 16381, 11021, 4654, 1913, 438, 202,…\n$ tot.sing.wo     &lt;dbl&gt; 36946, 61482, 152110, 129091, 69010, 23779, 7359, 1447…\n$ male.sing.w     &lt;dbl&gt; 563, 1457, 4264, 9491, 10937, 10369, 6530, 1786, 579, …\n$ female.sing.w   &lt;dbl&gt; 122, 275, 1920, 4662, 6576, 4962, 2585, 513, 144, 2175…\n$ tot.sing.w      &lt;dbl&gt; 685, 1732, 6184, 14153, 17513, 15331, 9115, 2299, 723,…\n$ male.joint.NA   &lt;dbl&gt; 139, 438, 3579, 8661, 12459, 8474, 5065, 1423, 458, 40…\n$ female.joint.NA &lt;dbl&gt; 141, 579, 4902, 9778, 11117, 6961, 3291, 651, 150, 375…\n$ tot.joint.NA    &lt;dbl&gt; 280, 1017, 8481, 18439, 23576, 15435, 8356, 2074, 608,…\n$ male.civ.NA     &lt;dbl&gt; 5060, 12483, 54795, 105556, 130944, 110322, 70001, 210…\n$ female.civ.NA   &lt;dbl&gt; 719, 1682, 6641, 9961, 8592, 5827, 3206, 820, 291, 377…\n$ tot.civ.NA      &lt;dbl&gt; 5779, 14165, 61436, 115517, 139536, 116149, 73207, 218…\n$ male.tot.NA     &lt;dbl&gt; 36991, 67472, 193729, 236418, 212329, 148290, 87042, 2…\n$ female.tot.NA   &lt;dbl&gt; 6699, 10924, 34482, 40782, 37306, 22404, 10995, 2422, …\n$ tot.tot.NA      &lt;dbl&gt; 43690, 78396, 228211, 277200, 249635, 170694, 98037, 2…\n\n# get rid of total columns & rows:\n\nnavyWR = navy %&gt;% select(-contains(\"tot\")) %&gt;%\n   filter(substr(pay.grade, 1, 5) != \"TOTAL\" & \n                   substr(pay.grade, 1, 5) != \"GRAND\" ) %&gt;%\n   pivot_longer(-pay.grade, \n                       values_to = \"numPeople\", \n                       names_to = \"status\") %&gt;%\n   separate(status, into = c(\"sex\", \"marital\", \"kids\"))\n\nnavyWR %&gt;% head()\n\n# A tibble: 6 × 5\n  pay.grade sex    marital kids  numPeople\n  &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt;\n1 E-1       male   sing    wo        31229\n2 E-1       female sing    wo         5717\n3 E-1       male   sing    w           563\n4 E-1       female sing    w           122\n5 E-1       male   joint   NA          139\n6 E-1       female joint   NA          141\n\n\nDoes a graph tell us if we did it right? what if we had done it wrong…?\n\nnavyWR %&gt;% ggplot(aes(x=pay.grade, y=numPeople, color=sex)) + \n  geom_point()  + \n  facet_grid(kids ~ marital) +\n  theme_minimal() +\n  scale_color_viridis_d() +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, \n                                   hjust = 1, size = rel(.5)))\n\n\n\n\n\n\n\n\n\n\n7.4.2 pivot_wider\n\nlibrary(babynames)\nbabynames %&gt;% dplyr::select(-prop) %&gt;%\n   tidyr::pivot_wider(names_from = sex, values_from = n) \n\n# A tibble: 1,756,284 × 4\n    year name          F     M\n   &lt;dbl&gt; &lt;chr&gt;     &lt;int&gt; &lt;int&gt;\n 1  1880 Mary       7065    27\n 2  1880 Anna       2604    12\n 3  1880 Emma       2003    10\n 4  1880 Elizabeth  1939     9\n 5  1880 Minnie     1746     9\n 6  1880 Margaret   1578    NA\n 7  1880 Ida        1472     8\n 8  1880 Alice      1414    NA\n 9  1880 Bertha     1320    NA\n10  1880 Sarah      1288    NA\n# ℹ 1,756,274 more rows\n\n\n\nbabynames %&gt;% \n  select(-prop) %&gt;% \n  pivot_wider(names_from = sex, values_from = n) %&gt;%\n  filter(!is.na(F) & !is.na(M)) %&gt;%\n  arrange(desc(year), desc(M))\n\n# A tibble: 168,381 × 4\n    year name         F     M\n   &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt; &lt;int&gt;\n 1  2017 Liam        36 18728\n 2  2017 Noah       170 18326\n 3  2017 William     18 14904\n 4  2017 James       77 14232\n 5  2017 Logan     1103 13974\n 6  2017 Benjamin     8 13733\n 7  2017 Mason       58 13502\n 8  2017 Elijah      26 13268\n 9  2017 Oliver      15 13141\n10  2017 Jacob       16 13106\n# ℹ 168,371 more rows\n\n\n\nbabynames %&gt;% \n  pivot_wider(names_from = sex, values_from = n) %&gt;%\n  filter(!is.na(F) & !is.na(M)) %&gt;%\n  arrange(desc(prop))\n\n# A tibble: 12 × 5\n    year name            prop     F     M\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt; &lt;int&gt;\n 1  1986 Marquette 0.0000130     24    25\n 2  1996 Dariel    0.0000115     22    23\n 3  2014 Laramie   0.0000108     21    22\n 4  1939 Earnie    0.00000882    10    10\n 5  1939 Vertis    0.00000882    10    10\n 6  1921 Vernis    0.00000703     9     8\n 7  1939 Alvia     0.00000529     6     6\n 8  1939 Eudell    0.00000529     6     6\n 9  1939 Ladell    0.00000529     6     6\n10  1939 Lory      0.00000529     6     6\n11  1939 Maitland  0.00000529     6     6\n12  1939 Delaney   0.00000441     5     5\n\n\n\n\n7.4.3 join (use join to merge two datasets)\n\n7.4.3.1 First get the data (GapMinder)\nBoth of the following datasets come from GapMinder. The first represents country, year, and female literacy rate. The second represents country, year, and GDP (in fixed 2000 US$).\n\ngs4_deauth()\nlitF = read_sheet(\"https://docs.google.com/spreadsheets/d/1hDinTIRHQIaZg1RUn6Z_6mo12PtKwEPFIz_mJVF6P5I/pub?gid=0\")\n\nlitF = litF %&gt;% select(country=starts_with(\"Adult\"), \n                              starts_with(\"1\"), starts_with(\"2\")) %&gt;%\n  pivot_longer(-country, \n                      names_to = \"year\", \n                      values_to = \"litRateF\") %&gt;%\n  filter(!is.na(litRateF))\n\n\ngs4_deauth()\nGDP = read_sheet(\"https://docs.google.com/spreadsheets/d/1RctTQmKB0hzbm1E8rGcufYdMshRdhmYdeL29nXqmvsc/pub?gid=0\")\n\nGDP = GDP %&gt;% select(country = starts_with(\"Income\"), \n                            starts_with(\"1\"), starts_with(\"2\")) %&gt;%\n  pivot_longer(-country, \n                      names_to = \"year\", \n                      values_to = \"gdp\") %&gt;%\n  filter(!is.na(gdp))\n\n\nhead(litF)\n\n# A tibble: 6 × 3\n  country     year  litRateF\n  &lt;chr&gt;       &lt;chr&gt;    &lt;dbl&gt;\n1 Afghanistan 1979      4.99\n2 Afghanistan 2011     13   \n3 Albania     2001     98.3 \n4 Albania     2008     94.7 \n5 Albania     2011     95.7 \n6 Algeria     1987     35.8 \n\nhead(GDP)\n\n# A tibble: 6 × 3\n  country year    gdp\n  &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;\n1 Albania 1980  1061.\n2 Albania 1981  1100.\n3 Albania 1982  1111.\n4 Albania 1983  1101.\n5 Albania 1984  1065.\n6 Albania 1985  1060.\n\n# left\nlitGDPleft = left_join(litF, GDP, by=c(\"country\", \"year\"))\ndim(litGDPleft)\n\n[1] 571   4\n\nsum(is.na(litGDPleft$gdp))\n\n[1] 66\n\nhead(litGDPleft)\n\n# A tibble: 6 × 4\n  country     year  litRateF   gdp\n  &lt;chr&gt;       &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 Afghanistan 1979      4.99   NA \n2 Afghanistan 2011     13      NA \n3 Albania     2001     98.3  1282.\n4 Albania     2008     94.7  1804.\n5 Albania     2011     95.7  1966.\n6 Algeria     1987     35.8  1902.\n\n# right\nlitGDPright = right_join(litF, GDP, by=c(\"country\", \"year\"))\ndim(litGDPright)\n\n[1] 7988    4\n\nsum(is.na(litGDPright$gdp))\n\n[1] 0\n\nhead(litGDPright)\n\n# A tibble: 6 × 4\n  country year  litRateF   gdp\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 Albania 2001      98.3 1282.\n2 Albania 2008      94.7 1804.\n3 Albania 2011      95.7 1966.\n4 Algeria 1987      35.8 1902.\n5 Algeria 2002      60.1 1872.\n6 Algeria 2006      63.9 2125.\n\n# inner\nlitGDPinner = inner_join(litF, GDP, by=c(\"country\", \"year\"))\ndim(litGDPinner)\n\n[1] 505   4\n\nsum(is.na(litGDPinner$gdp))\n\n[1] 0\n\nhead(litGDPinner)\n\n# A tibble: 6 × 4\n  country year  litRateF   gdp\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 Albania 2001      98.3 1282.\n2 Albania 2008      94.7 1804.\n3 Albania 2011      95.7 1966.\n4 Algeria 1987      35.8 1902.\n5 Algeria 2002      60.1 1872.\n6 Algeria 2006      63.9 2125.\n\n# full\nlitGDPfull = full_join(litF, GDP, by=c(\"country\", \"year\"))\ndim(litGDPfull)\n\n[1] 8054    4\n\nsum(is.na(litGDPfull$gdp))\n\n[1] 66\n\nhead(litGDPfull)\n\n# A tibble: 6 × 4\n  country     year  litRateF   gdp\n  &lt;chr&gt;       &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 Afghanistan 1979      4.99   NA \n2 Afghanistan 2011     13      NA \n3 Albania     2001     98.3  1282.\n4 Albania     2008     94.7  1804.\n5 Albania     2011     95.7  1966.\n6 Algeria     1987     35.8  1902.\n\n\n\n\n\n7.4.4 lubridate\nlubridate is a another R package meant for data wrangling (Grolemund and Wickham 2011). In particular, lubridate makes it very easy to work with days, times, and dates. The base idea is to start with dates in a ymd (year month day) format and transform the information into whatever you want. The linked table is from the original paper and provides many of the basic lubridate commands: http://blog.yhathq.com/static/pdf/R_date_cheat_sheet.pdf}.\nExample from https://cran.r-project.org/web/packages/lubridate/vignettes/lubridate.html\n\n7.4.4.1 If anyone drove a time machine, they would crash\nThe length of months and years change so often that doing arithmetic with them can be unintuitive. Consider a simple operation, January 31st + one month. Should the answer be:\n\nFebruary 31st (which doesn’t exist)\nMarch 4th (31 days after January 31), or\nFebruary 28th (assuming its not a leap year)\n\nA basic property of arithmetic is that a + b - b = a. Only solution 1 obeys the mathematical property, but it is an invalid date. Wickham wants to make lubridate as consistent as possible by invoking the following rule: if adding or subtracting a month or a year creates an invalid date, lubridate will return an NA.\nIf you thought solution 2 or 3 was more useful, no problem. You can still get those results with clever arithmetic, or by using the special %m+% and %m-% operators. %m+% and %m-% automatically roll dates back to the last day of the month, should that be necessary.\n\n\n7.4.4.2 R examples, lubridate()\n\nSome basics in lubridate\n\nrequire(lubridate)\nrightnow &lt;- now()\n\nday(rightnow)\n\n[1] 25\n\nweek(rightnow)\n\n[1] 34\n\nmonth(rightnow, label=FALSE)\n\n[1] 8\n\nmonth(rightnow, label=TRUE)\n\n[1] Aug\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\nyear(rightnow)\n\n[1] 2024\n\nminute(rightnow)\n\n[1] 15\n\nhour(rightnow)\n\n[1] 20\n\nyday(rightnow)\n\n[1] 238\n\nmday(rightnow)\n\n[1] 25\n\nwday(rightnow, label=FALSE)\n\n[1] 1\n\nwday(rightnow, label=TRUE)\n\n[1] Sun\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n\n\n\n\nBut how do I create a date object?\n\njan31 &lt;- ymd(\"2021-01-31\")\njan31 + months(0:11)\n\n [1] \"2021-01-31\" NA           \"2021-03-31\" NA           \"2021-05-31\"\n [6] NA           \"2021-07-31\" \"2021-08-31\" NA           \"2021-10-31\"\n[11] NA           \"2021-12-31\"\n\nfloor_date(jan31, \"month\") + months(0:11) + days(31)\n\n [1] \"2021-02-01\" \"2021-03-04\" \"2021-04-01\" \"2021-05-02\" \"2021-06-01\"\n [6] \"2021-07-02\" \"2021-08-01\" \"2021-09-01\" \"2021-10-02\" \"2021-11-01\"\n[11] \"2021-12-02\" \"2022-01-01\"\n\njan31 + months(0:11) + days(31)\n\n [1] \"2021-03-03\" NA           \"2021-05-01\" NA           \"2021-07-01\"\n [6] NA           \"2021-08-31\" \"2021-10-01\" NA           \"2021-12-01\"\n[11] NA           \"2022-01-31\"\n\njan31 %m+% months(0:11)\n\n [1] \"2021-01-31\" \"2021-02-28\" \"2021-03-31\" \"2021-04-30\" \"2021-05-31\"\n [6] \"2021-06-30\" \"2021-07-31\" \"2021-08-31\" \"2021-09-30\" \"2021-10-31\"\n[11] \"2021-11-30\" \"2021-12-31\"\n\n\n\n\nNYC flights\n\nlibrary(nycflights13)\nnames(flights)\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\"     \n\nflightsWK &lt;- flights %&gt;% \n   mutate(ymdday = ymd(paste(year, month,day, sep=\"-\"))) %&gt;%\n   mutate(weekdy = wday(ymdday, label=TRUE), \n          whichweek = week(ymdday))\n\nhead(flightsWK)\n\n# A tibble: 6 × 22\n   year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n1  2013     1     1      517            515         2      830            819\n2  2013     1     1      533            529         4      850            830\n3  2013     1     1      542            540         2      923            850\n4  2013     1     1      544            545        -1     1004           1022\n5  2013     1     1      554            600        -6      812            837\n6  2013     1     1      554            558        -4      740            728\n# ℹ 14 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, ymdday &lt;date&gt;, weekdy &lt;ord&gt;,\n#   whichweek &lt;dbl&gt;\n\nflightsWK &lt;- flights %&gt;% \n   mutate(ymdday = ymd(paste(year,\"-\", month,\"-\",day))) %&gt;%\n   mutate(weekdy = wday(ymdday, label=TRUE), whichweek = week(ymdday))\n\nflightsWK %&gt;% select(year, month, day, ymdday, weekdy, whichweek, dep_time, \n                     arr_time, air_time) %&gt;%  \n   head()\n\n# A tibble: 6 × 9\n   year month   day ymdday     weekdy whichweek dep_time arr_time air_time\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;date&gt;     &lt;ord&gt;      &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;    &lt;dbl&gt;\n1  2013     1     1 2013-01-01 Tue            1      517      830      227\n2  2013     1     1 2013-01-01 Tue            1      533      850      227\n3  2013     1     1 2013-01-01 Tue            1      542      923      160\n4  2013     1     1 2013-01-01 Tue            1      544     1004      183\n5  2013     1     1 2013-01-01 Tue            1      554      812      116\n6  2013     1     1 2013-01-01 Tue            1      554      740      150",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "07-wrangling.html#purrr-for-functional-programming",
    "href": "07-wrangling.html#purrr-for-functional-programming",
    "title": "7  Data wrangling",
    "section": "7.5 purrr for functional programming",
    "text": "7.5 purrr for functional programming\nWe will see the R package purrr in greater detail as we go, but for now, let’s get a hint for how it works.\nWe are going to focus on the map family of functions which will just get us started. Lots of other good purrr functions like pluck() and accumulate().\nMuch of below is taken from a tutorial by Rebecca Barter.\nThe map functions are named by the output the produce. For example:\n\nmap(.x, .f) is the main mapping function and returns a list\nmap_df(.x, .f) returns a data frame\nmap_dbl(.x, .f) returns a numeric (double) vector\nmap_chr(.x, .f) returns a character vector\nmap_lgl(.x, .f) returns a logical vector\n\nNote that the first argument is always the data object and the second object is always the function you want to iteratively apply to each element in the input object.\nThe input to a map function is always either a vector (like a column), a list (which can be non-rectangular), or a dataframe (like a rectangle).\nA list is a way to hold things which might be very different in shape:\n\na_list &lt;- list(a_number = 5,\n                      a_vector = c(\"a\", \"b\", \"c\"),\n                      a_dataframe = data.frame(a = 1:3, \n                                               b = c(\"q\", \"b\", \"z\"), \n                                               c = c(\"bananas\", \"are\", \"so very great\")))\n\nprint(a_list)\n\n$a_number\n[1] 5\n\n$a_vector\n[1] \"a\" \"b\" \"c\"\n\n$a_dataframe\n  a b             c\n1 1 q       bananas\n2 2 b           are\n3 3 z so very great\n\n\nConsider the following function:\n\nadd_ten &lt;- function(x) {\n  return(x + 10)\n  }\n\nWe can map() the add_ten() function across a vector. Note that the output is a list (the default).\n\nlibrary(tidyverse)\nmap(.x = c(2, 5, 10),\n    .f = add_ten)\n\n[[1]]\n[1] 12\n\n[[2]]\n[1] 15\n\n[[3]]\n[1] 20\n\n\nWhat if we use a different type of input? The default behavior is to still return a list!\n\ndata.frame(a = 2, b = 5, c = 10) %&gt;%\n  map(add_ten)\n\n$a\n[1] 12\n\n$b\n[1] 15\n\n$c\n[1] 20\n\n\nWhat if we want a different type of output? We use a different map() function, map_df(), for example.\n\ndata.frame(a = 2, b = 5, c = 10) %&gt;%\n  map_df(add_ten)\n\n# A tibble: 1 × 3\n      a     b     c\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    12    15    20\n\n\nShorthand lets us get away from pre-defining the function (which will be useful). Use the tilde ~ to indicate that you have a function:\n\ndata.frame(a = 2, b = 5, c = 10) %&gt;%\n  map_df(~{.x + 10})\n\n# A tibble: 1 × 3\n      a     b     c\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    12    15    20\n\n\nMostly, the tilde will be used for functions we already know:\n\nlibrary(palmerpenguins)\nlibrary(broom)\n\npenguins %&gt;%\n  split(.$species) %&gt;%\n  map(~ lm(body_mass_g ~ flipper_length_mm, data = .x)) %&gt;%\n  map_df(tidy)  # map(tidy)\n\n# A tibble: 6 × 5\n  term              estimate std.error statistic  p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)        -2536.     965.       -2.63 9.48e- 3\n2 flipper_length_mm     32.8      5.08      6.47 1.34e- 9\n3 (Intercept)        -3037.     997.       -3.05 3.33e- 3\n4 flipper_length_mm     34.6      5.09      6.79 3.75e- 9\n5 (Intercept)        -6787.    1093.       -6.21 7.65e- 9\n6 flipper_length_mm     54.6      5.03     10.9  1.33e-19\n\npenguins %&gt;%\n  group_by(species) %&gt;%\n  group_map(~lm(body_mass_g ~ flipper_length_mm, data = .x)) %&gt;%\n  map(tidy)  # map_df(tidy)\n\n[[1]]\n# A tibble: 2 × 5\n  term              estimate std.error statistic       p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)        -2536.     965.       -2.63 0.00948      \n2 flipper_length_mm     32.8      5.08      6.47 0.00000000134\n\n[[2]]\n# A tibble: 2 × 5\n  term              estimate std.error statistic       p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 (Intercept)        -3037.     997.       -3.05 0.00333      \n2 flipper_length_mm     34.6      5.09      6.79 0.00000000375\n\n[[3]]\n# A tibble: 2 × 5\n  term              estimate std.error statistic  p.value\n  &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)        -6787.    1093.       -6.21 7.65e- 9\n2 flipper_length_mm     54.6      5.03     10.9  1.33e-19",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "07-wrangling.html#reflection-questions",
    "href": "07-wrangling.html#reflection-questions",
    "title": "7  Data wrangling",
    "section": "7.6  Reflection questions",
    "text": "7.6  Reflection questions",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "07-wrangling.html#ethics-considerations",
    "href": "07-wrangling.html#ethics-considerations",
    "title": "7  Data wrangling",
    "section": "7.7  Ethics considerations",
    "text": "7.7  Ethics considerations\n\n\n\nIf you ever need to understand which join is the right join for you, try to find an image that will lay out what the function is doing. I found this one that is quite good and is taken from Statistics Globe blog: https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti\nhttps://docs.google.com/spreadsheets/d/1Ow6Cm4z-Z1Yybk3i352msulYCEDOUaOghmo9ALajyHo/edit# gid=1811988794\n\n\n\nGrolemund, G., and H. Wickham. 2011. “Dates and Times Made Easy with lubridate.” Journal of Statistical Software 40 (3). http://www.jstatsoft.org/v40/i03/paper.\n\n\nKaplan, Daniel. 2015. Data Computing: An Introduction to Wrangling and Visualization with r. Project Mosaic Books.\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal of Statistical Software 59 (10). http://www.jstatsoft.org/v59/i10/paper.",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "09-reg-expr.html",
    "href": "09-reg-expr.html",
    "title": "9  Regular expressions",
    "section": "",
    "text": "Main tasks in character matching:\nMany of the ideas below are taken from Jenny Bryan’s STAT545 class.",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "09-reg-expr.html#r-packages-to-make-your-life-easier",
    "href": "09-reg-expr.html#r-packages-to-make-your-life-easier",
    "title": "9  Regular expressions",
    "section": "\n9.1 R packages to make your life easier",
    "text": "9.1 R packages to make your life easier\n\n\nstringr package A core package in the tidyverse. It is installed via install.packages(\"tidyverse\") and also loaded via library(tidyverse). Of course, you can also install or load it individually.\n\nMany of the main functions start with str_. Auto-complete is your friend.\nReplacements for base functions re: string manipulation and regular expressions (see below).\nMain advantages over base functions: greater consistency about inputs and outputs. Outputs are more ready for your next analytical task.\nstringr cheat sheet\n\n\n\ntidyr package Especially useful for functions that split one character vector into many and vice versa: separate(), unite(), extract().\nBase functions: nchar(), strsplit(), substr(), paste(), paste0().\nThe glue package is fantastic for string interpolation. If stringr::str_interp() doesn’t get your job done, check out the glue package.\n\nString functions related to regular expression\nRegular expression is a pattern that describes a specific set of strings with a common structure. It is heavily used for string matching / replacing in many programming languages, although specific syntax may differ a bit. It is truly the heart and soul for string operations. In R, many string functions in base R as well as in stringr package use regular expressions, even RStudio’s search and replace allows regular expression:\n\nidentify match to a pattern: grep(..., value = FALSE), grepl(), stringr::str_detect()\n\nextract match to a pattern: grep(..., value = TRUE), stringr::str_extract(), stringr::str_extract_all()\n\nlocate pattern within a string, i.e. give the start position of matched patterns. regexpr(), gregexpr(), stringr::str_locate(), string::str_locate_all()\n\nreplace a pattern: sub(), gsub(), stringr::str_replace(), stringr::str_replace_all()\n\nsplit a string using a pattern: strsplit(), stringr::str_split()\n\n\nRegular expressions typically specify characters (or character classes) to seek out, possibly with information about repeats and location within the string. This is accomplished with the help of metacharacters that have specific meaning: $ * + . ? [ ] ^ { } | ( ) \\. We will use some small examples to introduce regular expression syntax and what these metacharacters mean.\ngrep() stands for “global regular expression print”. grep() returns a character vector containing the selected elements, grepl() returns a logical vector of TRUE/FALSE for whether or not there was a match.",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "09-reg-expr.html#tools-for-characterizing-a-regular-expression",
    "href": "09-reg-expr.html#tools-for-characterizing-a-regular-expression",
    "title": "9  Regular expressions",
    "section": "\n9.2 Tools for characterizing a regular expression",
    "text": "9.2 Tools for characterizing a regular expression\n\n9.2.1 Escape sequences\nThere are some special characters in R that cannot be directly coded in a string. For example, let’s say you specify your pattern with single quotes and you want to find countries with the single quote '. You would have to “escape” the single quote in the pattern, by preceding it with \\, so it is clear that it is not part of the string-specifying machinery.\nThere are other characters in R that require escaping, and this rule applies to all string functions in R, including regular expressions. See here for a complete list of R escape sequences.\n\n\n\\': single quote. You don’t need to escape single quote inside a double-quoted string, so we can also use \" ' \".\n\n\n\\\": double quote. Similarly, double quotes can be used inside a single-quoted string, i.e. ' \" '.\n\n\n\\n: newline.\n\n\n\\r: carriage return.\n\n\n\\t: tab character.\n\n\nNote: cat() and print() handle escape sequences differently, if you want to print a string out with the interpretation of the sequences above, use cat().\n\n\nprint(\"a\\nb\")\n\n[1] \"a\\nb\"\n\ncat(\"a\\nb\")\n\na\nb\n\n\n\n9.2.2 Quantifiers\nQuantifiers specify how many repetitions of the pattern.\n\n\n*: matches at least 0 times.\n\n\n+: matches at least 1 times.\n\n\n?: matches at most 1 times.\n\n\n{n}: matches exactly n times.\n\n\n{n,}: matches at least n times.\n\n\n{n,m}: matches between n and m times.\n\n\nstrings &lt;- c(\"a\", \"ab\", \"acb\", \"accb\", \"acccb\", \"accccb\")\ngrep(\"ac*b\", strings, value = TRUE)\n\n[1] \"ab\"     \"acb\"    \"accb\"   \"acccb\"  \"accccb\"\n\ngrep(\"ac*b\", strings, value = FALSE)\n\n[1] 2 3 4 5 6\n\ngrep(\"ac+b\", strings, value = TRUE)\n\n[1] \"acb\"    \"accb\"   \"acccb\"  \"accccb\"\n\ngrep(\"ac?b\", strings, value = TRUE)\n\n[1] \"ab\"  \"acb\"\n\ngrep(\"ac{2}b\", strings, value = TRUE)\n\n[1] \"accb\"\n\ngrep(\"ac{2,}b\", strings, value = TRUE)\n\n[1] \"accb\"   \"acccb\"  \"accccb\"\n\ngrep(\"ac{2,3}b\", strings, value = TRUE)\n\n[1] \"accb\"  \"acccb\"\n\n\n\n9.2.3 Position of pattern within the string\n\n\n^: matches the start of the string.\n\n\n$: matches the end of the string.\n\n\n\\b: matches the boundary of a word. Don’t confuse it with ^ $ which marks the edge of a string.\n\n\n\\B: matches the empty string provided it is not at an edge of a word.\n\n\nstrings &lt;- c(\"abcd\", \"cdab\", \"cabd\", \"c abd\")\ngrep(\"ab\", strings, value = TRUE)\n\n[1] \"abcd\"  \"cdab\"  \"cabd\"  \"c abd\"\n\ngrep(\"^ab\", strings, value = TRUE)\n\n[1] \"abcd\"\n\ngrep(\"ab$\", strings, value = TRUE)\n\n[1] \"cdab\"\n\ngrep(\"\\\\bab\", strings, value = TRUE)\n\n[1] \"abcd\"  \"c abd\"\n\n\n\n9.2.4 Operators\n\n\n.: matches any single character, as shown in the first example.\n\n[...]: a character list, matches any one of the characters inside the square brackets. We can also use - inside the brackets to specify a range of characters.\n\n\n[^...]: an inverted character list, similar to [...], but matches any characters except those inside the square brackets.\n\n\n\\: suppress the special meaning of metacharacters in regular expression, i.e. $ * + . ? [ ] ^ { } | ( ) \\, similar to its usage in escape sequences. Since \\ itself needs to be escaped in R, we need to escape these metacharacters with double backslash like \\\\$.\n\n\n|: an “or” operator, matches patterns on either side of the |.\n\n\n(...): grouping in regular expressions. This allows you to retrieve the bits that matched various parts of your regular expression so you can alter them or use them for building up a new string. Each group can than be refer using \\\\N, with N being the No. of (...) used. This is called backreference.\n\n\nstrings &lt;- c(\"^ab\", \"ab\", \"abc\", \"abd\", \"abe\", \"ab 12\", \"a|b\")\ngrep(\"ab.\", strings, value = TRUE)\n\n[1] \"abc\"   \"abd\"   \"abe\"   \"ab 12\"\n\ngrep(\"ab[c-e]\", strings, value = TRUE)\n\n[1] \"abc\" \"abd\" \"abe\"\n\ngrep(\"ab[^c]\", strings, value = TRUE)\n\n[1] \"abd\"   \"abe\"   \"ab 12\"\n\ngrep(\"^ab\", strings, value = TRUE)\n\n[1] \"ab\"    \"abc\"   \"abd\"   \"abe\"   \"ab 12\"\n\ngrep(\"\\\\^ab\", strings, value = TRUE)\n\n[1] \"^ab\"\n\ngrep(\"abc|abd\", strings, value = TRUE)\n\n[1] \"abc\" \"abd\"\n\ngrep(\"a[b|c]\", strings, value = TRUE)\n\n[1] \"^ab\"   \"ab\"    \"abc\"   \"abd\"   \"abe\"   \"ab 12\" \"a|b\"  \n\nstr_extract(strings, \"a[b|c]\")\n\n[1] \"ab\" \"ab\" \"ab\" \"ab\" \"ab\" \"ab\" \"a|\"\n\n\n\n9.2.5 Character classes\nCharacter classes allow specifying entire classes of characters, such as numbers, letters, etc. There are two flavors of character classes, one uses [: and :] around a predefined name inside square brackets and the other uses \\ and a special character. They are sometimes interchangeable.\n\n(?i) before the string indicates that the match should be case insensitive.\n\n[:digit:] or \\d: digits, 0 1 2 3 4 5 6 7 8 9, equivalent to [0-9].\n\n\n\\D: non-digits, equivalent to [^0-9].\n\n\n[:lower:]: lower-case letters, equivalent to [a-z].\n\n\n[:upper:]: upper-case letters, equivalent to [A-Z].\n\n\n[:alpha:]: alphabetic characters, equivalent to [[:lower:][:upper:]] or [A-z].\n\n\n[:alnum:]: alphanumeric characters, equivalent to [[:alpha:][:digit:]] or [A-z0-9].\n\n\n\\w: word characters, equivalent to [[:alnum:]_] or [A-z0-9_] (letter, number, or underscore).\n\n\\W: not word, equivalent to [^A-z0-9_].\n\n\n[:xdigit:]: hexadecimal digits (base 16), 0 1 2 3 4 5 6 7 8 9 A B C D E F a b c d e f, equivalent to [0-9A-Fa-f].\n\n[:blank:]: blank characters, i.e. space and tab.\n\n\n[:space:]: space characters: tab, newline, vertical tab, form feed, carriage return, space.\n\n\\s: space, . Matches any whitespace (space, tab, newline, and carriage return).\n\n\\S: not space.\n\n\n[:punct:]: punctuation characters, ! ” # $ % & ’ ( ) * + , - . / : ; &lt; = &gt; ? @ [  ] ^ _ ` { | } ~.\n\n[:graph:]: graphical (human readable) characters: equivalent to [[:alnum:][:punct:]].\n\n[:print:]: printable characters, equivalent to [[:alnum:][:punct:]\\\\s].\n\n[:cntrl:]: control characters, like \\n or \\r, [\\x00-\\x1F\\x7F].\n\nNote:\n* [:...:] has to be used inside square brackets, e.g. [[:digit:]].\n* \\ itself is a special character that needs escape, e.g. \\\\d. Do not confuse these regular expressions with R escape sequences such as \\t.",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "09-reg-expr.html#examples-to-work-through",
    "href": "09-reg-expr.html#examples-to-work-through",
    "title": "9  Regular expressions",
    "section": "\n9.3 Examples to work through",
    "text": "9.3 Examples to work through\nI have found that the best way to truly understand regular expressions is to work through as many examples as possible (actually, maybe this is true about learning anything new!). For the following examples, try to figure out the solution on your own before looking at the footnote which contains the solution.\n\n9.3.1 Case insenstive\n\nMatch only the word meter in “The cemetery is 1 meter from the stop sign.” Also match Meter in “The cemetery is 1 Meter from the stop sign.”\n\n\nstring &lt;- c(\"The cemetery is 1 meter from the stop sign.\", \n            \"The cemetery is 1 Meter from the stop sign.\")\n\nstr_extract(string, \"(?i)\\\\bmeter\\\\b\")\n\n[1] \"meter\" \"Meter\"\n\n\n\n9.3.2 Proper times and dates\n\nMatch dates like 01/15/24 and also like 01.15.24 and like 01-15-24.1\n\n\n\nstring &lt;- c(\"01/15/24\", \"01.15.24\", \"01-15-24\", \"01 15 24\", \"011524\", \"January 15, 2024\")\n\nstr_extract(string, \"\\\\d\\\\d.\\\\d\\\\d.\\\\d\\\\d\")\n\n[1] \"01/15/24\" \"01.15.24\" \"01-15-24\" \"01 15 24\" NA         NA        \n\nstr_extract(string, \"\\\\d\\\\d[/.\\\\-]\\\\d\\\\d[/.\\\\-]\\\\d\\\\d\")\n\n[1] \"01/15/24\" \"01.15.24\" \"01-15-24\" NA         NA         NA        \n\nstr_extract(string, \"\\\\d{2}[/.\\\\-]\\\\d{2}[/.\\\\-]\\\\d{2}\")\n\n[1] \"01/15/24\" \"01.15.24\" \"01-15-24\" NA         NA         NA        \n\n\n\nMatch a time of day such as “9:17 am” or “12:30 pm”. Require that the time be a valid time (not “99:99 pm”). Assume no leading zeros (i.e., “09:17 am”).2\n\n\n\nstring &lt;- c(\"9:17 am\", \"12:30 pm\", \"99:99 pm\", \"09:17 am\")\n\nstr_extract(string, \"(1[012]|[1-9]):[0-5][0-9] (am|pm)\")\n\n[1] \"9:17 am\"  \"12:30 pm\" NA         \"9:17 am\" \n\nstr_extract(string, \"^(1[012]|[1-9]):[0-5][0-9] (am|pm)$\")\n\n[1] \"9:17 am\"  \"12:30 pm\" NA         NA        \n\n\n\n9.3.3 Alternation operator\nThe “or” operator, | has the lowest precedence and parentheses have the highest precedence, which means that parentheses get evaluated before “or”.\n\nWhat is the difference between \\bMary|Jane|Sue\\b and \\b(Mary|Jane|Sue)\\b?3\n\n\n\nstring &lt;- c(\"Mary\", \"Mar\", \"Janet\", \"jane\", \"Susan\", \"Sue\")\n\nstr_extract(string, \"\\\\bMary|Jane|Sue\\\\b\")\n\n[1] \"Mary\" NA     \"Jane\" NA     NA     \"Sue\" \n\nstr_extract(string, \"\\\\b(Mary|Jane|Sue)\\\\b\")\n\n[1] \"Mary\" NA     NA     NA     NA     \"Sue\" \n\n\n\n9.3.4 An example from my work\nBelow are a handful of string characters that represent genomic sequences which were measured in an RNA Sequencing dataset. The task below is to find intergenic regions (IGR) and identify which coding sequences (CDS) bookend the intergenic regions. Note that IGRs do not code for proteins while CDSs do. Additionally, AS refers to anti-sense which identifies the genomic sequence in the opposite orientation (e.g., CGGATCC vs CCTAGGC). [The code below was written by Madison Hobbs, Scripps ’19.]\nThe names of the genomic pieces\n\nallCounts &lt;- data.frame(Geneid = c(\"CDS:b2743:pcm:L-isoaspartate_protein_carboxylmethyltransferase_type_II:cds2705:-:626:NC_000913.3\",\n            \"CDS:b2764:cysJ:sulfite_reductase2C_alpha_subunit2C_flavoprotein:cds2726:-:1799:NC_000913.3\",\n            \"IGR:(CDS,b1594,mlc,glucosamine_anaerobic_growth_regulon_transcriptional_repressor3B_autorepressor,cds1581,-,1220/CDS,b1595,ynfL,LysR_family_putative_transcriptional_regulator,cds1582,-,893):+:945:NC_000913.3\",\n            \"AS_IGR:(CDS,b0008,talB,transaldolase_B,cds7,+,953/CDS,b0009,mog,molybdochelatase_incorporating_molybdenum_into_molybdopterin,cds8,+,587):+:639:NC_000913.3\",\n            \"IGR:(CDS,b1808,yoaA,putative_ATP-dependent_helicase2C_DinG_family,cds1798,-,1910/CDS,b1809,yoaB,putative_reactive_intermediate_deaminase,cds1799,+,344):+:396:NC_000913.3\"))\n\nallCounts$GeneidBackup = allCounts$Geneid\n\nFirst, it is important to identify which are IGR, CDS, and anti-sense.\n\nallCounts &lt;- allCounts |&gt; tidyr::separate(Geneid, c(\"feature\", \"rest\"), sep=\"[:]\")\nallCounts\n\n  feature\n1     CDS\n2     CDS\n3     IGR\n4  AS_IGR\n5     IGR\n                                                                                                                                                                                       rest\n1                                                                                                                                                                                     b2743\n2                                                                                                                                                                                     b2764\n3 (CDS,b1594,mlc,glucosamine_anaerobic_growth_regulon_transcriptional_repressor3B_autorepressor,cds1581,-,1220/CDS,b1595,ynfL,LysR_family_putative_transcriptional_regulator,cds1582,-,893)\n4                                                         (CDS,b0008,talB,transaldolase_B,cds7,+,953/CDS,b0009,mog,molybdochelatase_incorporating_molybdenum_into_molybdopterin,cds8,+,587)\n5                                       (CDS,b1808,yoaA,putative_ATP-dependent_helicase2C_DinG_family,cds1798,-,1910/CDS,b1809,yoaB,putative_reactive_intermediate_deaminase,cds1799,+,344)\n                                                                                                                                                                                                     GeneidBackup\n1                                                                                                                CDS:b2743:pcm:L-isoaspartate_protein_carboxylmethyltransferase_type_II:cds2705:-:626:NC_000913.3\n2                                                                                                                      CDS:b2764:cysJ:sulfite_reductase2C_alpha_subunit2C_flavoprotein:cds2726:-:1799:NC_000913.3\n3 IGR:(CDS,b1594,mlc,glucosamine_anaerobic_growth_regulon_transcriptional_repressor3B_autorepressor,cds1581,-,1220/CDS,b1595,ynfL,LysR_family_putative_transcriptional_regulator,cds1582,-,893):+:945:NC_000913.3\n4                                                      AS_IGR:(CDS,b0008,talB,transaldolase_B,cds7,+,953/CDS,b0009,mog,molybdochelatase_incorporating_molybdenum_into_molybdopterin,cds8,+,587):+:639:NC_000913.3\n5                                       IGR:(CDS,b1808,yoaA,putative_ATP-dependent_helicase2C_DinG_family,cds1798,-,1910/CDS,b1809,yoaB,putative_reactive_intermediate_deaminase,cds1799,+,344):+:396:NC_000913.3\n\n\nWe keep only the IGR and AS_IGR strings, and we separate the two bookends. Note, the separation comes at the backslash.\n\nigr &lt;- allCounts |&gt; filter(feature %in% c(\"IGR\", \"AS_IGR\"))\nigr &lt;- igr |&gt; tidyr::separate(GeneidBackup, c(\"Geneid1\", \"Geneid2\"), sep = \"[/]\")\nnames(igr)\n\n[1] \"feature\" \"rest\"    \"Geneid1\" \"Geneid2\"\n\nigr\n\n  feature\n1     IGR\n2  AS_IGR\n3     IGR\n                                                                                                                                                                                       rest\n1 (CDS,b1594,mlc,glucosamine_anaerobic_growth_regulon_transcriptional_repressor3B_autorepressor,cds1581,-,1220/CDS,b1595,ynfL,LysR_family_putative_transcriptional_regulator,cds1582,-,893)\n2                                                         (CDS,b0008,talB,transaldolase_B,cds7,+,953/CDS,b0009,mog,molybdochelatase_incorporating_molybdenum_into_molybdopterin,cds8,+,587)\n3                                       (CDS,b1808,yoaA,putative_ATP-dependent_helicase2C_DinG_family,cds1798,-,1910/CDS,b1809,yoaB,putative_reactive_intermediate_deaminase,cds1799,+,344)\n                                                                                                           Geneid1\n1 IGR:(CDS,b1594,mlc,glucosamine_anaerobic_growth_regulon_transcriptional_repressor3B_autorepressor,cds1581,-,1220\n2                                                                AS_IGR:(CDS,b0008,talB,transaldolase_B,cds7,+,953\n3                                 IGR:(CDS,b1808,yoaA,putative_ATP-dependent_helicase2C_DinG_family,cds1798,-,1910\n                                                                                                   Geneid2\n1           CDS,b1595,ynfL,LysR_family_putative_transcriptional_regulator,cds1582,-,893):+:945:NC_000913.3\n2 CDS,b0009,mog,molybdochelatase_incorporating_molybdenum_into_molybdopterin,cds8,+,587):+:639:NC_000913.3\n3                 CDS,b1809,yoaB,putative_reactive_intermediate_deaminase,cds1799,+,344):+:396:NC_000913.3\n\n\nFor each of the two bookend Genes, we need to separate out the feature from the rest. Note that we write over feature1 in the second line of code below. Both of the bookends for all sequences are CDS elements.\n\nigr$feature1 &lt;- tidyr::separate(igr, Geneid1, c(\"feature1\", \"rest\"), sep = \"[,]\")$feature1\nigr$feature1 &lt;- tidyr::separate(igr, feature1, c(\"rest\", \"feature1\"), sep = \"[()]\")$feature1\nigr$feature2 &lt;- tidyr::separate(igr, Geneid2, c(\"feature2\", \"rest\"), sep = \"[,]\")$feature2\nnames(igr)\n\n[1] \"feature\"  \"rest\"     \"Geneid1\"  \"Geneid2\"  \"feature1\" \"feature2\"\n\nigr\n\n  feature\n1     IGR\n2  AS_IGR\n3     IGR\n                                                                                                                                                                                       rest\n1 (CDS,b1594,mlc,glucosamine_anaerobic_growth_regulon_transcriptional_repressor3B_autorepressor,cds1581,-,1220/CDS,b1595,ynfL,LysR_family_putative_transcriptional_regulator,cds1582,-,893)\n2                                                         (CDS,b0008,talB,transaldolase_B,cds7,+,953/CDS,b0009,mog,molybdochelatase_incorporating_molybdenum_into_molybdopterin,cds8,+,587)\n3                                       (CDS,b1808,yoaA,putative_ATP-dependent_helicase2C_DinG_family,cds1798,-,1910/CDS,b1809,yoaB,putative_reactive_intermediate_deaminase,cds1799,+,344)\n                                                                                                           Geneid1\n1 IGR:(CDS,b1594,mlc,glucosamine_anaerobic_growth_regulon_transcriptional_repressor3B_autorepressor,cds1581,-,1220\n2                                                                AS_IGR:(CDS,b0008,talB,transaldolase_B,cds7,+,953\n3                                 IGR:(CDS,b1808,yoaA,putative_ATP-dependent_helicase2C_DinG_family,cds1798,-,1910\n                                                                                                   Geneid2\n1           CDS,b1595,ynfL,LysR_family_putative_transcriptional_regulator,cds1582,-,893):+:945:NC_000913.3\n2 CDS,b0009,mog,molybdochelatase_incorporating_molybdenum_into_molybdopterin,cds8,+,587):+:639:NC_000913.3\n3                 CDS,b1809,yoaB,putative_reactive_intermediate_deaminase,cds1799,+,344):+:396:NC_000913.3\n  feature1 feature2\n1      CDS      CDS\n2      CDS      CDS\n3      CDS      CDS\n\n\nAs CDS, it is now important to find the actual genenames for each of the IGR sequences. We also keep each element’s bnum which represents a unique gene identifier in E. coli.\nbnum, genename, rna.name act as place holders for the types of elements that we will need to identify the bookends of the IGRs.\n\nbnum = \"b[0-9]{4}\"\nbnum\n\n[1] \"b[0-9]{4}\"\n\ngenename = \",[a-z]{3}[A-Z,].\"\nrna.name = \",rna[0-9]..\"\n\n\nigr$start.gene &lt;- dplyr::case_when(\n  igr$feature1 == \"CDS\" ~ stringr::str_extract(igr$Geneid1, genename),\n  TRUE ~ stringr::str_extract(igr$Geneid1, rna.name))\nigr$end.gene &lt;- dplyr::case_when(\n  igr$feature2 == \"CDS\" ~ stringr::str_extract(igr$Geneid2, genename),\n  TRUE ~ stringr::str_extract(igr$Geneid2, rna.name))\nigr$start.bnum &lt;- dplyr::case_when(\n  igr$feature1 == \"CDS\" ~ stringr::str_extract(igr$Geneid1, bnum),\n  TRUE ~ \"none\")\nigr$end.bnum &lt;- dplyr::case_when(\n  igr$feature2 == \"CDS\" ~ stringr::str_extract(igr$Geneid2, bnum),\n  TRUE ~ \"none\")\nigr &lt;- igr |&gt; tidyr::separate(start.gene, into = c(\"comma\", \"start.gene\"), sep = \"[,]\") |&gt; \n  dplyr::select(-comma) |&gt; \n  tidyr::separate(end.gene, into = c(\"comma\", \"end.gene\"), sep = \"[,]\") |&gt; \n  dplyr::select(-comma)\nnames(igr)\n\n [1] \"feature\"    \"rest\"       \"Geneid1\"    \"Geneid2\"    \"feature1\"  \n [6] \"feature2\"   \"start.gene\" \"end.gene\"   \"start.bnum\" \"end.bnum\"  \n\nigr\n\n  feature\n1     IGR\n2  AS_IGR\n3     IGR\n                                                                                                                                                                                       rest\n1 (CDS,b1594,mlc,glucosamine_anaerobic_growth_regulon_transcriptional_repressor3B_autorepressor,cds1581,-,1220/CDS,b1595,ynfL,LysR_family_putative_transcriptional_regulator,cds1582,-,893)\n2                                                         (CDS,b0008,talB,transaldolase_B,cds7,+,953/CDS,b0009,mog,molybdochelatase_incorporating_molybdenum_into_molybdopterin,cds8,+,587)\n3                                       (CDS,b1808,yoaA,putative_ATP-dependent_helicase2C_DinG_family,cds1798,-,1910/CDS,b1809,yoaB,putative_reactive_intermediate_deaminase,cds1799,+,344)\n                                                                                                           Geneid1\n1 IGR:(CDS,b1594,mlc,glucosamine_anaerobic_growth_regulon_transcriptional_repressor3B_autorepressor,cds1581,-,1220\n2                                                                AS_IGR:(CDS,b0008,talB,transaldolase_B,cds7,+,953\n3                                 IGR:(CDS,b1808,yoaA,putative_ATP-dependent_helicase2C_DinG_family,cds1798,-,1910\n                                                                                                   Geneid2\n1           CDS,b1595,ynfL,LysR_family_putative_transcriptional_regulator,cds1582,-,893):+:945:NC_000913.3\n2 CDS,b0009,mog,molybdochelatase_incorporating_molybdenum_into_molybdopterin,cds8,+,587):+:639:NC_000913.3\n3                 CDS,b1809,yoaB,putative_reactive_intermediate_deaminase,cds1799,+,344):+:396:NC_000913.3\n  feature1 feature2 start.gene end.gene start.bnum end.bnum\n1      CDS      CDS        mlc     ynfL      b1594    b1595\n2      CDS      CDS       talB      mog      b0008    b0009\n3      CDS      CDS       yoaA     yoaB      b1808    b1809",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "09-reg-expr.html#lookaround",
    "href": "09-reg-expr.html#lookaround",
    "title": "9  Regular expressions",
    "section": "\n9.4 Lookaround",
    "text": "9.4 Lookaround\nA lookaround specifies a place in the regular expression that will anchor the string you’d like to match. There are four types of lookarounds: positive lookahead, positive lookbehind, negative lookahead, and negative lookbehind.\n\n“x(?=y)” – positive lookahead (matches ‘x’ when it is followed by ‘y’)\n“x(?!y)” – negative lookahead (matches ‘x’ when it is not followed by ‘y’)\n“(?&lt;=y)x” – positive lookbehind (matches ‘x’ when it is preceded by ‘y’)\n“(?&lt;!y)x” – negative lookbehind (matches ‘x’ when it is not preceded by ‘y’)\n\nNote that the lookaround specifies a place in the string which means it does not return the details of the lookaround. Using lookarounds, you can test strings against patterns without including the lookaround pattern in the resulting match.\n\n\n\n\n\n\n\nFigure 9.1: Image credit: Stefan Judis https://www.stefanjudis.com/blog/a-regular-expression-lookahead-lookbehind-cheat-sheet/",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "09-reg-expr.html#example---taskmaster",
    "href": "09-reg-expr.html#example---taskmaster",
    "title": "9  Regular expressions",
    "section": "\n9.5 Example - Taskmaster",
    "text": "9.5 Example - Taskmaster\nIn the following example, we will wrangle some data scraped from the wiki site for the TV series, Taskmaster. We won’t cover the html scraping here, but I include the code for completeness.\n\n\n\n\n\n\n\nFigure 9.2: Taskmaster Wiki https://taskmaster.fandom.com/wiki/Series_11\n\n\n\n\n\n9.5.1 Scraping and wrangling Taskmaster\nGoal: to scrape the Taskmaster wiki into a data frame including task, description, episode, episode name, air date, contestant, score, and series.4\n\nresults &lt;- read_html(\"https://taskmaster.fandom.com/wiki/Series_11\") |&gt;\n  html_element(\".tmtable\") |&gt; \n  html_table() |&gt;\n  mutate(episode = ifelse(startsWith(Task, \"Episode\"), Task, NA)) |&gt;\n  fill(episode, .direction = \"down\") |&gt;\n  filter(!startsWith(Task, \"Episode\"), \n         !(Task %in% c(\"Total\", \"Grand Total\"))) |&gt;\n  pivot_longer(cols = -c(Task, Description, episode),\n               names_to = \"contestant\",\n               values_to = \"score\") |&gt;\n  mutate(series = 11)\n\n\nresults |&gt; \n  select(Task, Description, episode, contestant, score, series) |&gt;\n  head(10)\n\n# A tibble: 10 × 6\n  Task  Description                              episode contestant score series\n  &lt;chr&gt; &lt;chr&gt;                                    &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;\n1 1     Prize: Best thing you can carry, but on… Episod… Charlotte… 1         11\n2 1     Prize: Best thing you can carry, but on… Episod… Jamali Ma… 2         11\n3 1     Prize: Best thing you can carry, but on… Episod… Lee Mack   4         11\n4 1     Prize: Best thing you can carry, but on… Episod… Mike Wozn… 5         11\n5 1     Prize: Best thing you can carry, but on… Episod… Sarah Ken… 3         11\n6 2     Do the most impressive thing under the … Episod… Charlotte… 2         11\n# ℹ 4 more rows\n\n\nmore succinct results\n\n   Task  Description         episode   contestant score series\n  1     Prize: Best thing…  Episode 1… Charlotte… 1         11\n  1     Prize: Best thing…  Episode 1… Jamali Ma… 2         11\n  1     Prize: Best thing…  Episode 1… Lee Mack   4         11\n  1     Prize: Best thing…  Episode 1… Mike Wozn… 5         11\n  1     Prize: Best thing…  Episode 1… Sarah Ken… 3         11\n  2     Do the most…        Episode 1… Charlotte… 2         11\n  2     Do the most…        Episode 1… Jamali Ma… 3[1]      11\n  2     Do the most…        Episode 1… Lee Mack   3         11\n  2     Do the most…        Episode 1… Mike Wozn… 5         11\n  2     Do the most…        Episode 1… Sarah Ken… 4         11\n\nCurrently, the episode column contains entries like\n\n\"Episode 1: It's not your fault. (18 March 2021)\"\n\n\n9.5.2 Cleaning the score column\n\ntable(results$score)\n\n\n   –    ✔    ✘    0    1    2    3 3[1] 3[2]    4 4[2]    5   DQ \n   7    1    1   11   37   42   48    1    3   50    1   55   13 \n\n\nHow should the scores be stored? What is the cleaning task?\n\n\n\n\n\n\n\nFigure 9.3: Taskmaster Wiki https://taskmaster.fandom.com/wiki/Series_11\n\n\n\n\nExtracting numeric information\nSuppose we have the following string:\n\n\"3[1]\"\n\nAnd we want to extract just the number “3”:\n\nstr_extract(\"3[1]\", \"3\")\n\n[1] \"3\"\n\n\nWhat if we don’t know which number to extract?\n\nstr_extract(\"3[1]\", \"\\\\d\")\n\n[1] \"3\"\n\n\n\nstr_extract(\"4[1]\", \"\\\\d\")\n\n[1] \"4\"\n\n\n\nstr_extract(\"10[1]\", \"\\\\d\")\n\n[1] \"1\"\n\n\n\nstr_extract(\"10[1]\", \"\\\\d+\")\n\n[1] \"10\"\n\n\n\nstr_extract(\"DQ\", \"\\\\d\")\n\n[1] NA\n\n\nstr_extract()\nstr_extract() is an R function in the stringr package which finds regular expressions in strings of text.\n\nstr_extract(\"My cat is 3 years old\", \"cat\")\n\n[1] \"cat\"\n\n\n\nstr_extract(\"My cat is 3 years old\", \"3\")\n\n[1] \"3\"\n\n\nMatching multiple options\nstr_extract() returns the first match; str_extract_all() allows more than one match.\n\nstr_extract(\"My cat is 3 years old\", \"cat|dog\")\n\n[1] \"cat\"\n\nstr_extract(\"My dog is 10 years old\", \"cat|dog\")\n\n[1] \"dog\"\n\nstr_extract(\"My dog is 10 years old, my cat is 3 years old\", \n            \"cat|dog\")\n\n[1] \"dog\"\n\nstr_extract_all(\"My dog is 10 years old, my cat is 3 years old\", \n                \"cat|dog\")\n\n[[1]]\n[1] \"dog\" \"cat\"\n\n\nMatching groups of characters\nWhat if I want to extract a number?\n\nstr_extract(\"My cat is 3 years old\", \"\\\\d\")\n\n[1] \"3\"\n\n\nWhat will the result be for the following code?\n\nstr_extract(\"My dog is 10 years old\", \"\\\\d\")\n\n\nstr_extract(\"My dog is 10 years old\", \"\\\\d\")\n\n[1] \"1\"\n\n\nThe + symbol in a regular expression means “repeated one or more times”\n\nstr_extract(\"My dog is 10 years old\", \"\\\\d+\")\n\n[1] \"10\"\n\n\nExtracting from multiple strings\n\nstrings &lt;- c(\"My cat is 3 years old\", \"My dog is 10 years old\")\nstr_extract(strings, \"\\\\d+\")\n\n[1] \"3\"  \"10\"\n\n\nWhat if we have multiple instances across multiple strings? We need to be careful working with lists (instead of vectors).\n\nstrings &lt;- c(\"My cat is 3 years old\", \"My dog is 10 years old\")\nstr_extract(strings, \"\\\\w+\")\n\n[1] \"My\" \"My\"\n\nstr_extract_all(strings, \"\\\\w+\")\n\n[[1]]\n[1] \"My\"    \"cat\"   \"is\"    \"3\"     \"years\" \"old\"  \n\n[[2]]\n[1] \"My\"    \"dog\"   \"is\"    \"10\"    \"years\" \"old\"",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "09-reg-expr.html#extracting-episode-information",
    "href": "09-reg-expr.html#extracting-episode-information",
    "title": "9  Regular expressions",
    "section": "\n9.6 Extracting episode information",
    "text": "9.6 Extracting episode information\nCurrently, the episode column contains entries like:\n\n\"Episode 2: The pie whisperer. (4 August 2015)\"\n\nHow would I extract just the episode number?\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \"\\\\d+\")\n\n[1] \"2\"\n\n\nHow would I extract the episode name?\nGoal: find a pattern to match: anything that starts with a :, ends with a .\nLet’s break down that task into pieces.\nHow can we find the period at the end of the sentence? What does each of these lines of code return?\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \".\")\n\n[1] \"E\"\n\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \".+\")\n\n[1] \"Episode 2: The pie whisperer. (4 August 2015)\"\n\n\nWe use an escape character when we actually want to choose a period:\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \"\\\\.\")\n\n[1] \".\"\n\n\nRecall the goal: find a pattern to match: anything that starts with a :, ends with a .\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \n            \":.+\\\\.\")\n\n[1] \": The pie whisperer.\"",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "09-reg-expr.html#lookaround-again",
    "href": "09-reg-expr.html#lookaround-again",
    "title": "9  Regular expressions",
    "section": "\n9.7 Lookaround (again)",
    "text": "9.7 Lookaround (again)\n\n9.7.1 Lookbehinds\n(?&lt;=) is a positive lookbehind. It is used to identify expressions which are preceded by a particular expression.\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \n            \"(?&lt;=: ).+\")\n\n[1] \"The pie whisperer. (4 August 2015)\"\n\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \n            \"(?&lt;=\\\\. ).+\")\n\n[1] \"(4 August 2015)\"\n\n\n\n9.7.2 Lookaheads\n(?=) is a positive lookahead. It is used to identify expressions which are followed by a particular expression.\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \n            \".+(?=\\\\.)\")\n\n[1] \"Episode 2: The pie whisperer\"\n\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \n            \".+(?=:)\")\n\n[1] \"Episode 2\"\n\n\nExtracting episode information\nGetting everything between the : and the .\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \n            \"(?&lt;=: ).+(?=\\\\.)\")\n\n[1] \"The pie whisperer\"\n\n\nExtracting air date\nI want to extract just the air date. What pattern do I want to match?\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", ...)\n\n\nstr_extract(\"Episode 2: The pie whisperer. (4 August 2015)\", \n            \"(?&lt;=\\\\().+(?=\\\\))\")\n\n[1] \"4 August 2015\"\n\n\nWrangling the episode info\nCurrently:\n\n\n# A tibble: 270 × 1\n  episode                                        \n  &lt;chr&gt;                                          \n1 Episode 1: It's not your fault. (18 March 2021)\n2 Episode 1: It's not your fault. (18 March 2021)\n3 Episode 1: It's not your fault. (18 March 2021)\n4 Episode 1: It's not your fault. (18 March 2021)\n5 Episode 1: It's not your fault. (18 March 2021)\n6 Episode 1: It's not your fault. (18 March 2021)\n# ℹ 264 more rows\n\n\nOne option:\n\nresults |&gt;\n  select(episode) |&gt;\n  mutate(episode_name = str_extract(episode, \"(?&lt;=: ).+(?=\\\\.)\"),\n         air_date = str_extract(episode, \"(?&lt;=\\\\().+(?=\\\\))\"),\n         episode = str_extract(episode, \"\\\\d+\"))\n\n# A tibble: 270 × 3\n  episode episode_name        air_date     \n  &lt;chr&gt;   &lt;chr&gt;               &lt;chr&gt;        \n1 1       It's not your fault 18 March 2021\n2 1       It's not your fault 18 March 2021\n3 1       It's not your fault 18 March 2021\n4 1       It's not your fault 18 March 2021\n5 1       It's not your fault 18 March 2021\n6 1       It's not your fault 18 March 2021\n# ℹ 264 more rows\n\n\nAnother option:\n\nresults |&gt;\n  separate_wider_regex(episode, \n                       patterns = c(\".+ \", \n                                    episode = \"\\\\d+\", \n                                    \": \", \n                                    episode_name = \".+\", \n                                    \"\\\\. \\\\(\", \n                                    air_date = \".+\", \n                                    \"\\\\)\"))\n\n\n\n# A tibble: 270 × 3\n  episode episode_name        air_date     \n  &lt;chr&gt;   &lt;chr&gt;               &lt;chr&gt;        \n1 1       It's not your fault 18 March 2021\n2 1       It's not your fault 18 March 2021\n3 1       It's not your fault 18 March 2021\n4 1       It's not your fault 18 March 2021\n5 1       It's not your fault 18 March 2021\n6 1       It's not your fault 18 March 2021\n# ℹ 264 more rows",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "09-reg-expr.html#regular-expressions-and-sql",
    "href": "09-reg-expr.html#regular-expressions-and-sql",
    "title": "9  Regular expressions",
    "section": "\n9.8 Regular expressions and SQL\n",
    "text": "9.8 Regular expressions and SQL\n\nBack to the IMDb database…\n\nSELECT production_year, title\n  FROM title\n  WHERE kind_id = 1 AND\n        title REGEXP '(?i)star'\n  LIMIT 0, 20;\n\n\nDisplaying records 1 - 10\n\nproduction_year\ntitle\n\n\n\n2005\n“Dancing with the Stars” (I)\n\n\n2005\n“Dancing with the Stars” (II)\n\n\n2005\n“Dancing with the Stars” (III)\n\n\n2017\n“Girl Starter” (II)\n\n\n2001\n“Popstars” (I)\n\n\n2001\n“Popstars” (II)\n\n\n2002\n“Popstars” (I)\n\n\n2000\n“Popstars” (I)\n\n\n1959\n“Startime” (II)\n\n\n1959\n“Startime” (I)",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "09-reg-expr.html#reflection-questions",
    "href": "09-reg-expr.html#reflection-questions",
    "title": "9  Regular expressions",
    "section": "\n9.9  Reflection questions",
    "text": "9.9  Reflection questions\n\nWhat is the difference between [a|b] and (a|b)?\nWhat is the main character which needs to be escaped inside [...]? Why?\nWhy do we use lookarounds instead of just putting the location of interest inside our regular expression pattern?\nWhat are the differences between *, +, and ? ? How do the three metacharacters apply to a single character or a group of characters?\nHow can you find a string between two patterns without picking up the bookending patterns themselves?\nWhy does it make sense to write the regular expression pattern that matches the entire string of interest and not just a pattern which evaluates to TRUE?",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "09-reg-expr.html#ethics-considerations",
    "href": "09-reg-expr.html#ethics-considerations",
    "title": "9  Regular expressions",
    "section": "\n9.10  Ethics considerations",
    "text": "9.10  Ethics considerations\n\nHow can we use regular expressions to check for name mispellings or other similar data cleaning tasks?\nName one thing that you noticed in the course materials (either in class or reading the notes, etc.) where you thought to yourself “Oh, I’ll have to be really careful about that.” Why would you need to be careful?\n\n\n\n\nFigure 9.1: Image credit: Stefan Judis https://www.stefanjudis.com/blog/a-regular-expression-lookahead-lookbehind-cheat-sheet/\nFigure 9.2: Taskmaster Wiki https://taskmaster.fandom.com/wiki/Series_11\nFigure 9.3: Taskmaster Wiki https://taskmaster.fandom.com/wiki/Series_11",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "09-reg-expr.html#footnotes",
    "href": "09-reg-expr.html#footnotes",
    "title": "9  Regular expressions",
    "section": "",
    "text": "\\d\\d.\\d\\d.\\d\\d will work, but it will also match 123456. It is better to replace the dot with the characters of interest: \\d\\d[/.\\-]\\d\\d[/.\\-]\\d\\d. Remember that a dot inside a character class is just a dot. ↩︎\n^(1[012]|[1-9]):[0-5][0-9] (am|pm)$↩︎\nIn the former, the regex will search for \\bMary or Jane or Sue\\b. In the latter, the regex will search for \\bMary\\b or \\bJane\\b or \\bSue\\b. That is, Janet will match the former but not the latter.↩︎\nThanks to Ciaran Evans at Wake Forest University for example and code, https://sta279-f23.github.io/↩︎",
    "crumbs": [
      "Data exploration",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regular expressions</span>"
    ]
  },
  {
    "objectID": "01-intro.html#background",
    "href": "01-intro.html#background",
    "title": "1  Introduction1",
    "section": "1.2 Background",
    "text": "1.2 Background\nData Science includes the full pipeline for working with data. Some of the topics we will cover in DS 002R include:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDS workflow\nin DS002R\nbeyond DS002R\n\n\n\n\ndata acquisition\nweb scraping, relational databases\nAPIs\n\n\ndata exploration\nwrangling, strings, regular expressions\nnatural language processing\n\n\ndata visualization\ngrammar of graphics\nanimations\n\n\ndata conclusions\niteration, permutation tests\npredictive modeling, machine learning, AI\n\n\ndata communication\nyes!\nyes!\n\n\n\n\n\n\n\n\n\n1.2.1 Data\nWhat are data? Oftentimes, the word data brings to mind a spreadsheet, like the one below, which is tidy and describes characteristics of a group of penguins.\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntidy data\n\n\n\n\neach row = a unit of observation (here, a penguin)\neach column = a measure on some variable of interest, either quantitative (numbers with units) or categorical (discrete possibilities or categories)\neach entry contains a single data value; no analysis, summaries, footnotes, comments, etc, and only one value per cell\n\n\n\nBut the definition of datum can be much broader:\n\n\n\n\n\n\n\n\n\nDefinition of datum from the Oxford English Dictionary\n\n\n\n\nEach of the following can be thought of as data. How would you wrangle such information into a tidy format?\nData examples:\n\nthe emails in your inbox\n\nsocial media texts\n\nimages\n\nvideos\n\naudio files\n\nFor each example, provide:\n\nthe observational units (what does a row represent)\n\nat least 4 possible variables (what might we record for each observation)\n\nwho might use such data?\n\n\n\n1.2.2 Data Science in the Wild\nData science extracts knowledge from within a particular domain of inquiry. Examples from Pomona!\n\nShannon Burns (Psychological Science and Neuroscience) uses data to understand brain processes of social communication.\nAnthony (Tony) Clark uses data to improve the safety and reliability of mobile robots.\nJun Lang (Asian Languages and Literatures) uses data to analyze (1) the intersection of language, gender, and society, and (2) second language acquisition and pedagogy.\nFrank Pericolosi (Physical Education) uses data to improve his team’s chances on the field.\nAmi Radunskaya (Mathematics) uses data to model tumor growth and treatment.",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction^[Much of this content was inspired by great educators who provide open source materials for educational use.  Many thanks to Mine Çetinkaya-Rundel (Duke), Ben Baumer (Smith), Brianna Heggeseth (Macalester), Leslie Myint (Macalester), Paul Roback (St Olaf) for sharing their materials.]</span>"
    ]
  },
  {
    "objectID": "01-intro.html#tools",
    "href": "01-intro.html#tools",
    "title": "1  Introduction1",
    "section": "1.3 Tools",
    "text": "1.3 Tools\nWe use tools to do the things. But the tools are not the things.\n\nThe reproducible data analysis process\n\nScriptability \\(\\rightarrow\\) R\nLiterate programming \\(\\rightarrow\\) Quarto (via R Studio)\nVersion control \\(\\rightarrow\\) Git / GitHub\n\n\n\nScripting and literate programming\nDonald Knuth “Literate Programming” (1983)\n\nLet us change our traditional attitude to the construction of programs: Instead of imagining that our main task is to instruct a computer- what to do, let us concentrate rather on explaining to human beings- what we want a computer to do.\n\n\nThe ideas of literate programming have been around for many years!\nand tools for putting them to practice have also been around\nbut they have never been as accessible as the current tools\n\n\n\nReproducibility checklist\n\nAre the tables and figures reproducible from the code and data?\nDoes the code actually do what you think it does?\nIn addition to what was done, is it clear why it was done? (e.g., how were parameter settings chosen?)\nCan the code be used for other data?\nCan you extend the code to do other things?\n\n\n\n1.3.1 R and R Studio\n\nYou must use both R and R Studio software programs\nR does the programming\nR Studio brings everything together\nYou may use Pomona’s server: https://rstudio.pomona.edu/\n\n\n\n\n\n\n\n\n\n\nTaken from Modern Drive: An introduction to statistical and data sciences via R, by Ismay and Kim\n\n\n\n\n\n\n\n\n\n\n\n\n\nJessica Ward, PhD student at Newcastle University\n\n\n\n\n\n\n1.3.2 Git & GitHub\n\nYou must submit your assignments via GitHub\nFollow Jenny Bryan’s advice on how to get set-up: http://happygitwithr.com/\nClass specific instructions at https://ds002r-fds.netlify.app/github\n\nAdmittedly, there is a steep learning curve with Git. However, it is among the tools which you are most likely to use in your future endeavors, so spending a little time focusing on the concepts now may pay off big time in the future. Beyond practicing and working through http://happygitwithr.com/, you may want to read a little bit about what Git is doing behind the scenes. This reference: Learn git concepts, not commands is very good and accessible.\n\nTools: a GitHub merge conflict (demo)\n\nOn GitHub (on the web) edit the README document and Commit it with a message describing what you did.\nThen, in RStudio also edit the README document with a different change.\n\nCommit your changes\nTry to push \\(\\rightarrow\\) you’ll get an error!\nTry pulling\nResolve the merge conflict and then commit and push\n\nAs you work in teams you will run into merge conflicts, learning how to resolve them properly will be very important.\n\n\n\n\n\n\n\n\n\n\nhttps://xkcd.com/1597/\n\n\n\n\n\n\nSteps for weekly homework\n\nYou will get a link to the new assignment (clicking on the link will create a new private repo)\n\nUse R (within R Studio)\n\nNew Project, version control, Git\n\nClone the repo using SSH\n\n\nIf it exists, rename the Rmd file to ds002r-hw#-lname-fname.Rmd\n\nDo the assignment\n\ncommit and push after every problem\n\n\nAll necessary files must be in the same folder (e.g., data)",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction^[Much of this content was inspired by great educators who provide open source materials for educational use.  Many thanks to Mine Çetinkaya-Rundel (Duke), Ben Baumer (Smith), Brianna Heggeseth (Macalester), Leslie Myint (Macalester), Paul Roback (St Olaf) for sharing their materials.]</span>"
    ]
  },
  {
    "objectID": "01-intro.html#footnotes",
    "href": "01-intro.html#footnotes",
    "title": "1  Introduction1",
    "section": "",
    "text": "Much of this content was inspired by great educators who provide open source materials for educational use. Many thanks to Mine Çetinkaya-Rundel (Duke), Ben Baumer (Smith), Brianna Heggeseth (Macalester), Leslie Myint (Macalester), Paul Roback (St Olaf) for sharing their materials.↩︎",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction^[Much of this content was inspired by great educators who provide open source materials for educational use.  Many thanks to Mine Çetinkaya-Rundel (Duke), Ben Baumer (Smith), Brianna Heggeseth (Macalester), Leslie Myint (Macalester), Paul Roback (St Olaf) for sharing their materials.]</span>"
    ]
  },
  {
    "objectID": "02-github.html#pull",
    "href": "02-github.html#pull",
    "title": "2  GitHub",
    "section": "\n7.1 pull\n",
    "text": "7.1 pull\n\nIf you are working with a colleague or on different machines it is so incredibly important to get in the habit of immediately clicking on pull when you start your work. (If you are working alone on a single machine pull won’t hurt! You’ll just be told that your files are already up to date.)\n\n\n\n\nAlways pull before you start. pull-work-save-commit-push",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GitHub</span>"
    ]
  },
  {
    "objectID": "02-github.html#render-your-work",
    "href": "02-github.html#render-your-work",
    "title": "2  GitHub",
    "section": "\n7.2 Render your work",
    "text": "7.2 Render your work\nDon’t forget to put your name on the assignment. Also, make sure that you Render to pdf. Render early and often. The more often you Render, the fewer headaches you will have.\n\n\n\n\nAlways pull before you start. pull-work-render-commit-push",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GitHub</span>"
    ]
  },
  {
    "objectID": "02-github.html#commit-your-work",
    "href": "02-github.html#commit-your-work",
    "title": "2  GitHub",
    "section": "\n7.3 commit your work",
    "text": "7.3 commit your work\nYou don’t need to commit every file, but you do need to commit files that are integral to the analysis (always commit .qmd, .pdf, data files, images that created the pdf, etc.).\n\n\n\n\npull-work-render-commit-push",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GitHub</span>"
    ]
  },
  {
    "objectID": "02-github.html#push-your-work-to-github",
    "href": "02-github.html#push-your-work-to-github",
    "title": "2  GitHub",
    "section": "\n7.4 push your work to GitHub",
    "text": "7.4 push your work to GitHub\nIt is good practice to use meaningful commit messages to help your future self figure out your past work.\n\n\n\n\npull-work-render-commit-push",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GitHub</span>"
    ]
  },
  {
    "objectID": "02-github.html#check-your-work-on-github",
    "href": "02-github.html#check-your-work-on-github",
    "title": "2  GitHub",
    "section": "\n7.5 check your work on GitHub",
    "text": "7.5 check your work on GitHub\nTo make sure that the work went through, always check your GitHub repo online to confirm any changes you made.\n\n\n\n\nCheck that your changes are correct.",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GitHub</span>"
    ]
  },
  {
    "objectID": "02-github.html#connecting-your-github-account-to-gradescope",
    "href": "02-github.html#connecting-your-github-account-to-gradescope",
    "title": "2  GitHub",
    "section": "\n8.1 Connecting your GitHub account to Gradescope",
    "text": "8.1 Connecting your GitHub account to Gradescope\nThe first time you go to submit an assignment on Gradescope, you will be asked to connect to GitHub. Here are the steps to follow to make that connection:\n\nAccess Gradescope from Canvas: From Canvas, click on Gradescope in the Course Navigation menu. You will be asked to authorize the Gradescope integration.\nNavigate to Gradescope.com: In a new tab (same browser), navigate to https://www.gradescope.com/. Gradescope should recognize your student user account from the Canvas integration.\nGo to Gradescope Account Settings: Click on Account (bottom left of the screen) and then Edit Account.\n\n\n\n\n\nChange your Gradescope account settings.\n\n\n\nThis will take you to your Account Settings in Gradescope. Here, you’ll have the option to verify your Pomona email address and set up a password.\n\nLink Your GitHub Account to Gradescope: Scroll to the bottom of the page to the Link External Account menu. Click on Link a GitHub account.\n\n\n\n\n\nLinking GitHub to Gradescope.\n\n\n\nYou’ll be prompted to authorize GitHub and connect it to Gradescope. In the drop-down menu under Repositories, be sure to select “Public and private” to enable full access.\n\n\n\n\nAuthorizing Gradescope to talk to GitHub.\n\n\n\nWhen prompted, log in to your GitHub account to complete the process (I don’t know if you need your PAT or your “Go(ubs!” password, try both!).\nAfter your accounts have been linked, you’ll see a message that says “Successfully authenticated with GitHub.”\n\n\n\n\nSuccessful integration of GitHub and Gradescope\n\n\n\n\nReturn to Canvas & Verify the Connection\n\nNow, you can return to Canvas and navigate back to Gradescope. If you are returning to your previous tab, you may need to refresh the page to make sure your account settings are updated.\nClick on your programming assignment in Gradescope. Verify that the GitHub connection is working, and that you can see a list of your GitHub files in the drop-down menu when you are submitting an assignment.\n\n\n\n\nSubmitting HW from GitHub to Gradescope.",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GitHub</span>"
    ]
  },
  {
    "objectID": "02-github.html#submitting-assignments-after-having-connected-to-github",
    "href": "02-github.html#submitting-assignments-after-having-connected-to-github",
    "title": "2  GitHub",
    "section": "\n8.2 Submitting assignments after having connected to GitHub",
    "text": "8.2 Submitting assignments after having connected to GitHub\nTo submit your assignment, complete the following steps:\n\nVia Canvas, access the course’s Gradescope site, select the appropriate assignment, and then choose GitHub as the submission method.\nSelect the appropriate GitHub repository. The branch will always be “main”.\n\nYou can submit multiple times before the deadline. Your last submission will determine your grade.\nOnce assignments are completely graded, you will be able to see your grade and assignment feedback on Gradescope. Grades will also be synced with Canvas.",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GitHub</span>"
    ]
  },
  {
    "objectID": "02-github.html#reflection-questions",
    "href": "02-github.html#reflection-questions",
    "title": "2  GitHub",
    "section": "\n8.3  Reflection questions",
    "text": "8.3  Reflection questions",
    "crumbs": [
      "Introduction to data science",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GitHub</span>"
    ]
  }
]