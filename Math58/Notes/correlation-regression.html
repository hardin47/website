<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Correlation &amp; Regression | Introduction to (Bio)Statistics</title>
  <meta name="description" content="Class notes for both Math 58 and Math 58B at Pomona College: Introduction to Statistics and Introduction to Biostatistics. The notes are based extensively Introductory Statistics with Randomization and Simulation by Diez, Barr, and Cetinkaya-Rundel." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Correlation &amp; Regression | Introduction to (Bio)Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Class notes for both Math 58 and Math 58B at Pomona College: Introduction to Statistics and Introduction to Biostatistics. The notes are based extensively Introductory Statistics with Randomization and Simulation by Diez, Barr, and Cetinkaya-Rundel." />
  <meta name="github-repo" content="hardin47/website/Math58/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Correlation &amp; Regression | Introduction to (Bio)Statistics" />
  
  <meta name="twitter:description" content="Class notes for both Math 58 and Math 58B at Pomona College: Introduction to Statistics and Introduction to Biostatistics. The notes are based extensively Introductory Statistics with Randomization and Simulation by Diez, Barr, and Cetinkaya-Rundel." />
  

<meta name="author" content="Jo Hardin" />


<meta name="date" content="2020-04-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inference-for-numerical-data.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to (Bio)Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Class Information</a></li>
<li class="chapter" data-level="1" data-path="rfunc.html"><a href="rfunc.html"><i class="fa fa-check"></i><b>1</b> R functions</a><ul>
<li class="chapter" data-level="1.1" data-path="rfunc.html"><a href="rfunc.html#applets"><i class="fa fa-check"></i><b>1.1</b> Applets</a></li>
<li class="chapter" data-level="1.2" data-path="rfunc.html"><a href="rfunc.html#data-structure"><i class="fa fa-check"></i><b>1.2</b> Data Structure</a></li>
<li class="chapter" data-level="1.3" data-path="rfunc.html"><a href="rfunc.html#wrangling"><i class="fa fa-check"></i><b>1.3</b> Wrangling</a></li>
<li class="chapter" data-level="1.4" data-path="rfunc.html"><a href="rfunc.html#plotting"><i class="fa fa-check"></i><b>1.4</b> Plotting</a></li>
<li class="chapter" data-level="1.5" data-path="rfunc.html"><a href="rfunc.html#statistical-inference"><i class="fa fa-check"></i><b>1.5</b> Statistical Inference</a></li>
<li class="chapter" data-level="1.6" data-path="rfunc.html"><a href="rfunc.html#probability-models"><i class="fa fa-check"></i><b>1.6</b> Probability models</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#Jan21"><i class="fa fa-check"></i><b>2.1</b> 1/21/20 Agenda</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#course-logistics"><i class="fa fa-check"></i><b>2.2</b> Course Logistics</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#vocabulary"><i class="fa fa-check"></i>Vocabulary</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#ex:helper"><i class="fa fa-check"></i><b>2.3</b> Example: Friend or Foe</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html"><i class="fa fa-check"></i><b>3</b> Foundations for Inference</a><ul>
<li class="chapter" data-level="3.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Jan23"><i class="fa fa-check"></i><b>3.1</b> 1/23/20 Agenda</a></li>
<li class="chapter" data-level="3.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#ex:gend"><i class="fa fa-check"></i><b>3.2</b> Example: Gender Discrimination</a></li>
<li class="chapter" data-level="3.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#structure-of-hypothesis-testing"><i class="fa fa-check"></i><b>3.3</b> Structure of Hypothesis testing</a><ul>
<li class="chapter" data-level="3.3.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#hypotheses-1"><i class="fa fa-check"></i><b>3.3.1</b> Hypotheses</a></li>
<li class="chapter" data-level="3.3.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#other-pieces-of-the-process"><i class="fa fa-check"></i><b>3.3.2</b> Other pieces of the process</a></li>
<li class="chapter" data-level="3.3.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#all-together-structure-of-a-hypothesis-test"><i class="fa fa-check"></i><b>3.3.3</b> All together: structure of a hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Jan28"><i class="fa fa-check"></i><b>3.4</b> 1/28/20 Agenda</a></li>
<li class="chapter" data-level="3.5" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#normal-model"><i class="fa fa-check"></i><b>3.5</b> Normal Model</a><ul>
<li class="chapter" data-level="3.5.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#CLT"><i class="fa fa-check"></i><b>3.5.1</b> Central Limit Therm</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Jan30"><i class="fa fa-check"></i><b>3.6</b> 1/30/20 Agenda</a><ul>
<li class="chapter" data-level="3.6.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#norm"><i class="fa fa-check"></i><b>3.6.1</b> Normal Probabilities &amp; Z scores</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Feb4"><i class="fa fa-check"></i><b>3.7</b> 2/4/20 Agenda</a></li>
<li class="chapter" data-level="3.8" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#CI"><i class="fa fa-check"></i><b>3.8</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="3.8.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#theoretical-set-up"><i class="fa fa-check"></i><b>3.8.1</b> Theoretical set-up</a></li>
<li class="chapter" data-level="3.8.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-changes-in-extreme-poverty"><i class="fa fa-check"></i><b>3.8.2</b> Example: changes in extreme poverty</a></li>
<li class="chapter" data-level="3.8.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#modCI"><i class="fa fa-check"></i><b>3.8.3</b> Modifying CIs</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Feb6"><i class="fa fa-check"></i><b>3.9</b> 2/6/20 Agenda</a></li>
<li class="chapter" data-level="3.10" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Feb11"><i class="fa fa-check"></i><b>3.10</b> 2/11/20 Agenda</a></li>
<li class="chapter" data-level="3.11" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#samp"><i class="fa fa-check"></i><b>3.11</b> Sampling</a><ul>
<li class="chapter" data-level="3.11.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-aliens-on-earth"><i class="fa fa-check"></i><b>3.11.1</b> Example: aliens on Earth</a></li>
<li class="chapter" data-level="3.11.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-gettysburg-address"><i class="fa fa-check"></i><b>3.11.2</b> Example: Gettysburg Address</a></li>
<li class="chapter" data-level="3.11.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#key-sampling-terms"><i class="fa fa-check"></i><b>3.11.3</b> Key sampling terms</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Feb13"><i class="fa fa-check"></i><b>3.12</b> 2/13/20 Agenda</a></li>
<li class="chapter" data-level="3.13" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#errors"><i class="fa fa-check"></i><b>3.13</b> Errors &amp; Power</a><ul>
<li class="chapter" data-level="3.13.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-baseball-player"><i class="fa fa-check"></i><b>3.13.1</b> Example: baseball player</a></li>
<li class="chapter" data-level="3.13.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#errors-lessons-learned"><i class="fa fa-check"></i><b>3.13.2</b> Errors: lessons learned</a></li>
</ul></li>
<li class="chapter" data-level="3.14" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#reflection-questions"><i class="fa fa-check"></i><b>3.14</b> Reflection Questions</a><ul>
<li class="chapter" data-level="3.14.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#hypothesis-testing-chapter-2-sections-1-4"><i class="fa fa-check"></i><b>3.14.1</b> hypothesis testing: Chapter 2, Sections 1-4</a></li>
<li class="chapter" data-level="3.14.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#normal-model-chapter-2-sections-5-7"><i class="fa fa-check"></i><b>3.14.2</b> normal model: Chapter 2, Sections 5-7</a></li>
<li class="chapter" data-level="3.14.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#confidence-intervals-chapter-2-section-8"><i class="fa fa-check"></i><b>3.14.3</b> confidence intervals: Chapter 2, Section 8</a></li>
<li class="chapter" data-level="3.14.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#sampling-chapter-1-sections-3-4"><i class="fa fa-check"></i><b>3.14.4</b> sampling: Chapter 1, Sections 3-4</a></li>
<li class="chapter" data-level="3.14.5" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#errors-power-chapter-2-section-3"><i class="fa fa-check"></i><b>3.14.5</b> errors &amp; power: Chapter 2, Section 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html"><i class="fa fa-check"></i><b>4</b> Inference for categorical data</a><ul>
<li class="chapter" data-level="4.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#inference-for-a-single-proportion"><i class="fa fa-check"></i><b>4.1</b> Inference for a single proportion</a></li>
<li class="chapter" data-level="4.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb18M58"><i class="fa fa-check"></i><b>4.2</b> 2/18/20 Math 58 Agenda</a></li>
<li class="chapter" data-level="4.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb20M58"><i class="fa fa-check"></i><b>4.3</b> 2/20/20 Math 58 Agenda</a></li>
<li class="chapter" data-level="4.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-distribution-math-58-only"><i class="fa fa-check"></i><b>4.4</b> Binomial distribution (Math 58 only)</a><ul>
<li class="chapter" data-level="4.4.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-pop-quiz"><i class="fa fa-check"></i><b>4.4.1</b> Example: pop quiz</a></li>
<li class="chapter" data-level="4.4.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-hypothesis-testing"><i class="fa fa-check"></i><b>4.4.2</b> Binomial Hypothesis Testing</a></li>
<li class="chapter" data-level="4.4.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-power"><i class="fa fa-check"></i><b>4.4.3</b> Binomial Power</a></li>
<li class="chapter" data-level="4.4.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-confidence-intervals-for-p"><i class="fa fa-check"></i><b>4.4.4</b> Binomial Confidence Intervals for <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb18M58B"><i class="fa fa-check"></i><b>4.5</b> 2/18/20 Math 58B Agenda</a></li>
<li class="chapter" data-level="4.6" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb20M58B"><i class="fa fa-check"></i><b>4.6</b> 2/20/20 Math 58B Agenda</a></li>
<li class="chapter" data-level="4.7" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#relative-risk-math-58b-only"><i class="fa fa-check"></i><b>4.7</b> Relative Risk (Math 58B only)</a><ul>
<li class="chapter" data-level="4.7.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#inference-on-relative-risk"><i class="fa fa-check"></i><b>4.7.1</b> Inference on Relative Risk</a></li>
<li class="chapter" data-level="4.7.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#using-infer-for-inference-on-rr"><i class="fa fa-check"></i><b>4.7.2</b> Using <code>infer</code> for inference on RR</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#odds-ratios-math-58b-only"><i class="fa fa-check"></i><b>4.8</b> Odds Ratios (Math 58B only)</a><ul>
<li class="chapter" data-level="4.8.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-smoking-and-lung-cancer"><i class="fa fa-check"></i><b>4.8.1</b> Example: Smoking and Lung Cancer</a></li>
<li class="chapter" data-level="4.8.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#inference-on-odds-ratios"><i class="fa fa-check"></i><b>4.8.2</b> Inference on Odds Ratios</a></li>
<li class="chapter" data-level="4.8.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#confidence-interval-for-or-same-idea-as-with-rr"><i class="fa fa-check"></i><b>4.8.3</b> Confidence Interval for OR (same idea as with RR)</a></li>
<li class="chapter" data-level="4.8.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#using-infer-for-inference-on-or"><i class="fa fa-check"></i><b>4.8.4</b> Using <code>infer</code> for inference on OR</a></li>
<li class="chapter" data-level="4.8.5" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#ex:cov"><i class="fa fa-check"></i><b>4.8.5</b> Example: MERS-CoV</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb25"><i class="fa fa-check"></i><b>4.9</b> 2/25/20 Agenda</a></li>
<li class="chapter" data-level="4.10" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#diffprop"><i class="fa fa-check"></i><b>4.10</b> Difference of two proportions</a><ul>
<li class="chapter" data-level="4.10.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#clt-for-difference-in-two-proportions"><i class="fa fa-check"></i><b>4.10.1</b> CLT for difference in two proportions</a></li>
<li class="chapter" data-level="4.10.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#ht-difference-in-proportions"><i class="fa fa-check"></i><b>4.10.2</b> HT: difference in proportions</a></li>
<li class="chapter" data-level="4.10.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#ci-difference-in-proportions"><i class="fa fa-check"></i><b>4.10.3</b> CI: difference in proportions</a></li>
<li class="chapter" data-level="4.10.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-government-shutdown"><i class="fa fa-check"></i><b>4.10.4</b> Example: Government Shutdown</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb27"><i class="fa fa-check"></i><b>4.11</b> 2/27/20 Agenda</a></li>
<li class="chapter" data-level="4.12" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#experim"><i class="fa fa-check"></i><b>4.12</b> Types of Studies</a><ul>
<li class="chapter" data-level="4.12.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-hand-writing-sat-scores"><i class="fa fa-check"></i><b>4.12.1</b> Example: Hand Writing &amp; SAT Scores</a></li>
<li class="chapter" data-level="4.12.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-have-a-nice-trip"><i class="fa fa-check"></i><b>4.12.2</b> Example: Have a Nice Trip</a></li>
<li class="chapter" data-level="4.12.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#study-conclusions"><i class="fa fa-check"></i><b>4.12.3</b> Study conclusions</a></li>
</ul></li>
<li class="chapter" data-level="4.13" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Mar3"><i class="fa fa-check"></i><b>4.13</b> 3/3/20 Agenda</a></li>
<li class="chapter" data-level="4.14" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#chisq1"><i class="fa fa-check"></i><b>4.14</b> Goodness-of-fit: One categorical variable (<span class="math inline">\(\chi^2\)</span> test) <span class="math inline">\(\geq\)</span> 2 levels</a><ul>
<li class="chapter" data-level="4.14.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-household-ages"><i class="fa fa-check"></i><b>4.14.1</b> Example: Household Ages</a></li>
<li class="chapter" data-level="4.14.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-flax-seed"><i class="fa fa-check"></i><b>4.14.2</b> Example: Flax Seed</a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Mar5"><i class="fa fa-check"></i><b>4.15</b> 3/5/20 Agenda</a></li>
<li class="chapter" data-level="4.16" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#chisq2"><i class="fa fa-check"></i><b>4.16</b> Independence: Two categorical variables (<span class="math inline">\(\chi^2\)</span> test) <span class="math inline">\(\geq\)</span> 2 levels each</a><ul>
<li class="chapter" data-level="4.16.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-nightlights"><i class="fa fa-check"></i><b>4.16.1</b> Example: Nightlights</a></li>
</ul></li>
<li class="chapter" data-level="4.17" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#agenda"><i class="fa fa-check"></i><b>4.17</b> 3/10/20 &amp; 3/12/20 Agenda</a></li>
<li class="chapter" data-level="4.18" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#agenda-1"><i class="fa fa-check"></i><b>4.18</b> 3/17/20 &amp; 3/19/20 Agenda</a></li>
<li class="chapter" data-level="4.19" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#agenda-2"><i class="fa fa-check"></i><b>4.19</b> 3/24/20 Agenda</a></li>
<li class="chapter" data-level="4.20" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#census"><i class="fa fa-check"></i><b>4.20</b> Census</a><ul>
<li class="chapter" data-level="4.20.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#what-about-college-students"><i class="fa fa-check"></i><b>4.20.1</b> What about College students?</a></li>
</ul></li>
<li class="chapter" data-level="4.21" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#agenda-3"><i class="fa fa-check"></i><b>4.21</b> 3/26/20 Agenda</a></li>
<li class="chapter" data-level="4.22" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#covid19"><i class="fa fa-check"></i><b>4.22</b> COVID-19</a></li>
<li class="chapter" data-level="4.23" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#reflection-questions-1"><i class="fa fa-check"></i><b>4.23</b> Reflection Questions</a><ul>
<li class="chapter" data-level="4.23.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#no-isrs-binomial-probabilities-math-58-only"><i class="fa fa-check"></i><b>4.23.1</b> (no ISRS) Binomial probabilities (Math 58 only)</a></li>
<li class="chapter" data-level="4.23.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#no-isrs-relative-risk-odds-ratios-math-58b-only"><i class="fa fa-check"></i><b>4.23.2</b> (no ISRS) Relative Risk &amp; Odds Ratios (Math 58B only)</a></li>
<li class="chapter" data-level="4.23.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binary-variables-chapter-3-section-2"><i class="fa fa-check"></i><b>4.23.3</b> 2 binary variables: Chapter 3, Section 2</a></li>
<li class="chapter" data-level="4.23.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#types-of-studies-chapter-1-sections-4-5"><i class="fa fa-check"></i><b>4.23.4</b> Types of studies: Chapter 1, Sections 4-5</a></li>
<li class="chapter" data-level="4.23.5" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#categorical-variables-chapter-3-section-3"><i class="fa fa-check"></i><b>4.23.5</b> 2 categorical variables: Chapter 3, Section 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html"><i class="fa fa-check"></i><b>5</b> Inference for numerical data</a><ul>
<li class="chapter" data-level="5.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Mar31"><i class="fa fa-check"></i><b>5.1</b> 3/31/20 Agenda</a></li>
<li class="chapter" data-level="5.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#important-measures-related-to-quantitative-numeric-variables"><i class="fa fa-check"></i><b>5.2</b> Important measures related to quantitative (numeric) variables</a><ul>
<li class="chapter" data-level="5.2.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#quantitative-descriptives"><i class="fa fa-check"></i><b>5.2.1</b> Quantitative Descriptives</a></li>
<li class="chapter" data-level="5.2.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mean1dist"><i class="fa fa-check"></i><b>5.2.2</b> Sampling distribution of a sample mean</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Apr2"><i class="fa fa-check"></i><b>5.3</b> 4/2/20 Agenda</a></li>
<li class="chapter" data-level="5.4" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Apr7"><i class="fa fa-check"></i><b>5.4</b> 4/7/20 Agenda</a></li>
<li class="chapter" data-level="5.5" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mean1inf"><i class="fa fa-check"></i><b>5.5</b> Inference for a single mean, <span class="math inline">\(\mu\)</span></a><ul>
<li class="chapter" data-level="5.5.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mathematical-model-for-distribution-of-the-sample-mean"><i class="fa fa-check"></i><b>5.5.1</b> Mathematical model for distribution of the sample mean</a></li>
<li class="chapter" data-level="5.5.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#example-healthy-body-temperature"><i class="fa fa-check"></i><b>5.5.2</b> Example: healthy body temperature</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Apr9"><i class="fa fa-check"></i><b>5.6</b> 4/9/20 Agenda</a></li>
<li class="chapter" data-level="5.7" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Apr14"><i class="fa fa-check"></i><b>5.7</b> 4/14/20 Agenda</a></li>
<li class="chapter" data-level="5.8" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mean2inf"><i class="fa fa-check"></i><b>5.8</b> Comparing two independent means</a></li>
<li class="chapter" data-level="5.9" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#r-code-for-inference-on-1-or-2-means."><i class="fa fa-check"></i><b>5.9</b> R code for inference on 1 or 2 means.</a><ul>
<li class="chapter" data-level="5.9.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#t.test"><i class="fa fa-check"></i><b>5.9.1</b> <code>t.test</code></a></li>
<li class="chapter" data-level="5.9.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#infer"><i class="fa fa-check"></i><b>5.9.2</b> <code>infer</code></a></li>
<li class="chapter" data-level="5.9.3" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#nba-salaries-example-from-iscam-inv-4.2"><i class="fa fa-check"></i><b>5.9.3</b> NBA Salaries example from ISCAM Inv 4.2</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#reflection-questions-2"><i class="fa fa-check"></i><b>5.10</b> Reflection Questions</a><ul>
<li class="chapter" data-level="5.10.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#quantitative-variable-chapter-4-section-1"><i class="fa fa-check"></i><b>5.10.1</b> 1 quantitative variable: Chapter 4, Section 1</a></li>
<li class="chapter" data-level="5.10.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#means-1-quantitative-variable-1-binary-variable-chapter-4-section-3"><i class="fa fa-check"></i><b>5.10.2</b> 2 means (1 quantitative variable, 1 binary variable): Chapter 4, Section 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="correlation-regression.html"><a href="correlation-regression.html"><i class="fa fa-check"></i><b>6</b> Correlation &amp; Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="correlation-regression.html"><a href="correlation-regression.html#Apr16"><i class="fa fa-check"></i><b>6.1</b> 4/16/20 Agenda</a></li>
<li class="chapter" data-level="6.2" data-path="correlation-regression.html"><a href="correlation-regression.html#cor"><i class="fa fa-check"></i><b>6.2</b> Correlation</a><ul>
<li class="chapter" data-level="6.2.1" data-path="correlation-regression.html"><a href="correlation-regression.html#estimating-correlation"><i class="fa fa-check"></i><b>6.2.1</b> Estimating Correlation</a></li>
<li class="chapter" data-level="6.2.2" data-path="correlation-regression.html"><a href="correlation-regression.html#coefficient-of-determination-r2"><i class="fa fa-check"></i><b>6.2.2</b> Coefficient of Determination – <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="6.2.3" data-path="correlation-regression.html"><a href="correlation-regression.html#inference-for-correlation"><i class="fa fa-check"></i><b>6.2.3</b> Inference for correlation</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="correlation-regression.html"><a href="correlation-regression.html#Apr21"><i class="fa fa-check"></i><b>6.3</b> 4/21/20 Agenda</a></li>
<li class="chapter" data-level="6.4" data-path="correlation-regression.html"><a href="correlation-regression.html#Apr23"><i class="fa fa-check"></i><b>6.4</b> 4/23/20 Agenda</a></li>
<li class="chapter" data-level="6.5" data-path="correlation-regression.html"><a href="correlation-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.5</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="6.5.1" data-path="correlation-regression.html"><a href="correlation-regression.html#ls"><i class="fa fa-check"></i><b>6.5.1</b> Least Squares estimation of the regression line</a></li>
<li class="chapter" data-level="6.5.2" data-path="correlation-regression.html"><a href="correlation-regression.html#infbeta1"><i class="fa fa-check"></i><b>6.5.2</b> Inference on the slope, <span class="math inline">\(\beta_1\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="correlation-regression.html"><a href="correlation-regression.html#Apr28"><i class="fa fa-check"></i><b>6.6</b> 4/28/20 Agenda</a></li>
<li class="chapter" data-level="6.7" data-path="correlation-regression.html"><a href="correlation-regression.html#Apr30"><i class="fa fa-check"></i><b>6.7</b> 4/30/20 Agenda</a></li>
<li class="chapter" data-level="6.8" data-path="correlation-regression.html"><a href="correlation-regression.html#MLR"><i class="fa fa-check"></i><b>6.8</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="6.8.1" data-path="correlation-regression.html"><a href="correlation-regression.html#MLRmod"><i class="fa fa-check"></i><b>6.8.1</b> Model selection</a></li>
<li class="chapter" data-level="6.8.2" data-path="correlation-regression.html"><a href="correlation-regression.html#checking-model-assumptions"><i class="fa fa-check"></i><b>6.8.2</b> Checking model assumptions</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="correlation-regression.html"><a href="correlation-regression.html#r-code-for-regression"><i class="fa fa-check"></i><b>6.9</b> R code for regression</a><ul>
<li class="chapter" data-level="6.9.1" data-path="correlation-regression.html"><a href="correlation-regression.html#ex:cat"><i class="fa fa-check"></i><b>6.9.1</b> Example: Cat Jumping (Correlation &amp; SLR)</a></li>
<li class="chapter" data-level="6.9.2" data-path="correlation-regression.html"><a href="correlation-regression.html#ex:houses"><i class="fa fa-check"></i><b>6.9.2</b> Example: Housing Prices (SLR &amp; MLR &amp; Prediction)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://st47s.com/Math58" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to (Bio)Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="correlation-regression" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Correlation &amp; Regression</h1>
<div id="Apr16" class="section level2">
<h2><span class="header-section-number">6.1</span> 4/16/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Definition of correlation (r)</li>
<li>Interpretation of correlation (r)<br />
</li>
<li>(Probably not: Inference on <span class="math inline">\(\rho\)</span>)</li>
</ol>
<p>The last topic of the semester will focus on modeling and inference using two quantitative variables. That is, both the explanatory and the response variables are measured on a numeric scale.</p>
<p>To get started, consider a handful of variables taken on the top 80 PGA golfers in 2004. The example comes from Investigation 5.7 in <span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span></p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-1"></span>
<img src="figs/golf.jpg" alt="Investigation 5.7, `Drive for show, putt for dough`, @iscam" width="80%" />
<p class="caption">
Figure 2.1: Investigation 5.7, <code>Drive for show, putt for dough</code>, <span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span>
</p>
</div>
<p>Rank the seven scatterplots from strongest negative to strongest positive. Some questions to ask yourself:</p>
<ul>
<li>What would the correlation be if there was a perfect positive relationship?</li>
<li>What would the correlation be if there was a perfect negative relationship?</li>
<li>What would the correlation be if there was no relationship?</li>
</ul>
</div>
<div id="cor" class="section level2">
<h2><span class="header-section-number">6.2</span> Correlation</h2>
<p>Correlation measures the association between two numerical variables. [Note, that when describing how two categorical (or one numerical &amp; one categorical) variables vary together, they are said to be <em>associated</em> instead of <em>correlated</em>.]</p>
<blockquote>
<p>The <em>correlation coefficient</em> measures the strength and direction of the linear association between two numerical variables.</p>
</blockquote>
<div id="estimating-correlation" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Estimating Correlation</h3>
<p>The value of the correlation is defined as:</p>
<p><span class="math display">\[\begin{eqnarray*}
r &amp;=&amp; \frac{ \sum_i (x_i  - \overline{x})(y_i - \overline{y})}{\sqrt{\sum_i(x_i - \overline{x})^2} \sqrt{ \sum_i(y_i - \overline{y})^2}}\\
r &amp;=&amp; \frac{1}{n-1} \sum_{i=1}^n \bigg(\frac{x_i - \overline{x}}{s_x} \bigg) \bigg(\frac{y_i - \overline{y}}{s_y} \bigg)
\end{eqnarray*}\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-2"></span>
<img src="figs/golfcor.jpg" alt="Scatterplots with average X and Y values superimposed.  Investigation 5.7, `Drive for show, putt for dough`, @iscam" width="80%" />
<p class="caption">
Figure 2.2: Scatterplots with average X and Y values superimposed. Investigation 5.7, <code>Drive for show, putt for dough</code>, <span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span>
</p>
</div>
<p>For each red dot (on each plot), consider the distance the observation is from the <span class="math inline">\(\overline{X}\)</span> line and the <span class="math inline">\(\overline{Y}\)</span> line. Is the observation (red dot) above both? below both? above one and below the other?</p>
<p>How does the particular red dot (observation) contribute to the correlation? In a positive way (to make <span class="math inline">\(r\)</span> bigger)? In a negative way (to make <span class="math inline">\(r\)</span> smaller)?</p>
<p>Some ideas worth thinking about:</p>
<ul>
<li>quadratic plots can have zero correlation yet a perfect functional relationship</li>
<li><span class="math inline">\(-1 \leq r \leq 1\)</span></li>
<li>correlation does not imply causation (ice cream &amp; boating accidents!)</li>
<li>for inference with <span class="math inline">\(\rho\)</span> as well as <span class="math inline">\(\beta_1\)</span>, the data should come from a bivariate normal distribution. That is, histograms of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> should both be normal, and the scatterplot should be a cloud.</li>
<li>correlation will go down when only a narrow range of X values is represented (see denominator of r).</li>
<li>measurement error biases the estimate of a correlation coefficient toward zero.</li>
</ul>
</div>
<div id="coefficient-of-determination-r2" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Coefficient of Determination – <span class="math inline">\(R^2\)</span></h3>
<p>The coefficient of determination (<span class="math inline">\(R^2\)</span>) is the square of the correlation (given above). However, it also has an additional interpretation that will be useful for us. It can measure how much of the original variability in Y is given by the regression line. Both SSE and least-squares will be defined below when we fit a line to the scatter plot of observations.</p>
<p>SSE is “sum of squared errors” (think about how <span class="math inline">\(s^2\)</span> is defined). So, <span class="math inline">\(SSE(\overline{y})\)</span> is the amount the response variable varies on its own. <span class="math inline">\(SSE(\mbox{least-squares})\)</span> is the amount the response variable varies around the line.</p>
<p><span class="math display">\[\begin{eqnarray*}
R^2 &amp;=&amp; \frac{SSE(\overline{y}) - SSE(\mbox{least-squares})}{SSE(\overline{y})} \\
 &amp;=&amp; \frac{Var(y_i) - Var(e_i)}{Var(y_i)} \\
 &amp;=&amp; 1 - \frac{Var(e_i)}{Var(y_i)}\\
\end{eqnarray*}\]</span></p>
<p>[The value <span class="math inline">\(e_i\)</span> is discussed in detail below, but it is the distance from the observed response variable to the prediction on the line: $$e_i = y_i - _i.]$$</p>
<p><span class="math inline">\(R^2\)</span> can be used even in models with many explanatory variables. As such, the way to think about <span class="math inline">\(R^2\)</span> is in terms of how much of the variability in the response variable was removed (when we learned the values of the explanatory variables). <span class="math inline">\(R^2\)</span> <strong>is the proportion reduction in the variability of the response variable which is explained by the explanatory variable.</strong></p>
</div>
<div id="inference-for-correlation" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Inference for correlation</h3>
<p>Note: we won’t actually cover inference for correlation in class, but the notes on inference for correlation are included so that you can see that the process is very similar to all of the other statistics seen in the course to this point.</p>
<p>Parameter: <span class="math inline">\(\rho\)</span><br />
Statistic: <span class="math inline">\(r\)</span><br />
SE<span class="math inline">\(_r: \sqrt{\frac{1-r^2}{n-2}}\)</span><br />
<strong>BUT</strong>, <span class="math inline">\(r\)</span> is only normally distributed when <span class="math inline">\(\rho\)</span> = 0! Otherwise, the distribution of <span class="math inline">\(r\)</span> from sample to sample is skewed (think about the scenario when <span class="math inline">\(\rho = 0.9\)</span>).</p>
<div id="hypothesis-testing" class="section level4">
<h4><span class="header-section-number">6.2.3.1</span> Hypothesis Testing</h4>
<p><span class="math display">\[\begin{eqnarray*}
H_0:&amp;&amp; \rho = 0\\
H_A:&amp;&amp; \rho \ne 0\\
t^* &amp;=&amp; \frac{r}{SE_r} = \frac{r}{\sqrt{(1-r^2)/(n-2)}}\\
t^* &amp;\sim&amp; t_{n-2}  \mbox{ when } H_0 \mbox{ is true}
\end{eqnarray*}\]</span></p>
</div>
<div id="confidence-interval" class="section level4">
<h4><span class="header-section-number">6.2.3.2</span> Confidence Interval</h4>
<p>If <span class="math inline">\(\rho \ne 0\)</span>, then the SE might be okay, but the sampling distribution of <span class="math inline">\(r\)</span> will not be normal (and thus will not be a <span class="math inline">\(t\)</span> when we use the SE).</p>
<p>Let:</p>
<p><span class="math display">\[\begin{eqnarray*}
z &amp;=&amp; 0.5 \ln \bigg( \frac{1+r}{1-r} \bigg)\\
\xi &amp;=&amp; 0.5 \ln \bigg( \frac{1+\rho}{1-\rho} \bigg)\\
var(z) &amp;=&amp; \sqrt{\frac{1}{n-3}}\\
95\% \mbox{ CI for } \xi : &amp;&amp;\\
z &amp;\pm&amp; 1.96 \cdot \sqrt{\frac{1}{n-3}}\\
\mbox{we&#39;re 95% confident that } &amp;&amp; \\
&amp;&amp;z - 1.96 \cdot  \sqrt{\frac{1}{n-3}} \leq \xi \leq z + 1.96 \cdot \sqrt{\frac{1}{n-3}}\\
&amp;&amp; a \leq \xi \leq b\\
&amp;&amp; a \leq 0.5 \ln \bigg(\frac{1+\rho}{1-\rho} \bigg) \leq b\\
&amp;&amp; \frac{e^{2a} - 1}{e^{2a} + 1} \leq \rho \leq \frac{e^{2b} - 1}{e^{2b} + 1}
\end{eqnarray*}\]</span></p>
<p>See the Cat Jumping<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a> example below in section <a href="correlation-regression.html#ex:cat">6.9.1</a>.</p>
<p><strong>HT:</strong><br />
<span class="math display">\[\begin{eqnarray*}
H_0:&amp;&amp; \rho = 0\\
H_a:&amp;&amp; \rho \ne 0\\
t^* &amp;=&amp; \frac{r}{\sqrt{(1-r^2)/(n-2)}} = \frac{-0.496}{\sqrt{(1-0.496^2) / (18-2)}}= -2.2849\\
p-value &amp;=&amp; 2 \cdot P(t_{18-2} \leq -2.2849) = 2\cdot(pt(-2.2849,16)) = 0.036 \mbox{  (borderline significant)}
\end{eqnarray*}\]</span></p>
<p><strong>CI:</strong><br />
<span class="math display">\[\begin{eqnarray*}
95\% \mbox{CI for } \xi :&amp;&amp; \\
z \pm 1.96 \cdot \sqrt{\frac{1}{n-3}}&amp;&amp; \\
\mbox{we&#39;re } 95\% \mbox{ confident that}&amp;&amp;\\
 0.5 \ln\bigg(\frac{1+r}{1-r}\bigg) - 1.96 \cdot  \sqrt{\frac{1}{n-3}} &amp;\leq \xi \leq&amp; 0.5 \ln\bigg(\frac{1+r}{1-r}\bigg) + 1.96 \cdot \sqrt{\frac{1}{n-3}}\\
 0.5 \ln\bigg(\frac{1 - 0.496}{1+0.496}\bigg) - 1.96 \cdot  \sqrt{\frac{1}{18-3}} &amp;\leq \xi \leq &amp;0.5 \ln\bigg(\frac{1-0.496}{1+0.496}\bigg) + 1.96 \cdot \sqrt{\frac{1}{18-3}}\\
 -1.05 &amp;\leq \xi \leq &amp;-0.04\\
 \frac{e^{2\cdot -1.05} - 1}{e^{2\cdot -1.05} + 1} &amp;\leq \rho \leq&amp; \frac{e^{2\cdot -0.04} - 1}{e^{2\cdot -0.04} + 1}\\
&amp;&amp; (-0.781, -0.04)
\end{eqnarray*}\]</span></p>
</div>
</div>
</div>
<div id="Apr21" class="section level2">
<h2><span class="header-section-number">6.3</span> 4/21/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Least Squares estimation of the line</li>
<li>Distribution of the least squares line from sample to sample</li>
</ol>
</div>
<div id="Apr23" class="section level2">
<h2><span class="header-section-number">6.4</span> 4/23/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Inferential technical conditions</li>
<li>Residual Plots</li>
<li>Transformations</li>
<li>Prediction Intervals</li>
</ol>
</div>
<div id="simple-linear-regression" class="section level2">
<h2><span class="header-section-number">6.5</span> Simple Linear Regression</h2>
<p><em>Regression</em> is a method that predicts the value of one numerical variable from that of another. That is, as an extension to describing the degree of linearity of the relationship (correlation), the goal is now to create the best linear model – often for prediction. Note that many of the characteristics explored with correlation are applicable for regression. However, correlation treats <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> as interchangeable, whereas regression treats <span class="math inline">\(X\)</span> as fixed and known and <span class="math inline">\(Y\)</span> as random and unknown. As we have previously, we call <span class="math inline">\(X\)</span> the explanatory variable, and <span class="math inline">\(Y\)</span> the response variable. Again, we do not assume that there is any causal mechanism between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> even if they have a strong linear (or otherwise) relationship.</p>
<div id="population-model" class="section level4 unnumbered">
<h4>Population Model</h4>
<p>Notice the Greek letters representing parameters:</p>
<p><span class="math display">\[\begin{eqnarray*}
E[y|x] &amp;=&amp; \beta_0 + \beta_1 x \\
y_i &amp;=&amp; \beta_0 + \beta_1 x_i + \epsilon_i\\
\epsilon_i &amp;=&amp; y_i -  (\beta_0 + \beta_1 x_i)\\
\end{eqnarray*}\]</span></p>
</div>
<div id="predicted-values" class="section level4 unnumbered">
<h4>Predicted Values</h4>
<p>The predicted values of Y from a regression line estimate the <em>mean value</em> of <span class="math inline">\(Y\)</span> for all individuals that have a given value of <span class="math inline">\(X\)</span>. Notice the Roman letters (English letters) representing statistics:</p>
<p><span class="math display">\[\begin{eqnarray*}
\hat{y} &amp;=&amp; b_0 + b_1 x\\
\hat{y}_i &amp;=&amp; b_0 + b_1 x_i\\
y_i &amp;=&amp; b_0 + b_1 x_i + e_i\\
e_i &amp;=&amp; y_i - \hat{y}_i = y_i -  (b_0 + b_1 x_i)\\
\end{eqnarray*}\]</span></p>
<p>Notice, that we are predicting the <strong>mean</strong> value of the response variable at a given value of the explanatory variable!</p>
</div>
<div id="ls" class="section level3">
<h3><span class="header-section-number">6.5.1</span> Least Squares estimation of the regression line</h3>
<p>To find the values of the regression statistics, the sum of squared errors is minimized.</p>
<p><strong>SSE:</strong> Sum of squared errors (or residuals) is a measure of how closely the line fits to the points. SSE is the value of the squared deviations calculated at the “best” possible values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> for a given dataset.</p>
<p><span class="math display">\[\begin{eqnarray*}
SSE = \sum_i (y_i - \hat{y}_i)^2 = \sum_i (y_i - (b_0 + b_1 x_i) )^2
\end{eqnarray*}\]</span>
is minimized by the values:
<span class="math display">\[\begin{eqnarray*}
b_0 = \overline{y} - b_1 \overline{x} &amp; \ \ \ \ \ \ \ &amp; b_1 = r \frac{s_y}{s_x}
\end{eqnarray*}\]</span></p>
<p>To find the “best” fitting line, we searched for the line that has the smallest residuals (SSE) in some sense. In particular, the goal is to try to find the line that minimizes the following quantity: <span class="math display">\[Q=\sum e_i^2 = \sum (y_i-(b_0+b_1x_i))^2.\]</span></p>
<p>Finding <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> that minimize Q is a calculus problem.
<span class="math display">\[\frac{dQ}{db_0}=-2\sum (y_i-(b_0+b_1x_i)),\qquad \frac{dQ}{db_1}=-2\sum
x_i(y_i-(b_0+b_1x_i))\]</span>
Setting both derivatives equal to 0 and solving for <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> yields the optimal values, denoted as <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span></p>
<p>One aspect of the optimization problem that is worth pointing out has to do with the role of the two variables of interest <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. If we switch the roles of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, the best fitting line will be different. If the relationship was invariant to which variable we choose as a response, then switching the roles of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> should give a slope of <span class="math inline">\(1/b_1\)</span>, which is not the case. [Note that the role of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> <strong>is</strong> invariant when calculating the correlation but not when calculating the least squares regression line.]</p>
<div id="residuals" class="section level4 unnumbered">
<h4>Residuals</h4>
<p>Residuals measure the scatter of points above and below the least squares regression line. We use the residuals in many of the calculations and interpretations of the model. Indeed, the goal of the linear regression is to find a model that has small residuals. That is, ideally, the known variable <span class="math inline">\(X\)</span> will tell us all there is to know about the unknown variable <span class="math inline">\(Y\)</span>.</p>
<p><span class="math display">\[\begin{eqnarray*}
e_i &amp;=&amp; (y_i - \hat{y}_i)\\
MSE&amp;=&amp; \frac{\sum_i (y_i - \hat{y}_i)^2}{n-2} = \frac{\sum_i (e_i)^2}{n-2} = s^2\\
SSE &amp;=&amp; \sum_i (y_i - \hat{y}_i)^2 = \sum_i (e_i)^2\\
R^2 &amp;=&amp; 1 - \frac{Var(e_i)}{Var(y_i)}
\end{eqnarray*}\]</span></p>
</div>
</div>
<div id="infbeta1" class="section level3">
<h3><span class="header-section-number">6.5.2</span> Inference on the slope, <span class="math inline">\(\beta_1\)</span></h3>
<div id="se-of-the-slope" class="section level4 unnumbered">
<h4>SE of the slope</h4>
<p><span class="math display">\[\begin{eqnarray*}
SE(b_1) &amp;=&amp; \sqrt{\frac{MSE}{\sum_i (x_i - \overline{x})^2}} = \sqrt{\frac{MSE}{(n-1)s_x^2}} = = \sqrt{\frac{\frac{\sum_i (y_i - \hat{y}_i)^2}{n-2}}{(n-1)s_x^2}}\\
\end{eqnarray*}\]</span></p>
<p>Just like any other statistic, the value of <span class="math inline">\(b_1\)</span> can be calculated for every sample. The manner in which <span class="math inline">\(b_1\)</span> varies from sample to sample becomes the sampling distribution of the sample slope. The SE of the slope will be the standard deviation associated with the sampling distribution of the slope. The resulting inference theory is very similar to that which we saw with the mean. The CLT describes <span class="math inline">\(b_1\)</span> to have a normal distribution, and estimating the <span class="math inline">\(SE(b_1)\)</span> induces extra variability which leads to a t-score test statistic with a t-distribution with df = <span class="math inline">\(n-2\)</span>.</p>
<p><span class="math display">\[\begin{eqnarray*}
\mbox{t-score} = \frac{b_1 - \beta_1}{SE(b_1)} \sim t_{n-2}
\end{eqnarray*}\]</span></p>
</div>
<div id="ci-for-the-slope" class="section level4 unnumbered">
<h4>CI for the slope</h4>
<p><span class="math display">\[\begin{eqnarray*}
b_1- t^*_{\alpha/2, n-2} SE(b_1) \leq \beta_1 \leq b_1 + t^*_{\alpha/2, n-2} SE(b_1)
\end{eqnarray*}\]</span></p>
<p>See the Housing Prices<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a> example below in section <a href="correlation-regression.html#ex:houses">6.9.2</a>.</p>
<p><span class="math display">\[\begin{eqnarray*}
t_{\alpha/2,n-2} &amp;=&amp; qt(.975, 18-2) = 2.1199\\
SE(b_1) &amp;=&amp; 26.4\\
b_1 &amp;=&amp; 202\\
b_1 &amp;\pm&amp; t_{\alpha/2, n-2} SE(b_1): 202 \pm 2.1199 \cdot 26.4\\
&amp;&amp; (146.03, 257.97)\\
\end{eqnarray*}\]</span></p>
<p>That is, we are 95% confident that the true average change in price associated with an additional square foot of house is between $146.03 and $257.97.</p>
</div>
<div id="ht-for-the-slope" class="section level4 unnumbered">
<h4>HT for the slope</h4>
<p>As mentioned previously,
<span class="math display">\[\begin{eqnarray*}
\mbox{t-score} = \frac{b_1 - \beta_1}{SE(b_1)} \sim t_{n-2}
\end{eqnarray*}\]</span></p>
<p>Typically, interested is in testing whether or not the slope is zero. The null hypothesis of <span class="math inline">\(H_0: \beta_1 = 0\)</span> addresses whether there is a non-zero linear relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>:</p>
<p><span class="math display">\[\begin{eqnarray*}
H_0:&amp;&amp; \mbox{ the slope of the regression line is zero}, \beta_1=0\\
H_A:&amp;&amp; \mbox{ the slope of the regression line is not zero}, \beta_1 \ne 0\\
\end{eqnarray*}\]</span></p>
<p>As with previous tests, the alternative can be one- or two-sided (depending on the research question).</p>
<p>Again, back to the housing data… (consider a two sided test)
<span class="math display">\[\begin{eqnarray*}
t^* &amp;=&amp; 7.67\\
p-value &amp;=&amp; 2 \cdot P(t_{16} \geq 7.67) = 2 \cdot (1-pt(7.67, 16)) \approx 0
\end{eqnarray*}\]</span></p>
</div>
<div id="regression-technical-conditions" class="section level4 unnumbered">
<h4>Regression Technical Conditions</h4>
<ul>
<li><strong>L:</strong> At each value of X, there is a population of possible Y-values whose mean lies on the “true” regression line (<strong>linearity</strong>)</li>
<li><strong>I:</strong> At each value of X, the Y-measurements represent a random sample from the population of possible Y-values (<strong>independence</strong>) [Consider this example of lack of independence. The researcher is trying to determine whether the number of pieces in a puzzle is linearly associated with the time to complete the puzzle. At first we choose 2 people and let them do 10 puzzles each. Then we let 20 independent people do the puzzles. The first experiment will create a slope which is particular to the two people sampled (it may or may not be close to the parameter). The second one will create a slope close to the 20 people sampled. Note that the effective variability of the first model is based on n=2, but we <em>think</em> it is based on n=20 (if we don’t notice the lack of independence). The second slope is based on n=20, and so it will have the correct associated variability.]</li>
<li><strong>N:</strong> At each value of X, the distribution of possible Y-values is normal (<strong>normality</strong>)</li>
<li><strong>E:</strong> The variance of Y-values is the same at all values of X (<strong>equal variance</strong>)</li>
</ul>
</div>
<div id="residual-plots" class="section level4 unnumbered">
<h4>Residual Plots</h4>
<p>Within a residual plot, you should be looking for the same types of things you want in a scatter plot. [See the residual plots provided in section <a href="correlation-regression.html#ex:cat">6.9.1</a>.]</p>
<ul>
<li>a roughly symmetric cloud of points above and below the horizontal line at zero, with a higher density of points close to the line than far from the line,<br />
</li>
<li>little noticeable curvature as we move from left to right along the X-axis, and<br />
</li>
<li>approximately equal variance of points above and below the line at all values of X.</li>
</ul>
</div>
</div>
</div>
<div id="Apr28" class="section level2">
<h2><span class="header-section-number">6.6</span> 4/28/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Multiple Linear Regression</li>
</ol>
</div>
<div id="Apr30" class="section level2">
<h2><span class="header-section-number">6.7</span> 4/30/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Choosing model</li>
<li>Residual Plots</li>
<li>Prediction Intervals (harder to plot!)</li>
</ol>
</div>
<div id="MLR" class="section level2">
<h2><span class="header-section-number">6.8</span> Multiple Linear Regression</h2>
<div id="MLRmod" class="section level3">
<h3><span class="header-section-number">6.8.1</span> Model selection</h3>
</div>
<div id="checking-model-assumptions" class="section level3">
<h3><span class="header-section-number">6.8.2</span> Checking model assumptions</h3>
</div>
</div>
<div id="r-code-for-regression" class="section level2">
<h2><span class="header-section-number">6.9</span> R code for regression</h2>
<div id="ex:cat" class="section level3">
<h3><span class="header-section-number">6.9.1</span> Example: Cat Jumping<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a> (Correlation &amp; SLR)</h3>
<p>Consider the cat data given in Investigations 5.6 and 5.13. The idea is to understand cat jumping velocity as a function of body characteristics. Note that the correlation <span class="math inline">\(r=-0.496\)</span> between bodymass and velocity.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb170-1" data-line-number="1">cats &lt;-<span class="st"> </span><span class="kw">read_table2</span>(<span class="st">&quot;http://www.rossmanchance.com/iscam2/data/CatJumping.txt&quot;</span>)</a>
<a class="sourceLine" id="cb170-2" data-line-number="2"></a>
<a class="sourceLine" id="cb170-3" data-line-number="3"><span class="kw">ggplot</span>(cats, <span class="kw">aes</span>(<span class="dt">x=</span>bodymass, <span class="dt">y =</span> velocity)) <span class="op">+</span></a>
<a class="sourceLine" id="cb170-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb170-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<p><img src="05-CorReg_files/figure-html/unnamed-chunk-3-1.png" width="480" style="display: block; margin: auto;" /></p>
<div id="correlation" class="section level4 unnumbered">
<h4>Correlation</h4>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb171-1" data-line-number="1">cats <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb171-2" data-line-number="2"><span class="st">  </span><span class="kw">select</span>(bodymass, velocity) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb171-3" data-line-number="3"><span class="st">  </span><span class="kw">cor</span>()</a></code></pre></div>
<pre><code>##            bodymass   velocity
## bodymass  1.0000000 -0.4964022
## velocity -0.4964022  1.0000000</code></pre>
</div>
<div id="simple-linear-regression-1" class="section level4 unnumbered">
<h4>Simple Linear Regression</h4>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb173-1" data-line-number="1"><span class="kw">summary</span>(<span class="kw">lm</span>(velocity <span class="op">~</span><span class="st"> </span>bodymass, <span class="dt">data =</span> cats))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = velocity ~ bodymass, data = cats)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -48.069 -16.729  -8.524  10.546  84.625 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 394.473238  23.441939  16.828 1.35e-11 ***
## bodymass     -0.012196   0.005332  -2.287   0.0361 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 29.6 on 16 degrees of freedom
## Multiple R-squared:  0.2464, Adjusted R-squared:  0.1993 
## F-statistic: 5.232 on 1 and 16 DF,  p-value: 0.03613</code></pre>
<p>An alternative way to work with the output is in specific pieces (instead of the entire summary output).</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb175-1" data-line-number="1"><span class="kw">library</span>(broom)</a>
<a class="sourceLine" id="cb175-2" data-line-number="2"></a>
<a class="sourceLine" id="cb175-3" data-line-number="3"><span class="kw">lm</span>(velocity <span class="op">~</span><span class="st"> </span>bodymass, <span class="dt">data =</span> cats) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## # A tibble: 2 x 7
##   term        estimate std.error statistic  p.value conf.low  conf.high
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;
## 1 (Intercept) 394.      23.4         16.8  1.35e-11 345.     444.      
## 2 bodymass     -0.0122   0.00533     -2.29 3.61e- 2  -0.0235  -0.000893</code></pre>
</div>
<div id="residual-plot" class="section level4 unnumbered">
<h4>Residual Plot</h4>
<p>And to work with the residuals, use <code>augment()</code>.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb177-1" data-line-number="1"><span class="kw">lm</span>(velocity <span class="op">~</span><span class="st"> </span>bodymass, <span class="dt">data =</span> cats) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span>()</a></code></pre></div>
<pre><code>## # A tibble: 18 x 9
##    velocity bodymass .fitted .se.fit .resid   .hat .sigma .cooksd
##       &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
##  1     334.     3640    350.    7.58 -15.6  0.0656   30.3 1.04e-2
##  2     387.     2670    362.   10.7   25.4  0.131    29.7 6.40e-2
##  3     411.     5600    326.   10.2   84.6  0.119    19.8 6.29e-1
##  4     319.     4130    344.    6.99 -25.5  0.0557   29.8 2.32e-2
##  5     369.     3020    358.    9.38  11.1  0.101    30.4 8.67e-3
##  6     359.     2660    362.   10.8   -3.23 0.132    30.6 1.05e-3
##  7     345.     3240    355.    8.64 -10.4  0.0853   30.4 6.24e-3
##  8     325.     5140    332.    8.60  -7.19 0.0844   30.5 2.97e-3
##  9     301.     3690    349.    7.48 -48.1  0.0639   27.7 9.62e-2
## 10     332.     3620    350.    7.62 -18.5  0.0664   30.2 1.49e-2
## 11     313.     5310    330.    9.16 -17.1  0.0957   30.2 1.96e-2
## 12     317.     5560    327.   10.1   -9.86 0.116    30.4 8.23e-3
## 13     376.     3970    346.    7.08  29.5  0.0572   29.5 3.21e-2
## 14     372.     3770    348.    7.34  23.9  0.0615   29.9 2.28e-2
## 15     314.     5100    332.    8.48 -18.0  0.0820   30.2 1.79e-2
## 16     368.     2950    358.    9.64   9.01 0.106    30.5 6.14e-3
## 17     286.     7930    298.   21.1  -11.5  0.508    30.3 1.57e-1
## 18     352.     3550    351.    7.78   1.32 0.0692   30.6 7.97e-5
## # … with 1 more variable: .std.resid &lt;dbl&gt;</code></pre>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb179-1" data-line-number="1"><span class="kw">lm</span>(velocity <span class="op">~</span><span class="st"> </span>bodymass, <span class="dt">data =</span> cats) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb179-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> .fitted, <span class="dt">y =</span> .resid)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb179-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb179-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>)</a></code></pre></div>
<p><img src="05-CorReg_files/figure-html/unnamed-chunk-7-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<div id="confidence-prediction-intervals" class="section level4 unnumbered">
<h4>Confidence &amp; Prediction Intervals</h4>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb180-1" data-line-number="1">m_cats &lt;-<span class="st"> </span><span class="kw">lm</span>(velocity <span class="op">~</span><span class="st"> </span>bodymass, <span class="dt">data =</span> cats)</a>
<a class="sourceLine" id="cb180-2" data-line-number="2"></a>
<a class="sourceLine" id="cb180-3" data-line-number="3"><span class="kw">predict</span>(m_cats, <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">bodymass=</span><span class="dv">4700</span>), <span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>)</a></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 337.1514 321.3081 352.9947</code></pre>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb182-1" data-line-number="1"><span class="kw">predict</span>(m_cats, <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">bodymass=</span><span class="dv">4700</span>), <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)</a></code></pre></div>
<pre><code>##        fit      lwr     upr
## 1 337.1514 272.4378 401.865</code></pre>
<div id="plotting-1" class="section level5 unnumbered">
<h5>Plotting!</h5>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb184-1" data-line-number="1">catConf &lt;-<span class="st"> </span>m_cats <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb184-2" data-line-number="2"><span class="st">  </span><span class="kw">cbind</span>(<span class="kw">predict</span>(m_cats, <span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>) )  <span class="co"># cbind binds the columns together</span></a>
<a class="sourceLine" id="cb184-3" data-line-number="3"></a>
<a class="sourceLine" id="cb184-4" data-line-number="4">catConf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</a></code></pre></div>
<pre><code>##   velocity bodymass  .fitted   .se.fit     .resid       .hat   .sigma
## 1    334.5     3640 350.0793  7.582579 -15.579293 0.06563257 30.28374
## 2    387.3     2670 361.9095 10.722878  25.390452 0.13125270 29.74812
## 3    410.8     5600 326.1749 10.228079  84.625139 0.11941906 19.80527
## 4    318.6     4130 344.1032  6.985435 -25.503185 0.05570221 29.80778
## 5    368.7     3020 357.6409  9.384496  11.059101 0.10053270 30.41969
## 6    358.8     2660 362.0315 10.763427  -3.231509 0.13224725 30.55520
##       .cooksd .std.resid      fit      lwr      upr
## 1 0.010414418 -0.5445423 350.0793 334.0049 366.1536
## 2 0.063990821  0.9203785 361.9095 339.1781 384.6410
## 3 0.629490813  3.0468951 326.1749 304.4923 347.8574
## 4 0.023189898 -0.8867122 344.1032 329.2947 358.9116
## 5 0.008674247  0.3939761 357.6409 337.7467 377.5351
## 6 0.001046793 -0.1172061 362.0315 339.2141 384.8490</code></pre>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb186-1" data-line-number="1"><span class="kw">ggplot</span>(catConf, <span class="kw">aes</span>(<span class="dt">x=</span>bodymass)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb186-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y=</span>velocity)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb186-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>.fitted)) <span class="op">+</span></a>
<a class="sourceLine" id="cb186-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>lwr, <span class="dt">ymax=</span>upr), <span class="dt">fill=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.2</span>)</a></code></pre></div>
<p><img src="05-CorReg_files/figure-html/unnamed-chunk-9-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb187-1" data-line-number="1">catPred &lt;-<span class="st"> </span>m_cats <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb187-2" data-line-number="2"><span class="st">  </span><span class="kw">cbind</span>(<span class="kw">predict</span>(m_cats, <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>) )  <span class="co"># cbind binds the columns together</span></a>
<a class="sourceLine" id="cb187-3" data-line-number="3"></a>
<a class="sourceLine" id="cb187-4" data-line-number="4">catPred <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</a></code></pre></div>
<pre><code>##   velocity bodymass  .fitted   .se.fit     .resid       .hat   .sigma
## 1    334.5     3640 350.0793  7.582579 -15.579293 0.06563257 30.28374
## 2    387.3     2670 361.9095 10.722878  25.390452 0.13125270 29.74812
## 3    410.8     5600 326.1749 10.228079  84.625139 0.11941906 19.80527
## 4    318.6     4130 344.1032  6.985435 -25.503185 0.05570221 29.80778
## 5    368.7     3020 357.6409  9.384496  11.059101 0.10053270 30.41969
## 6    358.8     2660 362.0315 10.763427  -3.231509 0.13224725 30.55520
##       .cooksd .std.resid      fit      lwr      upr
## 1 0.010414418 -0.5445423 350.0793 285.3088 414.8498
## 2 0.063990821  0.9203785 361.9095 295.1746 428.6445
## 3 0.629490813  3.0468951 326.1749 259.7898 392.5599
## 4 0.023189898 -0.8867122 344.1032 279.6352 408.5712
## 5 0.008674247  0.3939761 357.6409 291.8183 423.4635
## 6 0.001046793 -0.1172061 362.0315 295.2672 428.7958</code></pre>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb189-1" data-line-number="1"><span class="kw">ggplot</span>(catPred, <span class="kw">aes</span>(<span class="dt">x=</span>bodymass)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb189-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y=</span>velocity)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb189-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>.fitted)) <span class="op">+</span></a>
<a class="sourceLine" id="cb189-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>lwr, <span class="dt">ymax=</span>upr), <span class="dt">fill=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.2</span>)</a></code></pre></div>
<p><img src="05-CorReg_files/figure-html/unnamed-chunk-10-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
<div id="ex:houses" class="section level3">
<h3><span class="header-section-number">6.9.2</span> Example: Housing Prices<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a> (SLR &amp; MLR &amp; Prediction)</h3>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb190-1" data-line-number="1"><span class="kw">library</span>(GGally)</a>
<a class="sourceLine" id="cb190-2" data-line-number="2">house =<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;http://www.rossmanchance.com/iscam2/data/housing.txt&quot;</span>, </a>
<a class="sourceLine" id="cb190-3" data-line-number="3">                   <span class="dt">header=</span><span class="ot">TRUE</span>, <span class="dt">sep=</span><span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>)</a>
<a class="sourceLine" id="cb190-4" data-line-number="4"><span class="kw">names</span>(house)</a></code></pre></div>
<pre><code>## [1] &quot;sqft&quot;     &quot;price&quot;    &quot;City&quot;     &quot;bedrooms&quot; &quot;baths&quot;</code></pre>
<div id="descriptive-statistics" class="section level4 unnumbered">
<h4>Descriptive Statistics</h4>
<p>A good first step is to investigate how all the variables relate to one another. The <code>ggpairs</code> function come from the R package <code>GGally</code>.</p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb192-1" data-line-number="1"><span class="kw">ggpairs</span>(house, <span class="dt">columns =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">5</span>))</a></code></pre></div>
<p><img src="05-CorReg_files/figure-html/unnamed-chunk-12-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<div id="simple-linear-regression-2" class="section level4 unnumbered">
<h4>Simple Linear Regression</h4>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb193-1" data-line-number="1">mod.sqft &lt;-<span class="st"> </span><span class="kw">lm</span>(price<span class="op">~</span>sqft, <span class="dt">data =</span> house)</a>
<a class="sourceLine" id="cb193-2" data-line-number="2">mod.sqft <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</a></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   65930.   60994.       1.08 2.83e- 1
## 2 sqft            202.      26.4      7.67 3.35e-11</code></pre>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb195-1" data-line-number="1">mod.bed &lt;-<span class="st"> </span><span class="kw">lm</span>(price <span class="op">~</span><span class="st"> </span>bedrooms, <span class="dt">data=</span>house)</a>
<a class="sourceLine" id="cb195-2" data-line-number="2">mod.bed <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</a></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)  220612.   107208.      2.06 0.0428 
## 2 bedrooms      76865.    28802.      2.67 0.00919</code></pre>
<p>The p-values for both explanatory variables (sqft and bedrooms) are significant. Sqft seems more significant, and indeed, the first model has a higher <span class="math inline">\(R^2\)</span> - that is, a higher proportion of the variability in price is explained by sqft (42.07%) than by number of bedrooms (8.08%).</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb197-1" data-line-number="1">mod.sqft <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">glance</span>()</a></code></pre></div>
<pre><code>## # A tibble: 1 x 11
##   r.squared adj.r.squared  sigma statistic  p.value    df logLik   AIC
##       &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1     0.421         0.414 2.22e5      58.8 3.35e-11     2 -1139. 2283.
## # … with 3 more variables: BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, df.residual &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb199-1" data-line-number="1">mod.bed <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">glance</span>()</a></code></pre></div>
<pre><code>## # A tibble: 1 x 11
##   r.squared adj.r.squared  sigma statistic p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1    0.0808        0.0695 2.80e5      7.12 0.00919     2 -1158. 2321. 2329.
## # … with 2 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;</code></pre>
<p>However, it is important for us to ask whether either of the relationships actually fit the technical conditions of the linear regression model. We can see from the pairs plots that the relationships look <strong>L</strong>inear, we’ll assume the variables were collected <strong>I</strong>ndependently, but the <strong>N</strong>ormality and the <strong>E</strong>quality of the error structure we can check using residual plots.</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb201-1" data-line-number="1">mod.sqft <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span> () <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb201-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> .fitted, <span class="dt">y =</span> .resid))<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb201-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb201-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept=</span><span class="dv">0</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb201-5" data-line-number="5"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Residual plot for price as a function of sqft&quot;</span>)</a></code></pre></div>
<p><img src="05-CorReg_files/figure-html/unnamed-chunk-15-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb202-1" data-line-number="1">mod.bed <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span> () <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb202-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> .fitted, <span class="dt">y =</span> .resid))<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb202-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb202-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept=</span><span class="dv">0</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb202-5" data-line-number="5"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Residual plot for price as a function of bedrooms&quot;</span>)</a></code></pre></div>
<p><img src="05-CorReg_files/figure-html/unnamed-chunk-15-2.png" width="480" style="display: block; margin: auto;" /></p>
<p>For both of the plots, it seems like the residuals have higher variability for positive residuals. Additionally, it seems that the variability of the residuals increases for larger fitted observations.</p>
<p>A natural log transformation should fix both of these problems.</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb203-1" data-line-number="1">mod.lnsqft &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(price)<span class="op">~</span>sqft, <span class="dt">data =</span> house)</a>
<a class="sourceLine" id="cb203-2" data-line-number="2">mod.lnbed &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(price) <span class="op">~</span><span class="st"> </span>bedrooms, <span class="dt">data=</span>house)</a>
<a class="sourceLine" id="cb203-3" data-line-number="3"></a>
<a class="sourceLine" id="cb203-4" data-line-number="4"></a>
<a class="sourceLine" id="cb203-5" data-line-number="5">mod.lnsqft <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span> () <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb203-6" data-line-number="6"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> .fitted, <span class="dt">y =</span> .resid))<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb203-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb203-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept=</span><span class="dv">0</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb203-9" data-line-number="9"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Residual plot for ln(price) as a function of sqft&quot;</span>)</a></code></pre></div>
<p><img src="05-CorReg_files/figure-html/unnamed-chunk-16-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb204-1" data-line-number="1">mod.lnbed <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span> () <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb204-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> .fitted, <span class="dt">y =</span> .resid))<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb204-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb204-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept=</span><span class="dv">0</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb204-5" data-line-number="5"><span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Residual plot for ln(price) as a function of bedrooms&quot;</span>)</a></code></pre></div>
<p><img src="05-CorReg_files/figure-html/unnamed-chunk-16-2.png" width="480" style="display: block; margin: auto;" /></p>
<p>Though no residual plot will ever look perfect, these residual plots seem to fit the technical conditions of the model better than the untransformed data.</p>
</div>
<div id="multiple-linear-regression" class="section level4 unnumbered">
<h4>Multiple Linear Regression</h4>
<p>Because the price variable had a large skew (and the <code>ln()</code> transformation helped the residuals), the following models will all use <code>ln(price)</code> as the response variable. What happens when we try to predict <code>price</code> (actually <code>ln(price)</code>, here) using BOTH <code>sqft</code> and <code>bedrooms</code>?</p>
<p>Note: the natural log funciton in R is <code>log()</code>.</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb205-1" data-line-number="1"><span class="kw">lm</span>(<span class="kw">log</span>(price) <span class="op">~</span><span class="st"> </span>sqft <span class="op">+</span><span class="st"> </span>bedrooms, <span class="dt">data=</span>house) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</a></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   term         estimate std.error statistic  p.value
##   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept) 12.2      0.174         70.1  1.39e-73
## 2 sqft         0.000468 0.0000660      7.09 4.73e-10
## 3 bedrooms    -0.0603   0.0572        -1.05 2.95e- 1</code></pre>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb207-1" data-line-number="1"><span class="kw">lm</span>(<span class="kw">log</span>(price) <span class="op">~</span><span class="st"> </span>sqft <span class="op">+</span><span class="st"> </span>bedrooms, <span class="dt">data=</span>house) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">glance</span>()</a></code></pre></div>
<pre><code>## # A tibble: 1 x 11
##   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     0.448         0.435 0.450      32.5 4.62e-11     3  -50.0  108.  118.
## # … with 2 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb209-1" data-line-number="1"><span class="kw">lm</span>(<span class="kw">log</span>(price) <span class="op">~</span><span class="st"> </span>sqft <span class="op">+</span><span class="st"> </span>baths, <span class="dt">data=</span>house) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</a></code></pre></div>
<pre><code>## # A tibble: 3 x 5
##   term         estimate std.error statistic  p.value
##   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept) 12.1      0.151        80.0   4.07e-78
## 2 sqft         0.000450 0.0000705     6.39  1.02e- 8
## 3 baths       -0.0377   0.0746       -0.505 6.15e- 1</code></pre>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb211-1" data-line-number="1"><span class="kw">lm</span>(<span class="kw">log</span>(price) <span class="op">~</span><span class="st"> </span>sqft <span class="op">+</span><span class="st"> </span>baths, <span class="dt">data=</span>house) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">glance</span>()</a></code></pre></div>
<pre><code>## # A tibble: 1 x 11
##   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     0.443         0.429 0.452      31.8 7.07e-11     3  -50.4  109.  118.
## # … with 2 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb213-1" data-line-number="1"><span class="kw">lm</span>(<span class="kw">log</span>(price) <span class="op">~</span><span class="st"> </span>sqft <span class="op">+</span><span class="st"> </span>bedrooms <span class="op">+</span><span class="st"> </span>baths, <span class="dt">data=</span>house) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</a></code></pre></div>
<pre><code>## # A tibble: 4 x 5
##   term         estimate std.error statistic  p.value
##   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept) 12.2      0.175        69.5   1.38e-72
## 2 sqft         0.000463 0.0000719     6.45  8.32e- 9
## 3 bedrooms    -0.0683   0.0730       -0.935 3.53e- 1
## 4 baths        0.0168   0.0947        0.177 8.60e- 1</code></pre>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb215-1" data-line-number="1"><span class="kw">lm</span>(<span class="kw">log</span>(price) <span class="op">~</span><span class="st"> </span>sqft <span class="op">+</span><span class="st"> </span>bedrooms <span class="op">+</span><span class="st"> </span>baths, <span class="dt">data=</span>house) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">glance</span>()</a></code></pre></div>
<pre><code>## # A tibble: 1 x 11
##   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     0.449         0.428 0.453      21.4 2.98e-10     4  -49.9  110.  122.
## # … with 2 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;</code></pre>
<p><strong>Sqft &amp; bedrooms</strong></p>
<p>Although the <span class="math inline">\(R^2\)</span> value went up (44.84% of variability in log price is explained by sqft and bedrooms), the p-value on bedrooms isn’t significant. The p-value here can be interpreted as a hypothesis test on the slope coefficient given the other variables in the model.</p>
<p>0.353 = P(a slope of -.06827 or more extreme <em>if sqft is in the model</em> and there is no relationship between bedrooms and price)</p>
<p>Our output says that once we have sqft in the model, we don’t actually need to know anything about the number of bedrooms (even though bedrooms was a significant predictor on its own).</p>
<p><strong>Sqft &amp; bathrooms</strong></p>
<p>Seems like we <em>really</em> don’t need bathrooms! The information about <code>sqft</code> is sufficient for predicting the price, and information about bathrooms doesn’t help much at all.</p>
<p><strong>Final model</strong></p>
<p>The final model will be run on log(price) using only sqft. Note that the coefficients and the <span class="math inline">\(R^2\)</span> values change slightly (from the original analysis) because the response variable is logged.</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb217-1" data-line-number="1"><span class="kw">summary</span>(mod.lnsqft)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(price) ~ sqft, data = house)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.08988 -0.29591 -0.05899  0.28717  1.20206 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 1.204e+01  1.236e-01   97.36  &lt; 2e-16 ***
## sqft        4.274e-04  5.349e-05    7.99 7.87e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4502 on 81 degrees of freedom
## Multiple R-squared:  0.4407, Adjusted R-squared:  0.4338 
## F-statistic: 63.83 on 1 and 81 DF,  p-value: 7.874e-12</code></pre>
</div>
<div id="prediction" class="section level4 unnumbered">
<h4>Prediction</h4>
<p>As with the prediction intervals we had when we had a single sample, we can now create intervals for either an average (a confidence interval) of an individual (a prediction interval).</p>
<div id="confidence-interval-1" class="section level5 unnumbered">
<h5>Confidence interval:</h5>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb219-1" data-line-number="1"><span class="kw">predict</span>(mod.lnsqft, <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">sqft=</span><span class="dv">2000</span>), <span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>)</a></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 12.89125 12.79211 12.99038</code></pre>
<p>I am 95% confident that the true average log price for a 2000 sqft home is between 12.79 ln$ and 12.99 ln$. (The predicted value is in natural-log-dollars … which is hard to interpret , but back-transforming can be a little tricky and beyond the scope of this semester).</p>
</div>
<div id="prediction-interval" class="section level5 unnumbered">
<h5>Prediction interval:</h5>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb221-1" data-line-number="1"><span class="kw">predict</span>(mod.lnsqft, <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">sqft=</span><span class="dv">2000</span>), <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>)</a></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 12.89125 11.98994 13.79255</code></pre>
<p>I am 95% of homes with 2000 sqft are between 11.99 ln$ and 13.79 ln$. Now back-transforming is easy (because there are no averages), so 95% of homes with 2000 sqft are between $161,126 and $977,301 (which are just <span class="math inline">\(e^{11.98994}\)</span> and <span class="math inline">\(e^{13.79255}\)</span>).</p>
</div>
<div id="plotting-confidence-bounds" class="section level5 unnumbered">
<h5>Plotting confidence bounds:</h5>
<p>A <strong>confidence</strong> interval around the line gives bounds on the parameter represented by the line. So we are 95% confident that the true population line lies within the bounds. Note that the interval is wider at the endpoints (because the variability is higher at the ends).</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb223-1" data-line-number="1">houseConf &lt;-<span class="st"> </span>mod.lnsqft <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb223-2" data-line-number="2"><span class="st">  </span><span class="kw">cbind</span>(<span class="kw">predict</span>(mod.lnsqft, <span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>) )  <span class="co"># cbind binds the columns together</span></a>
<a class="sourceLine" id="cb223-3" data-line-number="3"></a>
<a class="sourceLine" id="cb223-4" data-line-number="4">houseConf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</a></code></pre></div>
<pre><code>##   log.price. sqft  .fitted    .se.fit      .resid       .hat    .sigma
## 1   12.73376 3392 13.48618 0.08417041 -0.75242702 0.03494894 0.4448768
## 2   13.71004 4100 13.78878 0.11696192 -0.07874048 0.06748451 0.4529518
## 3   13.01398 3200 13.40412 0.07609566 -0.39014391 0.02856505 0.4508768
## 4   12.38839 1436 12.65019 0.06143750 -0.26180404 0.01862011 0.4520790
## 5   12.84133 1944 12.86731 0.05029208 -0.02598585 0.01247712 0.4530341
## 6   12.61120 1500 12.67755 0.05946735 -0.06634311 0.01744506 0.4529817
##        .cooksd  .std.resid      fit      lwr      upr
## 1 5.240194e-02 -1.70116646 13.48618 13.31871 13.65366
## 2 1.186788e-03 -0.18110383 13.78878 13.55606 14.02150
## 3 1.136429e-02 -0.87917543 13.40412 13.25272 13.55553
## 4 3.268479e-03 -0.58696923 12.65019 12.52795 12.77244
## 5 2.130978e-05 -0.05807924 12.86731 12.76725 12.96738
## 6 1.961713e-04 -0.14865344 12.67755 12.55923 12.79587</code></pre>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb225-1" data-line-number="1"><span class="kw">ggplot</span>(houseConf, <span class="kw">aes</span>(<span class="dt">x=</span>sqft)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb225-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y=</span>log.price.)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb225-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>.fitted)) <span class="op">+</span></a>
<a class="sourceLine" id="cb225-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>lwr, <span class="dt">ymax=</span>upr), <span class="dt">fill=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.2</span>)</a></code></pre></div>
<p><img src="05-CorReg_files/figure-html/unnamed-chunk-23-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>A <strong>prediction</strong> interval around the line bounds the individual points. That is, 95% of the observations are captured inside the interval. As with the confidence interval, the prediction interval is also wider at the ends, but it is harder to see in prediction intervals than confidence intervals</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb226-1" data-line-number="1">housePred &lt;-<span class="st"> </span>mod.lnsqft <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb226-2" data-line-number="2"><span class="st">  </span><span class="kw">cbind</span>(<span class="kw">predict</span>(mod.lnsqft, <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>) )  <span class="co"># cbind binds the columns together</span></a>
<a class="sourceLine" id="cb226-3" data-line-number="3"></a>
<a class="sourceLine" id="cb226-4" data-line-number="4">housePred <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</a></code></pre></div>
<pre><code>##   log.price. sqft  .fitted    .se.fit      .resid       .hat    .sigma
## 1   12.73376 3392 13.48618 0.08417041 -0.75242702 0.03494894 0.4448768
## 2   13.71004 4100 13.78878 0.11696192 -0.07874048 0.06748451 0.4529518
## 3   13.01398 3200 13.40412 0.07609566 -0.39014391 0.02856505 0.4508768
## 4   12.38839 1436 12.65019 0.06143750 -0.26180404 0.01862011 0.4520790
## 5   12.84133 1944 12.86731 0.05029208 -0.02598585 0.01247712 0.4530341
## 6   12.61120 1500 12.67755 0.05946735 -0.06634311 0.01744506 0.4529817
##        .cooksd  .std.resid      fit      lwr      upr
## 1 5.240194e-02 -1.70116646 13.48618 12.57483 14.39754
## 2 1.186788e-03 -0.18110383 13.78878 12.86321 14.71435
## 3 1.136429e-02 -0.87917543 13.40412 12.49558 14.31266
## 4 3.268479e-03 -0.58696923 12.65019 11.74606 13.55433
## 5 2.130978e-05 -0.05807924 12.86731 11.96591 13.76872
## 6 1.961713e-04 -0.14865344 12.67755 11.77393 13.58116</code></pre>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb228-1" data-line-number="1"><span class="kw">ggplot</span>(housePred, <span class="kw">aes</span>(<span class="dt">x=</span>sqft)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb228-2" data-line-number="2"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y=</span>log.price.)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb228-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>.fitted)) <span class="op">+</span></a>
<a class="sourceLine" id="cb228-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin=</span>lwr, <span class="dt">ymax=</span>upr), <span class="dt">fill=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">alpha=</span><span class="fl">0.2</span>)</a></code></pre></div>
<p><img src="05-CorReg_files/figure-html/unnamed-chunk-24-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<div id="predicting-with-more-than-one-explanatory-variable" class="section level5 unnumbered">
<h5>Predicting with more than one explanatory variable:</h5>
<p>The predict function still works to give estimates of the average value and the predicted individual values, but the plot is now much harder to draw because with three explanatory variables, we would need a 4-d plot to visualize the model and the predictions.</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb229-1" data-line-number="1">sqftbedbathlm =<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(price)<span class="op">~</span>sqft <span class="op">+</span><span class="st"> </span>bedrooms <span class="op">+</span><span class="st"> </span>baths, <span class="dt">data=</span>house)</a>
<a class="sourceLine" id="cb229-2" data-line-number="2"></a>
<a class="sourceLine" id="cb229-3" data-line-number="3"><span class="kw">predict</span>(sqftbedbathlm, </a>
<a class="sourceLine" id="cb229-4" data-line-number="4">        <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">sqft=</span><span class="dv">2000</span>, <span class="dt">bedrooms=</span><span class="dv">3</span>, <span class="dt">baths=</span><span class="dv">2</span>), </a>
<a class="sourceLine" id="cb229-5" data-line-number="5">        <span class="dt">interval=</span><span class="st">&quot;confidence&quot;</span>, <span class="dt">level=</span>.<span class="dv">95</span>)</a></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 12.91816 12.80085 13.03548</code></pre>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb231-1" data-line-number="1"><span class="kw">predict</span>(sqftbedbathlm, </a>
<a class="sourceLine" id="cb231-2" data-line-number="2">        <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">sqft=</span><span class="dv">2000</span>, <span class="dt">bedrooms=</span><span class="dv">3</span>, <span class="dt">baths=</span><span class="dv">2</span>), </a>
<a class="sourceLine" id="cb231-3" data-line-number="3">        <span class="dt">interval=</span><span class="st">&quot;prediction&quot;</span>, <span class="dt">level=</span>.<span class="dv">95</span>)</a></code></pre></div>
<pre><code>##        fit      lwr     upr
## 1 12.91816 12.00953 13.8268</code></pre>
<p>Again, it is hard to back-transform the prediction for the <strong>average</strong> (we end up thinking about it as a median), but we can back-transform the interval of individual prices. 95% of homes with 2000sqft, 3 bedrooms, and 2 baths cost between $164,312 and $1,011,356.</p>

</div>
</div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-iscam">
<p>Chance, Beth, and Allan Rossman. 2018. <em>Investigating Statistics, Concepts, Applications, and Methods</em>. 3rd ed. <a href="http://www.rossmanchance.com/iscam3/">http://www.rossmanchance.com/iscam3/</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="22">
<li id="fn22"><p><span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span>, Inv 5.6 &amp; 5.13<a href="correlation-regression.html#fnref22" class="footnote-back">↩</a></p></li>
<li id="fn23"><p><span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span>, Inv 5.14<a href="correlation-regression.html#fnref23" class="footnote-back">↩</a></p></li>
<li id="fn24"><p><span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span>, Inv 5.6 &amp; 5.13<a href="correlation-regression.html#fnref24" class="footnote-back">↩</a></p></li>
<li id="fn25"><p><span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span>, Inv 5.14<a href="correlation-regression.html#fnref25" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inference-for-numerical-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-CorReg.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Math-58-Notes.pdf", "Math-58-Notes.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
