<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Inference for categorical data | Introduction to (Bio)Statistics</title>
  <meta name="description" content="Class notes for both Math 58 and Math 58B at Pomona College: Introduction to Statistics and Introduction to Biostatistics. The notes are based extensively Introductory Statistics with Randomization and Simulation by Diez, Barr, and Cetinkaya-Rundel." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Inference for categorical data | Introduction to (Bio)Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Class notes for both Math 58 and Math 58B at Pomona College: Introduction to Statistics and Introduction to Biostatistics. The notes are based extensively Introductory Statistics with Randomization and Simulation by Diez, Barr, and Cetinkaya-Rundel." />
  <meta name="github-repo" content="hardin47/website/Math58/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Inference for categorical data | Introduction to (Bio)Statistics" />
  
  <meta name="twitter:description" content="Class notes for both Math 58 and Math 58B at Pomona College: Introduction to Statistics and Introduction to Biostatistics. The notes are based extensively Introductory Statistics with Randomization and Simulation by Diez, Barr, and Cetinkaya-Rundel." />
  

<meta name="author" content="Jo Hardin" />


<meta name="date" content="2020-04-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="foundations-for-inference.html"/>
<link rel="next" href="inference-for-numerical-data.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to (Bio)Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Class Information</a></li>
<li class="chapter" data-level="1" data-path="rfunc.html"><a href="rfunc.html"><i class="fa fa-check"></i><b>1</b> R functions</a><ul>
<li class="chapter" data-level="1.1" data-path="rfunc.html"><a href="rfunc.html#applets"><i class="fa fa-check"></i><b>1.1</b> Applets</a></li>
<li class="chapter" data-level="1.2" data-path="rfunc.html"><a href="rfunc.html#data-structure"><i class="fa fa-check"></i><b>1.2</b> Data Structure</a></li>
<li class="chapter" data-level="1.3" data-path="rfunc.html"><a href="rfunc.html#wrangling"><i class="fa fa-check"></i><b>1.3</b> Wrangling</a></li>
<li class="chapter" data-level="1.4" data-path="rfunc.html"><a href="rfunc.html#plotting"><i class="fa fa-check"></i><b>1.4</b> Plotting</a></li>
<li class="chapter" data-level="1.5" data-path="rfunc.html"><a href="rfunc.html#statistical-inference"><i class="fa fa-check"></i><b>1.5</b> Statistical Inference</a></li>
<li class="chapter" data-level="1.6" data-path="rfunc.html"><a href="rfunc.html#probability-models"><i class="fa fa-check"></i><b>1.6</b> Probability models</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#Jan21"><i class="fa fa-check"></i><b>2.1</b> 1/21/20 Agenda</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#course-logistics"><i class="fa fa-check"></i><b>2.2</b> Course Logistics</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#vocabulary"><i class="fa fa-check"></i>Vocabulary</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#ex:helper"><i class="fa fa-check"></i><b>2.3</b> Example: Friend or Foe</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html"><i class="fa fa-check"></i><b>3</b> Foundations for Inference</a><ul>
<li class="chapter" data-level="3.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Jan23"><i class="fa fa-check"></i><b>3.1</b> 1/23/20 Agenda</a></li>
<li class="chapter" data-level="3.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#ex:gend"><i class="fa fa-check"></i><b>3.2</b> Example: Gender Discrimination</a></li>
<li class="chapter" data-level="3.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#structure-of-hypothesis-testing"><i class="fa fa-check"></i><b>3.3</b> Structure of Hypothesis testing</a><ul>
<li class="chapter" data-level="3.3.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#hypotheses-1"><i class="fa fa-check"></i><b>3.3.1</b> Hypotheses</a></li>
<li class="chapter" data-level="3.3.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#other-pieces-of-the-process"><i class="fa fa-check"></i><b>3.3.2</b> Other pieces of the process</a></li>
<li class="chapter" data-level="3.3.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#all-together-structure-of-a-hypothesis-test"><i class="fa fa-check"></i><b>3.3.3</b> All together: structure of a hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Jan28"><i class="fa fa-check"></i><b>3.4</b> 1/28/20 Agenda</a></li>
<li class="chapter" data-level="3.5" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#normal-model"><i class="fa fa-check"></i><b>3.5</b> Normal Model</a><ul>
<li class="chapter" data-level="3.5.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#CLT"><i class="fa fa-check"></i><b>3.5.1</b> Central Limit Therm</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Jan30"><i class="fa fa-check"></i><b>3.6</b> 1/30/20 Agenda</a><ul>
<li class="chapter" data-level="3.6.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#norm"><i class="fa fa-check"></i><b>3.6.1</b> Normal Probabilities &amp; Z scores</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Feb4"><i class="fa fa-check"></i><b>3.7</b> 2/4/20 Agenda</a></li>
<li class="chapter" data-level="3.8" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#CI"><i class="fa fa-check"></i><b>3.8</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="3.8.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#theoretical-set-up"><i class="fa fa-check"></i><b>3.8.1</b> Theoretical set-up</a></li>
<li class="chapter" data-level="3.8.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-changes-in-extreme-poverty"><i class="fa fa-check"></i><b>3.8.2</b> Example: changes in extreme poverty</a></li>
<li class="chapter" data-level="3.8.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#modCI"><i class="fa fa-check"></i><b>3.8.3</b> Modifying CIs</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Feb6"><i class="fa fa-check"></i><b>3.9</b> 2/6/20 Agenda</a></li>
<li class="chapter" data-level="3.10" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Feb11"><i class="fa fa-check"></i><b>3.10</b> 2/11/20 Agenda</a></li>
<li class="chapter" data-level="3.11" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#samp"><i class="fa fa-check"></i><b>3.11</b> Sampling</a><ul>
<li class="chapter" data-level="3.11.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-aliens-on-earth"><i class="fa fa-check"></i><b>3.11.1</b> Example: aliens on Earth</a></li>
<li class="chapter" data-level="3.11.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-gettysburg-address"><i class="fa fa-check"></i><b>3.11.2</b> Example: Gettysburg Address</a></li>
<li class="chapter" data-level="3.11.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#key-sampling-terms"><i class="fa fa-check"></i><b>3.11.3</b> Key sampling terms</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Feb13"><i class="fa fa-check"></i><b>3.12</b> 2/13/20 Agenda</a></li>
<li class="chapter" data-level="3.13" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#errors"><i class="fa fa-check"></i><b>3.13</b> Errors &amp; Power</a><ul>
<li class="chapter" data-level="3.13.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-baseball-player"><i class="fa fa-check"></i><b>3.13.1</b> Example: baseball player</a></li>
<li class="chapter" data-level="3.13.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#errors-lessons-learned"><i class="fa fa-check"></i><b>3.13.2</b> Errors: lessons learned</a></li>
</ul></li>
<li class="chapter" data-level="3.14" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#reflection-questions"><i class="fa fa-check"></i><b>3.14</b> Reflection Questions</a><ul>
<li class="chapter" data-level="3.14.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#hypothesis-testing-chapter-2-sections-1-4"><i class="fa fa-check"></i><b>3.14.1</b> hypothesis testing: Chapter 2, Sections 1-4</a></li>
<li class="chapter" data-level="3.14.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#normal-model-chapter-2-sections-5-7"><i class="fa fa-check"></i><b>3.14.2</b> normal model: Chapter 2, Sections 5-7</a></li>
<li class="chapter" data-level="3.14.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#confidence-intervals-chapter-2-section-8"><i class="fa fa-check"></i><b>3.14.3</b> confidence intervals: Chapter 2, Section 8</a></li>
<li class="chapter" data-level="3.14.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#sampling-chapter-1-sections-3-4"><i class="fa fa-check"></i><b>3.14.4</b> sampling: Chapter 1, Sections 3-4</a></li>
<li class="chapter" data-level="3.14.5" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#errors-power-chapter-2-section-3"><i class="fa fa-check"></i><b>3.14.5</b> errors &amp; power: Chapter 2, Section 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html"><i class="fa fa-check"></i><b>4</b> Inference for categorical data</a><ul>
<li class="chapter" data-level="4.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#inference-for-a-single-proportion"><i class="fa fa-check"></i><b>4.1</b> Inference for a single proportion</a></li>
<li class="chapter" data-level="4.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb18M58"><i class="fa fa-check"></i><b>4.2</b> 2/18/20 Math 58 Agenda</a></li>
<li class="chapter" data-level="4.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb20M58"><i class="fa fa-check"></i><b>4.3</b> 2/20/20 Math 58 Agenda</a></li>
<li class="chapter" data-level="4.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-distribution-math-58-only"><i class="fa fa-check"></i><b>4.4</b> Binomial distribution (Math 58 only)</a><ul>
<li class="chapter" data-level="4.4.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-pop-quiz"><i class="fa fa-check"></i><b>4.4.1</b> Example: pop quiz</a></li>
<li class="chapter" data-level="4.4.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-hypothesis-testing"><i class="fa fa-check"></i><b>4.4.2</b> Binomial Hypothesis Testing</a></li>
<li class="chapter" data-level="4.4.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-power"><i class="fa fa-check"></i><b>4.4.3</b> Binomial Power</a></li>
<li class="chapter" data-level="4.4.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-confidence-intervals-for-p"><i class="fa fa-check"></i><b>4.4.4</b> Binomial Confidence Intervals for <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb18M58B"><i class="fa fa-check"></i><b>4.5</b> 2/18/20 Math 58B Agenda</a></li>
<li class="chapter" data-level="4.6" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb20M58B"><i class="fa fa-check"></i><b>4.6</b> 2/20/20 Math 58B Agenda</a></li>
<li class="chapter" data-level="4.7" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#relative-risk-math-58b-only"><i class="fa fa-check"></i><b>4.7</b> Relative Risk (Math 58B only)</a><ul>
<li class="chapter" data-level="4.7.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#inference-on-relative-risk"><i class="fa fa-check"></i><b>4.7.1</b> Inference on Relative Risk</a></li>
<li class="chapter" data-level="4.7.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#using-infer-for-inference-on-rr"><i class="fa fa-check"></i><b>4.7.2</b> Using <code>infer</code> for inference on RR</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#odds-ratios-math-58b-only"><i class="fa fa-check"></i><b>4.8</b> Odds Ratios (Math 58B only)</a><ul>
<li class="chapter" data-level="4.8.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-smoking-and-lung-cancer"><i class="fa fa-check"></i><b>4.8.1</b> Example: Smoking and Lung Cancer</a></li>
<li class="chapter" data-level="4.8.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#inference-on-odds-ratios"><i class="fa fa-check"></i><b>4.8.2</b> Inference on Odds Ratios</a></li>
<li class="chapter" data-level="4.8.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#confidence-interval-for-or-same-idea-as-with-rr"><i class="fa fa-check"></i><b>4.8.3</b> Confidence Interval for OR (same idea as with RR)</a></li>
<li class="chapter" data-level="4.8.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#using-infer-for-inference-on-or"><i class="fa fa-check"></i><b>4.8.4</b> Using <code>infer</code> for inference on OR</a></li>
<li class="chapter" data-level="4.8.5" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#ex:cov"><i class="fa fa-check"></i><b>4.8.5</b> Example: MERS-CoV</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb25"><i class="fa fa-check"></i><b>4.9</b> 2/25/20 Agenda</a></li>
<li class="chapter" data-level="4.10" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#diffprop"><i class="fa fa-check"></i><b>4.10</b> Difference of two proportions</a><ul>
<li class="chapter" data-level="4.10.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#clt-for-difference-in-two-proportions"><i class="fa fa-check"></i><b>4.10.1</b> CLT for difference in two proportions</a></li>
<li class="chapter" data-level="4.10.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#ht-difference-in-proportions"><i class="fa fa-check"></i><b>4.10.2</b> HT: difference in proportions</a></li>
<li class="chapter" data-level="4.10.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#ci-difference-in-proportions"><i class="fa fa-check"></i><b>4.10.3</b> CI: difference in proportions</a></li>
<li class="chapter" data-level="4.10.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-government-shutdown"><i class="fa fa-check"></i><b>4.10.4</b> Example: Government Shutdown</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb27"><i class="fa fa-check"></i><b>4.11</b> 2/27/20 Agenda</a></li>
<li class="chapter" data-level="4.12" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#experim"><i class="fa fa-check"></i><b>4.12</b> Types of Studies</a><ul>
<li class="chapter" data-level="4.12.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-hand-writing-sat-scores"><i class="fa fa-check"></i><b>4.12.1</b> Example: Hand Writing &amp; SAT Scores</a></li>
<li class="chapter" data-level="4.12.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-have-a-nice-trip"><i class="fa fa-check"></i><b>4.12.2</b> Example: Have a Nice Trip</a></li>
<li class="chapter" data-level="4.12.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#study-conclusions"><i class="fa fa-check"></i><b>4.12.3</b> Study conclusions</a></li>
</ul></li>
<li class="chapter" data-level="4.13" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Mar3"><i class="fa fa-check"></i><b>4.13</b> 3/3/20 Agenda</a></li>
<li class="chapter" data-level="4.14" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#chisq1"><i class="fa fa-check"></i><b>4.14</b> Goodness-of-fit: One categorical variable (<span class="math inline">\(\chi^2\)</span> test) <span class="math inline">\(\geq\)</span> 2 levels</a><ul>
<li class="chapter" data-level="4.14.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-household-ages"><i class="fa fa-check"></i><b>4.14.1</b> Example: Household Ages</a></li>
<li class="chapter" data-level="4.14.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-flax-seed"><i class="fa fa-check"></i><b>4.14.2</b> Example: Flax Seed</a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Mar5"><i class="fa fa-check"></i><b>4.15</b> 3/5/20 Agenda</a></li>
<li class="chapter" data-level="4.16" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#chisq2"><i class="fa fa-check"></i><b>4.16</b> Independence: Two categorical variables (<span class="math inline">\(\chi^2\)</span> test) <span class="math inline">\(\geq\)</span> 2 levels each</a><ul>
<li class="chapter" data-level="4.16.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-nightlights"><i class="fa fa-check"></i><b>4.16.1</b> Example: Nightlights</a></li>
</ul></li>
<li class="chapter" data-level="4.17" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#agenda"><i class="fa fa-check"></i><b>4.17</b> 3/10/20 &amp; 3/12/20 Agenda</a></li>
<li class="chapter" data-level="4.18" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#agenda-1"><i class="fa fa-check"></i><b>4.18</b> 3/17/20 &amp; 3/19/20 Agenda</a></li>
<li class="chapter" data-level="4.19" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#agenda-2"><i class="fa fa-check"></i><b>4.19</b> 3/24/20 Agenda</a></li>
<li class="chapter" data-level="4.20" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#census"><i class="fa fa-check"></i><b>4.20</b> Census</a><ul>
<li class="chapter" data-level="4.20.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#what-about-college-students"><i class="fa fa-check"></i><b>4.20.1</b> What about College students?</a></li>
</ul></li>
<li class="chapter" data-level="4.21" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#agenda-3"><i class="fa fa-check"></i><b>4.21</b> 3/26/20 Agenda</a></li>
<li class="chapter" data-level="4.22" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#covid19"><i class="fa fa-check"></i><b>4.22</b> COVID-19</a></li>
<li class="chapter" data-level="4.23" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#reflection-questions-1"><i class="fa fa-check"></i><b>4.23</b> Reflection Questions</a><ul>
<li class="chapter" data-level="4.23.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#no-isrs-binomial-probabilities-math-58-only"><i class="fa fa-check"></i><b>4.23.1</b> (no ISRS) Binomial probabilities (Math 58 only)</a></li>
<li class="chapter" data-level="4.23.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#no-isrs-relative-risk-odds-ratios-math-58b-only"><i class="fa fa-check"></i><b>4.23.2</b> (no ISRS) Relative Risk &amp; Odds Ratios (Math 58B only)</a></li>
<li class="chapter" data-level="4.23.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binary-variables-chapter-3-section-2"><i class="fa fa-check"></i><b>4.23.3</b> 2 binary variables: Chapter 3, Section 2</a></li>
<li class="chapter" data-level="4.23.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#types-of-studies-chapter-1-sections-4-5"><i class="fa fa-check"></i><b>4.23.4</b> Types of studies: Chapter 1, Sections 4-5</a></li>
<li class="chapter" data-level="4.23.5" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#categorical-variables-chapter-3-section-3"><i class="fa fa-check"></i><b>4.23.5</b> 2 categorical variables: Chapter 3, Section 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html"><i class="fa fa-check"></i><b>5</b> Inference for numerical data</a><ul>
<li class="chapter" data-level="5.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Mar31"><i class="fa fa-check"></i><b>5.1</b> 3/31/20 Agenda</a></li>
<li class="chapter" data-level="5.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#important-measures-related-to-quantitative-numeric-variables"><i class="fa fa-check"></i><b>5.2</b> Important measures related to quantitative (numeric) variables</a><ul>
<li class="chapter" data-level="5.2.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#quantitative-descriptives"><i class="fa fa-check"></i><b>5.2.1</b> Quantitative Descriptives</a></li>
<li class="chapter" data-level="5.2.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mean1dist"><i class="fa fa-check"></i><b>5.2.2</b> Sampling distribution of a sample mean</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Apr2"><i class="fa fa-check"></i><b>5.3</b> 4/2/20 Agenda</a></li>
<li class="chapter" data-level="5.4" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Apr7"><i class="fa fa-check"></i><b>5.4</b> 4/7/20 Agenda</a></li>
<li class="chapter" data-level="5.5" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mean1inf"><i class="fa fa-check"></i><b>5.5</b> Inference for a single mean, <span class="math inline">\(\mu\)</span></a><ul>
<li class="chapter" data-level="5.5.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mathematical-model-for-distribution-of-the-sample-mean"><i class="fa fa-check"></i><b>5.5.1</b> Mathematical model for distribution of the sample mean</a></li>
<li class="chapter" data-level="5.5.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#example-healthy-body-temperature"><i class="fa fa-check"></i><b>5.5.2</b> Example: healthy body temperature</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Apr9"><i class="fa fa-check"></i><b>5.6</b> 4/9/20 Agenda</a></li>
<li class="chapter" data-level="5.7" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Apr14"><i class="fa fa-check"></i><b>5.7</b> 4/14/20 Agenda</a></li>
<li class="chapter" data-level="5.8" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mean2inf"><i class="fa fa-check"></i><b>5.8</b> Comparing two independent means</a></li>
<li class="chapter" data-level="5.9" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#r-code-for-inference-on-1-or-2-means."><i class="fa fa-check"></i><b>5.9</b> R code for inference on 1 or 2 means.</a><ul>
<li class="chapter" data-level="5.9.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#t.test"><i class="fa fa-check"></i><b>5.9.1</b> <code>t.test</code></a></li>
<li class="chapter" data-level="5.9.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#infer"><i class="fa fa-check"></i><b>5.9.2</b> <code>infer</code></a></li>
<li class="chapter" data-level="5.9.3" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#nba-salaries-example-from-iscam-inv-4.2"><i class="fa fa-check"></i><b>5.9.3</b> NBA Salaries example from ISCAM Inv 4.2</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#reflection-questions-2"><i class="fa fa-check"></i><b>5.10</b> Reflection Questions</a><ul>
<li class="chapter" data-level="5.10.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#quantitative-variable-chapter-4-section-1"><i class="fa fa-check"></i><b>5.10.1</b> 1 quantitative variable: Chapter 4, Section 1</a></li>
<li class="chapter" data-level="5.10.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#means-1-quantitative-variable-1-binary-variable-chapter-4-section-3"><i class="fa fa-check"></i><b>5.10.2</b> 2 means (1 quantitative variable, 1 binary variable): Chapter 4, Section 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="correlation-regression.html"><a href="correlation-regression.html"><i class="fa fa-check"></i><b>6</b> Correlation &amp; Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="correlation-regression.html"><a href="correlation-regression.html#Apr16"><i class="fa fa-check"></i><b>6.1</b> 4/16/20 Agenda</a></li>
<li class="chapter" data-level="6.2" data-path="correlation-regression.html"><a href="correlation-regression.html#cor"><i class="fa fa-check"></i><b>6.2</b> Correlation</a><ul>
<li class="chapter" data-level="6.2.1" data-path="correlation-regression.html"><a href="correlation-regression.html#estimating-correlation"><i class="fa fa-check"></i><b>6.2.1</b> Estimating Correlation</a></li>
<li class="chapter" data-level="6.2.2" data-path="correlation-regression.html"><a href="correlation-regression.html#coefficient-of-determination-r2"><i class="fa fa-check"></i><b>6.2.2</b> Coefficient of Determination – <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="6.2.3" data-path="correlation-regression.html"><a href="correlation-regression.html#inference-for-correlation"><i class="fa fa-check"></i><b>6.2.3</b> Inference for correlation</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="correlation-regression.html"><a href="correlation-regression.html#Apr21"><i class="fa fa-check"></i><b>6.3</b> 4/21/20 Agenda</a></li>
<li class="chapter" data-level="6.4" data-path="correlation-regression.html"><a href="correlation-regression.html#Apr23"><i class="fa fa-check"></i><b>6.4</b> 4/23/20 Agenda</a></li>
<li class="chapter" data-level="6.5" data-path="correlation-regression.html"><a href="correlation-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.5</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="6.5.1" data-path="correlation-regression.html"><a href="correlation-regression.html#ls"><i class="fa fa-check"></i><b>6.5.1</b> Least Squares estimation of the regression line</a></li>
<li class="chapter" data-level="6.5.2" data-path="correlation-regression.html"><a href="correlation-regression.html#infbeta1"><i class="fa fa-check"></i><b>6.5.2</b> Inference on the slope, <span class="math inline">\(\beta_1\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="correlation-regression.html"><a href="correlation-regression.html#Apr28"><i class="fa fa-check"></i><b>6.6</b> 4/28/20 Agenda</a></li>
<li class="chapter" data-level="6.7" data-path="correlation-regression.html"><a href="correlation-regression.html#Apr30"><i class="fa fa-check"></i><b>6.7</b> 4/30/20 Agenda</a></li>
<li class="chapter" data-level="6.8" data-path="correlation-regression.html"><a href="correlation-regression.html#MLR"><i class="fa fa-check"></i><b>6.8</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="6.8.1" data-path="correlation-regression.html"><a href="correlation-regression.html#MLRmod"><i class="fa fa-check"></i><b>6.8.1</b> Model selection</a></li>
<li class="chapter" data-level="6.8.2" data-path="correlation-regression.html"><a href="correlation-regression.html#checking-model-assumptions"><i class="fa fa-check"></i><b>6.8.2</b> Checking model assumptions</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="correlation-regression.html"><a href="correlation-regression.html#r-code-for-regression"><i class="fa fa-check"></i><b>6.9</b> R code for regression</a><ul>
<li class="chapter" data-level="6.9.1" data-path="correlation-regression.html"><a href="correlation-regression.html#ex:cat"><i class="fa fa-check"></i><b>6.9.1</b> Example: Cat Jumping (Correlation &amp; SLR)</a></li>
<li class="chapter" data-level="6.9.2" data-path="correlation-regression.html"><a href="correlation-regression.html#ex:houses"><i class="fa fa-check"></i><b>6.9.2</b> Example: Housing Prices (SLR &amp; MLR &amp; Prediction)</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="correlation-regression.html"><a href="correlation-regression.html#reflection-questions-3"><i class="fa fa-check"></i><b>6.10</b> Reflection Questions</a><ul>
<li class="chapter" data-level="6.10.1" data-path="correlation-regression.html"><a href="correlation-regression.html#correlation-simple-linear-regression-chapter-5-section-1-4"><i class="fa fa-check"></i><b>6.10.1</b> Correlation &amp; Simple Linear Regression: Chapter 5, Section 1-4</a></li>
<li class="chapter" data-level="6.10.2" data-path="correlation-regression.html"><a href="correlation-regression.html#multiple-linear-regression-chapter-6-section-1-3"><i class="fa fa-check"></i><b>6.10.2</b> Multiple Linear Regression: Chapter 6, Section 1-3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://st47s.com/Math58" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to (Bio)Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inference-for-categorical-data" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Inference for categorical data</h1>
<div id="inference-for-a-single-proportion" class="section level2">
<h2><span class="header-section-number">4.1</span> Inference for a single proportion</h2>
<p>Previously, we used the normal approximation to describe the distribution of different values for <span class="math inline">\(\hat{p}\)</span> when random samples are taken. We learned that the central limit theorem describes the distribution such that if (see box in section 3.1.1 on page 124):</p>
<ol style="list-style-type: decimal">
<li>we take random, independent samples</li>
<li><span class="math inline">\(np \geq 10\)</span> and <span class="math inline">\(n(1-p) \geq 10\)</span></li>
</ol>
<p>then <span class="math display">\[\hat{p} \sim N(p, \sqrt{p(1-p)/n}).\]</span></p>
<p>If the <span class="math display">\[\mbox{Z score} = \frac{\hat{p} - p}{\sqrt{p(1-p)/n}}\]</span> is bigger than the <span class="math inline">\(Z^*\)</span> value at a particular value of <span class="math inline">\(\alpha\)</span>, then we know we can reject <span class="math inline">\(p\)</span> (the Null Hypothesis value) as the true population parameter.</p>
<p>If an interval estimate is desired, and no <span class="math inline">\(p\)</span> is hypothesized, then a confidence interval is created using:</p>
<p><span class="math display">\[\hat{p} \pm Z^* \cdot \sqrt{\hat{p}(1-\hat{p})}/n.\]</span></p>
<p>IMPORTANT: recall, the above interval is a method for capturing the <strong>parameter</strong>.</p>
</div>
<div id="Feb18M58" class="section level2">
<h2><span class="header-section-number">4.2</span> 2/18/20 Math 58 Agenda</h2>
<ol start="0" style="list-style-type: decimal">
<li>Math 58 Only</li>
<li>Binomial distribution</li>
</ol>
</div>
<div id="Feb20M58" class="section level2">
<h2><span class="header-section-number">4.3</span> 2/20/20 Math 58 Agenda</h2>
<ol start="0" style="list-style-type: decimal">
<li>Math 58 Only</li>
<li>Binomial hypothesis testing</li>
<li>Power</li>
<li>Confidence Intervals</li>
</ol>
</div>
<div id="binomial-distribution-math-58-only" class="section level2">
<h2><span class="header-section-number">4.4</span> Binomial distribution (Math 58 only)</h2>
<p>Math 58 (not Math 58B) will cover the binomial distribution which describes the exact probabilities associated with binary outcomes.</p>
<p><span class="citation">Diez, Barr, and Çetinkaya-Rundel (<a href="#ref-isrs">2014</a>)</span> do not discuss the binomial distribution. <span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span>, however, provide quite a bit of detail about the binomial concepts in chapter 1.</p>
<div id="example-pop-quiz" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Example: pop quiz</h3>
<p>There are 5 problems on this quiz; everyone number their papers 1. to 5. Each of the problems is multiple choice with answers A, B, C, or D. Go ahead. We’ll grade the papers when everyone is done.</p>
<p>Solution: 1.B, 2.C, 3.B, 4.C, 5.A</p>
<ul>
<li><p>The <strong>binomial distribution</strong> provides the probability distribution for the number of “successes” in a fixed number of independent trials, when the probability of success is the same in each trial.</p>
<ul>
<li>Outcome of each trial can be stated as a success / failure.</li>
<li>The number of trials (<span class="math inline">\(n\)</span>) is fixed.</li>
<li>Separate trials are independent.</li>
<li>The probability of success (<span class="math inline">\(p\)</span>) is the same in every trial.</li>
</ul></li>
</ul>
<p><span class="math display">\[\begin{eqnarray*}
P(X=k) &amp;=&amp; {n \choose k} p^k (1-p)^{n-k}\\
{n \choose k} &amp;=&amp; \frac{ n!}{(n-k)! k!}
\end{eqnarray*}\]</span></p>
<p>In our example… <span class="math inline">\(n=5\)</span>. How many ways are there to get 2 successes?
<span class="math display">\[\begin{eqnarray*}
{5 \choose 2} &amp;=&amp; \frac{ 5!}{2! 3!} = \frac{ 5 \cdot 4 \cdot 3 \cdot 2 \cdot 1}{(3 \cdot 2 \cdot 1)(2 \cdot 1)}
\end{eqnarray*}\]</span></p>
<p>The numerator represents the number of possibilities for each of the 5 questions. But we don’t distinguish between successes, so we don’t want to double count those. Similarly for failures.</p>
<table>
<tbody>
<tr class="odd">
<td align="center">SSSFF</td>
<td align="center">SSFFS</td>
<td align="center">SSFSF</td>
<td align="center">SFFSS</td>
<td align="center">SFSFS</td>
</tr>
<tr class="even">
<td align="center">SFSSF</td>
<td align="center">FFSSS</td>
<td align="center">FSFSS</td>
<td align="center">FSSFS</td>
<td align="center">FSSSF</td>
</tr>
</tbody>
</table>
<p>In class: different groups work out the probability of 0, 1, 2, … 5 correct answers.</p>
<p><span class="math display">\[\begin{eqnarray*}
P(X=0) = {5 \choose 0} (0.25)^0(0.75)^5  = 0.2373 &amp;&amp; P(X=3) = {5 \choose 3} (0.25)^3(0.75)^2  = 0.0879\\
P(X=1) = {5 \choose 1} (0.25)^1(0.75)^4  = 0.3955 &amp;&amp; P(X=4) = {5 \choose 4} (0.25)^4(0.75)^1  = 0.0146\\
P(X=2) = {5 \choose 2} (0.25)^2(0.75)^3  = 0.2637 &amp;&amp; P(X=5) = {5 \choose 5} (0.25)^5(0.75)^0  = 0.0010\\
\end{eqnarray*}\]</span></p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" data-line-number="1"><span class="kw">library</span>(mosaic)</a>
<a class="sourceLine" id="cb50-2" data-line-number="2"><span class="kw">xpbinom</span>(<span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">prob =</span> <span class="fl">0.25</span>)  <span class="co"># P(X &lt;= 2) vs. P(X &gt; 2)</span></a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-1-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.8964844</code></pre>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" data-line-number="1"><span class="kw">xpbinom</span>(<span class="dv">3</span>, <span class="dt">size =</span> <span class="dv">5</span>, <span class="dt">prob =</span> <span class="fl">0.25</span>)  <span class="co"># P(X &lt;= 3) vs. P(X &gt; 3)</span></a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-1-2.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.984375</code></pre>
</div>
<div id="binomial-hypothesis-testing" class="section level3">
<h3><span class="header-section-number">4.4.2</span> Binomial Hypothesis Testing</h3>
<p>Consider the example from the beginning of the semester on babies choosing the helper toy (instead of the hinderer), section <a href="intro.html#ex:helper">2.3</a>. Recall that 14 of the 16 babies chose the helper toy.</p>
<p>Does the binomial distribution apply to this setting? Let’s check:</p>
<ul>
<li>two choices? Yes, helper or hinderer.</li>
<li>fixed <span class="math inline">\(n\)</span>? Yes, there were 16 babies.</li>
<li><span class="math inline">\(p\)</span> same? Presumably. There is some inherent <span class="math inline">\(p\)</span> which represents the probability that a baby would choose a helper toy. And we are choosing babies from a population with that <span class="math inline">\(p\)</span>.</li>
<li>independent? I hope so! These babies don’t know each other or tell each other about the experiment.</li>
</ul>
<p>If there really had been no inclination of the babies to choose the helper toy, how many babies would the researchers have needed to choose the helper in order to get published?</p>
<p>Let’s choose <span class="math inline">\(\alpha = 0.01\)</span>. That means that if <span class="math inline">\(p=0.5\)</span>, then we should make a Type I error less than 1% of the time. From the calculations below, we see that the rejection region is <span class="math inline">\(\{ X \geq 14 \}\)</span>. That is, for the researchers to reject the null hypothesis at the <span class="math inline">\(\alpha = 0.01\)</span> significance level, they would have needed to see 14, 15, or 16 babies choose the helper (out of 16).</p>
<p><span class="math display">\[\begin{eqnarray*}
P(X \geq 12) &amp;=&amp; {16 \choose 12} (0.5)^{12}(0.5)^{4} + 0.0106 = 0.0384\\
P(X \geq 13) &amp;=&amp; {16 \choose 13} (0.5)^{13}(0.5)^{3} + 0.00209 = 0.0106\\
P(X \geq 14) &amp;=&amp; {16 \choose 14} (0.5)^{14}(0.5)^{2} + 0.000259 = 0.00209\\
P(X \geq 15) &amp;=&amp; {16 \choose 15} (0.5)^{15}(0.5)^{1} + 0.0000153 = 0.000259\\
P(X = 16) &amp;=&amp; {16 \choose 16} (0.5)^{16}(0.5)^{0} = 0.0000153\\
\end{eqnarray*}\]</span></p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" data-line-number="1"><span class="kw">xpbinom</span>(<span class="dv">12</span>, <span class="dv">16</span>, <span class="fl">0.5</span>)</a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-2-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.9893646</code></pre>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" data-line-number="1"><span class="kw">xpbinom</span>(<span class="dv">13</span>, <span class="dv">16</span>, <span class="fl">0.5</span>)</a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-2-2.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.9979095</code></pre>
</div>
<div id="binomial-power" class="section level3">
<h3><span class="header-section-number">4.4.3</span> Binomial Power</h3>
<p>Let’s say that the researchers had an inkling that babies liked helpers. But they thought that probably only about 70% of babies preferred helpers. The researchers then needed to decide if 16 babies was enough for them to do their research. That is, if they only measure 16 babies, will they have convincing evidence that babies actually prefer the helper? Said differently, with 16 babies, what is the power of the test?</p>
<p><span class="math display">\[\begin{eqnarray*}
\mbox{power} &amp;=&amp; P(X \geq 14 | p = 0.7)\\
&amp;=&amp; P(X=14 | p=0.7) + P(X = 15 | p=0.7)  + P(X = 16 | p=0.7)\\
&amp;=&amp; {16 \choose 14} (0.7)^{14}(0.3)^{2} + {16 \choose 15} (0.7)^{15}(0.3)^{1} + {16 \choose 16} (0.7)^{16}(0.3)^{0}\\
&amp;=&amp; 0.099
\end{eqnarray*}\]</span></p>
<p>Yikes! What if babies actually prefer the helper 90% of the time?</p>
<p><span class="math display">\[\mbox{power} = P(X \geq 14 | p = 0.9) = 0.789\]</span></p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" data-line-number="1"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">xpbinom</span>(<span class="dv">13</span>, <span class="dv">16</span>, <span class="fl">0.7</span>)</a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-3-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.09935968</code></pre>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" data-line-number="1"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">xpbinom</span>(<span class="dv">13</span>, <span class="dv">16</span>, <span class="fl">0.9</span>)</a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-3-2.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.7892493</code></pre>
</div>
<div id="binomial-confidence-intervals-for-p" class="section level3">
<h3><span class="header-section-number">4.4.4</span> Binomial Confidence Intervals for <span class="math inline">\(p\)</span></h3>
<p>The binomial distribution does not allow for the “plus or minus” creation of a range of plausible values for the confidence interval. Instead, hypothesis testing is used directly to come up with plausible values for the parameter <span class="math inline">\(p\)</span>. The method outlines below is much more tedious than the z - CI , but it does produce an exact interval for <span class="math inline">\(p\)</span> with the appropriate coverage level.</p>
<p>Consider a confidence interval created in the following way:</p>
<ul>
<li>Step 1: Collect data, calculate <span class="math inline">\(\hat{p}\)</span> for that particular dataset.</li>
<li>Step 2: Test a series of values for <span class="math inline">\(p&#39;\)</span> using the observed <span class="math inline">\(\hat{p}\)</span> from the dataset at hand.</li>
<li>Step 3: List all the values for <span class="math inline">\(p&#39;\)</span> that were not rejected. Sort them and find the smallest and biggest value: (<span class="math inline">\(p_{small}, p_{big}\)</span>).</li>
</ul>
<p>Ask yourself whether the <strong>true</strong> parameter (let’s call it <span class="math inline">\(p\)</span>) is in the interval.</p>
<ul>
<li>If a type I error was made when <span class="math inline">\(p\)</span> was tested, then <span class="math inline">\(p\)</span> is not in the interval.</li>
<li>If <span class="math inline">\(p\)</span> was not rejected, then it is in the interval.</li>
</ul>
<p>How often will a type I error be made? 5% of the time. Therefore (<span class="math inline">\(p_{small}, p_{big}\)</span>) is a 95% CI for the true population parameter <span class="math inline">\(p\)</span>.</p>
</div>
</div>
<div id="Feb18M58B" class="section level2">
<h2><span class="header-section-number">4.5</span> 2/18/20 Math 58B Agenda</h2>
<ol start="0" style="list-style-type: decimal">
<li>Math 58B Only</li>
<li>Relative Risk</li>
<li>Odds Ratios</li>
<li>Case-control studies</li>
</ol>
</div>
<div id="Feb20M58B" class="section level2">
<h2><span class="header-section-number">4.6</span> 2/20/20 Math 58B Agenda</h2>
<ol start="0" style="list-style-type: decimal">
<li>Math 58B Only</li>
<li>CI for relative risk</li>
<li>CI for odds ratios</li>
</ol>
</div>
<div id="relative-risk-math-58b-only" class="section level2">
<h2><span class="header-section-number">4.7</span> Relative Risk (Math 58B only)</h2>
<p>Math 58B (not Math 58) will cover relative risk, the ratio of two success proportions.</p>
<p>Previously (e.g., Gender discrimination example, <a href="foundations-for-inference.html#ex:gend">3.2</a>) when working with the proportion of success in two separate groups, the proportion of success was subtracted (see also lab 4). Next week, differences in proportions will be revisited, see section <a href="inference-for-categorical-data.html#diffprop">4.10</a>. First up, the new statistic of interest will be relative risk, followed by odds ratios.</p>
<p>In particular, interest is in the ratio of probabilities. [Note: the decision to measure a ratio instead of a difference comes with trying to model the particular research question at hand. There is nothing inherently better about ratios versus differences. It is, however, often easier to think about how a small probability changes if it is done as a ratio instead of a difference.]</p>
<p><span class="math display">\[\mbox{Relative Risk (RR)} = \frac{\mbox{proportion of successes in group 1}}{\mbox{proportion of successes in group 2}}\]</span></p>

<div class="definition">
<span id="def:unnamed-chunk-4" class="definition"><strong>Definition 4.1  </strong></span><strong>Relative Risk</strong> The relative risk (RR) is the ratio of risks for each group. We say, “The risk of success is <strong>RR</strong> times higher for those in group 1 compared to those in group 2.”
</div>

<div id="inference-on-relative-risk" class="section level3">
<h3><span class="header-section-number">4.7.1</span> Inference on Relative Risk</h3>
<p>Due to some theory we won’t cover, there is a fairly good mathematical approximation which describes how the natural log of the relative risk varies from sample to sample:</p>
<p><span class="math display">\[\ln(\hat{RR})  \stackrel{\mbox{approx}}{\sim}   N\Bigg(\ln(RR), \sqrt{\frac{1}{A} - \frac{1}{A+C} + \frac{1}{B} - \frac{1}{B+D}}\Bigg)\]</span></p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">explanatory 1</th>
<th align="center">explanatory 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>response 1</td>
<td align="center">A</td>
<td align="center">B</td>
</tr>
<tr class="even">
<td>response 2</td>
<td align="center">C</td>
<td align="center">D</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Statistic:</strong> <span class="math display">\[\hat{p}_1 / \hat{p}_2 = \frac{A/(A+C) }{B/ (B+D)}\]</span></li>
<li><strong>Null Hypothesis:</strong> <span class="math display">\[H_0: p_1/p_2 = 1\]</span></li>
<li><strong>CI:</strong> The CI is for the true relative risk in the population, <span class="math inline">\(p_1/p_2\)</span></li>
</ul>
<p><span class="math display">\[\mbox{exponentiate} \Bigg[ \ln(\hat{p}_1/\hat{p}_2) \pm z^*\sqrt{ \frac{1}{A} - \frac{1}{A+C} + \frac{1}{B} - \frac{1}{B+D}}\Bigg]\]</span></p>
<p>To remember with relative risk:</p>
<ul>
<li><p>The percent change is defined as:
<span class="math display">\[\begin{eqnarray*}
(RR - 1)*100\% = \frac{\hat{p}_1 - \hat{p}_2}{\hat{p}_2}*100\% = \mbox{percent change from 2 to 1}
\end{eqnarray*}\]</span></p></li>
<li><p>The CI for <span class="math inline">\(p_1/p_2\)</span> is typically considered significant if 1 is not in the interval. That is because usually the null hypothesis is <span class="math inline">\(H_0: p_1 = p_2\)</span> or equivalently, <span class="math inline">\(H_0: p_1/p_2 = 1\)</span>.</p></li>
</ul>
</div>
<div id="using-infer-for-inference-on-rr" class="section level3">
<h3><span class="header-section-number">4.7.2</span> Using <code>infer</code> for inference on RR</h3>
<!--
devtools::install_github("tidymodels/infer", ref="develop")
-->
<p>As with the difference in proportions, the <code>infer</code> syntax can be used to simulate a sampling distribution of the sample relative risk under the null hypothesis that the population proportions are identical.</p>
<p><strong>NOTE</strong> in order to provide syntax that was comparable and correct for the RR and the OR, <code>smoking</code> has been specified as the response variable, and <code>lungs</code> has been specified as the explanatory variable.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb62-1" data-line-number="1"><span class="kw">library</span>(infer)</a>
<a class="sourceLine" id="cb62-2" data-line-number="2">WynderGraham &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">lungs =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;cancer&quot;</span>, <span class="dv">605</span>), <span class="kw">rep</span>(<span class="st">&quot;healthy&quot;</span>, <span class="dv">780</span>)),</a>
<a class="sourceLine" id="cb62-3" data-line-number="3">                            <span class="dt">smoking =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;light&quot;</span>, <span class="dv">22</span>), <span class="kw">rep</span>(<span class="st">&quot;heavy&quot;</span>, <span class="dv">583</span>),</a>
<a class="sourceLine" id="cb62-4" data-line-number="4">                                        <span class="kw">rep</span>(<span class="st">&quot;light&quot;</span>, <span class="dv">204</span>), <span class="kw">rep</span>(<span class="st">&quot;heavy&quot;</span>, <span class="dv">576</span>)))</a>
<a class="sourceLine" id="cb62-5" data-line-number="5"></a>
<a class="sourceLine" id="cb62-6" data-line-number="6">(obs_RR &lt;-<span class="st"> </span>WynderGraham <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb62-7" data-line-number="7"><span class="st">  </span><span class="kw">specify</span>(smoking <span class="op">~</span><span class="st"> </span>lungs, <span class="dt">success =</span> <span class="st">&quot;heavy&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb62-8" data-line-number="8"><span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;ratio of props&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;cancer&quot;</span>, <span class="st">&quot;healthy&quot;</span>)))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##    stat
##   &lt;dbl&gt;
## 1  1.30</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb64-1" data-line-number="1">null_RR &lt;-<span class="st"> </span>WynderGraham <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb64-2" data-line-number="2"><span class="st">  </span><span class="kw">specify</span>(smoking <span class="op">~</span><span class="st"> </span>lungs, <span class="dt">success =</span> <span class="st">&quot;heavy&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb64-3" data-line-number="3"><span class="st">  </span><span class="kw">hypothesize</span>(<span class="dt">null =</span> <span class="st">&quot;independence&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb64-4" data-line-number="4"><span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;permute&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb64-5" data-line-number="5"><span class="st">  </span>infer<span class="op">::</span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;ratio of props&quot;</span>, <span class="dt">order=</span> <span class="kw">c</span>(<span class="st">&quot;cancer&quot;</span>, <span class="st">&quot;healthy&quot;</span>))</a>
<a class="sourceLine" id="cb64-6" data-line-number="6"></a>
<a class="sourceLine" id="cb64-7" data-line-number="7">null_RR <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb64-8" data-line-number="8"><span class="st">  </span><span class="kw">visualize</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb64-9" data-line-number="9"><span class="st">  </span><span class="kw">shade_p_value</span>(<span class="dt">obs_stat =</span> obs_RR, <span class="dt">direction =</span> <span class="st">&quot;right&quot;</span>)</a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-5-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="odds-ratios-math-58b-only" class="section level2">
<h2><span class="header-section-number">4.8</span> Odds Ratios (Math 58B only)</h2>
<p>Experience shows that very few introductory statistics students have seen odds or odds ratios in their prior mathematical or scientific study. That makes odds ratios a <strong>new</strong> idea, but not a fundamentally hard idea. Which is to say, it is perfectly acceptable to find relative risk a very intuitive idea that you can easily discuss and odds ratios a very strange idea which is hard to interpret. Do not be discouraged! Odds ratios are <em>not</em> fundamentally harder to understand than relative risk, they are simply a new idea.</p>
<p>Math 58B (not Math 58) will cover odds ratios, the ratio of two success odds.</p>
<p><span class="citation">Diez, Barr, and Çetinkaya-Rundel (<a href="#ref-isrs">2014</a>)</span> do not discuss relative risk and odds ratios. <span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span>, however, provide quite a bit of detail about the concepts in Investigations 3.9, 3.10, 3.11.</p>
<p><span class="math display">\[\mbox{risk} = \frac{\mbox{number of successes}}{\mbox{total number}}\]</span></p>
<p><span class="math display">\[\mbox{odds} = \frac{\mbox{number of successes}}{\mbox{number of failures}}\]</span></p>
<p><span class="math display">\[\mbox{Odds Ratio (OR)} = \frac{\mbox{odds of success in group 1}}{\mbox{odds of success in group 2}}\]</span></p>

<div class="definition">
<span id="def:unnamed-chunk-6" class="definition"><strong>Definition 4.2  </strong></span><strong>Odds Ratio</strong> A related concept to risk is odds. It is often used in horse racing, where “success” is typically defined as losing. So, if the odds are 3 to 1 we would expect to lose 3/4 of the time. The odds ratio (OR) is the ratio of odds for each group. We say, “The odds of success is <strong>OR</strong> times higher for those in group 1 compared to those group 2.”
</div>

<div id="example-smoking-and-lung-cancer" class="section level3">
<h3><span class="header-section-number">4.8.1</span> Example: Smoking and Lung Cancer<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></h3>
<blockquote>
<p>After World War II, evidence began mounting that there was a link between cigarette smoking and pulmonary carcinoma (lung cancer). In the 1950s, three now classic articles were published on the topic. One of these studies was conducted in the United States by Wynder and Graham.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> They found records from a large number of patients with a specific type of lung cancer in hospitals in California, Colorado, Missouri, New Jersey, New York, Ohio, Pennsylvania, and Utah. Of those in the study, the researchers focused on 605 male patients with this form of lung cancer. Another 780 male hospital patients with similar age and economic distributions without this type of lung cancer were interviewed in St. Louis, Boston, Cleveland, and Hines, IL. Subjects (or family members) were interviewed to assess their smoking habits, occupation, education, etc. The table below classifies them as non-smoker or light smoker, or at least a moderate smoker.</p>
</blockquote>
<p>The following two-way table replicates the counts for the 605 male patients with the same form of cancer and for the “control-group” of 780 males.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">none</th>
<th align="center">light</th>
<th align="center">mod heavy</th>
<th align="center">heavy</th>
<th align="center">excessive</th>
<th align="center">chain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td align="center"><span class="math inline">\(&lt;\)</span> 1/day</td>
<td align="center">1-9/day</td>
<td align="center">10-15/day</td>
<td align="center">16-20/day</td>
<td align="center">21-34/day</td>
<td align="center">35<span class="math inline">\(+\)</span>/day</td>
</tr>
<tr class="even">
<td>patients</td>
<td align="center">8</td>
<td align="center">14</td>
<td align="center">61</td>
<td align="center">213</td>
<td align="center">187</td>
<td align="center">122</td>
</tr>
<tr class="odd">
<td>controls</td>
<td align="center">114</td>
<td align="center">90</td>
<td align="center">148</td>
<td align="center">278</td>
<td align="center">90</td>
<td align="center">60</td>
</tr>
</tbody>
</table>
<p>Given the results of the study, do you think we can generalize from the sample to the population? Explain and make it clear that you know the difference between a sample and a population.</p>
<p>In order to focus the research question, combine the data into two groups: light smoking is less than 10 cigarettes per day, heavy smoking is 10 or more cigarettes per day. The 2x2 observed data is now:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">light smoking</th>
<th align="center">heavy smoking</th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>cancer</td>
<td align="center">22</td>
<td align="center">583</td>
<td align="center">605</td>
</tr>
<tr class="even">
<td>healthy</td>
<td align="center">204</td>
<td align="center">576</td>
<td align="center">780</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">226</td>
<td align="center">1159</td>
<td align="center">1385</td>
</tr>
</tbody>
</table>
<ul>
<li>Causation? (Is it an experiment or are there possible confounding variables?)</li>
<li>Case-control study (605 with lung cancer, 780 without… baseline rate?)</li>
<li>What is the response variable and what is the explanatory variable? What happens if the role of the two variables is switched?</li>
</ul>
<table>
<thead>
<tr class="header">
<th>Group A</th>
<th>Group B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>expl = smoking status</td>
<td>expl = lung cancer</td>
</tr>
<tr class="even">
<td>resp = lung cancer</td>
<td>resp = smoking status</td>
</tr>
</tbody>
</table>
<ul>
<li>If lung cancer is considered a success and light smoking is baseline:
<span class="math display">\[\begin{eqnarray*}
RR &amp;=&amp; \frac{583/1159}{22/226} = 5.17\\
OR &amp;=&amp; \frac{583/576}{22/204} = 9.39\\
\end{eqnarray*}\]</span></li>
</ul>
<p><strike>The risk of lung cancer is 5.17 times higher for those who heavy smoke than for those who don’t smoke.</strike></p>
<p>The odds of lung cancer is 9.39 times higher for those who heavy smoke than for those who don’t smoke.</p>
<ul>
<li>If heavy smoking is considered a success and healthy is baseline:
<span class="math display">\[\begin{eqnarray*}
RR &amp;=&amp; \frac{583/605}{576/780} = 1.31\\
OR &amp;=&amp; \frac{583/22}{576/204} = 9.39\\
\end{eqnarray*}\]</span></li>
</ul>
<p>The risk of heavy smoking is 1.31 times higher for those who have lung cancer than for those who don’t have lung cancer.</p>
<p>The odds of heavy smoking is 9.39 times higher for those who have lung cancer than for those who don’t have lung cancer.</p>
<ul>
<li>Observational study (who worked in each place?)<br />
</li>
<li>Cross sectional (only one point in time)<br />
</li>
<li>Healthy worker effect (who stayed home sick?)<br />
</li>
<li><strong>Explanatory variable</strong> is one that is a potential explanation for any changes (here smoking level).<br />
</li>
<li><p><strong>Response variable</strong> is the measured outcome of interest (here lung cancer).</p></li>
<li><strong>Case-control study:</strong> identify observational units by the response variable</li>
<li><p><strong>Cohort study:</strong> identify observational units by the explanatory variable</p></li>
</ul>
<p>The risk of being a light smoker if the person has lung cancer can be estimated, but there is no possible way to estimate the risk of lung cancer if you are a light smoker. Consider a <em>population</em> of 1,000,000 people:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">no smoking</th>
<th align="center">light smoking</th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>cancer</td>
<td align="center">1,000</td>
<td align="center">49,000</td>
<td align="center">50,000</td>
</tr>
<tr class="even">
<td>healthy</td>
<td align="center">899,000</td>
<td align="center">51,000</td>
<td align="center">950,000</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">900,000</td>
<td align="center">100,000</td>
<td align="center">1,000,000</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\begin{eqnarray*}
P(\mbox{light} | \mbox{lung cancer}) &amp;=&amp; \frac{49,000}{50,000} = 0.98\\
P(\mbox{lung cancer} | \mbox{light}) &amp;=&amp; \frac{49,000}{100,000} = 0.49\\
\end{eqnarray*}\]</span></p>
<ul>
<li>What is the explanatory variable?</li>
<li>What is the response variable?</li>
<li>relative risk?</li>
<li>odds ratio?</li>
<li><table>
<thead>
<tr class="header">
<th>Group A</th>
<th>Group B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>expl = smoking status</td>
<td>expl = lung cancer</td>
</tr>
<tr class="even">
<td>resp = lung cancer</td>
<td>resp = smoking status</td>
</tr>
</tbody>
</table></li>
<li><p>If lung cancer is considered a success and no smoking is baseline:
<span class="math display">\[\begin{eqnarray*}
RR &amp;=&amp; \frac{49/100}{1/900} = 441\\
OR &amp;=&amp; \frac{49/51}{1/899} = 863.75\\
\end{eqnarray*}\]</span></p></li>
<li><p>If light smoking is considered a success and healthy is baseline:
<span class="math display">\[\begin{eqnarray*}
RR &amp;=&amp; \frac{49/50}{51/950} = 18.25\\
OR &amp;=&amp; \frac{49/1}{51/899} = 863.75\\
\end{eqnarray*}\]</span></p></li>
</ul>
<p>OR is the same no matter which variable you choose as explanatory versus response! Though, in general, baseline odds or baseline risk (which we can’t know with a case-control study) is still a number that can provide a lot of information about the study.</p>
<p>IMPORTANT: Relative risk cannot be used with case-control studies but odds ratios can be used!</p>
</div>
<div id="inference-on-odds-ratios" class="section level3">
<h3><span class="header-section-number">4.8.2</span> Inference on Odds Ratios</h3>
<p>Due to some theory we won’t cover, there is a fairly good mathematical approximation which describes how the natural log of the odds ratio varies from sample to sample:</p>
<p><span class="math display">\[\ln(\hat{OR}) \stackrel{\mbox{approx}}{\sim}  N\Bigg(\ln(OR), \sqrt{\frac{1}{A} + \frac{1}{B} + \frac{1}{C} + \frac{1}{D}}\Bigg)\]</span></p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">explanatory 1</th>
<th align="center">explanatory 2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>response 1</td>
<td align="center">A</td>
<td align="center">B</td>
</tr>
<tr class="even">
<td>response 2</td>
<td align="center">C</td>
<td align="center">D</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Statistic:</strong> <span class="math display">\[\hat{OR} = \frac{A D}{B C}\]</span></li>
<li><strong>Null Hypothesis:</strong> <span class="math display">\[H_0: OR = 1\]</span></li>
<li><strong>CI:</strong> The CI is for the true odds ratio in the population, <span class="math inline">\(OR\)</span></li>
</ul>
<p><span class="math display">\[\mbox{exponentiate} \Bigg[ \ln{\hat{OR}} \pm z^* \sqrt{ \frac{1}{A} + \frac{1}{B} + \frac{1}{C} + \frac{1}{D}}\Bigg]\]</span></p>
<div id="or-is-more-extreme-than-rr" class="section level4">
<h4><span class="header-section-number">4.8.2.1</span> OR is more extreme than RR</h4>
<p>Without loss of generality, assume the true <span class="math inline">\(RR &gt; 1\)</span>, implying <span class="math inline">\(p_1 / p_2 &gt; 1\)</span> and <span class="math inline">\(p_1 &gt; p_2\)</span>.</p>
<p>Note the following sequence of consequences:</p>
<p><span class="math display">\[\begin{eqnarray*}
RR = \frac{p_1}{p_2} &amp;&gt;&amp; 1\\
\frac{1 - p_1}{1 - p_2} &amp;&lt;&amp; 1\\
\frac{ 1 / (1 - p_1)}{1 / (1 - p_2)} &amp;&gt;&amp; 1\\
\frac{p_1}{p_2} \cdot \frac{ 1 / (1 - p_1)}{1 / (1 - p_2)} &amp;&gt;&amp; \frac{p_1}{p_2}\\
OR &amp;&gt;&amp; RR
\end{eqnarray*}\]</span></p>
</div>
</div>
<div id="confidence-interval-for-or-same-idea-as-with-rr" class="section level3">
<h3><span class="header-section-number">4.8.3</span> Confidence Interval for OR (same idea as with RR)</h3>
<p><span class="math display">\[\begin{eqnarray*}
SE(\ln (\hat{OR})) &amp;\approx&amp; \sqrt{ \frac{1}{A} + \frac{1}{B} + \frac{1}{C} + \frac{1}{D}}
\end{eqnarray*}\]</span></p>
<p>So, a <span class="math inline">\((1-\alpha)100\%\)</span> CI for the <span class="math inline">\(\ln(OR)\)</span> is:
<span class="math display">\[\begin{eqnarray*}
\ln(\hat{OR}) \pm z_{1-\alpha/2} SE(\ln(\hat{OR}))
\end{eqnarray*}\]</span></p>
<p>Which gives a <span class="math inline">\((1-\alpha)100\%\)</span> CI for the <span class="math inline">\(OR\)</span>:
<span class="math display">\[\begin{eqnarray*}
(e^{\ln(OR) - z_{1-\alpha/2} SE(\ln(OR))}, e^{\ln(OR) + z_{1-\alpha/2} SE(\ln(OR))})
\end{eqnarray*}\]</span></p>
<p><span class="math inline">\(\frac{583/576}{22/204} = 9.39\)</span>
Back to the example… OR = 9.39.
<span class="math display">\[\begin{eqnarray*}
SE(\ln(\hat{OR})) &amp;=&amp; \sqrt{\frac{1}{583} + \frac{1}{576} + \frac{1}{22} + \frac{1}{204}}\\
&amp;=&amp; 0.232\\
90\% \mbox{ CI for } \ln(OR) &amp;&amp; \ln(9.39) \pm 1.645 \cdot 0.232\\
&amp;&amp; 2.24 \pm 1.645 \cdot 0.232\\
&amp;&amp; (1.858, 2.62)\\
90\% \mbox{ CI for } OR &amp;&amp; (e^{1.858}, e^{2.62})\\
&amp;&amp; (6.41, 13.75)\\
\end{eqnarray*}\]</span></p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb65-1" data-line-number="1">(<span class="dt">SE_lnOR =</span> <span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="dv">583</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">576</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">22</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">204</span>))</a></code></pre></div>
<pre><code>## [1] 0.2319653</code></pre>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" data-line-number="1"><span class="kw">xqnorm</span>(<span class="fl">0.95</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">plot=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## [1] 1.644854</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" data-line-number="1"><span class="kw">log</span>(<span class="fl">9.39</span>) <span class="op">-</span><span class="st"> </span><span class="fl">1.645</span><span class="op">*</span><span class="fl">0.232</span></a></code></pre></div>
<pre><code>## [1] 1.858005</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" data-line-number="1"><span class="kw">log</span>(<span class="fl">9.39</span>) <span class="op">+</span><span class="st"> </span><span class="fl">1.645</span><span class="op">*</span><span class="fl">0.232</span></a></code></pre></div>
<pre><code>## [1] 2.621285</code></pre>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" data-line-number="1"><span class="kw">exp</span>(<span class="kw">log</span>(<span class="fl">9.39</span>) <span class="op">-</span><span class="st"> </span><span class="fl">1.645</span><span class="op">*</span><span class="fl">0.232</span>)</a></code></pre></div>
<pre><code>## [1] 6.410936</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb75-1" data-line-number="1"><span class="kw">exp</span>(<span class="kw">log</span>(<span class="fl">9.39</span>) <span class="op">+</span><span class="st"> </span><span class="fl">1.645</span><span class="op">*</span><span class="fl">0.232</span>)</a></code></pre></div>
<pre><code>## [1] 13.75339</code></pre>
<p>We are 90% confident that the true <span class="math inline">\(\ln(OR)\)</span> is between 1.858 and 2.62. We are 90% confident that the true <span class="math inline">\(OR\)</span> is between 6.41 and 13.75. That is, the true odds of getting lung cancer if you smoke heavily are somewhere between 6.41 and 13.75 times higher than if you don’t, with 90% confidence.</p>
<p>Note 1: we use the theory which allows us to understand the sampling distribution for the <span class="math inline">\(\ln(\hat{OR}).\)</span> We use the <em>process</em> for creating CIs to transform back to <span class="math inline">\(OR\)</span>.</p>
<!--
Note 2: We do not use the t-distribution here because we are not estimating the population standard deviation.
-->
<p>Note 2: There are not good general guidelines for checking whether the sample sizes are large enough for the normal approximation. Most authorities agree that one can get away with smaller sample sizes here than for the differences of two proportions. If the sample sizes pass the rough check discussed for <span class="math inline">\(\chi^2\)</span>, they should be large enough to support inferences based on the approximate normality of the log of the estimated odds ratio, too. <span class="citation">(Ramsey and Schafer <a href="#ref-sleuth">2012</a>, 541)</span></p>
<p>From one author, for the normal approximation to hold, we need the expected counts in each cell to be at least 5. <span class="citation">(Pagano and Gauvreau <a href="#ref-pagano">2000</a>, 355)</span></p>
<p>Note 3: If any of the cells are zero, many people will add 0.5 to that cell’s observed value.</p>
<p>Note 4: The OR will always be more extreme than the RR (one more reason to be careful…)</p>
<!--
\begin{eqnarray*}
\mbox{assume } && \frac{X_1 / n_1}{X_2 / n_2} = RR > 1\\
& & \\
\frac{X_1}{n_1} &=& RR \ \ \frac{X_2}{n_2}\\
\frac{X_1}{n_1 - X_1} &=& RR \ \ \bigg( \frac{n_1}{n_2}  \frac{n_2 - X_2}{n_1 - X_1} \bigg) \frac{X_2}{n_2-X_2}\\
OR &=& RR \ \ \bigg(\frac{n_1}{n_2} \bigg) \frac{n_2 - X_2}{n_1 - X_1}\\
 &=& RR \ \ \bigg(\frac{1/n_2}{1/n_1} \bigg) \frac{n_2 - X_2}{n_1 - X_1}\\
 &=& RR  \ \ \frac{1 - X_2/n_2}{1 - X_1/n_1}\\
 & > & RR
\end{eqnarray*}
[$1 - \frac{X_2}{n_2} > 1 - \frac{X_1}{n_1} \rightarrow \frac{1 - \frac{X_2}{n_2}}{1 - \frac{X_1}{n_1}} > 1$]
-->
<p>Note 5: <span class="math inline">\(RR \approx OR\)</span> if RR is very small (the denominator of the OR will be very similar to the denominator of the RR).</p>
</div>
<div id="using-infer-for-inference-on-or" class="section level3">
<h3><span class="header-section-number">4.8.4</span> Using <code>infer</code> for inference on OR</h3>
<!--
devtools::install_github("tidymodels/infer", ref="develop")
-->
<p>As with the difference in proportions, the <code>infer</code> syntax can be used to simulate a sampling distribution of the sample odds ratio under the null hypothesis that the population proportions are identical.</p>
<p><strong>NOTE</strong> in order to provide syntax that was comparable and correct for the RR and the OR, <code>smoking</code> has been specified as the response variable, and <code>lungs</code> has been specified as the explanatory variable.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb77-1" data-line-number="1"><span class="kw">library</span>(infer)</a>
<a class="sourceLine" id="cb77-2" data-line-number="2">WynderGraham &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">lungs =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;cancer&quot;</span>, <span class="dv">605</span>), <span class="kw">rep</span>(<span class="st">&quot;healthy&quot;</span>, <span class="dv">780</span>)),</a>
<a class="sourceLine" id="cb77-3" data-line-number="3">                            <span class="dt">smoking =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;light&quot;</span>, <span class="dv">22</span>), <span class="kw">rep</span>(<span class="st">&quot;heavy&quot;</span>, <span class="dv">583</span>),</a>
<a class="sourceLine" id="cb77-4" data-line-number="4">                                        <span class="kw">rep</span>(<span class="st">&quot;light&quot;</span>, <span class="dv">204</span>), <span class="kw">rep</span>(<span class="st">&quot;heavy&quot;</span>, <span class="dv">576</span>)))</a>
<a class="sourceLine" id="cb77-5" data-line-number="5"></a>
<a class="sourceLine" id="cb77-6" data-line-number="6">(obs_OR &lt;-<span class="st"> </span>WynderGraham <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb77-7" data-line-number="7"><span class="st">  </span><span class="kw">specify</span>(smoking <span class="op">~</span><span class="st"> </span>lungs, <span class="dt">success =</span> <span class="st">&quot;heavy&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb77-8" data-line-number="8"><span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;odds ratio&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;cancer&quot;</span>, <span class="st">&quot;healthy&quot;</span>)))</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##    stat
##   &lt;dbl&gt;
## 1  9.39</code></pre>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb79-1" data-line-number="1">null_OR &lt;-<span class="st"> </span>WynderGraham <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb79-2" data-line-number="2"><span class="st">  </span><span class="kw">specify</span>(smoking <span class="op">~</span><span class="st"> </span>lungs, <span class="dt">success =</span> <span class="st">&quot;heavy&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb79-3" data-line-number="3"><span class="st">  </span><span class="kw">hypothesize</span>(<span class="dt">null =</span> <span class="st">&quot;independence&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb79-4" data-line-number="4"><span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">1000</span>, <span class="dt">type =</span> <span class="st">&quot;permute&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb79-5" data-line-number="5"><span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;odds ratio&quot;</span>, <span class="dt">order=</span> <span class="kw">c</span>(<span class="st">&quot;cancer&quot;</span>, <span class="st">&quot;healthy&quot;</span>))</a>
<a class="sourceLine" id="cb79-6" data-line-number="6"></a>
<a class="sourceLine" id="cb79-7" data-line-number="7">null_OR <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb79-8" data-line-number="8"><span class="st">  </span><span class="kw">visualize</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb79-9" data-line-number="9"><span class="st">  </span><span class="kw">shade_p_value</span>(<span class="dt">obs_stat =</span> obs_OR, <span class="dt">direction =</span> <span class="st">&quot;right&quot;</span>)</a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-8-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<div id="ex:cov" class="section level3">
<h3><span class="header-section-number">4.8.5</span> Example: MERS-CoV</h3>
<p>The following study is a case-control study, so it is impossible to estimate the proportion of cases in the population. However, you will notice that the authors don’t try to do that. They flip the explanatory and response variables so that the case status is predicting all of the other clinical variables. In such a setting, the authors would have been able to present relative risk estimates, but they still chose to provide odds ratios (possibly because odds ratios are somewhat standard in the medical literature).</p>
<p>Middle East Respiratory Syndrome Coronavirus: A Case-Control Study of Hospitalized Patients<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a></p>
<blockquote>
<p>Background. There is a paucity of data regarding the differentiating characteristics of patients with laboratory-confirmed and those negative for Middle East respiratory syndrome coronavirus (MERS-CoV).</p>
</blockquote>
<blockquote>
<p>Methods. This is a hospital-based case-control study comparing MERS-CoV–positive patients (cases) with MERS-CoV–negative controls.</p>
</blockquote>
<blockquote>
<p>Results. A total of 17 case patients and 82 controls with a mean age of 60.7 years and 57 years, respectively (P = .553), were included. No statistical differences were observed in relation to sex, the presence of a fever or cough, and the presence of a single or multilobar infiltrate on chest radiography. The case patients were more likely to be overweight than the control group (mean body mass index, 32 vs 27.8; P = .035), to have diabetes mellitus (87% vs 47%; odds ratio [OR], 7.24; P = .015), and to have end-stage renal disease (33% vs 7%; OR, 7; P = .012). At the time of admission, tachypnea (27% vs 60%; OR, 0.24; P = .031) and respiratory distress (15% vs 51%; OR, 0.15; P = .012) were less frequent among case patients. MERS-CoV patients were more likely to have a normal white blood cell count than the control group (82% vs 52%; OR, 4.33; P = .029). Admission chest radiography with interstitial infiltrates was more frequent in case patients than in controls (67% vs 20%; OR, 8.13; P = .001). Case patients were more likely to be admitted to the intensive care unit (53% vs 20%; OR, 4.65; P = .025) and to have a high mortality rate (76% vs 15%; OR, 18.96; P &lt; .001).</p>
</blockquote>
<blockquote>
<p>Conclusions. Few clinical predictors could enhance the ability to predict which patients with pneumonia would have MERS-CoV. However, further prospective analysis and matched case-control studies may shed light on other predictors of infection.</p>
</blockquote>
<p>Consider the results above on diabetes. Of 17 cases, 13 had diabetes; of 82 controls, 35 had diabetes. So the data can be summarized as follows:</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" data-line-number="1">MERSCoV &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">coronov =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;case&quot;</span>, <span class="dv">17</span>), <span class="kw">rep</span>(<span class="st">&quot;control&quot;</span>, <span class="dv">82</span>)),</a>
<a class="sourceLine" id="cb80-2" data-line-number="2">                      <span class="dt">diab =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;hasdiab&quot;</span>, <span class="dv">13</span>), <span class="kw">rep</span>(<span class="st">&quot;nodiab&quot;</span>, <span class="dv">4</span>), </a>
<a class="sourceLine" id="cb80-3" data-line-number="3">                               <span class="kw">rep</span>(<span class="st">&quot;hasdiab&quot;</span>, <span class="dv">35</span>), <span class="kw">rep</span>(<span class="st">&quot;nodiab&quot;</span>, <span class="dv">47</span>)))</a>
<a class="sourceLine" id="cb80-4" data-line-number="4"><span class="kw">table</span>(MERSCoV)</a></code></pre></div>
<pre><code>##          diab
## coronov   hasdiab nodiab
##   case         13      4
##   control      35     47</code></pre>
<div id="ci-for-95-or" class="section level4 unnumbered">
<h4>CI for 95% OR</h4>
<p>As with the calculations above, we can find a CI for the true OR of diabetes for those with MRES-CoV and those without.</p>
<p>We are 95% confident that the true odds of diabetes are between 1.31 times and 14.5 times higher for those with CoV than those without. Note that the results calculated here do not match with the results in the paper.</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" data-line-number="1">(<span class="dt">ORhat =</span> (<span class="dv">13</span><span class="op">/</span><span class="dv">4</span>)<span class="op">/</span>(<span class="dv">35</span><span class="op">/</span><span class="dv">47</span>))</a></code></pre></div>
<pre><code>## [1] 4.364286</code></pre>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" data-line-number="1">(<span class="dt">SE_lnOR =</span> <span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="dv">13</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">4</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">35</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">47</span>))</a></code></pre></div>
<pre><code>## [1] 0.6138168</code></pre>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" data-line-number="1"><span class="kw">xqnorm</span>(<span class="fl">0.975</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">plot=</span><span class="ot">FALSE</span>)</a></code></pre></div>
<pre><code>## [1] 1.959964</code></pre>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" data-line-number="1"><span class="kw">log</span>(ORhat) <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>SE_lnOR</a></code></pre></div>
<pre><code>## [1] 0.2703735</code></pre>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" data-line-number="1"><span class="kw">log</span>(ORhat) <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>SE_lnOR</a></code></pre></div>
<pre><code>## [1] 2.676536</code></pre>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb92-1" data-line-number="1"><span class="kw">exp</span>(<span class="kw">log</span>(ORhat) <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>SE_lnOR)</a></code></pre></div>
<pre><code>## [1] 1.310454</code></pre>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" data-line-number="1"><span class="kw">exp</span>(<span class="kw">log</span>(ORhat) <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>SE_lnOR)</a></code></pre></div>
<pre><code>## [1] 14.53465</code></pre>
<p>Working backwards from their percentages, if 13 is 87% of their cases, then there are 15 cases. If 35 is 47% of their controls, then there are 74 controls. Using the revised numbers, the odds ratio would by <span class="math inline">\(\hat{OR}\)</span> = (13/2)/(35/39) = 7.24, with a CI of (1.53, 34.37).</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" data-line-number="1">(<span class="dt">ORhat =</span> (<span class="dv">13</span><span class="op">/</span><span class="dv">2</span>)<span class="op">/</span>(<span class="dv">35</span><span class="op">/</span><span class="dv">39</span>))</a></code></pre></div>
<pre><code>## [1] 7.242857</code></pre>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb98-1" data-line-number="1">(<span class="dt">SE_lnOR =</span> <span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="dv">13</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">35</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">39</span>))</a></code></pre></div>
<pre><code>## [1] 0.7944404</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb100-1" data-line-number="1"><span class="kw">exp</span>(<span class="kw">log</span>(ORhat) <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>SE_lnOR)</a></code></pre></div>
<pre><code>## [1] 1.526401</code></pre>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb102-1" data-line-number="1"><span class="kw">exp</span>(<span class="kw">log</span>(ORhat) <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>SE_lnOR)</a></code></pre></div>
<pre><code>## [1] 34.36776</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-12"></span>
<img src="figs/CoV.jpg" alt="Al-Tawfig et al. `Middle East Respiratory Syndrome Coronavirus: A Case-Control Study of Hospitalized Patients`" width="909" />
<p class="caption">
Figure 4.1: Al-Tawfig et al. <code>Middle East Respiratory Syndrome Coronavirus: A Case-Control Study of Hospitalized Patients</code>
</p>
</div>
</div>
</div>
</div>
<div id="Feb25" class="section level2">
<h2><span class="header-section-number">4.9</span> 2/25/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Difference in Proportion HT</li>
<li>Difference in Proportion CI</li>
</ol>
</div>
<div id="diffprop" class="section level2">
<h2><span class="header-section-number">4.10</span> Difference of two proportions</h2>
<div id="clt-for-difference-in-two-proportions" class="section level3">
<h3><span class="header-section-number">4.10.1</span> CLT for difference in two proportions</h3>
<p>As before, we apply the mathematical model (i.e., normal distribution) derived from the central limit theorem to investigate the properties of the statistic of interest. Here, the statistic of interest is the difference in two sample proportions: <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span>. The CLT describes how <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span> varies as many random samples are taken from the population.</p>
<p>As with the single sample proportion, the normal distribution is a good fit only under certain technical conditions:</p>
<ul>
<li><p><strong>Independence</strong> The data are independent within and between the two groups. Generally this is satisfied if the data come from two independent random samples or if the data come from a randomized experiment. However, there may be times when the independence condition seems reasonable even if it is not precisely met.</p></li>
<li><p><strong>Success-failure condition</strong> (i.e., large enough sample sized). We need at least 10 successes and 10 failures (expected) in each group. Some authors suggest that 5 of each in each group is sufficient.</p></li>
</ul>
<div id="the-central-limit-theorem-for-hatp_1---hatp_2" class="section level4 unnumbered">
<h4>The Central Limit Theorem for <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span>:</h4>
<p>The central limit theorem describes how <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span> varies as many random samples are taken from the population.</p>
<p><span class="math display">\[\hat{p}_1 - \hat{p}_2 \sim N\Bigg(p_1 - p_2, \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}\Bigg)\]</span></p>
</div>
</div>
<div id="ht-difference-in-proportions" class="section level3">
<h3><span class="header-section-number">4.10.2</span> HT: difference in proportions</h3>
<p>Note that the equation above describing the central limit theorem has a formula for the variability of <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span>. That is,</p>
<p><span class="math display">\[SE(\hat{p}_1 - \hat{p}_2) = \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}\]</span></p>
<p>However, when testing a particular hypothesis, the research question does not (usually) provide values of <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span> to use in the formula for the SE. Instead, the research question is usually one of independence, that is, that knowing the level of the explanatory (group) variable tells you nothing about the probability of the response variable. Indeed, typically the null hypothesis is written as:</p>
<p><span class="math display">\[H_0: p_1 = p_2\]</span></p>
<p>with the alternative hypothesis incorporating the direction of the research claim.</p>
<p>In order to calculate a p-value, the sampling distribution of <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span> <strong>under <span class="math inline">\(H_0\)</span></strong> is needed. The CLT is a start to understanding the distribution of <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span>, but the additional step which incorporates the null hypothesis of <span class="math inline">\(p_1 = p_2\)</span> is implemented through the SE.
If <span class="math inline">\(H_0: p_1 = p_2\)</span> is true, then our best guess for the true value of either <span class="math inline">\(p_1\)</span> or <span class="math inline">\(p_2\)</span> is:</p>
<p><span class="math display">\[\hat{p}_{pooled} = \frac{\mbox{number of successed}}{\mbox{number of observations}} = \frac{\hat{p}_1 n_1 + \hat{p}_2 n_2}{n_1 + n_2}\]</span></p>
<div id="two-proportion-z-test" class="section level4 unnumbered">
<h4>Two proportion z-test</h4>
<p>To perform a hypothesis test using the normal distribution (i.e., the central limit theorem) we use a z-score as the test statistic and then <code>xpnorm</code> to find the p-value.</p>
<p><span class="math display">\[\mbox{Z score} = \frac{(\hat{p}_1 - \hat{p}_2) - 0}{\sqrt{\frac{\hat{p}_{pooled}(1-\hat{p}_{pooled})}{n_1} + \frac{\hat{p}_{pooled}(1-\hat{p}_{pooled})}{n_2}}}\]</span></p>
<p><span class="math display">\[\mbox{p-value} = \mbox{probability of Z score or more extreme using N(0,1) probability}\]</span></p>
</div>
</div>
<div id="ci-difference-in-proportions" class="section level3">
<h3><span class="header-section-number">4.10.3</span> CI: difference in proportions</h3>
<p>When creating a confidence interval for the true parameter of interest, there is no underlying research assumption about the values of <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span>. The best we can do to calculate the SE is to use the sample values.</p>
<p><strong>population parameter:</strong> <span class="math inline">\(p_1 - p_2\)</span>: the true difference in success proportion (or probability) between groups 1 and 2.</p>
<p><strong>CI for</strong> <span class="math inline">\(p_1 - p_2\)</span>:</p>
<p><span class="math display">\[(\hat{p}_1 - \hat{p}_2) \pm Z^* \sqrt{\frac{\hat{p}_1 (1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2 (1-\hat{p}_2)}{n_2}}\]</span></p>
</div>
<div id="example-government-shutdown" class="section level3">
<h3><span class="header-section-number">4.10.4</span> Example: Government Shutdown<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></h3>
<blockquote>
<p>The United States federal government shutdown of 2018-2019 occurred from December 22, 2018 until January 25, 2019, a span of 35 days. A Survey USA poll of 608 randomly sampled Americans during this time period reported that 48% (77 of 160 people) of those who make less than $40,000 per year and 55% (247 of 448 people) of those who make $40,000 or more per year said the government shutdown has not at all affected them personally.</p>
</blockquote>
<ol start="0" style="list-style-type: decimal">
<li><p>Notice that the observational units have been selected from the entire population: <strong>not</strong> by using the response or explanatory variable. (This type of study is called a cross-classification study.) The beauty of having been selected from the entire population is that we have a good sense of <strong>both</strong> the proportions of each group as well as the proportion of people for whom the shutdown has affected them.</p></li>
<li><p>Test the research claim that the proportion of people who are affected by the shutdown is different in comparing those who make more than $40,000 and less than $40,000 per year.</p></li>
</ol>
<p>The p-value for the test is 0.128 indicating that there is no evidence of a difference in the proportion of people affected by the shutdown across the two income groups. <strong>NOTE</strong> we cannot claim “no difference”!! We claim “there is no evidence of a difference.” Try to explain to yourself (or your classmate) the difference in those two claims.</p>
<p><span class="math display">\[\mbox{p-value} = 2* P( Z \leq -1.522) = 0.128\]</span></p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" data-line-number="1">(p_pool &lt;-<span class="st"> </span>(<span class="dv">247</span><span class="op">+</span><span class="dv">77</span>)<span class="op">/</span><span class="st"> </span><span class="dv">614</span>)</a></code></pre></div>
<pre><code>## [1] 0.5276873</code></pre>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb106-1" data-line-number="1">(z_score &lt;-<span class="st"> </span>(<span class="fl">0.48</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.55</span>) <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(p_pool<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p_pool) <span class="op">*</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">160</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">448</span>)))</a></code></pre></div>
<pre><code>## [1] -1.522447</code></pre>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb108-1" data-line-number="1"><span class="dv">2</span><span class="op">*</span><span class="kw">xpnorm</span>(z_score,<span class="dv">0</span>,<span class="dv">1</span>)</a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-13-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.1278972</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>A 95% confidence interval for (<span class="math inline">\(p_{&lt;40K}- p_{ \geq40K}\)</span>) ), where p is the proportion of those who said the government shutdown has not at all affected them personally, is (-0.16, 0.02).</li>
</ol>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb110-1" data-line-number="1">(z_star95 &lt;-<span class="st"> </span><span class="kw">xqnorm</span>(<span class="fl">0.975</span>, <span class="dv">0</span>, <span class="dv">1</span>))</a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-14-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 1.959964</code></pre>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb112-1" data-line-number="1">(<span class="fl">0.48</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.55</span>) <span class="op">-</span><span class="st"> </span>z_star95<span class="op">*</span><span class="kw">sqrt</span>(<span class="fl">0.48</span><span class="op">*</span>(<span class="dv">1</span><span class="fl">-0.48</span>)<span class="op">/</span><span class="dv">160</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.55</span><span class="op">*</span>(<span class="dv">1</span><span class="fl">-0.55</span>)<span class="op">/</span><span class="dv">448</span>)</a></code></pre></div>
<pre><code>## [1] -0.1600828</code></pre>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb114-1" data-line-number="1">(<span class="fl">0.48</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.55</span>) <span class="op">+</span><span class="st"> </span>z_star95<span class="op">*</span><span class="kw">sqrt</span>(<span class="fl">0.48</span><span class="op">*</span>(<span class="dv">1</span><span class="fl">-0.48</span>)<span class="op">/</span><span class="dv">160</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.55</span><span class="op">*</span>(<span class="dv">1</span><span class="fl">-0.55</span>)<span class="op">/</span><span class="dv">448</span>)</a></code></pre></div>
<pre><code>## [1] 0.0200828</code></pre>
<p>Determine if the following statements are true or false, and explain your reasoning if you identify the statement as false.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a></p>
<ol style="list-style-type: lower-alpha">
<li><p>At the 5% significance level, the data provide convincing evidence of a real difference in the proportion who are not affected personally between Americans who make less than $40,000 annually and Americans who make $40,000 or more annually.</p></li>
<li><p>We are 95% confident that 16% more to 2% fewer Americans who make less than $40,000 per year are not at all personally affected by the government shutdown compared to those who make $40,000 or more per year.</p></li>
<li><p>A 90% confidence interval for (<span class="math inline">\(p_{&lt;40K}- p_{ \geq40K}\)</span>) would be wider than the (-0.16, 0.02) interval.</p></li>
<li><p>A 95% confidence interval for(<span class="math inline">\(p_{ \geq40K} - p_{&lt;40K}\)</span>) is (-0.02, 0.16).</p></li>
</ol>
</div>
</div>
<div id="Feb27" class="section level2">
<h2><span class="header-section-number">4.11</span> 2/27/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Observational Studies</li>
<li>Experiments</li>
<li>Causation</li>
</ol>
</div>
<div id="experim" class="section level2">
<h2><span class="header-section-number">4.12</span> Types of Studies</h2>
<p>The two basic types of studies encountered are <strong>observational</strong> and <strong>experimental</strong>.</p>
<ul>
<li><p>In an <strong>experiment</strong>, researchers assign treatments to cases. That is, the researchers decide who gets which level of the treatment (also known as explanatory variable). When the treatment is assigned randomly, the experiment is known as a <strong>randomized experiment</strong>.</p></li>
<li><p>In an <strong>observational</strong> study, the researchers observe both the explanatory and the response variable without interfering in how the data arise.</p></li>
</ul>
<p>Remembering the types of variables in most studies, we add one more category of variables: a <strong>confounding</strong> variable:</p>
<ul>
<li><strong>Explanatory variable</strong> is one that is a potential explanation for any changes (here smoking level).<br />
</li>
<li><strong>Response variable</strong> is the measured outcome of interest (here lung cancer).<br />
</li>
<li><strong>Confounding variable</strong> is a variable (typically not measured!) that is associated with both the explanatory and response variables.</li>
</ul>
<div id="example-hand-writing-sat-scores" class="section level3">
<h3><span class="header-section-number">4.12.1</span> Example: Hand Writing &amp; SAT Scores<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></h3>
<blockquote>
<p>An article about handwriting appeared in the October 11, 2006 issue of the Washington Post. The article mentioned that among students who took the essay portion of the SAT exam in 2005-06, those who wrote in cursive style scored significantly higher on the essay, on average, than students who used printed block letters. Researchers wanted to know whether simply writing in cursive would be a way to increase scores.</p>
</blockquote>
<ul>
<li><p>Identify the observational units, the variables, the types of variables, the parameter of interest, and the statistic which was measured. What type of study was it?</p></li>
<li><p><strong>Q1</strong> does writing in cursive <strong>cause</strong> higher scores? What are some potential confounding variables?</p></li>
</ul>
<blockquote>
<p>The article also mentioned a different study in which the same one essay was given to all graders. But some graders were shown a cursive version of the essay and the other graders were shown a version with printed block letters. The average score assigned to the essay with the cursive style was <em>significantly</em> higher than the average score assigned to the essay with the printed block letters.</p>
</blockquote>
<ul>
<li><p>Do any of these change? the observational units, the variables, the types of variables, the parameter of interest, and the statistic which was measured. What type of study was it?</p></li>
<li><p><strong>Q2</strong> can the conclusion include a causal statement now? Why? What changed?</p></li>
</ul>
</div>
<div id="example-have-a-nice-trip" class="section level3">
<h3><span class="header-section-number">4.12.2</span> Example: Have a Nice Trip<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></h3>
<blockquote>
<p>An area of research in biomechanics and gerontology concerns falls and fall-related injuries, especially for elderly people. Recent studies have focused on how individuals respond to large postural disturbances (e.g., tripping, induced slips). One question is whether subjects can be instructed to improve their recovery from such perturbations. Suppose researchers want to compare two such recovery strategies, lowering (making the next step shorter, but in normal step time) and elevating (using a longer or normal step length with normal step time). Subjects will have first been trained on one of these two recovery strategies, and they will be asked to apply it after they feel themselves tripping. The researchers will then induce the subject to trip while walking (but harnessed for safety), using a concealed mechanical obstacle.</p>
</blockquote>
<blockquote>
<p>Suppose the following 24 subjects have agreed to participate in such a study. Both males and female were recruited because females tend to have better balance (lower center of gravity).</p>
</blockquote>
<blockquote>
<p>Females: Alisha, Alice, Betty, Martha, Audrey, Mary, Barbie, Anna</p>
</blockquote>
<blockquote>
<p>Males: Matt, Peter, Shawn, Brad, Michael, Kyle, Russ, Patrick, Bob, Kevin, Mitch, Marvin,
Paul, Pedro, Roger, Sam</p>
</blockquote>
<blockquote>
<p>The applet at <a href="http://www.rossmanchance.com/applets/Subjects.html" class="uri">http://www.rossmanchance.com/applets/Subjects.html</a> is helpful for visualizing why confounding variables are removed when the treatment is randomly assigned.</p>
</blockquote>
<ul>
<li><p><strong>Q1</strong> Why would we not want to allow all the women to be trained in the “lowering” technique and all the men trained in the “elevating” technique?</p></li>
<li><p><strong>Q2</strong> Why do we randomize the treatment? How does it affect gender balance? Height distribution? Gene distribution? Factor “X”?</p></li>
<li><p><strong>Q3</strong> What if gender balance across the two treatments is required for the study? How is the treatment randomly allocated to the observational units? That is, what would change from Q2?</p></li>
</ul>
</div>
<div id="study-conclusions" class="section level3">
<h3><span class="header-section-number">4.12.3</span> Study conclusions</h3>
<p>The ideas surrounding study design typically connect to the question of causality: is it possible or not to infer causality at the end of the study? However, the words we use (“random allocation”) sound a lot like the words we used when describing sampling (“random sample” or “random selection”).</p>
<p>Random sampling and random allocation are <strong>VERY DIFFERENT</strong> concepts! And most importantly, the <em>conclusions</em> made from the two different study characteristics are different.</p>
<ul>
<li><strong>Random selection</strong> or <strong>Random sample</strong> - each unit in the population is equally likely to be chosen for the sample.</li>
<li><strong>Random allocation</strong> - each observational unit is equally likely to be assigned to any of the treatments (explanatory variable).</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:randSleuth"></span>
<img src="figs/randsampexp.png" alt="Random Sample vs Randomized Experiment, taken from @sleuth" width="1901" />
<p class="caption">
Figure 4.2: Random Sample vs Randomized Experiment, taken from <span class="citation">Ramsey and Schafer (<a href="#ref-sleuth">2012</a>)</span>
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:randgoodQ"></span>
<img src="figs/randsampexp2.png" alt="Random Sample vs Randomized Experiment, taken from https://askgoodquestions.blog/" width="80%" />
<p class="caption">
Figure 4.3: Random Sample vs Randomized Experiment, taken from <a href="https://askgoodquestions.blog/" class="uri">https://askgoodquestions.blog/</a>
</p>
</div>
<p>In an ideal world, every study would have participants who were randomly sampled from the population and randomly allocated to the treatments. However, the limitations of ethical research makes simultaneously doing both random processes difficult. Why is that? Consider the following:</p>
<ul>
<li><p>In a clinical trial, it makes sense to randomly allocate the subjects. You cannot, however, randomly select people from the population to take part in the clinical trial. Why not?</p></li>
<li><p>In a political poll, it seems reasonable that the participants who are called (not necessarily the people who respond!) are a random sample from the population. It does not make sense, however, to randomly allocate those people to different treatments. Why not?</p></li>
</ul>
</div>
</div>
<div id="Mar3" class="section level2">
<h2><span class="header-section-number">4.13</span> 3/3/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>More than two proportions</li>
<li>Chi-square goodness-of-fit test</li>
</ol>
</div>
<div id="chisq1" class="section level2">
<h2><span class="header-section-number">4.14</span> Goodness-of-fit: One categorical variable (<span class="math inline">\(\chi^2\)</span> test) <span class="math inline">\(\geq\)</span> 2 levels</h2>
<p>Consider <span class="math inline">\(E_k\)</span> which is the number expected in the <span class="math inline">\(k^{th}\)</span> category.</p>
<p>When testing a null hypothesis of a pre-specified set of proportions (or probabilities) across <span class="math inline">\(K\)</span> categories, the test statistics is:</p>
<p><span class="math display">\[X^2 = \sum_{k=1}^K \frac{(O_k - E_k)^2}{E_k} \sim \chi^2_{K-1}\]</span></p>
<p>which has a null sampling distribution which is well-described by a chi-square distribution with <span class="math inline">\(K-1\)</span> degrees of freedom … if:</p>
<ul>
<li>Each case that contributes a count to the table is <strong>independent</strong> of all the other cases in the table.</li>
<li>Each particular scenario (i.e. cell count) has at least 5 expected cases. (sample size criterion)</li>
</ul>
<p>If the conditions don’t hold, then the test statistic won’t have the predicted distribution, so any p-value calculations will be meaningless.</p>
<div id="example-household-ages" class="section level3">
<h3><span class="header-section-number">4.14.1</span> Example: Household Ages<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a></h3>
<p>Suppose we had a class picnic, and all the people in everyone’s household showed up. Would their ages be representative of the ages of all Americans? Probably not. After all, this is not a random sample! But how unrepresentative are the ages?</p>
<p>The 2010 Census estimates<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a> the percent of people in the following age categories.</p>
<table>
<thead>
<tr class="header">
<th align="center">Age</th>
<th align="right">2010 Census Percent</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">&lt;18</td>
<td align="right">24.03%</td>
</tr>
<tr class="even">
<td align="center">18-44</td>
<td align="right">36.53%</td>
</tr>
<tr class="odd">
<td align="center">45+</td>
<td align="right">39.43%</td>
</tr>
</tbody>
</table>
<div id="is-the-age-distribution-of-the-people-from-households-in-our-class-typical-of-that-of-all-residents-of-the-us" class="section level4 unnumbered">
<h4>Is the age distribution of the people from households in our class typical of that of all residents of the US?</h4>
<p>Let’s collect some data. Note that we would never expect the last two columns to have the exact same values, even if the class <em>was</em> a perfect random sample. (Why not?)</p>
<table>
<thead>
<tr class="header">
<th align="center">Age</th>
<th align="right">2010 Census Percent</th>
<th align="center">Number Observed in Class</th>
<th align="center">Expected Number in Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">&lt;18</td>
<td align="right">24.03%</td>
<td align="center">5</td>
<td align="center">12.015</td>
</tr>
<tr class="even">
<td align="center">18-44</td>
<td align="right">36.54%</td>
<td align="center">22</td>
<td align="center">18.27</td>
</tr>
<tr class="odd">
<td align="center">45+</td>
<td align="right">39.43%</td>
<td align="center">23</td>
<td align="center">19.715</td>
</tr>
</tbody>
</table>
<p>Somehow we need to measure how closely the observed data match the expected values. We have the chi-square statistic (<span class="math inline">\(\chi^2\)</span>):</p>
<p><span class="math display">\[\chi^2 = \sum_{k=1}^K \frac{(O_k - E_k)^2}{E_k}\]</span></p>
<p>Let’s use the data collected from class to calculate an observed <span class="math inline">\(\chi^2\)</span> test statistic. Is it big enough to indicate that individuals from our class’s households don’t follow the 2010 Census proportions? How would we know? We need a null hypothesis!</p>
<p><span class="math inline">\(H_0: p_1 = 0.2403, p_2 = 0.3653, p_3 = 0.3943\)</span></p>
<p><span class="math inline">\(H_A: \mbox{ not } H_0\)</span></p>
<p>The null hypothesis is as specified by the 2010 Census. The alternative hypothesis is a deviation from that claim.</p>
<p>The observed test statistic is:</p>
<p><span class="math display">\[\begin{eqnarray*}
X^2 &amp;=&amp; \frac{(5 - 12.015)^2}{12.015} + \frac{(22 - 18.265)^2}{18.27} + \frac{(23-19.715)^2}{19.715}\\
&amp;=&amp; 5.41
\end{eqnarray*}\]</span></p>
<p>But how would we know if the value of the observed test statistic is “large enough” ? We need the <strong>distribution</strong> of the test statistic assuming the null hypothesis is true. Let’s generate it</p>
<table>
<colgroup>
<col width="9%" />
<col width="28%" />
<col width="30%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Age</th>
<th align="center">Random Digits</th>
<th align="center">Number Observed in Random Sample</th>
<th align="center">Expected Number in Random Sample</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">&lt;18</td>
<td align="center">0 - 25</td>
<td align="center">13</td>
<td align="center"><span class="math inline">\(50 \cdot 0.2403 = 12.015\)</span></td>
</tr>
<tr class="even">
<td align="center">18-44</td>
<td align="center">26 - 60</td>
<td align="center">18</td>
<td align="center"><span class="math inline">\(50 \cdot 0.3654 = 18.27\)</span></td>
</tr>
<tr class="odd">
<td align="center">45+</td>
<td align="center">61 - 99</td>
<td align="center">19</td>
<td align="center"><span class="math inline">\(50 \cdot 0.3943 = 19.715\)</span></td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\begin{eqnarray*}
X^2 &amp;=&amp; \frac{(13 - 12.015)^2}{12.015} + \frac{(18 - 18.265)^2}{18.27} + \frac{(19-19.715)^2}{19.715}\\
&amp;=&amp; 0.1105
\end{eqnarray*}\]</span></p>
<p>In class, we used random numbers (on pieces of paper) to generate the null sampling distribution of <span class="math inline">\(X^2\)</span>. It turns out, there is also a mathematical model which describes the variability of <span class="math inline">\(X^2\)</span>: the chi-square distribution with <span class="math inline">\(K-1\)</span> degrees of freedom. The p-value below says that we can’t reject <span class="math inline">\(H_0\)</span>, we don’t know that our household ages come from a distribution other than the census percentages. (To be clear: the conclusion is that we know nothing. We don’t have evidence to reject <span class="math inline">\(H_0\)</span>. But that also doesn’t mean we know <span class="math inline">\(H_0\)</span> is true. Unfortunately, we can’t conclude anything.)</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb116-1" data-line-number="1"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">xpchisq</span>(<span class="fl">5.41</span>, <span class="dv">2</span>)</a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-15-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.06687032</code></pre>
</div>
</div>
<div id="example-flax-seed" class="section level3">
<h3><span class="header-section-number">4.14.2</span> Example: Flax Seed</h3>
<p>Researchers studied a mutant type of flax seed that they hoped would produce oil for use in margarine and shortening. The amount of palmitic acid in the flax seed was an important factor in this research; a related factor was whether the seed was brown or was variegated. The seeds were classified into six combinations or palmitic acid and color. According to a hypothesized genetic model, the six combinations should occur in a 3:6:3:1:2:1 ratio.</p>
<table>
<thead>
<tr class="header">
<th>Color</th>
<th>Acid Level</th>
<th align="center">Observed</th>
<th align="center">Expected</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Brown</td>
<td>Low</td>
<td align="center">15</td>
<td align="center">13.5</td>
</tr>
<tr class="even">
<td>Brown</td>
<td>Intermediate</td>
<td align="center">26</td>
<td align="center">27</td>
</tr>
<tr class="odd">
<td>Brown</td>
<td>High</td>
<td align="center">15</td>
<td align="center">13.5</td>
</tr>
<tr class="even">
<td>Variegated</td>
<td>Low</td>
<td align="center">0</td>
<td align="center">4.5</td>
</tr>
<tr class="odd">
<td>Variegated</td>
<td>Intermediate</td>
<td align="center">8</td>
<td align="center">9</td>
</tr>
<tr class="even">
<td>Variegated</td>
<td>High</td>
<td align="center">8</td>
<td align="center">4.5</td>
</tr>
<tr class="odd">
<td>Total</td>
<td></td>
<td align="center">72</td>
<td align="center">72</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\begin{eqnarray*}
H_0: &amp;&amp; p_1 = 3/16, p_2=6/16, p_3 = 3/16, p_4 = 1/16, p_5=2/16, p_6 = 1/16\\
H_A: &amp;&amp; \mbox{ not the distribution in } H_0
\end{eqnarray*}\]</span></p>
<p><span class="math display">\[\begin{eqnarray*}
\chi^2 &amp;=&amp; \frac{(15-13.5)^2}{13.5} + \frac{(26-27)^2}{27} + \frac{(15-13.5)^2}{13.5} + \frac{(0-4.5)^2}{4.5} + \frac{(8-9)^2}{9} + \frac{(8-4.5)^2}{4.5}\\
&amp;=&amp; 7.71\\
\mbox{p-value} &amp;=&amp; P(\chi^2_5 \geq 7.71)\\
&amp;=&amp; 0.173\\
\end{eqnarray*}\]</span></p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb118-1" data-line-number="1"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">xpchisq</span>(<span class="fl">7.71</span>, <span class="dv">5</span>)</a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-16-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.172959</code></pre>
<div id="how-could-we-simulate-power" class="section level4 unnumbered">
<h4>How could we simulate power?</h4>
<p>Consider the flax seed example, As with the household ages example, use random digits.</p>
<ol style="list-style-type: decimal">
<li>Come up with an alternative hypothesis that specified the probabilities of each type of seed.</li>
<li>Allocate digits appropriately given the alternative model.</li>
<li>Randomly generate 72 random digits (from 00 to 99) and collect <em>observed</em> data based on the <strong>alternative</strong> model.</li>
<li>Calculate the test statistic from the randomly generated observed data (as compared to the expected counts under <span class="math inline">\(H_0\)</span>), and indicate whether it is above 11.07 (see below for the <span class="math inline">\(\chi^2_5\)</span> cutoff).</li>
<li>Repeat 3 &amp; 4 many many times. The power will be estimated by the proportion of times you reject the null hypothesis when the alternative is true.</li>
</ol>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb120-1" data-line-number="1"><span class="kw">xqchisq</span>(.<span class="dv">95</span>, <span class="dv">5</span>)</a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-17-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 11.0705</code></pre>
</div>
</div>
</div>
<div id="Mar5" class="section level2">
<h2><span class="header-section-number">4.15</span> 3/5/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>More than two levels (two variables)</li>
<li>Chi-square test of independence</li>
</ol>
</div>
<div id="chisq2" class="section level2">
<h2><span class="header-section-number">4.16</span> Independence: Two categorical variables (<span class="math inline">\(\chi^2\)</span> test) <span class="math inline">\(\geq\)</span> 2 levels each</h2>
<p>As when we were working with binary variables, most research questions have to do with two variables. Our main question now will be whether there is an association between two categorical variables of interest.</p>
<p><span class="math inline">\(H_0\)</span>:the two variables are independent</p>
<p><span class="math inline">\(H_A\)</span>: the two variables are not independent</p>
<p>How do we know if our test statistic is a big number or not? Well, it turns out that the test statistic will have an approximate <span class="math inline">\(\chi^2\)</span> distribution with degrees of freedom = <span class="math inline">\((r- 1)\cdot (c-1)\)</span> when <span class="math inline">\(H_0\)</span> is true. As long as:</p>
<ul>
<li>We have a random sample from the population.</li>
<li>We expect at least 1 observation in every cell (<span class="math inline">\(E_i \geq 1 \forall i\)</span>)</li>
<li>We expect at least 5 observations in 80% of the cells (<span class="math inline">\(E_i \geq 5\)</span> for 80% of <span class="math inline">\(i\)</span>)</li>
</ul>
<p><span class="math display">\[X^2 = \sum_{\mbox{all cells}} \frac{(Obs - Exp)^2}{Exp} \sim \chi^2_{(r-1)(c-1)}\]</span></p>
<p>Consider the following (silly?) example data on CA vs. notCA and soda preference:</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="center">CA</th>
<th align="center">no CA</th>
<th align="center">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Coke</td>
<td align="center">72</td>
<td align="center">8</td>
<td align="center">80</td>
</tr>
<tr class="even">
<td align="left">Pepsi</td>
<td align="center">18</td>
<td align="center">22</td>
<td align="center">40</td>
</tr>
<tr class="odd">
<td align="left">total</td>
<td align="center">90</td>
<td align="center">30</td>
<td align="center">120</td>
</tr>
</tbody>
</table>
<p>What if we had those same number of people in each group and category, but we wanted absolutely no association between the two variables of soda preference and location:</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="center">CA</th>
<th align="center">no CA</th>
<th align="center">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Coke</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">80</td>
</tr>
<tr class="even">
<td align="left">Pepsi</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">40</td>
</tr>
<tr class="odd">
<td align="left">total</td>
<td align="center">90</td>
<td align="center">30</td>
<td align="center">120</td>
</tr>
</tbody>
</table>
<p>If the distribution of Coke and Pepsi preference were the same in CA vs not CA, how many Californians would prefer Coke? 60!</p>
<p><span class="math display">\[\mbox{# CA who prefer Coke} = 90 \cdot \frac{80}{120} = 60\]</span>
The rest of the table can be filled out in a similar manner:</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="center">CA</th>
<th align="center">no CA</th>
<th align="center">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Coke</td>
<td align="center">60</td>
<td align="center">20</td>
<td align="center">80</td>
</tr>
<tr class="even">
<td align="left">Pepsi</td>
<td align="center">30</td>
<td align="center">10</td>
<td align="center">40</td>
</tr>
<tr class="odd">
<td align="left">total</td>
<td align="center">90</td>
<td align="center">30</td>
<td align="center">120</td>
</tr>
</tbody>
</table>
<p>The Coke &amp; Pepsi example motivates the idea of how many observations we expect to see in each cell if there is no association between the variables. Note that the expected number is almost always a decimal value.</p>
<p><span class="math display">\[\mbox{Exp} = \frac{(\mbox{row total})(\mbox{col total})}{\mbox{table total}}\]</span></p>
<div id="example-nightlights" class="section level3">
<h3><span class="header-section-number">4.16.1</span> Example: Nightlights<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a></h3>
<blockquote>
<p>Myopia, or near-sightedness, typically develops during the childhood years. Recent studies have explored whether there is an association between development of myopia and the use of night-lights with infants. Quinn, Shin, Maguire, and Stone (1999) examined the type of light children aged 2-16 were exposed to. Between January and June 1998, the parents of 479 children who were seen as outpatients in a university pediatric ophthalmology clinic completed a questionnaire (children who had already developed serious eye conditions were excluded). One of the questions asked was “Under which lighting condition did/does your child sleep at night?” before the age of 2 years. The following two-way table classifies the children’s eye condition and whether or not they slept with some kind of light (e.g., a night light or full room light) or in darkness.</p>
</blockquote>
<p>The data are given by the following R code:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" data-line-number="1">lights &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">eyesight =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;far&quot;</span>, <span class="dv">40</span>), <span class="kw">rep</span>(<span class="st">&quot;neither&quot;</span>, <span class="dv">114</span>), <span class="kw">rep</span>(<span class="st">&quot;near&quot;</span>, <span class="dv">18</span>),</a>
<a class="sourceLine" id="cb122-2" data-line-number="2">                           <span class="kw">rep</span>(<span class="st">&quot;far&quot;</span>, <span class="dv">39</span>), <span class="kw">rep</span>(<span class="st">&quot;neither&quot;</span>, <span class="dv">115</span>), <span class="kw">rep</span>(<span class="st">&quot;near&quot;</span>, <span class="dv">78</span>),</a>
<a class="sourceLine" id="cb122-3" data-line-number="3">                           <span class="kw">rep</span>(<span class="st">&quot;far&quot;</span>, <span class="dv">12</span>), <span class="kw">rep</span>(<span class="st">&quot;neither&quot;</span>, <span class="dv">22</span>), <span class="kw">rep</span>(<span class="st">&quot;near&quot;</span>, <span class="dv">41</span>)),</a>
<a class="sourceLine" id="cb122-4" data-line-number="4">                     <span class="dt">lighting =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;dark&quot;</span>, <span class="dv">172</span>), <span class="kw">rep</span>(<span class="st">&quot;nightlight&quot;</span>, <span class="dv">232</span>), <span class="kw">rep</span>(<span class="st">&quot;roomlight&quot;</span>, <span class="dv">75</span>)))</a>
<a class="sourceLine" id="cb122-5" data-line-number="5"></a>
<a class="sourceLine" id="cb122-6" data-line-number="6"><span class="kw">table</span>(lights)</a></code></pre></div>
<pre><code>##          lighting
## eyesight  dark nightlight roomlight
##   far       40         39        12
##   near      18         78        41
##   neither  114        115        22</code></pre>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" data-line-number="1">lights <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb124-2" data-line-number="2"><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb124-3" data-line-number="3"><span class="st">  </span><span class="kw">geom_bar</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lighting, <span class="dt">fill =</span> eyesight), <span class="dt">position =</span> <span class="st">&quot;fill&quot;</span>)</a></code></pre></div>
<p><img src="03-InfCat_files/figure-html/unnamed-chunk-18-1.png" width="768" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(H_0\)</span>: There is no association between lighting condition and eye condition</p>
<p><span class="math inline">\(H_A\)</span>: There is an association between lighting condition and eye condition</p>
<ul>
<li><p>What are the observational units?</p></li>
<li><p>What are the explanatory and response variables?</p></li>
<li><p>Let’s say that we conclude there is an association (we reject <span class="math inline">\(H_0\)</span>). Can we also conclude that lighting causes particular eye conditions?</p></li>
<li><p>Try to come up with as many confounding variables as possible.</p></li>
</ul>
<p>The chi-square test can be applied to the table of counts. The test statistic is 56.513 with a very small p-value. Note that the observed and expected tables can be pulled out of the <code>chisq.test()</code> output.</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb125-1" data-line-number="1">(chi.lights &lt;-<span class="st"> </span>lights <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb125-2" data-line-number="2"><span class="st">  </span><span class="kw">select</span>(eyesight, lighting) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb125-3" data-line-number="3"><span class="st">  </span><span class="kw">table</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb125-4" data-line-number="4"><span class="st">  </span><span class="kw">chisq.test</span>())</a></code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  .
## X-squared = 56.513, df = 4, p-value = 1.565e-11</code></pre>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb127-1" data-line-number="1">chi.lights<span class="op">$</span>observed</a></code></pre></div>
<pre><code>##          lighting
## eyesight  dark nightlight roomlight
##   far       40         39        12
##   near      18         78        41
##   neither  114        115        22</code></pre>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb129-1" data-line-number="1">chi.lights<span class="op">$</span>expected</a></code></pre></div>
<pre><code>##          lighting
## eyesight      dark nightlight roomlight
##   far     32.67641   44.07516  14.24843
##   near    49.19415   66.35491  21.45094
##   neither 90.12944  121.56994  39.30063</code></pre>
<p>The conclusion from Inv 5.3 in <span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span> is excellent:</p>
<blockquote>
<p>The segmented bar graph reveals that for the children in this sample the incidence of near-sightedness increases as the level of lighting increases. When we have a random sample with two categorical variables, we can perform a chi-square test of association. Because the expected counts are large (smallest is 14.25 &gt; 5), we can apply the chi-square test to these data. The p-value of this chi-square test is essentially zero, which says that if there were no association between eye condition and lighting in the population, then it’s virtually impossible for chance alone to produce a table in which the conditional distributions would differ by as much as they did in the actual study. Thus, the sample data provide overwhelming evidence that there is indeed an association between eye condition and
lighting in the population of children like those in this study. A closer analysis of the table and the chi-square calculation reveals that there are many fewer children with near-sightedness than would be expected in the “darkness” group and many more children with near-sightedness than would be expected in the “room light” group. But remember, we cannot draw a cause-and-effect conclusion between lighting and eye condition because this is an observational study. Several confounding variables could explain the observed association. For example, perhaps near-sighted children tend to have near-sighted parents who prefer to leave a light on because of their own vision difficulties, while also passing this genetic predisposition on to their children. We also have to be careful in generalizing from this sample to a larger population because the children were making voluntary visits to an eye doctor and were not selected at random from a larger population.</p>
</blockquote>
</div>
</div>
<div id="agenda" class="section level2">
<h2><span class="header-section-number">4.17</span> 3/10/20 &amp; 3/12/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Review for exam</li>
<li>Exam 1</li>
</ol>
</div>
<div id="agenda-1" class="section level2">
<h2><span class="header-section-number">4.18</span> 3/17/20 &amp; 3/19/20 Agenda</h2>
<p>Spring Break 1 !</p>
</div>
<div id="agenda-2" class="section level2">
<h2><span class="header-section-number">4.19</span> 3/24/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Census</li>
</ol>
</div>
<div id="census" class="section level2">
<h2><span class="header-section-number">4.20</span> Census</h2>
<p>I recently filled out my census form. Here is the full list of questions that I was asked:</p>
<ul>
<li>address</li>
<li>name (of all residents at my address); including how many people live at the address</li>
<li>the ownership status of the residence where I live</li>
<li>my sex (only binary options provided, asked for all residents)</li>
<li>birthday (asked for all residents)</li>
<li>Hispanic, Latino, or Spanish origin (asked for all residents)</li>
<li>race (with ethnicity options, asked for all residents)</li>
<li>relationship status of each of the residents to me. flexibility given for marital status, family status, etc. but no flexibility for sex (e.g., I could choose whether my spouse and I were married or not, but I was required to choose whether they were the same sex as me or the opposite sex as me)</li>
</ul>
<div id="what-about-college-students" class="section level3">
<h3><span class="header-section-number">4.20.1</span> What about College students?</h3>
<p>The Census provides great information at their website (particularly with respect to the changes due to COVID-19).</p>
<p><a href="https://2020census.gov/en/who-to-count.html" class="uri">https://2020census.gov/en/who-to-count.html</a></p>
<p><a href="https://2020census.gov/en/news-events/press-releases/modifying-2020-operations.html" class="uri">https://2020census.gov/en/news-events/press-releases/modifying-2020-operations.html</a></p>
<blockquote>
<p>College students who live away from home should be counted at the on- or off-campus residence where they live and sleep most of the time, even if they are at home on April 1, 2020. If they live in housing designed for college students (such as dorms and apartments with “by-the-bed” leases), they will be counted as part of the Group Quarters Operation. If they live off campus in housing that is not designed for college students (such as a private house or apartment), they should count themselves at that address.</p>
</blockquote>
<blockquote>
<p>During our recent 2020 Census Group Quarters Advance Contact operation we contacted college/university student housing administrators to get their input on the enumeration methods that will allow students to participate in the 2020 Census. The majority, about 47 percent, have chosen the eResponse methodology and about 7 percent chose paper listings… About 35 percent, however, chose drop-off/pick-up which allows students to self-respond using an Individual Census Questionnaire (or ICQ). We are contacting those schools to ask whether they would like to change that preference in light of the emerging situation.</p>
</blockquote>
<blockquote>
<p>In general, students in colleges and universities temporarily closed due to the COVID-19 virus will still be counted as part of this process. Even if they are home on census day, April 1, they should be counted according to the residence criteria which states they should be counted where they live and sleep most of the time.</p>
</blockquote>
</div>
</div>
<div id="agenda-3" class="section level2">
<h2><span class="header-section-number">4.21</span> 3/26/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>COVID-19</li>
</ol>
</div>
<div id="covid19" class="section level2">
<h2><span class="header-section-number">4.22</span> COVID-19</h2>
<p>Thursday’s optional class meeting is about COVID-19 and how it connects to the ideas in introductory statistics. T</p>
<p>A good starting place for solid information about COVID-19:
<a href="https://www.sciencemuseumgroup.org.uk/coronavirus-science-what-we-know-and-dont-know-about-the-virus/" class="uri">https://www.sciencemuseumgroup.org.uk/coronavirus-science-what-we-know-and-dont-know-about-the-virus/</a></p>
<div id="visualizing-the-data" class="section level4 unnumbered">
<h4>Visualizing the data:</h4>
<p>I find these two dashboards to be among the best out there. Good display, constantly being updated, reliable data.</p>
<ul>
<li>Coronavirus COVID-19 Global Cases by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University (JHU): <a href="https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6" class="uri">https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6</a></li>
<li>COVID-19 Global Pandemic Real-time Report: <a href="https://ncov.dxy.cn/ncovh5/view/en_pneumonia?link=&amp;share=&amp;source=" class="uri">https://ncov.dxy.cn/ncovh5/view/en_pneumonia?link=&amp;share=&amp;source=</a></li>
</ul>
<p>That said, it is also worth thinking about how to visualize the data and to do so responsibly.</p>
<ul>
<li>Visualizing COVID-19 data (responsibly): <a href="https://medium.com/nightingale/ten-considerations-before-you-create-another-chart-about-covid-19-27d3bd691be8" class="uri">https://medium.com/nightingale/ten-considerations-before-you-create-another-chart-about-covid-19-27d3bd691be8</a></li>
</ul>
</div>
<div id="current-medical-studies-on-treatment-of-covid-19" class="section level4 unnumbered">
<h4>Current medical studies on treatment of COVID-19:</h4>
<ul>
<li>French study investigating azithromycin – chloroquine on COVID-19.</li>
</ul>
<p><a href="https://www.sciencedirect.com/science/article/pii/S0924857920300996" class="uri">https://www.sciencedirect.com/science/article/pii/S0924857920300996</a></p>
<blockquote>
<p>French Confirmed COVID-19 patients were included in a single arm protocol from early March to March 16th, to receive 600mg of hydroxychloroquine daily and their viral load in nasopharyngeal swabs was tested daily in a hospital setting. Depending on their clinical presentation, azithromycin was added to the treatment. Untreated patients from another center and cases refusing the protocol were included as negative controls. Presence and absence of virus at Day6-post inclusion was considered the end point.</p>
</blockquote>
<blockquote>
<p>Assuming a 50% efficacy of hydroxychloroquine in reducing the viral load at day 7, a 85% power, a type I error rate of 5% and 10% loss to follow-up, we calculated that a total of 48 COVID-19 patients (i.e., 24 cases in the hydroxychloroquine group and 24 in the control group) would be required for the analysis (Fleiss with CC). Statistical differences were evaluated by Pearson’s chi-square or Fisher’s exact tests as categorical variables, as appropriate. Means of quantitative data were compared using Student’s t-test.</p>
</blockquote>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-20"></span>
<img src="figs/covid1.jpg" alt="Gautret et al. Hydroxychloroquine and azithromycin as a treatment of COVID-19: results of an open-label non-randomized clinical trial" width="80%" /><img src="figs/covid2.jpg" alt="Gautret et al. Hydroxychloroquine and azithromycin as a treatment of COVID-19: results of an open-label non-randomized clinical trial" width="80%" />
<p class="caption">
Figure 4.4: Gautret et al. Hydroxychloroquine and azithromycin as a treatment of COVID-19: results of an open-label non-randomized clinical trial
</p>
</div>
<ul>
<li>In late March, WHO launches global megatrial of the four most promising coronavirus treatments (not any antibiotics). The study, which could include many thousands of patients in dozens of countries, has been designed to be as simple as possible so that even hospitals overwhelmed by an onslaught of COVID-19 patients can participate.</li>
</ul>
<p><a href="https://www.sciencemag.org/news/2020/03/who-launches-global-megatrial-four-most-promising-coronavirus-treatments#" class="uri">https://www.sciencemag.org/news/2020/03/who-launches-global-megatrial-four-most-promising-coronavirus-treatments#</a></p>
<blockquote>
<p>Enrolling subjects in SOLIDARITY will be easy. When a person with a confirmed case of COVID-19 is deemed eligible, the physician can enter the patient’s data into a WHO website, including any underlying condition that could change the course of the disease, such as diabetes or HIV infection. The participant has to sign an informed consent form that is scanned and sent to WHO electronically. After the physician states which drugs are available at his or her hospital, the website will randomize the patient to one of the drugs available or to the local standard care for COVID-19.</p>
</blockquote>
<blockquote>
<p>“After that, no more measurements or documentation are required,” says Ana Maria Henao Restrepo, a medical officer at WHO’s Department of Immunization Vaccines and Biologicals. Physicians will record the day the patient left the hospital or died, the duration of the hospital stay, and whether the patient required oxygen or ventilation, she says. “That’s all.”</p>
</blockquote>
<blockquote>
<p>The design is not double-blind, the gold standard in medical research, so there could be placebo effects from patients knowing they received a candidate drug. But WHO says it had to balance scientific rigor against speed.</p>
</blockquote>
</div>
<div id="studies-related-to-covid-19" class="section level4 unnumbered">
<h4>Studies related to COVID-19:</h4>
<ul>
<li><p>Medical studies discussing side effects of azithromycin – chloroquine treatment. <a href="https://threadreaderapp.com/thread/1242119303811514369.html" class="uri">https://threadreaderapp.com/thread/1242119303811514369.html</a></p></li>
<li><p>Studies on cloth masks vs medical masks for healthcare workers. <a href="https://bmjopen.bmj.com/content/5/4/e006577" class="uri">https://bmjopen.bmj.com/content/5/4/e006577</a></p></li>
<li><p>Different blood types and COVID-19</p></li>
</ul>
<p><a href="https://www.medrxiv.org/content/10.1101/2020.03.11.20031096v1" class="uri">https://www.medrxiv.org/content/10.1101/2020.03.11.20031096v1</a> (not yet peer-reviewed)</p>
<blockquote>
<p>The authors write of a “significantly higher risk” for blood group A but, as one reader pointed out in the comments section, this does not mean that the risk is greatly higher; it means that a p-value was small. Notice that the CI for the odds ratio is above 1, but it comes close to 1 and is centered a 1.20 and not, say, 2.5.
“Meta-analyses on the pooled data showed that blood group A had a significantly higher risk for COVID-19 (odds ratio-OR, 1.20; 95% confidence interval-CI [1.02,1.43], P = 0.02) compared with non-A blood groups.”</p>
</blockquote>
<p>The language might lead the reader to think “blood group A has a much higher risk for COVID-19” which is markedly untrue! That is, significance is a completely different concept as compared to “a lot”.</p>
</div>
<div id="being-careful-with-your-analysis" class="section level4 unnumbered">
<h4>Being careful with your analysis:</h4>
<ul>
<li>CDC report: “Severe Outcomes Among Patients with Coronavirus Disease 2019 (COVID-19) — United States, February 12–March 16, 2020” <a href="https://www.cdc.gov/mmwr/volumes/69/wr/mm6912e2.htm" class="uri">https://www.cdc.gov/mmwr/volumes/69/wr/mm6912e2.htm</a></li>
</ul>
<p>Pay attention to counts per group. 20-44 is 24 years. 65-74 is 9 years.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-21"></span>
<img src="figs/covid3.jpg" alt="CDC report: Severe Outcomes Among Patients with Coronavirus Disease 2019 (COVID-19) — United States, February 12–March 16, 2020" width="80%" />
<p class="caption">
Figure 4.5: CDC report: Severe Outcomes Among Patients with Coronavirus Disease 2019 (COVID-19) — United States, February 12–March 16, 2020
</p>
</div>
<ul>
<li>There has been some talk about a 2% fatality rate, but fatality is incredibly difficult to measure so early in the disease.
<ul>
<li>If the number of reported confirmed cases of COVID-19 continues to slow down, the 2% fatality rate people have been quoting may appear to rise because of two main factors: under-reporting of the number of cases and the delay from symptoms first appearing to death. It is possible that the errors will cancel each other out and end up being correct for the wrong reasons!</li>
<li>Also, the “fatality rate” is an incredibly misleading number because it varies so much based on age. Averaging over all ages will give different numbers based on the age distribution of the country at hand.</li>
<li>And maybe just as important &amp; harder to measure: what is the fatality rate for the pandemic? The pandemic will cause deaths directly due to the coronavirus and also due to: cardiac arrest (or other emergency condition) without adequate space in ERs; lack of food / heat for people who are unable to work; lack of access to medical supplies / dialysis / pharmaceuticals; etc.</li>
</ul></li>
<li><p>What is the trade-off between putting a cap on the disease and resisting tracking our personal data?</p>
<ul>
<li><p>Can smart thermometers help track the coronavirus? (March 18, 2020) <a href="https://www.nytimes.com/2020/03/18/health/coronavirus-fever-thermometers.html" class="uri">https://www.nytimes.com/2020/03/18/health/coronavirus-fever-thermometers.html</a></p></li>
<li><p>Follow-up: Restrictions are Slowing Coronavirus Infections, New Data Suggests (March 30, 2020) <a href="https://www.nytimes.com/2020/03/30/health/coronavirus-restrictions-fevers.html?searchResultPosition=1" class="uri">https://www.nytimes.com/2020/03/30/health/coronavirus-restrictions-fevers.html?searchResultPosition=1</a></p></li>
<li><p>Social distancing scoreboard based on movement of mobile phones: <a href="https://www.unacast.com/covid19/social-distancing-scoreboard" class="uri">https://www.unacast.com/covid19/social-distancing-scoreboard</a> (info about their work: <a href="https://www.unacast.com/post/the-unacast-social-distancing-scoreboard" class="uri">https://www.unacast.com/post/the-unacast-social-distancing-scoreboard</a>)</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="reflection-questions-1" class="section level2">
<h2><span class="header-section-number">4.23</span> Reflection Questions</h2>
<div id="no-isrs-binomial-probabilities-math-58-only" class="section level3">
<h3><span class="header-section-number">4.23.1</span> (no ISRS) Binomial probabilities (Math 58 only)</h3>
<ol style="list-style-type: decimal">
<li>How can the binomial distribution be used to calculate probabilities?<br />
</li>
<li>What are the technical conditions of the binomial distribution?</li>
<li>How is the normal distribution different from the binomial distribution? (one answer is that the normal describes a continuous variable and the binomial describes a discrete variable. what does that mean? what is another distinction?)</li>
<li>What are the technical conditions allowing the normal distribution to approximate the binomial distribution?</li>
<li>What is one reason to choose to use the normal distribution?</li>
<li>What is one reason to choose to use the binomial distribution?</li>
</ol>
</div>
<div id="no-isrs-relative-risk-odds-ratios-math-58b-only" class="section level3">
<h3><span class="header-section-number">4.23.2</span> (no ISRS) Relative Risk &amp; Odds Ratios (Math 58B only)</h3>
<ol style="list-style-type: decimal">
<li>What is the differences between cross-classification, cohort, and case-control studies?</li>
<li>When is it not appropriate to calculate differences or ratios of proportions? Why isn’t it appropriate?</li>
<li>How are odds calculated? How is OR calculated?</li>
<li>What do we do when we we can’t calculate statistics based on proportions? Why does this ``fix&quot; work?</li>
<li>What is the statistic of interest? What is the parameter of interest?</li>
<li>Why do we look at the natural log of the RR and the natural log of the OR when finding confidence intervals for the respective parameters?</li>
<li>How do you calculate the SE for the <span class="math inline">\(\ln(\hat{RR})\)</span> and <span class="math inline">\(\ln(\hat{OR})\)</span>?</li>
<li>Once you have the CI for <span class="math inline">\(\ln(RR)\)</span> or for <span class="math inline">\(\ln(OR)\)</span>, what do you do? Why does that process work?</li>
</ol>
</div>
<div id="binary-variables-chapter-3-section-2" class="section level3">
<h3><span class="header-section-number">4.23.3</span> 2 binary variables: Chapter 3, Section 2</h3>
<ol style="list-style-type: decimal">
<li>What is the statistic of interest? What is the parameter of interest?</li>
<li>How does the inference <em>change</em> now that there is binary (response) data taken from two populations?</li>
<li>How does the inference <em>stay the same</em> now that there is binary (response) data taken from two populations?</li>
<li>What does the Central Limit Theorem say about <em>two</em> sample proportions?</li>
<li>When is it appropriate to apply a hypothesis test to the data? And when is it appropriate to apply a confidence interval to the data?</li>
<li>How do we calculate SE(<span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span>)?</li>
<li>What technical conditions must hold for the Central Limit Theorem to apply?</li>
</ol>
</div>
<div id="types-of-studies-chapter-1-sections-4-5" class="section level3">
<h3><span class="header-section-number">4.23.4</span> Types of studies: Chapter 1, Sections 4-5</h3>
<ol style="list-style-type: decimal">
<li>What is the difference between an observational study and an experiment?</li>
<li>Why aren’t all studies done as experiments?</li>
<li>What is a confounding variable?</li>
<li>Have you looked at Figure <a href="inference-for-categorical-data.html#fig:randSleuth">4.2</a> and Figure <a href="inference-for-categorical-data.html#fig:randgoodQ">4.3</a>? Do you understand the two figures? Could you explain what their main message is to a friend? [Random sampling vs. Random allocation]</li>
<li>How is the statistical meaning of the word <em>cause</em> different from the usage in the sentence: <em>The ball that hit me in the head caused me to get a headache.</em></li>
<li>What are the meanings of the words: randomized, double-blind (single-blind), control, placebo, significant, and comparative. Why are these ideas important to interpreting study results?</li>
</ol>
</div>
<div id="categorical-variables-chapter-3-section-3" class="section level3">
<h3><span class="header-section-number">4.23.5</span> 2 categorical variables: Chapter 3, Section 3</h3>
<ol style="list-style-type: decimal">
<li>How would you describe the data seen in <span class="math inline">\(r \times c\)</span> tables?</li>
<li>Describe the simulation mechanism that creates a sampling distribution under the assumption that the null hypothesis is true (like the cards in the first week of class using the gender discrimination example).</li>
<li>What is the test statistic (for both the <code>infer</code> simulation and the chi-square test with the mathematical model!!)? Why do we need a complicated test statistic here and we didn’t need one with <span class="math inline">\(2 \times 2\)</span> tables?</li>
<li>How do you compute the expected count? What is the intuition behind the computation?</li>
<li>What is one benefit that the two sample z-test of proportions has? That is, what is one thing we can do if we have a <span class="math inline">\(2\times 2\)</span> table instead of an <span class="math inline">\(r \times c\)</span> table?</li>
<li>Describe the directionality of the test statistic. That is, what values of <span class="math inline">\(X^2\)</span> make you reject <span class="math inline">\(H_0\)</span>?</li>
<li>What are the technical assumptions for the chi-square test? Why do you need the technical assumptions?</li>
<li>What are the null and alternative hypotheses?</li>
</ol>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-iscam">
<p>Chance, Beth, and Allan Rossman. 2018. <em>Investigating Statistics, Concepts, Applications, and Methods</em>. 3rd ed. <a href="http://www.rossmanchance.com/iscam3/">http://www.rossmanchance.com/iscam3/</a>.</p>
</div>
<div id="ref-isrs">
<p>Diez, David, Christopher Barr, and Mine Çetinkaya-Rundel. 2014. <em>Introductory Statistics with Randomization and Simulation</em>. 1st ed. <a href="https://www.openintro.org/">https://www.openintro.org/</a>.</p>
</div>
<div id="ref-pagano">
<p>Pagano, M., and K. Gauvreau. 2000. <em>Principles of Biostatistics</em>. 2nd ed. Duxbury Press.</p>
</div>
<div id="ref-sleuth">
<p>Ramsey, F., and D. Schafer. 2012. <em>The Statistical Sleuth</em>. 3rd ed. Cengage Learning.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="8">
<li id="fn8"><p>Inv 3.10, Chance &amp; Rossman, ISCAM<a href="inference-for-categorical-data.html#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>“Tobacco Smoking as a Possible Etiologic Factor in Bronchiogenic Cancer,” 1950, Journal of the American Medical Association<a href="inference-for-categorical-data.html#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>Jaffar A. Al-Tawfiq, Kareem Hinedi, Jihad Ghandour, Hanan Khairalla, Samir Musleh, Alaa Ujayli, Ziad A. Memish, Clinical Infectious Diseases, Volume 59, Issue 2, 15 July 2014, Pages 160–165, <a href="https://doi.org/10.1093/cid/ciu226" class="uri">https://doi.org/10.1093/cid/ciu226</a><a href="inference-for-categorical-data.html#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>From <span class="citation">Diez, Barr, and Çetinkaya-Rundel (<a href="#ref-oi4">2019</a>)</span>, exercise 6.20. Data taken from: Survey USA, News Poll #24568, data collected on April 21, 2019. <a href="http://www.surveyusa.com/client/PollReport.aspx?g=d0102205-d95b-48b2-9e39-4c0284747d97" class="uri">http://www.surveyusa.com/client/PollReport.aspx?g=d0102205-d95b-48b2-9e39-4c0284747d97</a><a href="inference-for-categorical-data.html#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p>(a) FALSE (because the interval overlaps zero), (b) FALSE (We are 95% confident that 16% more to 2% fewer Americans who make $40,000 or more per year are not at all personally affected by the government shutdown compared to those who less than $40,000 per year.), (c) FALSE (it would be more narrow), (d) TRUE<a href="inference-for-categorical-data.html#fnref12" class="footnote-back">↩</a></p></li>
<li id="fn13"><p><span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span>, Inv 3.3<a href="inference-for-categorical-data.html#fnref13" class="footnote-back">↩</a></p></li>
<li id="fn14"><p><span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span>, Inv 3.4<a href="inference-for-categorical-data.html#fnref14" class="footnote-back">↩</a></p></li>
<li id="fn15"><p><span class="citation">Scheaffer et al. (<a href="#ref-activstats">2008</a>)</span>, “How Typical are Our Households’ Ages”<a href="inference-for-categorical-data.html#fnref15" class="footnote-back">↩</a></p></li>
<li id="fn16"><p><a href="https://www.census.gov/prod/cen2010/briefs/c2010br-03.pdf" class="uri">https://www.census.gov/prod/cen2010/briefs/c2010br-03.pdf</a><a href="inference-for-categorical-data.html#fnref16" class="footnote-back">↩</a></p></li>
<li id="fn17"><p><span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span>, Inv 5.3<a href="inference-for-categorical-data.html#fnref17" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="foundations-for-inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="inference-for-numerical-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-InfCat.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Math-58-Notes.pdf", "Math-58-Notes.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
