<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Foundations for Inference | Introduction to (Bio)Statistics</title>
  <meta name="description" content="Class notes for both Math 58 and Math 58B at Pomona College: Introduction to Statistics and Introduction to Biostatistics. The notes are based extensively Introductory Statistics with Randomization and Simulation by Diez, Barr, and Cetinkaya-Rundel." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Foundations for Inference | Introduction to (Bio)Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Class notes for both Math 58 and Math 58B at Pomona College: Introduction to Statistics and Introduction to Biostatistics. The notes are based extensively Introductory Statistics with Randomization and Simulation by Diez, Barr, and Cetinkaya-Rundel." />
  <meta name="github-repo" content="hardin47/website/Math58/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Foundations for Inference | Introduction to (Bio)Statistics" />
  
  <meta name="twitter:description" content="Class notes for both Math 58 and Math 58B at Pomona College: Introduction to Statistics and Introduction to Biostatistics. The notes are based extensively Introductory Statistics with Randomization and Simulation by Diez, Barr, and Cetinkaya-Rundel." />
  

<meta name="author" content="Jo Hardin" />


<meta name="date" content="2020-04-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intro.html"/>
<link rel="next" href="inference-for-categorical-data.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to (Bio)Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Class Information</a></li>
<li class="chapter" data-level="1" data-path="rfunc.html"><a href="rfunc.html"><i class="fa fa-check"></i><b>1</b> R functions</a><ul>
<li class="chapter" data-level="1.1" data-path="rfunc.html"><a href="rfunc.html#applets"><i class="fa fa-check"></i><b>1.1</b> Applets</a></li>
<li class="chapter" data-level="1.2" data-path="rfunc.html"><a href="rfunc.html#data-structure"><i class="fa fa-check"></i><b>1.2</b> Data Structure</a></li>
<li class="chapter" data-level="1.3" data-path="rfunc.html"><a href="rfunc.html#wrangling"><i class="fa fa-check"></i><b>1.3</b> Wrangling</a></li>
<li class="chapter" data-level="1.4" data-path="rfunc.html"><a href="rfunc.html#plotting"><i class="fa fa-check"></i><b>1.4</b> Plotting</a></li>
<li class="chapter" data-level="1.5" data-path="rfunc.html"><a href="rfunc.html#statistical-inference"><i class="fa fa-check"></i><b>1.5</b> Statistical Inference</a></li>
<li class="chapter" data-level="1.6" data-path="rfunc.html"><a href="rfunc.html#probability-models"><i class="fa fa-check"></i><b>1.6</b> Probability models</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#Jan21"><i class="fa fa-check"></i><b>2.1</b> 1/21/20 Agenda</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#course-logistics"><i class="fa fa-check"></i><b>2.2</b> Course Logistics</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#vocabulary"><i class="fa fa-check"></i>Vocabulary</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#ex:helper"><i class="fa fa-check"></i><b>2.3</b> Example: Friend or Foe</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html"><i class="fa fa-check"></i><b>3</b> Foundations for Inference</a><ul>
<li class="chapter" data-level="3.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Jan23"><i class="fa fa-check"></i><b>3.1</b> 1/23/20 Agenda</a></li>
<li class="chapter" data-level="3.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#ex:gend"><i class="fa fa-check"></i><b>3.2</b> Example: Gender Discrimination</a></li>
<li class="chapter" data-level="3.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#structure-of-hypothesis-testing"><i class="fa fa-check"></i><b>3.3</b> Structure of Hypothesis testing</a><ul>
<li class="chapter" data-level="3.3.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#hypotheses-1"><i class="fa fa-check"></i><b>3.3.1</b> Hypotheses</a></li>
<li class="chapter" data-level="3.3.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#other-pieces-of-the-process"><i class="fa fa-check"></i><b>3.3.2</b> Other pieces of the process</a></li>
<li class="chapter" data-level="3.3.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#all-together-structure-of-a-hypothesis-test"><i class="fa fa-check"></i><b>3.3.3</b> All together: structure of a hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Jan28"><i class="fa fa-check"></i><b>3.4</b> 1/28/20 Agenda</a></li>
<li class="chapter" data-level="3.5" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#normal-model"><i class="fa fa-check"></i><b>3.5</b> Normal Model</a><ul>
<li class="chapter" data-level="3.5.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#CLT"><i class="fa fa-check"></i><b>3.5.1</b> Central Limit Therm</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Jan30"><i class="fa fa-check"></i><b>3.6</b> 1/30/20 Agenda</a><ul>
<li class="chapter" data-level="3.6.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#norm"><i class="fa fa-check"></i><b>3.6.1</b> Normal Probabilities &amp; Z scores</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Feb4"><i class="fa fa-check"></i><b>3.7</b> 2/4/20 Agenda</a></li>
<li class="chapter" data-level="3.8" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#CI"><i class="fa fa-check"></i><b>3.8</b> Confidence Intervals</a><ul>
<li class="chapter" data-level="3.8.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#theoretical-set-up"><i class="fa fa-check"></i><b>3.8.1</b> Theoretical set-up</a></li>
<li class="chapter" data-level="3.8.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-changes-in-extreme-poverty"><i class="fa fa-check"></i><b>3.8.2</b> Example: changes in extreme poverty</a></li>
<li class="chapter" data-level="3.8.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#modCI"><i class="fa fa-check"></i><b>3.8.3</b> Modifying CIs</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Feb6"><i class="fa fa-check"></i><b>3.9</b> 2/6/20 Agenda</a></li>
<li class="chapter" data-level="3.10" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Feb11"><i class="fa fa-check"></i><b>3.10</b> 2/11/20 Agenda</a></li>
<li class="chapter" data-level="3.11" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#samp"><i class="fa fa-check"></i><b>3.11</b> Sampling</a><ul>
<li class="chapter" data-level="3.11.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-aliens-on-earth"><i class="fa fa-check"></i><b>3.11.1</b> Example: aliens on Earth</a></li>
<li class="chapter" data-level="3.11.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-gettysburg-address"><i class="fa fa-check"></i><b>3.11.2</b> Example: Gettysburg Address</a></li>
<li class="chapter" data-level="3.11.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#key-sampling-terms"><i class="fa fa-check"></i><b>3.11.3</b> Key sampling terms</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#Feb13"><i class="fa fa-check"></i><b>3.12</b> 2/13/20 Agenda</a></li>
<li class="chapter" data-level="3.13" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#errors"><i class="fa fa-check"></i><b>3.13</b> Errors &amp; Power</a><ul>
<li class="chapter" data-level="3.13.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-baseball-player"><i class="fa fa-check"></i><b>3.13.1</b> Example: baseball player</a></li>
<li class="chapter" data-level="3.13.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#errors-lessons-learned"><i class="fa fa-check"></i><b>3.13.2</b> Errors: lessons learned</a></li>
</ul></li>
<li class="chapter" data-level="3.14" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#reflection-questions"><i class="fa fa-check"></i><b>3.14</b> Reflection Questions</a><ul>
<li class="chapter" data-level="3.14.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#hypothesis-testing-chapter-2-sections-1-4"><i class="fa fa-check"></i><b>3.14.1</b> hypothesis testing: Chapter 2, Sections 1-4</a></li>
<li class="chapter" data-level="3.14.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#normal-model-chapter-2-sections-5-7"><i class="fa fa-check"></i><b>3.14.2</b> normal model: Chapter 2, Sections 5-7</a></li>
<li class="chapter" data-level="3.14.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#confidence-intervals-chapter-2-section-8"><i class="fa fa-check"></i><b>3.14.3</b> confidence intervals: Chapter 2, Section 8</a></li>
<li class="chapter" data-level="3.14.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#sampling-chapter-1-sections-3-4"><i class="fa fa-check"></i><b>3.14.4</b> sampling: Chapter 1, Sections 3-4</a></li>
<li class="chapter" data-level="3.14.5" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#errors-power-chapter-2-section-3"><i class="fa fa-check"></i><b>3.14.5</b> errors &amp; power: Chapter 2, Section 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html"><i class="fa fa-check"></i><b>4</b> Inference for categorical data</a><ul>
<li class="chapter" data-level="4.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#inference-for-a-single-proportion"><i class="fa fa-check"></i><b>4.1</b> Inference for a single proportion</a></li>
<li class="chapter" data-level="4.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb18M58"><i class="fa fa-check"></i><b>4.2</b> 2/18/20 Math 58 Agenda</a></li>
<li class="chapter" data-level="4.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb20M58"><i class="fa fa-check"></i><b>4.3</b> 2/20/20 Math 58 Agenda</a></li>
<li class="chapter" data-level="4.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-distribution-math-58-only"><i class="fa fa-check"></i><b>4.4</b> Binomial distribution (Math 58 only)</a><ul>
<li class="chapter" data-level="4.4.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-pop-quiz"><i class="fa fa-check"></i><b>4.4.1</b> Example: pop quiz</a></li>
<li class="chapter" data-level="4.4.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-hypothesis-testing"><i class="fa fa-check"></i><b>4.4.2</b> Binomial Hypothesis Testing</a></li>
<li class="chapter" data-level="4.4.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-power"><i class="fa fa-check"></i><b>4.4.3</b> Binomial Power</a></li>
<li class="chapter" data-level="4.4.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-confidence-intervals-for-p"><i class="fa fa-check"></i><b>4.4.4</b> Binomial Confidence Intervals for <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb18M58B"><i class="fa fa-check"></i><b>4.5</b> 2/18/20 Math 58B Agenda</a></li>
<li class="chapter" data-level="4.6" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb20M58B"><i class="fa fa-check"></i><b>4.6</b> 2/20/20 Math 58B Agenda</a></li>
<li class="chapter" data-level="4.7" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#relative-risk-math-58b-only"><i class="fa fa-check"></i><b>4.7</b> Relative Risk (Math 58B only)</a><ul>
<li class="chapter" data-level="4.7.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#inference-on-relative-risk"><i class="fa fa-check"></i><b>4.7.1</b> Inference on Relative Risk</a></li>
<li class="chapter" data-level="4.7.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#using-infer-for-inference-on-rr"><i class="fa fa-check"></i><b>4.7.2</b> Using <code>infer</code> for inference on RR</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#odds-ratios-math-58b-only"><i class="fa fa-check"></i><b>4.8</b> Odds Ratios (Math 58B only)</a><ul>
<li class="chapter" data-level="4.8.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-smoking-and-lung-cancer"><i class="fa fa-check"></i><b>4.8.1</b> Example: Smoking and Lung Cancer</a></li>
<li class="chapter" data-level="4.8.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#inference-on-odds-ratios"><i class="fa fa-check"></i><b>4.8.2</b> Inference on Odds Ratios</a></li>
<li class="chapter" data-level="4.8.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#confidence-interval-for-or-same-idea-as-with-rr"><i class="fa fa-check"></i><b>4.8.3</b> Confidence Interval for OR (same idea as with RR)</a></li>
<li class="chapter" data-level="4.8.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#using-infer-for-inference-on-or"><i class="fa fa-check"></i><b>4.8.4</b> Using <code>infer</code> for inference on OR</a></li>
<li class="chapter" data-level="4.8.5" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#ex:cov"><i class="fa fa-check"></i><b>4.8.5</b> Example: MERS-CoV</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb25"><i class="fa fa-check"></i><b>4.9</b> 2/25/20 Agenda</a></li>
<li class="chapter" data-level="4.10" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#diffprop"><i class="fa fa-check"></i><b>4.10</b> Difference of two proportions</a><ul>
<li class="chapter" data-level="4.10.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#clt-for-difference-in-two-proportions"><i class="fa fa-check"></i><b>4.10.1</b> CLT for difference in two proportions</a></li>
<li class="chapter" data-level="4.10.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#ht-difference-in-proportions"><i class="fa fa-check"></i><b>4.10.2</b> HT: difference in proportions</a></li>
<li class="chapter" data-level="4.10.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#ci-difference-in-proportions"><i class="fa fa-check"></i><b>4.10.3</b> CI: difference in proportions</a></li>
<li class="chapter" data-level="4.10.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-government-shutdown"><i class="fa fa-check"></i><b>4.10.4</b> Example: Government Shutdown</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Feb27"><i class="fa fa-check"></i><b>4.11</b> 2/27/20 Agenda</a></li>
<li class="chapter" data-level="4.12" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#experim"><i class="fa fa-check"></i><b>4.12</b> Types of Studies</a><ul>
<li class="chapter" data-level="4.12.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-hand-writing-sat-scores"><i class="fa fa-check"></i><b>4.12.1</b> Example: Hand Writing &amp; SAT Scores</a></li>
<li class="chapter" data-level="4.12.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-have-a-nice-trip"><i class="fa fa-check"></i><b>4.12.2</b> Example: Have a Nice Trip</a></li>
<li class="chapter" data-level="4.12.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#study-conclusions"><i class="fa fa-check"></i><b>4.12.3</b> Study conclusions</a></li>
</ul></li>
<li class="chapter" data-level="4.13" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Mar3"><i class="fa fa-check"></i><b>4.13</b> 3/3/20 Agenda</a></li>
<li class="chapter" data-level="4.14" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#chisq1"><i class="fa fa-check"></i><b>4.14</b> Goodness-of-fit: One categorical variable (<span class="math inline">\(\chi^2\)</span> test) <span class="math inline">\(\geq\)</span> 2 levels</a><ul>
<li class="chapter" data-level="4.14.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-household-ages"><i class="fa fa-check"></i><b>4.14.1</b> Example: Household Ages</a></li>
<li class="chapter" data-level="4.14.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-flax-seed"><i class="fa fa-check"></i><b>4.14.2</b> Example: Flax Seed</a></li>
</ul></li>
<li class="chapter" data-level="4.15" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#Mar5"><i class="fa fa-check"></i><b>4.15</b> 3/5/20 Agenda</a></li>
<li class="chapter" data-level="4.16" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#chisq2"><i class="fa fa-check"></i><b>4.16</b> Independence: Two categorical variables (<span class="math inline">\(\chi^2\)</span> test) <span class="math inline">\(\geq\)</span> 2 levels each</a><ul>
<li class="chapter" data-level="4.16.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-nightlights"><i class="fa fa-check"></i><b>4.16.1</b> Example: Nightlights</a></li>
</ul></li>
<li class="chapter" data-level="4.17" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#agenda"><i class="fa fa-check"></i><b>4.17</b> 3/10/20 &amp; 3/12/20 Agenda</a></li>
<li class="chapter" data-level="4.18" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#agenda-1"><i class="fa fa-check"></i><b>4.18</b> 3/17/20 &amp; 3/19/20 Agenda</a></li>
<li class="chapter" data-level="4.19" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#agenda-2"><i class="fa fa-check"></i><b>4.19</b> 3/24/20 Agenda</a></li>
<li class="chapter" data-level="4.20" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#census"><i class="fa fa-check"></i><b>4.20</b> Census</a><ul>
<li class="chapter" data-level="4.20.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#what-about-college-students"><i class="fa fa-check"></i><b>4.20.1</b> What about College students?</a></li>
</ul></li>
<li class="chapter" data-level="4.21" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#agenda-3"><i class="fa fa-check"></i><b>4.21</b> 3/26/20 Agenda</a></li>
<li class="chapter" data-level="4.22" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#covid19"><i class="fa fa-check"></i><b>4.22</b> COVID-19</a></li>
<li class="chapter" data-level="4.23" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#reflection-questions-1"><i class="fa fa-check"></i><b>4.23</b> Reflection Questions</a><ul>
<li class="chapter" data-level="4.23.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#no-isrs-binomial-probabilities-math-58-only"><i class="fa fa-check"></i><b>4.23.1</b> (no ISRS) Binomial probabilities (Math 58 only)</a></li>
<li class="chapter" data-level="4.23.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#no-isrs-relative-risk-odds-ratios-math-58b-only"><i class="fa fa-check"></i><b>4.23.2</b> (no ISRS) Relative Risk &amp; Odds Ratios (Math 58B only)</a></li>
<li class="chapter" data-level="4.23.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binary-variables-chapter-3-section-2"><i class="fa fa-check"></i><b>4.23.3</b> 2 binary variables: Chapter 3, Section 2</a></li>
<li class="chapter" data-level="4.23.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#types-of-studies-chapter-1-sections-4-5"><i class="fa fa-check"></i><b>4.23.4</b> Types of studies: Chapter 1, Sections 4-5</a></li>
<li class="chapter" data-level="4.23.5" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#categorical-variables-chapter-3-section-3"><i class="fa fa-check"></i><b>4.23.5</b> 2 categorical variables: Chapter 3, Section 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html"><i class="fa fa-check"></i><b>5</b> Inference for numerical data</a><ul>
<li class="chapter" data-level="5.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Mar31"><i class="fa fa-check"></i><b>5.1</b> 3/31/20 Agenda</a></li>
<li class="chapter" data-level="5.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#important-measures-related-to-quantitative-numeric-variables"><i class="fa fa-check"></i><b>5.2</b> Important measures related to quantitative (numeric) variables</a><ul>
<li class="chapter" data-level="5.2.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#quantitative-descriptives"><i class="fa fa-check"></i><b>5.2.1</b> Quantitative Descriptives</a></li>
<li class="chapter" data-level="5.2.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mean1dist"><i class="fa fa-check"></i><b>5.2.2</b> Sampling distribution of a sample mean</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Apr2"><i class="fa fa-check"></i><b>5.3</b> 4/2/20 Agenda</a></li>
<li class="chapter" data-level="5.4" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Apr7"><i class="fa fa-check"></i><b>5.4</b> 4/7/20 Agenda</a></li>
<li class="chapter" data-level="5.5" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mean1inf"><i class="fa fa-check"></i><b>5.5</b> Inference for a single mean, <span class="math inline">\(\mu\)</span></a><ul>
<li class="chapter" data-level="5.5.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mathematical-model-for-distribution-of-the-sample-mean"><i class="fa fa-check"></i><b>5.5.1</b> Mathematical model for distribution of the sample mean</a></li>
<li class="chapter" data-level="5.5.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#example-healthy-body-temperature"><i class="fa fa-check"></i><b>5.5.2</b> Example: healthy body temperature</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Apr9"><i class="fa fa-check"></i><b>5.6</b> 4/9/20 Agenda</a></li>
<li class="chapter" data-level="5.7" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#Apr14"><i class="fa fa-check"></i><b>5.7</b> 4/14/20 Agenda</a></li>
<li class="chapter" data-level="5.8" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mean2inf"><i class="fa fa-check"></i><b>5.8</b> Comparing two means</a></li>
<li class="chapter" data-level="5.9" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#r-code-for-inference-on-1-or-2-means."><i class="fa fa-check"></i><b>5.9</b> R code for inference on 1 or 2 means.</a><ul>
<li class="chapter" data-level="5.9.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#t.test"><i class="fa fa-check"></i><b>5.9.1</b> <code>t.test</code></a></li>
<li class="chapter" data-level="5.9.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#infer"><i class="fa fa-check"></i><b>5.9.2</b> <code>infer</code></a></li>
<li class="chapter" data-level="5.9.3" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#nba-salaries-example-from-iscam-inv-4.2"><i class="fa fa-check"></i><b>5.9.3</b> NBA Salaries example from ISCAM Inv 4.2</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#reflection-questions-2"><i class="fa fa-check"></i><b>5.10</b> Reflection Questions</a><ul>
<li class="chapter" data-level="5.10.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#quantitative-variable-chapter-4-section-1"><i class="fa fa-check"></i><b>5.10.1</b> 1 quantitative variable: Chapter 4, Section 1</a></li>
<li class="chapter" data-level="5.10.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#means-1-quantitative-variable-1-binary-variable-chapter-4-section-3"><i class="fa fa-check"></i><b>5.10.2</b> 2 means (1 quantitative variable, 1 binary variable): Chapter 4, Section 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://st47s.com/Math58" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to (Bio)Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="foundations-for-inference" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Foundations for Inference</h1>
<div id="Jan23" class="section level2">
<h2><span class="header-section-number">3.1</span> 1/23/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Example: gender discrimination</li>
<li><code>infer</code> again</li>
<li>Hypothesis testing structure</li>
</ol>
</div>
<div id="ex:gend" class="section level2">
<h2><span class="header-section-number">3.2</span> Example: Gender Discrimination</h2>
<blockquote>
<p>We consider a study investigating gender discrimination in the 1970s, which is set in the context of personnel decisions within a bank.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> The research question we hope to answer is, “Are females discriminated against in promotion decisions made by male managers?”</p>
</blockquote>
<blockquote>
<p>The participants in this study were 48 male bank supervisors attending a management institute at the University of North Carolina in 1972. They were asked to assume the role of the personnel director of a bank and were given a personnel file to judge whether the person should be promoted to a branch manager position. The files given to the participants were identical, except that half of them indicated the candidate was male and the other half indicated the candidate was female. These files were randomly assigned to the subjects.</p>
</blockquote>
<blockquote>
<p>For each supervisor we recorded the gender associated with the assigned file and the promotion decision. Using the results of the study summarized in Table 2.1, we would like to evaluate if females are unfairly discriminated against in promotion decisions. In this study, a smaller proportion of females are promoted than males (0.583 versus 0.875), but it is unclear whether the difference provides convincing evidence that females are unfairly discriminated against. (<span class="citation">Diez, Barr, and Çetinkaya-Rundel (<a href="#ref-isrs">2014</a>)</span>, pg 61)</p>
</blockquote>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th></th>
<th>decision</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>promoted</td>
<td>not promoted</td>
<td>total</td>
</tr>
<tr class="even">
<td></td>
<td>male</td>
<td>21</td>
<td>3</td>
<td>24</td>
</tr>
<tr class="odd">
<td></td>
<td>female</td>
<td>14</td>
<td>10</td>
<td>24</td>
</tr>
<tr class="even">
<td></td>
<td>total</td>
<td>35</td>
<td>13</td>
<td>48</td>
</tr>
</tbody>
</table>
<div id="always-ask-1" class="section level4 unnumbered">
<h4>Always Ask</h4>
<ul>
<li>What are the observational units?
<ul>
<li>supervisor</li>
</ul></li>
<li>What are the variables? What type of variables?
<ul>
<li><ol style="list-style-type: decimal">
<li>whether the resume was male or female (categorical)</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>decision to promote or not promote (categorical)</li>
</ol></li>
</ul></li>
<li>What is the statistic?
<ul>
<li><span class="math inline">\(\hat{p}_m - \hat{p}_f\)</span> = 21/24 - 14/24 = 0.292 (the difference between the proportion of men who were promoted and the proportion of women who were promoted)</li>
</ul></li>
<li>What is the parameter?
<ul>
<li><span class="math inline">\(p_m - p_f\)</span> = the true difference in the probability of a man being promoted minus the probability of a woman being promoted.</li>
</ul></li>
</ul>
</div>
<div id="hypotheses" class="section level4 unnumbered">
<h4>Hypotheses</h4>
<p>H0: Null hypothesis. The variables gender and decision are independent. They have no relationship, and therefore any observed difference between the proportion of males and females who were promoted is due to chance.</p>
<p>HA: Alternative hypothesis. The variables gender and decision are not independent. Any observed difference between the proportion of males and females who were promoted is <strong>not</strong> due to chance.</p>
</div>
<div id="computation-1" class="section level4 unnumbered">
<h4>Computation</h4>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="kw">library</span>(infer)</a>
<a class="sourceLine" id="cb13-2" data-line-number="2"></a>
<a class="sourceLine" id="cb13-3" data-line-number="3"><span class="co"># to control the randomness</span></a>
<a class="sourceLine" id="cb13-4" data-line-number="4"><span class="kw">set.seed</span>(<span class="dv">47</span>)</a>
<a class="sourceLine" id="cb13-5" data-line-number="5"></a>
<a class="sourceLine" id="cb13-6" data-line-number="6"><span class="co"># first create a data frame with the discrimination data</span></a>
<a class="sourceLine" id="cb13-7" data-line-number="7">discrim &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">gender =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;male&quot;</span>, <span class="dv">24</span>), <span class="kw">rep</span>(<span class="st">&quot;female&quot;</span>, <span class="dv">24</span>)),</a>
<a class="sourceLine" id="cb13-8" data-line-number="8">                      <span class="dt">decision =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;promote&quot;</span>, <span class="dv">21</span>), <span class="kw">rep</span>(<span class="st">&quot;not&quot;</span>, <span class="dv">3</span>), </a>
<a class="sourceLine" id="cb13-9" data-line-number="9">                                   <span class="kw">rep</span>(<span class="st">&quot;promote&quot;</span>, <span class="dv">14</span>), <span class="kw">rep</span>(<span class="st">&quot;not&quot;</span>, <span class="dv">10</span>)))</a>
<a class="sourceLine" id="cb13-10" data-line-number="10"></a>
<a class="sourceLine" id="cb13-11" data-line-number="11">discrim <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</a></code></pre></div>
<pre><code>##   gender decision
## 1   male  promote
## 2   male  promote
## 3   male  promote
## 4   male  promote
## 5   male  promote
## 6   male  promote</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1"><span class="co"># then find the difference in proportion who are promoted</span></a>
<a class="sourceLine" id="cb15-2" data-line-number="2">(diff_obs &lt;-<span class="st"> </span>discrim <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb15-3" data-line-number="3"><span class="st">    </span><span class="kw">specify</span>(decision <span class="op">~</span><span class="st"> </span>gender, <span class="dt">success =</span> <span class="st">&quot;promote&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb15-4" data-line-number="4"><span class="st">    </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in props&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>)) )</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##    stat
##   &lt;dbl&gt;
## 1 0.292</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1"><span class="co"># now apply the infer framework to get the null differences in proportions</span></a>
<a class="sourceLine" id="cb17-2" data-line-number="2">null_discrim &lt;-<span class="st"> </span>discrim <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb17-3" data-line-number="3"><span class="st">  </span><span class="kw">specify</span>(decision <span class="op">~</span><span class="st"> </span>gender, <span class="dt">success =</span> <span class="st">&quot;promote&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb17-4" data-line-number="4"><span class="st">  </span><span class="kw">hypothesize</span>(<span class="dt">null =</span> <span class="st">&quot;independence&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb17-5" data-line-number="5"><span class="st">  </span><span class="kw">generate</span>(<span class="dt">reps =</span> <span class="dv">10000</span>, <span class="dt">type =</span> <span class="st">&quot;permute&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb17-6" data-line-number="6"><span class="st">  </span><span class="kw">calculate</span>(<span class="dt">stat =</span> <span class="st">&quot;diff in props&quot;</span>, <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>))</a>
<a class="sourceLine" id="cb17-7" data-line-number="7"></a>
<a class="sourceLine" id="cb17-8" data-line-number="8"><span class="co"># then visualize the null sampling distribution &amp; p-value</span></a>
<a class="sourceLine" id="cb17-9" data-line-number="9"><span class="kw">visualize</span>(null_discrim, <span class="dt">bins =</span> <span class="dv">10</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb17-10" data-line-number="10"><span class="st">  </span><span class="kw">shade_p_value</span>(<span class="dt">obs_stat =</span> diff_obs, <span class="dt">direction =</span> <span class="st">&quot;greater&quot;</span>)</a></code></pre></div>
<p><img src="02-FoundInf_files/figure-html/unnamed-chunk-1-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="co"># calculate the actual p-value</span></a>
<a class="sourceLine" id="cb18-2" data-line-number="2">null_discrim <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb18-3" data-line-number="3"><span class="st">  </span><span class="kw">get_p_value</span>(<span class="dt">obs_stat =</span> diff_obs, <span class="dt">direction =</span> <span class="st">&quot;greater&quot;</span>)</a></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1   0.026</code></pre>
</div>
<div id="logic-for-what-we-believe-1" class="section level4 unnumbered">
<h4>Logic for what we believe</h4>
<ol style="list-style-type: decimal">
<li><p>We know that the study was an experiment, so there should be no <strong>systematic</strong> differences between the group who received “male” applications and “female” applications.</p></li>
<li><p>We’ve ruled out random chance as the reason for the huge difference in proportions. (We reject the null hypothesis.) if we lived in the null reality, we’d only see data like these about 2.5% of the time.</p></li>
<li><p>We conclude that gender and decision are not independent. That is, knowing the gender changes the probability of promotion.</p></li>
</ol>
</div>
</div>
<div id="structure-of-hypothesis-testing" class="section level2">
<h2><span class="header-section-number">3.3</span> Structure of Hypothesis testing</h2>
<div id="hypotheses-1" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Hypotheses</h3>
<ul>
<li><p><strong>Hypothesis Testing</strong> compares data to the expectation of a specific null hypothesis. If the data are unusual, assuming that the null hypothesis is true, then the null hypothesis is rejected.</p></li>
<li><p>The <strong>Null Hypothesis</strong>, <span class="math inline">\(H_0\)</span>, is a specific statement about a population made for the purposes of argument. A good null hypothesis is a statement that would be interesting to reject.</p></li>
<li><p>The <strong>Alternative Hypothesis</strong>, <span class="math inline">\(H_A\)</span>, is a specific statement about a population that is in the researcher’s interest to demonstrate. Typically, the alternative hypothesis contains all the values of the population that are not included in the null hypothesis.</p></li>
<li><p>In a <strong>two-sided</strong> (or two-tailed) test, the alternative hypothesis includes values on both sides of the value specified by the null hypothesis.</p></li>
<li><p>In a <strong>one-sided</strong> (or one-tailed) test, the alternative hypothesis includes parameter values on only one side of the value specified by the null hypothesis. <span class="math inline">\(H_0\)</span> is rejected only if the data depart from it in the direction stated by <span class="math inline">\(H_A\)</span>.</p></li>
</ul>
</div>
<div id="other-pieces-of-the-process" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Other pieces of the process</h3>
<ul>
<li><p>A <strong>statistic</strong> is a numerical measurement we get from the sample, a function of the data. [Also sometimes called an <strong>estimate</strong>.]</p></li>
<li><p>A <strong>parameter</strong> is a numerical measurement of the population. We never know the true value of the parameter.</p></li>
<li><p>The <strong>test statistic</strong> is a quantity calculated from the data that is used to evaluate how compatible the data are with the result expected under the null hypothesis.</p></li>
<li><p>The <strong>null distribution</strong> is the sampling distribution of outcomes for a test statistic under the assumption that the null hypothesis is true.</p></li>
<li><p>The <strong>p-value</strong> is the probability of obtaining the data (or data showing as great or greater difference from the null hypothesis) if the null hypothesis is true. <em>The p-value is a number calculated from the dataset.</em></p></li>
</ul>
<div id="examples-of-hypotheses" class="section level4 unnumbered">
<h4>Examples of Hypotheses</h4>
<p>Identify whether each of the following statements is more appropriate as the null hypothesis or as the alternative hypothesis in a test:</p>
<ul>
<li><p>The number of hours preschool children spend watching TV affects how they behave with other children when at day care. <em>Alternative</em></p></li>
<li><p>Most genetic mutations are deleterious. <em>Alternative</em></p></li>
<li><p>A diet of fast foods has no effect on liver function. <em>Null</em></p></li>
<li><p>Cigarette smoking influences risk of suicide. <em>Alternative</em></p></li>
<li><p>Growth rates of forest trees are unaffected by increases in carbon dioxide levels in the atmosphere. <em>Null</em></p></li>
<li><p>The number of hours that grade-school children spend doing homework predicts their future success on standardized tests. <em>Alternative</em></p></li>
<li><p>King cheetahs on average run the same speed as standard spotted cheetahs. <em>Null</em></p></li>
<li><p>The risk of facial clefts is equal for babies born to mothers who take folic acid supplements compared with those from mothers who do not. <em>Null</em></p></li>
<li><p>The mean length of African elephant tusks has changed over the last 100 years. <em>Alternative</em></p></li>
<li><p>Caffeine intake during pregnancy affects mean birth weight. <em>Alternative</em></p></li>
</ul>
</div>
<div id="what-is-an-alternative-hypothesis" class="section level4 unnumbered">
<h4>What is an Alternative Hypothesis?</h4>
<p>Consider the brief video from the movie Slacker, an early movie by Richard Linklater (director of Boyhood, School of Rock, Before Sunrise, etc.). You can view the video here from starting at 2:22 and ending at 4:30: <a href="https://www.youtube.com/watch?v=b-U_I1DCGEY" class="uri">https://www.youtube.com/watch?v=b-U_I1DCGEY</a></p>
<p>In the video, a rider in the back of a taxi (played by Linklater himself) muses about alternate realities that could have happened as he arrived in Austin on the bus. What if instead of taking a taxi, he had found a ride with a woman at the bus station? He could have take a different road into a different alternate reality, and in that reality his current reality would be an alternate reality. And so on.</p>
<p>What is the point? Why did we see the video? How does it relate the to the material from class? What is the relationship to sampling distributions?</p>
</div>
</div>
<div id="all-together-structure-of-a-hypothesis-test" class="section level3">
<h3><span class="header-section-number">3.3.3</span> All together: structure of a hypothesis test</h3>
<ul>
<li>decide on a research question (which will determine the test)</li>
<li>collect data, <strong>specify</strong> the variables of interest</li>
<li>state the null (and alternative) <strong>hypothesis</strong> values (often statements about parameters)
<ul>
<li>the null claim is the science we want to reject</li>
<li>the alternative claim is the science we want to prove</li>
</ul></li>
<li><strong>generate</strong> a (null) sampling distribution to describe the variability of the statistic that was <strong>calculated</strong> along the way</li>
<li><strong>visualize</strong> the distribution of the statistics under the null model</li>
<li><strong>get_p_value</strong> to measure the consistency of the observed statistic and the possible values of the statistic under the null model</li>
<li>make a conclusion using words that describe the research setting</li>
</ul>
</div>
</div>
<div id="Jan28" class="section level2">
<h2><span class="header-section-number">3.4</span> 1/28/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Central Limit Theorem</li>
<li>Mathematical approximation for the distribution of one sample proportion</li>
</ol>
</div>
<div id="normal-model" class="section level2">
<h2><span class="header-section-number">3.5</span> Normal Model</h2>
<div id="CLT" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Central Limit Therm</h3>
<div id="example-reeses-pieces" class="section level4 unnumbered">
<h4>Example: Reese’s Pieces<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></h4>
<p>As with many of the examples, the Reese’s Pieces example comes from <span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span>. The example focuses on how the samples of orange Reese’s Pieces vary from sample to sample. Today we aren’t particularly interested in a specific research question, instead we are trying to understand the details of the model which describes how <span class="math inline">\(\hat{p}\)</span> varies from sample to sample. [Spoiler: the distribution is going to look like a bell! and the mathematical model which describes the variability is called the normal distribution.]</p>
<p>Notes from the applet: <a href="http://www.rossmanchance.com/applets/OneProp/OneProp.htm?candy=1" class="uri">http://www.rossmanchance.com/applets/OneProp/OneProp.htm?candy=1</a></p>
<ul>
<li>How does the sampling distribution change as a function of <span class="math inline">\(p\)</span> and <span class="math inline">\(n\)</span>?</li>
<li>When a normal distribution is placed on top of the empirical (computational) distribution, does it fit well?</li>
</ul>
<p>A <em>sampling distribution</em> is the probability distribution of all possible values of the <em>statistic</em> in all possible samples of the same size from the same population. Note: increasing the sample size reduces the spread of the sampling distribution of a statistic (i.e., increases the precision).</p>
<div id="normal-probability-curve" class="section level5 unnumbered">
<h5>Normal Probability Curve</h5>
<ul>
<li>symmetric</li>
<li>bell-shaped</li>
<li>centered at <span class="math inline">\(\mu\)</span></li>
<li><span class="math inline">\(\sigma\)</span> shows the point of inflection</li>
<li>draw a picture <strong>every</strong> time you start a normal problem!</li>
</ul>
<p>The Central Limit Theorem</p>
<blockquote>
<p><strong>The Central Limit Theorem</strong> says that the sampling distribution of an <em>average</em> will have a bell shaped distribution if <span class="math inline">\(n\)</span> is big enough.</p>
</blockquote>
<p>The sampling distribution of <span class="math inline">\(\hat{p} = X/n\)</span> can be thought of as taking lots of random samples from a population, calculating <span class="math inline">\(\hat{p}\)</span>, and creating a histogram. We can easily calculate what we’d expect from that sampling distribution if we know <span class="math inline">\(p\)</span>, the true population proportion.</p>
<p>Because <span class="math inline">\(\hat{p}\)</span> is actually an average, the sampling distribution of <span class="math inline">\(\hat{p}\)</span> can be described by a normal distribution (as long as <span class="math inline">\(n\)</span> is big enough).</p>
<p><span class="math display">\[\begin{eqnarray*}
\hat{p} &amp;=&amp; \frac{X}{n}\\
SD(\hat{p}) = \sigma_{\hat{p}} &amp;=&amp; \sqrt{\frac{p (1-p)}{n}}\\
SE(\hat{p}) &amp;=&amp; \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\\
\hat{p} &amp;\sim&amp; N\bigg(p, \sqrt{\frac{p(1-p)}{n}} \bigg) \ \ \ \ \ \mbox{ (if the sample size is large enough)}\\
\end{eqnarray*}\]</span></p>
<p>Notice the slight difference between <span class="math inline">\(SD\)</span> (uses <span class="math inline">\(p\)</span>) and <span class="math inline">\(SE\)</span> (uses <span class="math inline">\(\hat{p}\)</span>). We won’t make a big deal of the difference here (and indeed, your book calls both equations <span class="math inline">\(SD\)</span>). We would expect 95% of our <span class="math inline">\(\hat{p}\)</span> values to be within 2 standard deviations of the mean. That is, 95% of <span class="math inline">\(\hat{p}\)</span> are:
<span class="math display">\[\begin{eqnarray*}
p \pm 2 \sqrt{\frac{p(1-p)}{n}}
\end{eqnarray*}\]</span>
Or put differently, when referring to a randomly selected <span class="math inline">\(\hat{p}\)</span>,
<span class="math display">\[\begin{eqnarray*}
P\bigg( - 2 \sqrt{\frac{p(1-p)}{n}} \leq \hat{p} - p \leq 2 \sqrt{\frac{p(1-p)}{n}}\bigg) = 0.95\\
P\bigg(\hat{p} - 2 \sqrt{\frac{p(1-p)}{n}} \leq  p \leq \hat{p} + 2 \sqrt{\frac{p(1-p)}{n}}\bigg) = 0.95
\end{eqnarray*}\]</span></p>
<p>We’d love to create our interval for <span class="math inline">\(p\)</span> using <span class="math inline">\(\hat{p} \pm 2 \sqrt{\frac{p(1-p)}{n}}\)</span>, but we don’t know <span class="math inline">\(p\)</span>! One option is to use <span class="math inline">\(SE(\hat{p})\)</span> in the estimate of the variability.</p>
</div>
<div id="the-empirical-rule" class="section level5 unnumbered">
<h5>The Empirical Rule</h5>
<p>In a bell-shaped, symmetric distribution,</p>
<table>
<thead>
<tr class="header">
<th align="left">% of data</th>
<th align="left">in what interval</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\approx 68\%\)</span></td>
<td align="left">of the observations fall within 1 st dev of the mean</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\approx 95\%\)</span></td>
<td align="left">of the observations fall within 2 st dev of the mean</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\approx 99.7\%\)</span></td>
<td align="left">of the observations fall within 3 st dev of the mean</td>
</tr>
</tbody>
</table>
<!--
%Show gorilla move:
%\url{viscog.beckman.uiuc.edu/flashmovie/15.php}
-->
</div>
</div>
</div>
</div>
<div id="Jan30" class="section level2">
<h2><span class="header-section-number">3.6</span> 1/30/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Normal distribution (no q-q plots)</li>
<li>Calculating normal probabilities</li>
</ol>
<div id="norm" class="section level3">
<h3><span class="header-section-number">3.6.1</span> Normal Probabilities &amp; Z scores</h3>
<div id="z-score" class="section level4 unnumbered">
<h4>Z score</h4>
<blockquote>
<p>A <strong>Z score</strong> of an observation is the number of standard deviations it falls above or below the mean. We compute the Z score for an observation x that follows a distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> using</p>
</blockquote>
<p><span class="math display">\[ Z = \frac{x - \mu}{\sigma}\]</span></p>
</div>
<div id="normal-probabilities" class="section level4 unnumbered">
<h4>Normal probabilities</h4>
<p>We return to the Reese’s Pieces example to investigate the probability of a particular number of orange candies, using the normal approximation.</p>
<p>Remember: <span class="math display">\[SD(\hat{p}) = \sqrt{\frac{p(1-p)}{n}}\]</span></p>
<p>And the respective Z score is: <span class="math display">\[ Z = \frac{\hat{p} - p}{\sqrt{\frac{p(1-p)}{n}}}\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>What is the probability that in a sample of 25 candies, you would get less than 40% orange (provided that the machine colors 50% of the candies orange). Answer: 0.1587</p></li>
<li><p>What is the probability that in a sample of 250 candies, you would get less than 40% orange (provided that the machine colors 50% of the candies orange). Answer: 0.0007888</p></li>
<li><p>What is the probability that in a sample of 25 candies, you would get between 40% and 55% orange (provided that the machine colors 50% of the candies orange). Answer: 0.5328</p></li>
</ol>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="kw">library</span>(mosaic)</a>
<a class="sourceLine" id="cb20-2" data-line-number="2"><span class="co"># (a)</span></a>
<a class="sourceLine" id="cb20-3" data-line-number="3">(<span class="fl">0.4</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span>) <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="fl">0.5</span><span class="op">*</span><span class="fl">0.5</span><span class="op">/</span><span class="dv">25</span>)</a></code></pre></div>
<pre><code>## [1] -1</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1"><span class="kw">xpnorm</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a></code></pre></div>
<p><img src="02-FoundInf_files/figure-html/unnamed-chunk-2-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.1586553</code></pre>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1"><span class="co"># (b)</span></a>
<a class="sourceLine" id="cb24-2" data-line-number="2">(<span class="fl">0.4</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span>) <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="fl">0.5</span><span class="op">*</span><span class="fl">0.5</span><span class="op">/</span><span class="dv">250</span>)</a></code></pre></div>
<pre><code>## [1] -3.162278</code></pre>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" data-line-number="1"><span class="kw">xpnorm</span>(<span class="op">-</span><span class="fl">3.16</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a></code></pre></div>
<p><img src="02-FoundInf_files/figure-html/unnamed-chunk-2-2.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.0007888457</code></pre>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1"><span class="co"># (c)</span></a>
<a class="sourceLine" id="cb28-2" data-line-number="2">(<span class="fl">0.55</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span>) <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="fl">0.5</span><span class="op">*</span><span class="fl">0.5</span><span class="op">/</span><span class="dv">25</span>)</a></code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1"><span class="kw">xpnorm</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="fl">0.5</span>), <span class="dv">0</span>, <span class="dv">1</span>)</a></code></pre></div>
<p><img src="02-FoundInf_files/figure-html/unnamed-chunk-2-3.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.1586553 0.6914625</code></pre>
<p>Note that normal probabilities can be estimated for any variable that has a distribution which is well approximated by the bell shape given by a normal curve. Below we calculate Z scores and probabilities for a non-proportion setting and then ask whether the values could possibly be normal. (What do you think?)</p>
</div>
<div id="example-athletic-comparison" class="section level4">
<h4><span class="header-section-number">3.6.1.1</span> Example: Athletic comparison<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></h4>
<p>The example below allows for a comparison between two athletes based on speed and strength. The following information is provided about the sample of individuals who were measured:</p>
<ul>
<li><p>Speed is measured by the time required to run a distance of 40 yards, with smaller times indicating more desirable (faster) speeds. From the data, the times to run 40 yards have a mean of 4.60 seconds and a standard devotion of 0.15 seconds, with a minimum of 4.40 seconds.</p></li>
<li><p>Strength is measured by the amount of weight lifted, with more weight indicating more desirable (greater) strength From the data, the amount of weight lifted has a mean of 310 pounds and a standard deviation of 25 pounds.</p></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">mean</th>
<th align="left">std dev</th>
<th align="left">minimum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Time to run 40 yards</td>
<td align="left">4.60 sec</td>
<td align="left">0.15 sec</td>
<td align="left">4.40 sec</td>
</tr>
<tr class="even">
<td align="left">Amount lifted</td>
<td align="left">310 lbs</td>
<td align="left">25 lbs</td>
<td align="left">NA</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li>Calculate and interpret the Z score for a player who can lift weight of 370 pounds.</li>
</ol>
<p><span class="math display">\[Z = \frac{370-310}{25} = 2.4\]</span></p>
<p>This z-score tells us that a player who can lift 370 pounds is lifting 2.4 SDs more than average. Saying that this weight is 2.4 SDs away from the average would leave out important information about direction.</p>
<ol start="2" style="list-style-type: decimal">
<li>Consider two players, A and B (with data given as below). Which player should be selected for the team if only one player can be selected?</li>
</ol>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">Player A</th>
<th align="left">Player B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Time to run 40 yards</td>
<td align="left">4.42 sec</td>
<td align="left">4.57 sec</td>
</tr>
<tr class="even">
<td align="left">Amount lifted</td>
<td align="left">370 lbs</td>
<td align="left">375 lbs</td>
</tr>
</tbody>
</table>
<p>At a first glance, we can see that A is faster, and B is stronger. Understanding how each player performs (in strength and speed) relative to the rest of the players is the first step in answering the question. We will calculate four Z scores, one for each player and each task:</p>
<p><span class="math display">\[\begin{align*}
Z_{Aspeed} =  \frac{4.42 - 4.6}{0.15} = -1.2\\
Z_{Astrength} = \frac{370-310}{25} = 2.4\\
Z_{Bspeed} =  \frac{4.57 - 4.6}{0.15} = -0.2\\
Z_{Bstrength} = \frac{375-310}{25} = 2.6\\
\end{align*}\]</span></p>
<p>After calculating Z scores, it is found that Player B is only slightly stronger than Player A, but Player A is considerably faster than Player B. Because the question advised us to consider both criteria as equally valuable, Player A is the better choice.</p>
<ol start="3" style="list-style-type: decimal">
<li>Using the full information about the speed data, do you think that the distribution of 40 yard running times is approximately normal?</li>
</ol>
<p>NO! The minimum is too close to the mean for the normal distribution to provide a reasonable model. What does “too close” mean here? Let’s see how many standard deviations the minimum is below the mean:</p>
<p><span class="math display">\[ Z = \frac{4.4 - 4.6}{0.15} = -1.33 \]</span></p>
<p>The Z score tells us that the minimum speed is only -1.33 standard deviations below the mean. According to the normal distribution (see the plot below), we would expect about 9% of the observations to be lower than 4.4 seconds, so the normal distribution does not seem to be a great fit to these observations.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1"><span class="kw">xpnorm</span>(<span class="op">-</span><span class="fl">1.333</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">plot =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<p><img src="02-FoundInf_files/figure-html/unnamed-chunk-3-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.0912659</code></pre>
</div>
</div>
</div>
<div id="Feb4" class="section level2">
<h2><span class="header-section-number">3.7</span> 2/4/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Theoretical basis for confidence intervals</li>
<li><span class="math inline">\(Z^*\)</span> (different from Z score!)</li>
<li>Example: extreme poverty</li>
</ol>
</div>
<div id="CI" class="section level2">
<h2><span class="header-section-number">3.8</span> Confidence Intervals</h2>
<div id="theoretical-set-up" class="section level3">
<h3><span class="header-section-number">3.8.1</span> Theoretical set-up</h3>
<div id="conditions-for-when-the-sampling-distribution-of-hatp-is-nearly-normal-the-central-limit-theorem" class="section level4 unnumbered">
<h4>Conditions for when the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is nearly normal (The Central Limit Theorem!!)</h4>
<p>The sampling distribution for <span class="math inline">\(\hat{p}\)</span>, taken from a sample of size <span class="math inline">\(n\)</span> from a population with a true proportion <span class="math inline">\(p\)</span>, is nearly normal when:</p>
<ol style="list-style-type: decimal">
<li>the sample observations are independent</li>
<li>we expected to see at least 10 successes and 10 failures in our samples. Said differently, <span class="math inline">\(np \geq 10\)</span> and <span class="math inline">\(n(1-p) \geq 10\)</span>. This is sometimes called the <strong>success-failure condition</strong>.</li>
</ol>
<p>If the conditions are met, then the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is nearly normal with mean <span class="math inline">\(p\)</span> and standard error:</p>
<p><span class="math display">\[SE_{\hat{p}} = SE (\hat{p}) = \sqrt{\frac{p(1-p)}{n}}\]</span></p>
</div>
<div id="how-far-is-hatp-from-p" class="section level4 unnumbered">
<h4>How far is <span class="math inline">\(\hat{p}\)</span> from <span class="math inline">\(p\)</span> ???</h4>
<p>Great news, the <span class="math inline">\(SE(\hat{p})\)</span> measures the distance we can expect between <span class="math inline">\(\hat{p}\)</span> from <span class="math inline">\(p\)</span>!!! Indeed, a Z score tells us the distance between <span class="math inline">\(\hat{p}\)</span> from <span class="math inline">\(p\)</span> in units of standard error.</p>
<p>The normal distribution provides <strong>percentages</strong> for how often Z scores should fall in certain ranges.</p>
<p>From the empirical rule, we would expect 95% of our <span class="math inline">\(\hat{p}\)</span> values to be within 2 standard deviations of the mean. That is, 95% of <span class="math inline">\(\hat{p}\)</span> are:
<span class="math display">\[\begin{eqnarray*}
p \pm 2 \sqrt{\frac{p(1-p)}{n}}
\end{eqnarray*}\]</span>
Or put differently, when referring to a randomly selected <span class="math inline">\(\hat{p}\)</span>,
<span class="math display">\[\begin{eqnarray*}
P\bigg( p - 2 \sqrt{\frac{p(1-p)}{n}} \leq \hat{p} \leq p + 2 \sqrt{\frac{p(1-p)}{n}}\bigg) = 0.95\\
P\bigg( - 2 \sqrt{\frac{p(1-p)}{n}} \leq \hat{p} - p \leq 2 \sqrt{\frac{p(1-p)}{n}}\bigg) = 0.95\\
P\bigg(\hat{p} - 2 \sqrt{\frac{p(1-p)}{n}} \leq  p \leq \hat{p} + 2 \sqrt{\frac{p(1-p)}{n}}\bigg) = 0.95
\end{eqnarray*}\]</span></p>
<p>Putting it all together, we create a confidence interval for <span class="math inline">\(p\)</span> which says that 95% of all samples will create confidence intervals that capture the true (unknown <span class="math inline">\(p\)</span>):</p>
<p><span class="math display">\[95\% \mbox{ CI for }p:  \hat{p} \pm 1.96 \sqrt{\frac{p(1-p)}{n}}\]</span></p>
<p>And if a different percentage is needed, change the multiplier appropriately:</p>
</div>
<div id="confidence-interval-formula" class="section level4 unnumbered">
<h4>Confidence Interval Formula</h4>
<p><span class="math display">\[\mbox{ CI for }p:  \hat{p} \pm Z^* \sqrt{\frac{p(1-p)}{n}}\]</span></p>
<p>What is <span class="math inline">\(Z^*\)</span>? It is defined using the normal distribution which is centered at zero with a standard deviation of one.</p>
<p>For example, if a 99% confidence interval is desired, find the <span class="math inline">\(Z^*\)</span> value that captures 99% of the observations between <span class="math inline">\(-Z^*\)</span> and <span class="math inline">\(Z^*\)</span>.</p>
<p><span class="math display">\[99\% \mbox{ CI for }p:  \hat{p} \pm 2.58 \sqrt{\frac{p(1-p)}{n}}\]</span></p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" data-line-number="1"><span class="kw">xpnorm</span>(<span class="kw">c</span>(<span class="op">-</span><span class="fl">2.58</span>, <span class="fl">2.58</span>), <span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">plot =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<p><img src="02-FoundInf_files/figure-html/unnamed-chunk-4-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.004940016 0.995059984</code></pre>
</div>
<div id="what-does-the-percentage-level-mean" class="section level4 unnumbered">
<h4>What does the percentage level <em>mean</em>?</h4>
<p>A <em>confidence level</em> is the long-run percent of intervals that capture the true parameter.</p>
</div>
</div>
<div id="example-changes-in-extreme-poverty" class="section level3">
<h3><span class="header-section-number">3.8.2</span> Example: changes in extreme poverty</h3>
<div id="in-class-activity-set-up" class="section level4 unnumbered">
<h4>In-class activity set-up</h4>
<p>Recall from the in-class activity:</p>
<p>Some of you may be familiar with Hans Rosling who founded the website <a href="https://www.gapminder.org/" class="uri">https://www.gapminder.org/</a> and dedicated his life to promoting awareness of global health issues, see his Ted talks here: <a href="https://www.ted.com/playlists/474/the_best_hans_rosling_talks_yo" class="uri">https://www.ted.com/playlists/474/the_best_hans_rosling_talks_yo</a>. One question he liked to ask is:</p>
<blockquote>
<p>Has the percentage of the world’s population who live in extreme poverty doubled, halved, or remained about the same over the past twenty years?</p>
</blockquote>
<ul>
<li>Before you go on, answer the question. Has the extreme poverty doubled, halved, or remained about the same? What do you think?</li>
</ul>
<blockquote>
<p>The correct answer is that this percentage has halved, but only 5% of a sample of 1005 U.S. adults in 2017 got this right. Rosling liked to say that chimpanzees would do better than people: With only three options, we would expect 33.33% of chimpanzees to answer correctly.</p>
</blockquote>
<ul>
<li>If in fact the students are randomly guessing, how many standard deviations away from the “random guess” value is 0.05? [Hint: use proportions and not percentages in your calculations.]</li>
</ul>
<p>note: we covered this in class on Tuesday, so it’s in the notes, but the formula doesn’t show up in your text until the box on page 124 in section 3.1.1.</p>
<p>Do not use the computer here (except as a calculator, and feel free to use a calculator or use the computer / R as a calculator). Note: you need to know how many people were asked, look above.</p>
<p><strong>Solution</strong></p>
<p><span class="math display">\[SD(\hat{p}) = \sqrt{p(1-p)/n} = \sqrt{(1/3)(2/3)/1005} = 0.0149\]</span></p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" data-line-number="1"><span class="kw">sqrt</span>((<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)<span class="op">*</span>(<span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)<span class="op">/</span><span class="dv">1005</span>)</a></code></pre></div>
<pre><code>## [1] 0.01486999</code></pre>
<p>How far is 0.05 from (1/3) in units of standard deviation? That’s just a Z score! Yikes, the 5% value is MORE THAN 19 STANDARD DEVIATIONS BELOW RANDOM GUESSING!!!</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" data-line-number="1">Z_p =<span class="st"> </span>(<span class="fl">0.05</span> <span class="op">-</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)) <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>((<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)<span class="op">*</span>(<span class="dv">2</span><span class="op">/</span><span class="dv">3</span>)<span class="op">/</span><span class="dv">1005</span>)</a>
<a class="sourceLine" id="cb38-2" data-line-number="2">Z_p</a></code></pre></div>
<pre><code>## [1] -19.05404</code></pre>
<ul>
<li>What does this say about humans doing so much <em>worse</em> than random guessing when answering the question about poverty? (No hypothesis test here, just a reflection on the distance between the observed data and the random guess answer.)</li>
</ul>
<p><strong>Solution</strong></p>
<p>Not only are humans <em>wrong</em>, but they are <em>wrong</em> at an extremely high rate. That is, they are wrong in such a way that they can’t possibly be guessing. There must be something about the question that makes so many people get it wrong (maybe that they are all seeing the same media narrative which describes continued problems with extreme poverty?)</p>
<p>We could find the percent of samples that would have produced such a small <span class="math inline">\(\hat{p}\)</span> if people were indeed random guessing. Unsurprisingly, the proportion of such samples is exceedingly small:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" data-line-number="1"><span class="kw">xpnorm</span>(<span class="op">-</span><span class="fl">19.05</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">plot=</span><span class="ot">TRUE</span>)</a></code></pre></div>
<p><img src="02-FoundInf_files/figure-html/unnamed-chunk-7-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 3.28511e-81</code></pre>
</div>
<div id="confidence-interval-for-true-population-proportion" class="section level4">
<h4><span class="header-section-number">3.8.2.1</span> Confidence Interval for true population proportion</h4>
<p>Given the extreme poverty set-up above, the question turns from one of a hypothesis test to one of a confidence interval. Note that we are making one more change to the question, we are curious about the proportion of people who think that the rate has doubled.</p>
<p><span class="math display">\[\begin{eqnarray*}
p &amp;=&amp; \mbox{true proportion of people who incorrectly believe that the % of the}\\
&amp;=&amp; \mbox{ world’s population who live in extreme poverty has doubled}\\
\hat{p} &amp;=&amp; \mbox{sample proportion of people who incorrectly believe that the % of the}\\
&amp;=&amp; \mbox{ world’s population who live in extreme poverty has doubled}
\end{eqnarray*}\]</span></p>
<p>It turns out that in the sample of 1005 adult Americans, 593 people thought that the rate had doubled.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<p><span class="math display">\[\hat{p} = \frac{593}{1005} = 0.59\]</span></p>
<p>A 95% confidence interval for the true proportion of adult Americans who think the rate has doubled is (0.56, 0.62). We are 95% confident that the true proportion of adult Americans who think the extreme poverty rate has doubled is between 0.56 and 0.62.</p>
<p><span class="math display">\[ \hat{p} \pm 1.96 * \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\]</span></p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" data-line-number="1"><span class="dv">593</span><span class="op">/</span><span class="dv">1005</span> <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>((<span class="dv">593</span><span class="op">/</span><span class="dv">1005</span>)<span class="op">*</span>(<span class="dv">412</span><span class="op">/</span><span class="dv">1005</span>) <span class="op">/</span><span class="st"> </span><span class="dv">1005</span>)</a></code></pre></div>
<pre><code>## [1] 0.5596421</code></pre>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" data-line-number="1"><span class="dv">593</span><span class="op">/</span><span class="dv">1005</span> <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>((<span class="dv">593</span><span class="op">/</span><span class="dv">1005</span>)<span class="op">*</span>(<span class="dv">412</span><span class="op">/</span><span class="dv">1005</span>) <span class="op">/</span><span class="st"> </span><span class="dv">1005</span>)</a></code></pre></div>
<pre><code>## [1] 0.6204574</code></pre>
<p>Question: Survey researchers typically select only one random sample from a population, and then they produce a confidence interval based on that sample.How do we know whether the resulting confidence interval is successful in capturing the unknown value of the population parameter?</p>
<p>Answer: we don’t know! We never know if the interval actually captures the parameter or not. We just know that over our lifetime as scientists, we will capture at the rate we set.</p>
<p>Question: If we can’t know for sure whether the confidence interval contains the value of the population parameter, on what grounds can we be confident about this?</p>
<p>Answer: well, we agree about the <strong>process</strong> that created the CI.</p>
</div>
</div>
<div id="modCI" class="section level3">
<h3><span class="header-section-number">3.8.3</span> Modifying CIs</h3>
<div id="changing-n" class="section level4 unnumbered">
<h4>Changing <span class="math inline">\(n\)</span></h4>
<p>As we can see from the CI formula, increasing <span class="math inline">\(n\)</span> has the effect of <strong>decreasing</strong> the width of the CI.</p>
<p><span class="math display">\[ \hat{p} \pm 1.96 * \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\]</span></p>
</div>
<div id="changing-p" class="section level4 unnumbered">
<h4>Changing <span class="math inline">\(p\)</span></h4>
<p>A different value of <span class="math inline">\(p\)</span> means that the sampling distribution will have a different center (and a different SE), but the coverage rate will not change, and the SE probably won’t change very much.</p>
</div>
<div id="changing-the-confidence-level" class="section level4 unnumbered">
<h4>Changing the confidence level</h4>
<p>The choice of <span class="math inline">\(Z^*\)</span> determines (over, say, your lifetime as a scientist) the percent of your research confidence intervals that will capture the true parameter of interest. Note that the larger the <span class="math inline">\(Z^*\)</span> value, the more likely it is that a sample will produce a CI which captures the true parameter.</p>
<p>Note that <span class="math inline">\(Z^* = 1.645\)</span> produces CIs that capture at a 90% rate. <span class="math inline">\(Z^* = 2.58\)</span> produces CIs that capture at a 99% rate.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" data-line-number="1"><span class="kw">xpnorm</span>(<span class="fl">1.645</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a></code></pre></div>
<p><img src="02-FoundInf_files/figure-html/unnamed-chunk-9-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.9500151</code></pre>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1"><span class="kw">xpnorm</span>(<span class="fl">2.58</span>, <span class="dv">0</span>, <span class="dv">1</span>)</a></code></pre></div>
<p><img src="02-FoundInf_files/figure-html/unnamed-chunk-9-2.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 0.99506</code></pre>
<p>Question: why don’t we always use 99.99% CIs?</p>
<p>Answer: because the intervals would typically be too wide to provide any real information about the actual population parameter.</p>
</div>
</div>
</div>
<div id="Feb6" class="section level2">
<h2><span class="header-section-number">3.9</span> 2/6/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Putting together all the pieces of the CI</li>
<li>Effects of sample size, <span class="math inline">\(p\)</span>, and confidence level on CI</li>
<li>What is the confidence level?</li>
</ol>
</div>
<div id="Feb11" class="section level2">
<h2><span class="header-section-number">3.10</span> 2/11/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Biased sampling</li>
<li>Simple Random Sampling</li>
</ol>
</div>
<div id="samp" class="section level2">
<h2><span class="header-section-number">3.11</span> Sampling</h2>
<div id="example-aliens-on-earth" class="section level3">
<h3><span class="header-section-number">3.11.1</span> Example: aliens on Earth<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></h3>
<p>Assume that an alien has landed on Earth and wants to understand the gender diversity of humans. Fortunately, the alien took a good statistics course on its home planet, so it knows to take a sample of human beings and produce a confidence interval for this proportion. Unfortunately, the alien happens upon the 2019 US Senate as its sample of human beings. The US Senate has 25 senators who self-identify as having a female gender (its most ever!) among its 100 members in 2019.</p>
<ol style="list-style-type: lower-alpha">
<li>Calculate the alien’s 95% confidence interval. (uh… confidence interval for <em>what</em>?)</li>
</ol>
<p>This calculation becomes .25 <span class="math inline">\(\pm\)</span> .085, which is the interval (.165 <span class="math inline">\(\rightarrow\)</span> .335).</p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Interpret the interval.</li>
</ol>
<p>The alien would be 95% confident that the proportion of all humans on earth who self identify as female is between .165 and .335.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Is this consistent with your experience living on this planet?</li>
</ol>
<p>No, the actual proportion of humans who self identify as female is much larger than this interval, closer to 0.5.</p>
<ol start="4" style="list-style-type: lower-alpha">
<li>What went wrong?</li>
</ol>
<p>The alien did not select a random sample of humans. In fact, the alien’s sampling method was very biased toward under-representing self-identifying females.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>As we saw with the applet, about 5% of all 95% confidence intervals fail to capture the actual value of the population parameter. Is that the explanation for what went wrong here?</li>
</ol>
<p>No! The explanation about 5% of all intervals failing is only relevant when you have selected random samples over and over again. The lack of random sampling is the problem here.</p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Would it be reasonable for the alien to conclude, with 95% confidence, that between 16.5% and 33.5% of US senators in the year 2019 self-identify as female?</li>
</ol>
<p>No. We know (for sure, with 100% confidence) that exactly 25% of U.S. senators in 2019 self identify as female. If that’s the entire population of interest, there’s no reason to calculate a confidence interval.</p>
<p>Confidence intervals are not appropriate when the data were collected with a biased sampling method. A confidence interval calculated from such a sample can provide very dubious and misleading information.</p>
<p>Confidence intervals are not appropriate when you have access to the entire population of interest. In this unusual and happy circumstance, you should simply describe the population.</p>
</div>
<div id="example-gettysburg-address" class="section level3">
<h3><span class="header-section-number">3.11.2</span> Example: Gettysburg Address<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></h3>
<blockquote>
<p>The authorship of literary works is often a topic for debate. Were some of the works attributed to Shakespeare actually written by Bacon or Marlowe? Which of the anonymously published Federalist Papers were written by Hamilton, which by Madison, which by Jay? Who were the authors of the writings contained in the Bible? The fields of “literary computing” and “forensic stylometry” examine ways of numerically analyzing authors’ works, looking at variables such as sentence length and rates of occurrence of specific words.</p>
</blockquote>
<blockquote>
<p>The above passage is of course Abraham Lincoln’s Gettysburg Address, given November 19, 1863 on the battlefield near Gettysburg, PA. In characterizing this passage, we would ideally examine every word. However, often it is much more convenient and even more efficient to only examine a subset of words.</p>
</blockquote>
<ul>
<li>Step 1: sample 10 representative words.</li>
</ul>
<p>Are they representative of the Gettysburg Address in <em>all</em> ways? What about in length? [Note, the parameter representing the the true average word length is 4.29 letters.]</p>
<p>In class, we found that different samples (i.e., different student’s selection of 10 words) produced different sample means. But that generally, those sample means varied well above the true population mean of 4.29 letters.</p>
<ul>
<li>Step 2: sample 10 random words.</li>
</ul>
<p>Again, in class different sample produced different sample means. But now the sample means varied around the center of 4.29 letters.</p>
<ul>
<li>Step 3: sample 20 random words.</li>
</ul>
<p>The in-class samples are again centered around 4.29 letters, but they are less variable (from sample to sample) when 20 words are selected than when 10 words were selected.</p>
</div>
<div id="key-sampling-terms" class="section level3">
<h3><span class="header-section-number">3.11.3</span> Key sampling terms</h3>
<p><strong>convenience sample</strong> where individuals who are easily accessible are more likely to be included in the sample. For instance, if a political survey is done by stopping people walking in the Bronx, it will not represent all of New York City. It is often difficult to discern what sub-population a convenience sample represents.</p>
<p><strong>simple random sample</strong> equivalent to using a raffle to select cases. This means that each case in the population has an equal chance of being included and there is no implied connection between the cases in the sample.</p>
<p>A <strong>sampling distribution</strong> is the distribution of all possible values of the <em>statistic</em> in all possible samples of the same size from the same population.</p>
<ul>
<li>increasing the sample size reduces the spread of the sampling distribution of a statistic (i.e., increases the precision).</li>
<li>the sampling distribution of a statistic does <em>not</em> depend on the population size! (we assume it is “big enough” so that the sample isn’t basically the same set as the population.)</li>
<li>when characteristics of the resulting samples are systematically different from the population, we call the sampling mechanism <em>biased</em>. If the distribution of the sample statistics, under repeated samples from the same population, is centered at the value of the population parameter, the distribution of the statistic is said to be <em>unbiased</em>.</li>
</ul>
</div>
</div>
<div id="Feb13" class="section level2">
<h2><span class="header-section-number">3.12</span> 2/13/20 Agenda</h2>
<ol style="list-style-type: decimal">
<li>Type I &amp; Type II errors</li>
<li>Power</li>
<li>CI and HT together</li>
</ol>
</div>
<div id="errors" class="section level2">
<h2><span class="header-section-number">3.13</span> Errors &amp; Power</h2>
<ul>
<li><p>The <em>significance level</em>, <span class="math inline">\(\alpha\)</span>, is a probability used as a criterion for rejecting the null hypothesis. If the p-value for a test is less than or equal to <span class="math inline">\(\alpha\)</span>, then the null hypothesis is rejected. If the p-value is greater than <span class="math inline">\(\alpha\)</span>, then the null hypothesis is not rejected. <strong>The significance level is a number calculated before the experiment is run and not based on the dataset.</strong> (Often the significance level is set by the journal or granting agency.)</p></li>
<li><p>The <em>rejection region</em> is the values of the statistic we would need to be able to reject <span class="math inline">\(H_0\)</span>.</p></li>
<li><p>A <em>type I error</em> is rejecting a true null hypothesis. The significance level <span class="math inline">\(\alpha\)</span> sets the probability of committing a type I error.</p></li>
<li><p>A <em>type II error</em> is failing to reject a false null hypothesis.</p></li>
<li><p>The <em>power</em> of a test is the probability that a random sample will lead to rejection of a false null hypothesis.</p></li>
</ul>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th align="center">Truth</th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="center"><span class="math inline">\(H_0\)</span> true</td>
<td align="center"><span class="math inline">\(H_A\)</span> true</td>
</tr>
<tr class="even">
<td>Test</td>
<td>Reject <span class="math inline">\(H_0\)</span></td>
<td align="center">type I error</td>
<td align="center">😄</td>
</tr>
<tr class="odd">
<td></td>
<td>Fail to reject <span class="math inline">\(H_0\)</span></td>
<td align="center">😄</td>
<td align="center">type II error</td>
</tr>
</tbody>
</table>
<div id="example-baseball-player" class="section level3">
<h3><span class="header-section-number">3.13.1</span> Example: baseball player<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></h3>
<p>The following example is taken from <span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span>, and is used to explain many of the most important and nuanced ideas related to the structure of hypothesis testing. I will provide the basic idea here, but you are encouraged to go to the applet on your own to convince yourself that the idea is true and that you understand why the idea is true. <a href="http://www.rossmanchance.com/applets/power.html" class="uri">http://www.rossmanchance.com/applets/power.html</a></p>
<p><strong>Set-up:</strong> Assume that you are a manager of a professional baseball team. One of your players has (for many years) been a 0.250 hitter. That means every time he goes up to bat he has a 1 in 4 chance of hitting the ball (baseball aficionados may want to talk about baseball errors at this point, but we won’t be mentioning baseball errors in today’s example).</p>
<p>Your player tells you that he has been working extremely hard over the off-season and has improved to become a 0.333 hitter. That is, he now believes that every time he goes up to bat he has a 1 in 3 chance of hitting the ball.</p>
<p>You may be aware that profession baseball players who are good make a lot of money. And an increase from hitting the ball 1 in 4 tries to 1 in 3 tries is worth many millions of dollars. Of course, your player is trying to convince you that he is now worth many additional millions of dollars and should be paid accordingly.</p>
<p>What should you do? Well, you need him to convince you that he has, indeed, improved.</p>
<p>Before we get started, we’ll just ask one of our usual questions: what is the parameter of interest?</p>
<p><span class="math inline">\(p\)</span> = baseball players <strong>current</strong> probability of hitting the ball</p>
</div>
<div id="errors-lessons-learned" class="section level3">
<h3><span class="header-section-number">3.13.2</span> Errors: lessons learned</h3>
<p>You are encouraged to go to the applet on your own to convince yourself that you understand why the ideas below are true. <a href="http://www.rossmanchance.com/applets/power.html" class="uri">http://www.rossmanchance.com/applets/power.html</a></p>
<p><strong>What are the Type I and Type II errors/</strong> A Type I error means the manager became convinced the player is better than a 0.250 hitter but in reality he is just still a 0.250 hitter. A Type II error means the player has improved but does not do well enough in his 20 at-bats to convince the manager.</p>
<p><strong>Who is worried about which type of error?</strong> Player would like to minimize the probability of a Type II error – of the manager missing his improvement. The manager would like to minimize the probability of a Type I error – incorrectly thinking the player has improved</p>
<p><strong>What factors impact power? And how?</strong></p>
<ul>
<li><p>Increasing sample size increases power. As the sample size increases, the distribution of the sample proportion gets more narrow (the SE decreases). The SE decrease means that the null and alternative curves overlap less. You will always have the ability to take more observations, although it might be extremely expensive or time consuming to measure more data.</p></li>
<li><p>Increasing the significance level <span class="math inline">\(\alpha\)</span> will increase the power. Ideally, the probabilities of both types of errors would be small, but unfortunately they are inversely related: as one error probability decreases, the other increases (unless other factors change also). What’s typically done in practice is to set the maximum allowable probability of Type I error in advance by setting the level of significance <span class="math inline">\(\alpha\)</span>, the most common value is 0.05, followed by 0.10 and 0.01, and then determine the sample size necessary for the probability of a Type II error to be below a specific value.</p></li>
<li><p>Increasing the distance between the null and alternative will increase the power. Unfortunately, you have very little control over the alternative value. Your science will determine the alternative (in this case, the baseball player’s ability determined his alternative value). The better your science (i.e., the more non-null) it is, the better your chances are of convincing your audience (i.e., publishing) that your results are interesting. (Consider this: it is much easier to convince someone that 8th graders are taller, on average, than kindergartners than it is to convince someone that 1st graders are taller, on average than kindergartners.)</p></li>
</ul>
<p><strong>Why does the Type I error rate double if we consider two sides?</strong></p>
<ul>
<li>Consider the situation where the null hypothesis really is true. And you wait to make your alternative hypothesis until after you’ve seen the data. You choose your rejection region to be the 5% tail region on <strong>one</strong> side. You reject if the observed statistic is in that tail (reminder: in this example the null hypothesis is really true!). Well, instead of making a Type I error 5% of the time, the process described above actually makes a “rejection” 10% of the time!</li>
</ul>
<p><strong>If a CI for <span class="math inline">\(p\)</span> does not overlap a particular number, why is it consistent with rejecting a null HT for that value of <span class="math inline">\(p\)</span>?</strong></p>
<ul>
<li>If a 95% CI does not overlap <span class="math inline">\(p\)</span> (for example, p=0.47), then <span class="math inline">\(p\)</span> and <span class="math inline">\(\hat{p}\)</span> are more than 1.96 SEs away from each other. If <span class="math inline">\(p\)</span> and <span class="math inline">\(\hat{p}\)</span> are more than 1.96 SEs away from each other, then the Z score associate with <span class="math inline">\(\hat{p}\)</span> is larger (in absolute value) than 1.96 (by definition of the Z score!). If the Z score is larger (in absolute value) than 1.96, then the two-sided p-value will be less than 0.05.</li>
</ul>
<!--

i took my dog to the vet to see if she had eaten anything she shouldn't have.  the vet took an x-ray and said "I do not see anything foreign in her body, but that does not mean there is no foreign object eaten."  

we cannot accept the null.

-->
</div>
</div>
<div id="reflection-questions" class="section level2">
<h2><span class="header-section-number">3.14</span> Reflection Questions</h2>
<div id="hypothesis-testing-chapter-2-sections-1-4" class="section level3">
<h3><span class="header-section-number">3.14.1</span> hypothesis testing: Chapter 2, Sections 1-4</h3>
<ol style="list-style-type: decimal">
<li>What is the difference between a statistic and a parameter?</li>
<li>In a typical study, do you have one statistic or more than one statistic? And do you know the value of the statistic?</li>
<li>In a typical study, do you have one parameter or more than one parameter? And do you know the value of the parameter?</li>
<li>Explain what it means for a statistic to have a distribution.</li>
<li>What is a p-value?</li>
<li>What is the difference between a one- and two-sided hypothesis?</li>
<li>What is the difference between a null hypothesis and an alternative hypothesis?</li>
</ol>
</div>
<div id="normal-model-chapter-2-sections-5-7" class="section level3">
<h3><span class="header-section-number">3.14.2</span> normal model: Chapter 2, Sections 5-7</h3>
<ol style="list-style-type: decimal">
<li>What does it mean for something to have a normal distribution?</li>
<li>How can you use the normal curve to calculate percentages or probabilities?</li>
<li>What does it mean for <span class="math inline">\(\hat{p}\)</span> to have a distribution? Can you explain in words?</li>
<li>What does the central limit theorem tell us about the distribution of <span class="math inline">\(\hat{p}\)</span>?</li>
<li>What technical conditions are important in order for the central limit theorem to apply?</li>
<li>What does a Z score measure?</li>
</ol>
</div>
<div id="confidence-intervals-chapter-2-section-8" class="section level3">
<h3><span class="header-section-number">3.14.3</span> confidence intervals: Chapter 2, Section 8</h3>
<ol style="list-style-type: decimal">
<li>What is a confidence interval?</li>
<li>Part of the CI interpretation includes a phrase “95% confident.” Explain what 95% means.</li>
<li>How can you find the appropriate <span class="math inline">\(Z^*\)</span> value?</li>
<li>What is the difference between a Z score and <span class="math inline">\(Z^*\)</span>?</li>
<li>When computing a confidence interval (i.e., when we don’t have a preconceived idea for <span class="math inline">\(p\)</span>), how is the standard deviation of <span class="math inline">\(\hat{p}\)</span> estimated?</li>
<li>When using the normal distribution to create a confidence interval for <span class="math inline">\(p\)</span>, how is the critical value for, say, a 94.7% interval calculated?</li>
</ol>
</div>
<div id="sampling-chapter-1-sections-3-4" class="section level3">
<h3><span class="header-section-number">3.14.4</span> sampling: Chapter 1, Sections 3-4</h3>
<ol style="list-style-type: decimal">
<li>Why is it good to take random samples?</li>
<li>What is a simple random sample?</li>
<li>Why don’t researchers always take random samples?</li>
<li>What benefit(s) does a large sample provide to the study?</li>
<li>What is the difference between practical significance and statistical significance?</li>
</ol>
</div>
<div id="errors-power-chapter-2-section-3" class="section level3">
<h3><span class="header-section-number">3.14.5</span> errors &amp; power: Chapter 2, Section 3</h3>
<ol style="list-style-type: decimal">
<li>Why is it never okay to accept <span class="math inline">\(H_0\)</span>?</li>
<li>What is the difference between a Type I and Type II error?</li>
<li>Which is worse: a Type I error or a Type II error?</li>
<li>What is power? How is power calculated? What does power depend on?</li>
</ol>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-iscam">
<p>Chance, Beth, and Allan Rossman. 2018. <em>Investigating Statistics, Concepts, Applications, and Methods</em>. 3rd ed. <a href="http://www.rossmanchance.com/iscam3/">http://www.rossmanchance.com/iscam3/</a>.</p>
</div>
<div id="ref-isrs">
<p>Diez, David, Christopher Barr, and Mine Çetinkaya-Rundel. 2014. <em>Introductory Statistics with Randomization and Simulation</em>. 1st ed. <a href="https://www.openintro.org/">https://www.openintro.org/</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Rosen B and Jerdee T. 1974. Influence of sex role stereotypes on personnel decisions. Journal of Applied Psychology 59(1):9-14.<a href="foundations-for-inference.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>Inv 1.8, Chance &amp; Rossman, ISCAM<a href="foundations-for-inference.html#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>taken from <a href="https://askgoodquestions.blog/2019/08/26/8-end-of-the-alphabet/" class="uri">https://askgoodquestions.blog/2019/08/26/8-end-of-the-alphabet/</a> by Allan Rossman, he borrowed from 2011 AP Statistics exam<a href="foundations-for-inference.html#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>see results here: <a href="https://www.gapminder.org/ignorance/gms/" class="uri">https://www.gapminder.org/ignorance/gms/</a><a href="foundations-for-inference.html#fnref4" class="footnote-back">↩</a></p></li>
<li id="fn5"><p>From Allan Rossman: <a href="https://askgoodquestions.blog/2019/10/07/14-how-confident-are-you-part-1/" class="uri">https://askgoodquestions.blog/2019/10/07/14-how-confident-are-you-part-1/</a><a href="foundations-for-inference.html#fnref5" class="footnote-back">↩</a></p></li>
<li id="fn6"><p>From Inv 1.12, <span class="citation">Chance and Rossman (<a href="#ref-iscam">2018</a>)</span><a href="foundations-for-inference.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>Inv 1.7, Chance &amp; Rossman, ISCAM<a href="foundations-for-inference.html#fnref7" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="inference-for-categorical-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-FoundInf.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Math-58-Notes.pdf", "Math-58-Notes.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
