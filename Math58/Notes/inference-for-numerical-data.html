<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Inference for numerical data | Introduction to (Bio)Statistics</title>
  <meta name="description" content="Class notes for both Math 58 and Math 58B at Pomona College: Introduction to Statistics and Introduction to Biostatistics. The notes are based extensively on Introduction to Modern Statistics by Çetinkaya-Rundel and Hardin Investigating Statistical Concepts, Applications, and Methods by Chance and Rossman." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Inference for numerical data | Introduction to (Bio)Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Class notes for both Math 58 and Math 58B at Pomona College: Introduction to Statistics and Introduction to Biostatistics. The notes are based extensively on Introduction to Modern Statistics by Çetinkaya-Rundel and Hardin Investigating Statistical Concepts, Applications, and Methods by Chance and Rossman." />
  <meta name="github-repo" content="hardin47/website/Math58/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Inference for numerical data | Introduction to (Bio)Statistics" />
  
  <meta name="twitter:description" content="Class notes for both Math 58 and Math 58B at Pomona College: Introduction to Statistics and Introduction to Biostatistics. The notes are based extensively on Introduction to Modern Statistics by Çetinkaya-Rundel and Hardin Investigating Statistical Concepts, Applications, and Methods by Chance and Rossman." />
  

<meta name="author" content="Jo Hardin" />


<meta name="date" content="2021-01-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="interlude-in-spring-2020.html"/>
<link rel="next" href="correlation-regression.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to (Bio)Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Class Information</a></li>
<li class="chapter" data-level="1" data-path="rfunc.html"><a href="rfunc.html"><i class="fa fa-check"></i><b>1</b> R functions</a>
<ul>
<li class="chapter" data-level="1.1" data-path="rfunc.html"><a href="rfunc.html#applets"><i class="fa fa-check"></i><b>1.1</b> Applets</a></li>
<li class="chapter" data-level="1.2" data-path="rfunc.html"><a href="rfunc.html#data-structure"><i class="fa fa-check"></i><b>1.2</b> Data Structure</a></li>
<li class="chapter" data-level="1.3" data-path="rfunc.html"><a href="rfunc.html#wrangling"><i class="fa fa-check"></i><b>1.3</b> Wrangling</a></li>
<li class="chapter" data-level="1.4" data-path="rfunc.html"><a href="rfunc.html#plotting"><i class="fa fa-check"></i><b>1.4</b> Plotting</a></li>
<li class="chapter" data-level="1.5" data-path="rfunc.html"><a href="rfunc.html#statistical-inference"><i class="fa fa-check"></i><b>1.5</b> Statistical Inference</a></li>
<li class="chapter" data-level="1.6" data-path="rfunc.html"><a href="rfunc.html#probability-models"><i class="fa fa-check"></i><b>1.6</b> Probability models</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#course-logistics"><i class="fa fa-check"></i><b>2.1</b> Course Logistics</a>
<ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#vocabulary"><i class="fa fa-check"></i>Vocabulary</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#ex:helper"><i class="fa fa-check"></i><b>2.2</b> Example: Friend or Foe</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#experim"><i class="fa fa-check"></i><b>2.3</b> Types of Studies</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="intro.html"><a href="intro.html#example-hand-writing-sat-scores"><i class="fa fa-check"></i><b>2.3.1</b> Example: Hand Writing &amp; SAT Scores</a></li>
<li class="chapter" data-level="2.3.2" data-path="intro.html"><a href="intro.html#example-have-a-nice-trip"><i class="fa fa-check"></i><b>2.3.2</b> Example: Have a Nice Trip</a></li>
<li class="chapter" data-level="2.3.3" data-path="intro.html"><a href="intro.html#study-conclusions"><i class="fa fa-check"></i><b>2.3.3</b> Study conclusions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html"><i class="fa fa-check"></i><b>3</b> Foundations for Inference</a>
<ul>
<li class="chapter" data-level="3.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#ex:gend"><i class="fa fa-check"></i><b>3.1</b> Example: Gender Discrimination</a></li>
<li class="chapter" data-level="3.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#structure-of-hypothesis-testing"><i class="fa fa-check"></i><b>3.2</b> Structure of Hypothesis testing</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#hypotheses-1"><i class="fa fa-check"></i><b>3.2.1</b> Hypotheses</a></li>
<li class="chapter" data-level="3.2.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#other-pieces-of-the-process"><i class="fa fa-check"></i><b>3.2.2</b> Other pieces of the process</a></li>
<li class="chapter" data-level="3.2.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#all-together-structure-of-a-hypothesis-test"><i class="fa fa-check"></i><b>3.2.3</b> All together: structure of a hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#normal-model"><i class="fa fa-check"></i><b>3.3</b> Normal Model</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#CLT"><i class="fa fa-check"></i><b>3.3.1</b> Central Limit Therm</a></li>
<li class="chapter" data-level="3.3.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#norm"><i class="fa fa-check"></i><b>3.3.2</b> Normal Probabilities &amp; Z scores</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#CI"><i class="fa fa-check"></i><b>3.4</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#theoretical-set-up"><i class="fa fa-check"></i><b>3.4.1</b> Theoretical set-up</a></li>
<li class="chapter" data-level="3.4.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-changes-in-extreme-poverty"><i class="fa fa-check"></i><b>3.4.2</b> Example: changes in extreme poverty</a></li>
<li class="chapter" data-level="3.4.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#modCI"><i class="fa fa-check"></i><b>3.4.3</b> Modifying CIs</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#samp"><i class="fa fa-check"></i><b>3.5</b> Sampling</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-aliens-on-earth"><i class="fa fa-check"></i><b>3.5.1</b> Example: aliens on Earth</a></li>
<li class="chapter" data-level="3.5.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-gettysburg-address"><i class="fa fa-check"></i><b>3.5.2</b> Example: Gettysburg Address</a></li>
<li class="chapter" data-level="3.5.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#key-sampling-terms"><i class="fa fa-check"></i><b>3.5.3</b> Key sampling terms</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#errors"><i class="fa fa-check"></i><b>3.6</b> Errors &amp; Power</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#example-baseball-player"><i class="fa fa-check"></i><b>3.6.1</b> Example: baseball player</a></li>
<li class="chapter" data-level="3.6.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#errors-lessons-learned"><i class="fa fa-check"></i><b>3.6.2</b> Errors: lessons learned</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#reflection-questions"><i class="fa fa-check"></i><b>3.7</b> Reflection Questions</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#hypothesis-testing-chapter-2-sections-1-4"><i class="fa fa-check"></i><b>3.7.1</b> hypothesis testing: Chapter 2, Sections 1-4</a></li>
<li class="chapter" data-level="3.7.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#normal-model-chapter-2-sections-5-7"><i class="fa fa-check"></i><b>3.7.2</b> normal model: Chapter 2, Sections 5-7</a></li>
<li class="chapter" data-level="3.7.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#confidence-intervals-chapter-2-section-8"><i class="fa fa-check"></i><b>3.7.3</b> confidence intervals: Chapter 2, Section 8</a></li>
<li class="chapter" data-level="3.7.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#sampling-chapter-1-sections-3-4"><i class="fa fa-check"></i><b>3.7.4</b> sampling: Chapter 1, Sections 3-4</a></li>
<li class="chapter" data-level="3.7.5" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#errors-power-chapter-2-section-3"><i class="fa fa-check"></i><b>3.7.5</b> errors &amp; power: Chapter 2, Section 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html"><i class="fa fa-check"></i><b>4</b> Inference for categorical data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#inference-for-a-single-proportion"><i class="fa fa-check"></i><b>4.1</b> Inference for a single proportion</a></li>
<li class="chapter" data-level="4.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-distribution"><i class="fa fa-check"></i><b>4.2</b> Binomial distribution</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-pop-quiz"><i class="fa fa-check"></i><b>4.2.1</b> Example: pop quiz</a></li>
<li class="chapter" data-level="4.2.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-hypothesis-testing"><i class="fa fa-check"></i><b>4.2.2</b> Binomial Hypothesis Testing</a></li>
<li class="chapter" data-level="4.2.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-power"><i class="fa fa-check"></i><b>4.2.3</b> Binomial Power</a></li>
<li class="chapter" data-level="4.2.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binomial-confidence-intervals-for-p"><i class="fa fa-check"></i><b>4.2.4</b> Binomial Confidence Intervals for <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#relative-risk"><i class="fa fa-check"></i><b>4.3</b> Relative Risk</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#inference-on-relative-risk"><i class="fa fa-check"></i><b>4.3.1</b> Inference on Relative Risk</a></li>
<li class="chapter" data-level="4.3.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#using-infer-for-inference-on-rr"><i class="fa fa-check"></i><b>4.3.2</b> Using <code>infer</code> for inference on RR</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#odds-ratios"><i class="fa fa-check"></i><b>4.4</b> Odds Ratios</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-smoking-and-lung-cancer"><i class="fa fa-check"></i><b>4.4.1</b> Example: Smoking and Lung Cancer</a></li>
<li class="chapter" data-level="4.4.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#inference-on-odds-ratios"><i class="fa fa-check"></i><b>4.4.2</b> Inference on Odds Ratios</a></li>
<li class="chapter" data-level="4.4.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#confidence-interval-for-or-same-idea-as-with-rr"><i class="fa fa-check"></i><b>4.4.3</b> Confidence Interval for OR (same idea as with RR)</a></li>
<li class="chapter" data-level="4.4.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#using-infer-for-inference-on-or"><i class="fa fa-check"></i><b>4.4.4</b> Using <code>infer</code> for inference on OR</a></li>
<li class="chapter" data-level="4.4.5" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#ex:cov"><i class="fa fa-check"></i><b>4.4.5</b> Example: MERS-CoV</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#diffprop"><i class="fa fa-check"></i><b>4.5</b> Difference of two proportions</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#clt-for-difference-in-two-proportions"><i class="fa fa-check"></i><b>4.5.1</b> CLT for difference in two proportions</a></li>
<li class="chapter" data-level="4.5.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#ht-difference-in-proportions"><i class="fa fa-check"></i><b>4.5.2</b> HT: difference in proportions</a></li>
<li class="chapter" data-level="4.5.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#ci-difference-in-proportions"><i class="fa fa-check"></i><b>4.5.3</b> CI: difference in proportions</a></li>
<li class="chapter" data-level="4.5.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-government-shutdown"><i class="fa fa-check"></i><b>4.5.4</b> Example: Government Shutdown</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#chisq1"><i class="fa fa-check"></i><b>4.6</b> Goodness-of-fit: One categorical variable (<span class="math inline">\(\chi^2\)</span> test) <span class="math inline">\(\geq\)</span> 2 levels</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-household-ages"><i class="fa fa-check"></i><b>4.6.1</b> Example: Household Ages</a></li>
<li class="chapter" data-level="4.6.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-flax-seed"><i class="fa fa-check"></i><b>4.6.2</b> Example: Flax Seed</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#chisq2"><i class="fa fa-check"></i><b>4.7</b> Independence: Two categorical variables (<span class="math inline">\(\chi^2\)</span> test) <span class="math inline">\(\geq\)</span> 2 levels each</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#example-nightlights"><i class="fa fa-check"></i><b>4.7.1</b> Example: Nightlights</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#reflection-questions-1"><i class="fa fa-check"></i><b>4.8</b> Reflection Questions</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#no-isrs-binomial-probabilities-not-covered"><i class="fa fa-check"></i><b>4.8.1</b> (no ISRS) Binomial probabilities (not covered)</a></li>
<li class="chapter" data-level="4.8.2" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#no-isrs-relative-risk-odds-ratios"><i class="fa fa-check"></i><b>4.8.2</b> (no ISRS) Relative Risk &amp; Odds Ratios</a></li>
<li class="chapter" data-level="4.8.3" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#binary-variables-chapter-3-section-2"><i class="fa fa-check"></i><b>4.8.3</b> 2 binary variables: Chapter 3, Section 2</a></li>
<li class="chapter" data-level="4.8.4" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#types-of-studies-chapter-1-sections-4-5"><i class="fa fa-check"></i><b>4.8.4</b> Types of studies: Chapter 1, Sections 4-5</a></li>
<li class="chapter" data-level="4.8.5" data-path="inference-for-categorical-data.html"><a href="inference-for-categorical-data.html#categorical-variables-chapter-3-section-3"><i class="fa fa-check"></i><b>4.8.5</b> 2 categorical variables: Chapter 3, Section 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="interlude-in-spring-2020.html"><a href="interlude-in-spring-2020.html"><i class="fa fa-check"></i><b>5</b> Interlude in Spring 2020</a>
<ul>
<li class="chapter" data-level="5.1" data-path="interlude-in-spring-2020.html"><a href="interlude-in-spring-2020.html#census"><i class="fa fa-check"></i><b>5.1</b> Census</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="interlude-in-spring-2020.html"><a href="interlude-in-spring-2020.html#what-about-college-students"><i class="fa fa-check"></i><b>5.1.1</b> What about College students?</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="interlude-in-spring-2020.html"><a href="interlude-in-spring-2020.html#covid19"><i class="fa fa-check"></i><b>5.2</b> COVID-19</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="interlude-in-spring-2020.html"><a href="interlude-in-spring-2020.html#dashboard-for-predicting"><i class="fa fa-check"></i><b>5.2.1</b> Dashboard for Predicting</a></li>
<li class="chapter" data-level="5.2.2" data-path="interlude-in-spring-2020.html"><a href="interlude-in-spring-2020.html#visualizing-the-data"><i class="fa fa-check"></i><b>5.2.2</b> Visualizing the data</a></li>
<li class="chapter" data-level="5.2.3" data-path="interlude-in-spring-2020.html"><a href="interlude-in-spring-2020.html#current-medical-studies-on-treatment-of-covid-19"><i class="fa fa-check"></i><b>5.2.3</b> Current medical studies on treatment of COVID-19</a></li>
<li class="chapter" data-level="5.2.4" data-path="interlude-in-spring-2020.html"><a href="interlude-in-spring-2020.html#studies-related-to-covid-19"><i class="fa fa-check"></i><b>5.2.4</b> Studies related to COVID-19</a></li>
<li class="chapter" data-level="5.2.5" data-path="interlude-in-spring-2020.html"><a href="interlude-in-spring-2020.html#being-careful-with-your-analysis"><i class="fa fa-check"></i><b>5.2.5</b> Being careful with your analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html"><i class="fa fa-check"></i><b>6</b> Inference for numerical data</a>
<ul>
<li class="chapter" data-level="6.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#important-measures-related-to-quantitative-numeric-variables"><i class="fa fa-check"></i><b>6.1</b> Important measures related to quantitative (numeric) variables</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#quantitative-descriptives"><i class="fa fa-check"></i><b>6.1.1</b> Quantitative Descriptives</a></li>
<li class="chapter" data-level="6.1.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mean1dist"><i class="fa fa-check"></i><b>6.1.2</b> Sampling distribution of a sample mean</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mean1inf"><i class="fa fa-check"></i><b>6.2</b> Inference for a single mean, <span class="math inline">\(\mu\)</span></a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mathematical-model-for-distribution-of-the-sample-mean"><i class="fa fa-check"></i><b>6.2.1</b> Mathematical model for distribution of the sample mean</a></li>
<li class="chapter" data-level="6.2.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#example-healthy-body-temperature"><i class="fa fa-check"></i><b>6.2.2</b> Example: healthy body temperature</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#mean2inf"><i class="fa fa-check"></i><b>6.3</b> Comparing two independent means</a></li>
<li class="chapter" data-level="6.4" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#r-code-for-inference-on-1-or-2-means."><i class="fa fa-check"></i><b>6.4</b> R code for inference on 1 or 2 means.</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#t.test"><i class="fa fa-check"></i><b>6.4.1</b> <code>t.test()</code></a></li>
<li class="chapter" data-level="6.4.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#infer"><i class="fa fa-check"></i><b>6.4.2</b> <code>infer</code></a></li>
<li class="chapter" data-level="6.4.3" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#nba-salaries-example-from-iscam-inv-4.2"><i class="fa fa-check"></i><b>6.4.3</b> NBA Salaries example from ISCAM Inv 4.2</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#reflection-questions-2"><i class="fa fa-check"></i><b>6.5</b> Reflection Questions</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#quantitative-variable-chapter-4-section-1"><i class="fa fa-check"></i><b>6.5.1</b> 1 quantitative variable: Chapter 4, Section 1</a></li>
<li class="chapter" data-level="6.5.2" data-path="inference-for-numerical-data.html"><a href="inference-for-numerical-data.html#means-1-quantitative-variable-1-binary-variable-chapter-4-section-3"><i class="fa fa-check"></i><b>6.5.2</b> 2 means (1 quantitative variable, 1 binary variable): Chapter 4, Section 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="correlation-regression.html"><a href="correlation-regression.html"><i class="fa fa-check"></i><b>7</b> Correlation &amp; Regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="correlation-regression.html"><a href="correlation-regression.html#cor"><i class="fa fa-check"></i><b>7.1</b> Correlation</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="correlation-regression.html"><a href="correlation-regression.html#estimating-correlation"><i class="fa fa-check"></i><b>7.1.1</b> Estimating Correlation</a></li>
<li class="chapter" data-level="7.1.2" data-path="correlation-regression.html"><a href="correlation-regression.html#coefficient-of-determination-r2"><i class="fa fa-check"></i><b>7.1.2</b> Coefficient of Determination – <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="7.1.3" data-path="correlation-regression.html"><a href="correlation-regression.html#inference-for-correlation"><i class="fa fa-check"></i><b>7.1.3</b> Inference for correlation</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="correlation-regression.html"><a href="correlation-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>7.2</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="correlation-regression.html"><a href="correlation-regression.html#ls"><i class="fa fa-check"></i><b>7.2.1</b> Least Squares estimation of the regression line</a></li>
<li class="chapter" data-level="7.2.2" data-path="correlation-regression.html"><a href="correlation-regression.html#infbeta1"><i class="fa fa-check"></i><b>7.2.2</b> Inference on the slope, <span class="math inline">\(\beta_1\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="correlation-regression.html"><a href="correlation-regression.html#MLR"><i class="fa fa-check"></i><b>7.3</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="correlation-regression.html"><a href="correlation-regression.html#MLRmod"><i class="fa fa-check"></i><b>7.3.1</b> Model selection</a></li>
<li class="chapter" data-level="7.3.2" data-path="correlation-regression.html"><a href="correlation-regression.html#checking-model-assumptions"><i class="fa fa-check"></i><b>7.3.2</b> Checking model assumptions</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="correlation-regression.html"><a href="correlation-regression.html#r-code-for-regression"><i class="fa fa-check"></i><b>7.4</b> R code for regression</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="correlation-regression.html"><a href="correlation-regression.html#ex:cat"><i class="fa fa-check"></i><b>7.4.1</b> Example: Cat Jumping (Correlation &amp; SLR)</a></li>
<li class="chapter" data-level="7.4.2" data-path="correlation-regression.html"><a href="correlation-regression.html#ex:houses"><i class="fa fa-check"></i><b>7.4.2</b> Example: Housing Prices (SLR &amp; MLR &amp; Prediction)</a></li>
<li class="chapter" data-level="7.4.3" data-path="correlation-regression.html"><a href="correlation-regression.html#ex:1819flu"><i class="fa fa-check"></i><b>7.4.3</b> Example: 1918-19 Flu and Excess Deaths</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="correlation-regression.html"><a href="correlation-regression.html#reflection-questions-3"><i class="fa fa-check"></i><b>7.5</b> Reflection Questions</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="correlation-regression.html"><a href="correlation-regression.html#correlation-simple-linear-regression-chapter-5-section-1-4"><i class="fa fa-check"></i><b>7.5.1</b> Correlation &amp; Simple Linear Regression: Chapter 5, Section 1-4</a></li>
<li class="chapter" data-level="7.5.2" data-path="correlation-regression.html"><a href="correlation-regression.html#multiple-linear-regression-chapter-6-section-1-3"><i class="fa fa-check"></i><b>7.5.2</b> Multiple Linear Regression: Chapter 6, Section 1-3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://st47s.com/Math58" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to (Bio)Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inference-for-numerical-data" class="section level1" number="6">
<h1><span class="header-section-number">Chapter 6</span> Inference for numerical data</h1>
<!--
## 3/31/20 Agenda {#Mar31}
1. New statistics: mean, standard deviation, standard error of the mean
2. Sampling distribution of the sample mean
-->
<div id="important-measures-related-to-quantitative-numeric-variables" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Important measures related to quantitative (numeric) variables</h2>
<div id="quantitative-descriptives" class="section level3" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> Quantitative Descriptives</h3>
<p>What measures can we look at to get a first sense of whether two groups are different (let alone substantially different enough for us to conclude a difference in a related population). We might look at what is called the <strong>Five Number Summary</strong>.</p>
<ul>
<li><strong>Five Number Summary</strong>: Min, Q1, Median, Q3, Max
<ul>
<li>Q1 = median of the values <em>below</em> the median</li>
<li>Q3 = median of the values <em>above</em> the median</li>
<li>IQR = Interquartile range (measure of spread/variability) = Q3 - Q1</li>
<li>1.5 x IQR rule for possible outliers: If an observation falls more than 1.5IQR outside of Q1 or Q3, flag the observation as a possible outlier.</li>
</ul></li>
<li>Boxplot
<ul>
<li>Box spans Q1 to Q3</li>
<li>Line in box marks median (M)</li>
<li>Perpendicular line extends from box to smallest and largest observations <em>within</em> 1.5IQR of Q1 and Q3.</li>
<li>Dots for observations outside of 1.5IQR</li>
</ul></li>
<li>Summaries often used when variable has a bell-shaped distribution</li>
</ul>
<p><span class="math display">\[\begin{eqnarray*}
\mbox{sample mean} &amp;=&amp; \overline{X} = \frac{1}{n} \sum_{i=1}^n X_i\\
\mbox{sample standard deviation} &amp;=&amp; s = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2}\\
\mbox{sample variance} &amp;=&amp; s^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2
\end{eqnarray*}\]</span></p>
<p>Loosely, the standard deviation is the size of the typical deviation from the mean of the data set. Note that we divide by <span class="math inline">\(n-1\)</span> instead of by <span class="math inline">\(n\)</span> because the true deviation is defined as the average of the observations from the true mean <span class="math inline">\(\mu\)</span>, and, in fact, they will always be closer to <span class="math inline">\(\overline{X}\)</span> than to <span class="math inline">\(\mu\)</span>.</p>
</div>
<div id="mean1dist" class="section level3" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Sampling distribution of a sample mean</h3>
<p>As before, the <strong>Central Limit Theorem</strong> tells us that averages are normally distributed if the sample size is large enough. Here, that means:
<span class="math display">\[\overline{X} \sim N(\mu, \sigma/\sqrt{n})\]</span>
where <span class="math inline">\(SD(\overline{X}) = \sigma/\sqrt{n}\)</span> and <span class="math inline">\(SE(\overline{X}) = s/\sqrt{n}\)</span>. <span class="math inline">\(\mu\)</span> is the center of the <em>population</em> of observations from which the sample data were taken. <span class="math inline">\(\sigma\)</span> is the variability of the <em>population</em> of observations from which the sample data were taken.</p>
<p>As before, we won’t spend much time worried about the difference between <span class="math inline">\(SD(\overline{X})\)</span> and <span class="math inline">\(SE(\overline{X})\)</span>. Generally, we’ll only know / use <span class="math inline">\(SE(\overline{X}) = s/\sqrt{n}\)</span>. Typically, with quantitative variables, “large enough” is at least 30 or so observations.</p>
<p>Spend some time clicking through different datasets in the ICAM applet: <a href="http://www.rossmanchance.com/applets/OneSample.html?showBoth=1" class="uri">http://www.rossmanchance.com/applets/OneSample.html?showBoth=1</a></p>
<p>You should notice:</p>
<ul>
<li>If the population (or sample of data) is skewed, the sampling distribution of the sample mean is normal (bell-shaped) when the sample size is large.</li>
<li>The larger the sample size, the less variable the sampling distribution.</li>
<li>The sample size does <em>not</em> change the distribution of the dataset (the middle graph). The middle graph will always be a representation of the population graph (left side); although with small sample sizes, the middle graph is somewhat sparse.</li>
<li>In an actual data analysis, we <strong>only</strong> see the middle graph. We do not see the population graph (left side) or the sampling distribution (right side).</li>
</ul>
<!--
## 4/2/20 Agenda {#Apr2}
1. The t-distribution
2. Standardized t-score 
3. Hypothesis Testing & Confidence Intervals for one mean


## 4/7/20 Agenda {#Apr7}
1. Review of confidence interval for one mean
2. Prediction Interval for a future observation
-->
</div>
</div>
<div id="mean1inf" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Inference for a single mean, <span class="math inline">\(\mu\)</span></h2>
<div id="mathematical-model-for-distribution-of-the-sample-mean" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Mathematical model for distribution of the sample mean</h3>
<p>Before coming up with the mathematical model appropriate for this section, it is important to notice that we almost never know the true variability of the data (i.e., <span class="math inline">\(\sigma\)</span>). Instead, we almost always have to estimate <span class="math inline">\(\sigma\)</span> using <span class="math inline">\(s\)</span>, the sample standard deviation. It turns out that when the estimate of the variability is used in the denominator, the sampling distribution becomes more variability (longer tails). Recall that it is the tails of the distribution in which we are the most interested, so we don’t want to get those wrong!!</p>
<p>If <span class="math inline">\(\sigma\)</span> is somehow known: <span class="math display">\[\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \sim N(0,1)\]</span></p>
<p>But in the more typical situation where <span class="math inline">\(\sigma\)</span> is estimated using <span class="math inline">\(s\)</span>: <span class="math display">\[\frac{\overline{X} - \mu}{s/\sqrt{n}} \sim t_{df = n-1}\]</span></p>
<div id="hypothesis-testing-isrs-4.1" class="section level4" number="6.2.1.1">
<h4><span class="header-section-number">6.2.1.1</span> Hypothesis Testing (ISRS 4.1)</h4>
<p>If <span class="math inline">\(H_0: \mu = \mu_0\)</span> is true, then we know that: <span class="math display">\[\frac{\overline{X} - \mu}{s/\sqrt{n}} \sim t_{df = n-1}\]</span></p>
<p>That is, we can use the <span class="math inline">\(t_{df = n-1}\)</span> distribution to find the p-value for the test. Note, in R we we use the function <code>xpt</code> in the <code>mosaic</code> package.</p>
</div>
<div id="confidence-intervals-isrs-4.1.4" class="section level4" number="6.2.1.2">
<h4><span class="header-section-number">6.2.1.2</span> Confidence Intervals (ISRS 4.1.4)</h4>
<p>In the setting where there is no null hypothesis statement and an interval estimate is needed, the interval is created in the exact same way as was done with proportions using: <span class="math display">\[\overline{X} \pm t_{n-1}^* \cdot SE(\overline{X})\]</span></p>
<p>Which is the same thing as: <span class="math display">\[\overline{X} \pm t_{n-1}^* \cdot s/ \sqrt{n}\]</span></p>
</div>
<div id="predint" class="section level4" number="6.2.1.3">
<h4><span class="header-section-number">6.2.1.3</span> Prediction Intervals (ISCAM 2.6, not in ISRS)</h4>
<p>A prediction interval is <strong>different</strong> from a confidence interval!!! Remember that a confidence interval is a range of values that try to capture a <strong>parameter</strong>. A prediction interval is meant to capture 95% of future observations (see below for the example on healthy body temperatures). Note that in order to capture the variability in the observations, we combine the variability of the center of the interval (<span class="math inline">\(s/\sqrt{n}\)</span>) with the variability of the observations themselves (<span class="math inline">\(s\)</span>).</p>
<p>A <span class="math inline">\((1-\alpha)100%\)</span> prediction interval has a <span class="math inline">\((1-\alpha)\)</span> probability of capturing a new observation from the population.</p>
<p><span class="math display">\[\overline{X} \pm t_{n-1}^* \cdot s \sqrt{1 + \frac{1}{n}}\]</span></p>
</div>
</div>
<div id="example-healthy-body-temperature" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Example: healthy body temperature<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a></h3>
<p>The study at hand is meant to determine whether the average healthy body temperature is actually 98.6 F.<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a></p>
<blockquote>
<p>Body temperatures (oral temperatures using a digital thermometer) were recorded for healthy men and women, aged 18-40 years, who were volunteers in Shigella vaccine trials at the University of Maryland Center for Vaccine Development, Baltimore. For these adults, the mean body temperature was found to be 98.249 F with a standard deviation of 0.733 F.<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a></p>
</blockquote>
<p>In order to work through the analysis it is imperative that we understand the data that was collected as part of the research.</p>
<table style="width:100%;">
<colgroup>
<col width="28%" />
<col width="33%" />
<col width="33%" />
<col width="4%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">center</th>
<th align="left">variability of data</th>
<th align="left">variability of sample means</th>
<th align="left">sample size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\overline{X} = 98.249\)</span> F</td>
<td align="left"><span class="math inline">\(s = 0.733\)</span> F</td>
<td align="left"><span class="math inline">\(SE(\overline{X}) = \frac{s}{\sqrt{n}} = \frac{0.733}{\sqrt{130}} = 0.0643\)</span></td>
<td align="left"><span class="math inline">\(n=130\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\mu\)</span> = true ave healthy body temp (unknown!)</td>
<td align="left"><span class="math inline">\(\sigma\)</span> = true sd of healthy body temps (unknown!)</td>
<td align="left"><span class="math inline">\(SD(\overline{X}) = \frac{\sigma}{\sqrt{n}}\)</span> = unknown!</td>
<td align="left"></td>
</tr>
</tbody>
</table>
<div id="hypothesis-test-on-true-average-healthy-body-temperature" class="section level4" number="6.2.2.1">
<h4><span class="header-section-number">6.2.2.1</span> Hypothesis test on true average healthy body temperature</h4>
<p>The first research question we want to ask is: how surprising would it be to select a group of 13 participants who have an average healthy body temperature of 98.249 F ?</p>
<p>The questions is set up perfectly for a hypothesis test!</p>
<p><span class="math inline">\(H_0: \mu = 98.6\)</span></p>
<p><span class="math inline">\(H_A: \mu \ne 98.6\)</span></p>
<p>We use the t-distribution to investigate the claim.</p>
<p><span class="math display">\[t-score = \frac{98.249 - 98.6}{0.733/\sqrt{130}} = -5.46\]</span></p>
<p>How likely is the standardized version of our test statistic to happen if the null hypothesis is true? Well, if <span class="math inline">\(H_0\)</span> is true, then the t-statistics should have a t-distribution. So we can use the t-distribution to find the p-value (recall that the p-value is the probability of the data or more extreme if <span class="math inline">\(H_0\)</span> is true.)</p>
<p>The test statistic is -5.46, and even a two-sided p-value (the area doubled) is way less than 0.001.</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="inference-for-numerical-data.html#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span> <span class="sc">*</span> mosaic<span class="sc">::</span><span class="fu">xpt</span>(<span class="sc">-</span><span class="fl">5.46</span>, <span class="at">df =</span> <span class="dv">129</span>, <span class="at">ncp =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="04-InfNum_files/figure-html/unnamed-chunk-1-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 2.354246e-07</code></pre>
</div>
<div id="confidence-interval-for-true-average-healthy-body-temperature" class="section level4" number="6.2.2.2">
<h4><span class="header-section-number">6.2.2.2</span> Confidence interval for true average healthy body temperature</h4>
<p>Possibly more interesting is the confidence interval which would tell us a range of plausible values for healthy body temperatures.</p>
<p>The confidence interval is given by the following formula: <span class="math display">\[\overline{X} \pm t_{n-1}^* \cdot s/ \sqrt{n}\]</span></p>
<p>and is calculated to be (98.121, 98.376). That is, we are 95% confident that the true average healthy body temperature is somewhere between 98.121 F and 98.376 F. Note that 98.6 F is not in the interval!!! Wow.</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="inference-for-numerical-data.html#cb133-1" aria-hidden="true" tabindex="-1"></a>mosaic<span class="sc">::</span><span class="fu">xqt</span>(.<span class="dv">975</span>, <span class="at">df =</span> <span class="dv">129</span>)</span></code></pre></div>
<p><img src="04-InfNum_files/figure-html/unnamed-chunk-2-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 1.978524</code></pre>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="inference-for-numerical-data.html#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="fl">98.249</span> <span class="sc">-</span> <span class="fl">1.9785</span> <span class="sc">*</span> <span class="fl">0.733</span> <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">130</span>)</span></code></pre></div>
<pre><code>## [1] 98.12181</code></pre>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="inference-for-numerical-data.html#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="fl">98.249</span> <span class="sc">+</span> <span class="fl">1.9785</span> <span class="sc">*</span> <span class="fl">0.733</span> <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="dv">130</span>)</span></code></pre></div>
<pre><code>## [1] 98.37619</code></pre>
</div>
<div id="prediction-interval-for-individual-healthy-body-temperatures" class="section level4" number="6.2.2.3">
<h4><span class="header-section-number">6.2.2.3</span> Prediction interval for individual healthy body temperatures<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a></h4>
<p>Note the fundamental difference between the <strong>goal</strong> of the confidence interval above and the <strong>goal</strong> of the prediction interval calculated in this section. A confidence interval is an interval of plausible values for a population parameter. A prediction interval is for a future <em>individual</em> observations.</p>
<p>A <span class="math inline">\((1-\alpha)100%\)</span> prediction interval has a <span class="math inline">\((1-\alpha)\)</span> probability of capturing a new observation from the population.</p>
<p>Here, a 95% prediction interval for healthy body temperatures can be calculated using:</p>
<p><span class="math display">\[\overline{X} \pm t_{n-1}^* \cdot s \cdot \sqrt{1 + \frac{1}{n}}\]</span></p>
<p><span class="math display">\[98.249 \pm t_{129}^* \cdot 0.733 \cdot \sqrt{1 + \frac{1}{130}}\]</span></p>
<p>Which gives a 95% prediction interval of (96.79 F, 99.70 F). There is a 0.95 probability that if I reach into the population, the person selected will have a healthy body temperature between 96.79 F and 99.70 F. Said differently, 95% of the individuals in the population will have a healthy body temperature between 96.79 F and 99.70 F (a <strong>much</strong> wider range of values than the confidence interval!)</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="inference-for-numerical-data.html#cb139-1" aria-hidden="true" tabindex="-1"></a>mosaic<span class="sc">::</span><span class="fu">xqt</span>(.<span class="dv">975</span>, <span class="at">df =</span> <span class="dv">129</span>)</span></code></pre></div>
<p><img src="04-InfNum_files/figure-html/unnamed-chunk-3-1.png" width="480" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 1.978524</code></pre>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="inference-for-numerical-data.html#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fl">98.249</span> <span class="sc">-</span> <span class="fl">1.9785</span><span class="sc">*</span><span class="fl">0.733</span><span class="sc">*</span><span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">130</span>)</span></code></pre></div>
<pre><code>## [1] 96.79319</code></pre>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="inference-for-numerical-data.html#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="fl">98.249</span> <span class="sc">+</span> <span class="fl">1.9785</span><span class="sc">*</span><span class="fl">0.733</span><span class="sc">*</span><span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">130</span>)</span></code></pre></div>
<pre><code>## [1] 99.70481</code></pre>
<!--
## 4/9/20 Agenda {#Apr9}
under the random sample model:

1. Sampling distribution of $\overline{X}_1 - \overline{X}_2$
2. Hypothesis testing (and CI) of $\mu_1 - \mu_2$

## 4/14/20 Agenda {#Apr14}
under the random allocation model:

1. Sampling distribution of $\overline{X}_1 - \overline{X}_2$
2. Confidence interval (and HT) for $\mu_1 - \mu_2$
-->
</div>
</div>
</div>
<div id="mean2inf" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Comparing two independent means</h2>
<p>It turns out that in <em>both</em> the setting where random samples are taken (e.g., NBA salaries) and the setting where random allocation is done (e.g., sleep deprivation), the t-distribution describes the distribution of the test statistic quite well. Note that the variability associated with the difference in means uses the variability of both the samples (and their individual sample sizes!).</p>
<p><span class="math display">\[\begin{eqnarray*}
\mbox{parameter} &amp;=&amp; \mu_1 - \mu_2\\
\mbox{statistic} &amp;=&amp; \overline{X}_1 - \overline{X}_2\\
SE_{\overline{X}_1 - \overline{X}_2} &amp;=&amp; ?????
\end{eqnarray*}\]</span></p>
<p>In general, the math is done on the variance (which is just the squared standard deviations).
<span class="math display">\[\begin{eqnarray*}
var(A - B) &amp;=&amp; var(A) + var(B)\\
var(\overline{X}_1 - \overline{X}_2) &amp;=&amp; var(\overline{X}_1) + var(\overline{X}_2)\\
&amp;=&amp; \sigma^2_1 / n_1 + \sigma^2_2 / n_2\\
SE(\overline{X}_1 - \overline{X}_2) &amp;=&amp; \sqrt{s^2_1 / n_1 + s^2_2 / n_2}\\
\end{eqnarray*}\]</span></p>
<p>The above methods can be used when the samples are of different sizes and when the variability in the two samples is quite different (<span class="math inline">\(s_1 \ne s_2\)</span>). If we use the above procedures, the exact degrees of freedom are not straightforward to calculate:</p>
<p><span class="math display">\[\begin{eqnarray*}
df &amp;=&amp; \frac{ \bigg(\frac{s^2_1}{n_1} + \frac{s^2_2}{n_2} \bigg)^2}{ \bigg[ \frac{(s^2_1/n_1)^2}{n_1 - 1} + \frac{(s^2_2/n_2)^2}{n_2 - 1} \bigg] }\ \ \ \ \ \ \ \mbox{Yikes!!!!}\\
df &amp;\approx&amp; \min \{ n_1 - 1, n_2 -1 \} \\
\end{eqnarray*}\]</span></p>
<p>With the SE appropriately defined, the hypothesis test and confidence interval follow the methods from earlier in the semester.</p>
<p><span class="math inline">\(H_0: \mu_1 - \mu_2 = 0\)</span><br />
<span class="math inline">\(H_A: \mu_1 - \mu_2 \ne 0\)</span></p>
<p><strong>When <span class="math inline">\(H_0\)</span> is true</strong>:</p>
<p><span class="math display">\[\begin{eqnarray*}
t &amp;=&amp; \frac{(\overline{X}_1 - \overline{X}_2) - (\mu_1 - \mu_2)_0}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}}\\
&amp;=&amp; \frac{(\overline{X}_1 - \overline{X}_2) - 0}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}}\\
&amp;\sim&amp; t_{\min \{ n_1 - 1, n_2 -1 \} }
\end{eqnarray*}\]</span></p>
<p>Which means that the <span class="math inline">\(t_{\min \{ n_1 - 1, n_2 -1 \} }\)</span>-distribution can be used to find a p-value associated with the t-score:
<span class="math display">\[\mbox{t-score} = \frac{(\overline{X}_1 - \overline{X}_2) - 0}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}}.\]</span></p>
<p>Additionally, a <span class="math inline">\((1-\alpha)100\)</span>% confidence interval for <span class="math inline">\((\mu_1 - \mu_2)\)</span> can be found by computing:</p>
<p><span class="math display">\[(\overline{X}_1 - \overline{X}_2) \pm t_{\min \{ n_1 - 1, n_2 -1 \} }^* \cdot \sqrt{s_1^2 / n_1 + s_2^2 / n_2}.\]</span></p>
<!--
$$(\overline{X}_1 - \overline{X}_2) ~ \sim N\bigg( (\mu_1 - \mu_2), \sqrt{\sigma_1^2 / n_1 + \sigma_2^2 / n_2} \bigg)$$

$$\mbox{t-score} = \frac{(\overline{X}_1 - \overline{X}_2) - 0}{\sqrt{s_1^2 / n_1 + s_2^2 / n_2}} \sim t_{\min \{ n_1 - 1, n_2 -1 \} }$$


Unfortunately, however Welch's t-test is not used as often as other t-tests (though there is research to show that Welch's t-test should be the default).  \\

\medskip
\noindent
In particular, if the standard errors are reasonably similar ($\sigma_1 \approx \sigma_2$), a more powerful test is given by:
\begin{eqnarray*}
SE(\overline{X}_1 - \overline{X}_2) &=& \sqrt{s^2_p (1/ n_1 + 1 / n_2)}\\
s^2_p &=& \frac{(n_1-1) s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 -2}\\4
df &=& n_1 + n_2 - 2
\end{eqnarray*}
-->
</div>
<div id="r-code-for-inference-on-1-or-2-means." class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> R code for inference on 1 or 2 means.</h2>
<p>Above, R is used primarily as a calculator and a way to find the appropriate values from the t-distribution (using <code>mosaic::xpt</code> and <code>mosaic::xqt</code> <span class="math inline">\(\rightarrow\)</span> note that along with the first argument (either a probability or a place on the x-axis) it is important to add the degrees of freedom <code>df</code> and possibly the argument <code>ncp=0</code> which centers the graph at zero).</p>
<p>Consider the teacher salary data available in the OpenIntro textbook.</p>
<blockquote>
<p>This data set contains teacher salaries from 2009-2010 for 71 teachers employed by the St. Louis Public School in Michigan, as well as several covariates.
Posted on opendata.socrata.com by Jeff Kowalski. Original source: <a href="http://stlouis.edzone.net" class="uri">http://stlouis.edzone.net</a></p>
</blockquote>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="inference-for-numerical-data.html#cb145-1" aria-hidden="true" tabindex="-1"></a>teachers <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(<span class="st">&quot;https://www.openintro.org/data/tab-delimited/teacher.txt&quot;</span>, </span>
<span id="cb145-2"><a href="inference-for-numerical-data.html#cb145-2" aria-hidden="true" tabindex="-1"></a>                       <span class="at">delim=</span> <span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>)</span></code></pre></div>
<div id="t.test" class="section level3" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> <code>t.test()</code></h3>
<p>The function which is typically used to do t-tests is the function <code>t.test()</code>. Note that the <code>t.test()</code> function requires a complete dataset, not just the summary statistics. However, the <code>t.test()</code> can be used to do any of the variety of tests we’ve seen (and the ones we haven’t seen!): one sample t-test, two independent samples t-test (with or without equal variances), paired t-test.</p>
<div id="one-sample-t-test" class="section level4" number="6.4.1.1">
<h4><span class="header-section-number">6.4.1.1</span> One sample t-test</h4>
<p>For example, we might be interested in testing whether the average salary (of all teachers in St Louis) is above $47,000 a year. The p-value is extremely small. We reject <span class="math inline">\(H_0\)</span>. That is, we can claim that the true average base salary is above $47,000. (Note, to calculate a CI, use <code>alternative = "two.sided"</code>.)</p>
<p><span class="math inline">\(H_0: \mu = 47,000\)</span></p>
<p><span class="math inline">\(H_A: \mu &gt; 47,000\)</span></p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="inference-for-numerical-data.html#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(teachers<span class="sc">$</span>base, <span class="at">mu =</span> <span class="dv">47000</span>, <span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  teachers$base
## t = 7.9466, df = 70, p-value = 1.146e-11
## alternative hypothesis: true mean is greater than 47000
## 95 percent confidence interval:
##  54440.82      Inf
## sample estimates:
## mean of x 
##  56415.96</code></pre>
</div>
<div id="two-independent-samples-t-test" class="section level4" number="6.4.1.2">
<h4><span class="header-section-number">6.4.1.2</span> Two independent samples t-test</h4>
<p>Or, maybe interest is in knowing whether the base salary for teachers with a BA degree is less than those with an MA degree, on average. Note, <span class="math inline">\(\mu\)</span> denotes the average salary in the population group denoted by the subscript. The p-value is 0.442, so we would not reject the null hypothesis. (Note, to calculate a CI, use <code>alternative = "two.sided"</code>.)</p>
<p><span class="math inline">\(H_0: \mu_{BA} = \mu_{MA}\)</span></p>
<p><span class="math inline">\(H_A: \mu_{BA} &lt; \mu_{MA}\)</span></p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="inference-for-numerical-data.html#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(base <span class="sc">~</span> degree, <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>, <span class="at">data =</span> teachers)</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  base by degree
## t = -0.14639, df = 65.238, p-value = 0.442
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##      -Inf 3664.912
## sample estimates:
## mean in group BA mean in group MA 
##         56257.10         56609.56</code></pre>
</div>
</div>
<div id="infer" class="section level3" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> <code>infer</code></h3>
<p>We aren’t going to cover the bootstrapping or randomization tests for the quantitative variables. But notice that the <code>infer</code> syntax is almost identical to that which we covered when we were working with proportions.</p>
<p>Also, notice that the computational approach gives almost identical answers to the mathematical model (t-distribution) from above.</p>
<div id="one-sample-bootstrapping-on-mean" class="section level4" number="6.4.2.1">
<h4><span class="header-section-number">6.4.2.1</span> One sample bootstrapping on mean</h4>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="inference-for-numerical-data.html#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">47</span>)</span>
<span id="cb150-2"><a href="inference-for-numerical-data.html#cb150-2" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the observed test statistic</span></span>
<span id="cb150-3"><a href="inference-for-numerical-data.html#cb150-3" aria-hidden="true" tabindex="-1"></a><span class="co"># note that we could use `stat = &quot;median&quot;` or `stat = &quot;t&quot;`</span></span>
<span id="cb150-4"><a href="inference-for-numerical-data.html#cb150-4" aria-hidden="true" tabindex="-1"></a>( x_bar_base <span class="ot">&lt;-</span> teachers <span class="sc">%&gt;%</span></span>
<span id="cb150-5"><a href="inference-for-numerical-data.html#cb150-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">response =</span> base) <span class="sc">%&gt;%</span></span>
<span id="cb150-6"><a href="inference-for-numerical-data.html#cb150-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;mean&quot;</span>) )</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##     stat
##    &lt;dbl&gt;
## 1 56416.</code></pre>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="inference-for-numerical-data.html#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create the null sampling distribution</span></span>
<span id="cb152-2"><a href="inference-for-numerical-data.html#cb152-2" aria-hidden="true" tabindex="-1"></a>null_dist <span class="ot">&lt;-</span> teachers <span class="sc">%&gt;%</span></span>
<span id="cb152-3"><a href="inference-for-numerical-data.html#cb152-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">response =</span> base) <span class="sc">%&gt;%</span></span>
<span id="cb152-4"><a href="inference-for-numerical-data.html#cb152-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hypothesize</span>(<span class="at">null =</span> <span class="st">&quot;point&quot;</span>, <span class="at">mu =</span> <span class="dv">47000</span>) <span class="sc">%&gt;%</span></span>
<span id="cb152-5"><a href="inference-for-numerical-data.html#cb152-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">generate</span>(<span class="at">reps =</span> <span class="dv">1000</span>, <span class="at">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb152-6"><a href="inference-for-numerical-data.html#cb152-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;mean&quot;</span>)</span>
<span id="cb152-7"><a href="inference-for-numerical-data.html#cb152-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb152-8"><a href="inference-for-numerical-data.html#cb152-8" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the null sampling distribution</span></span>
<span id="cb152-9"><a href="inference-for-numerical-data.html#cb152-9" aria-hidden="true" tabindex="-1"></a><span class="fu">visualize</span>(null_dist) <span class="sc">+</span></span>
<span id="cb152-10"><a href="inference-for-numerical-data.html#cb152-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">shade_p_value</span>(<span class="at">obs_stat =</span> x_bar_base, <span class="at">direction =</span> <span class="st">&quot;greater&quot;</span>)</span></code></pre></div>
<p><img src="04-InfNum_files/figure-html/unnamed-chunk-7-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="inference-for-numerical-data.html#cb153-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the p-value</span></span>
<span id="cb153-2"><a href="inference-for-numerical-data.html#cb153-2" aria-hidden="true" tabindex="-1"></a>null_dist <span class="sc">%&gt;%</span></span>
<span id="cb153-3"><a href="inference-for-numerical-data.html#cb153-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">get_p_value</span>(<span class="at">obs_stat =</span> x_bar_base, <span class="at">direction =</span> <span class="st">&quot;greater&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1       0</code></pre>
</div>
<div id="two-independent-samples-comparing-two-means" class="section level4" number="6.4.2.2">
<h4><span class="header-section-number">6.4.2.2</span> Two independent samples comparing two means</h4>
<p>p-value is now 0.464 (very close to 0.442 given by the smooth t-distribution curve).</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="inference-for-numerical-data.html#cb155-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">47</span>)</span>
<span id="cb155-2"><a href="inference-for-numerical-data.html#cb155-2" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the observed test statistic</span></span>
<span id="cb155-3"><a href="inference-for-numerical-data.html#cb155-3" aria-hidden="true" tabindex="-1"></a>( diff_x_bar_base <span class="ot">&lt;-</span> teachers <span class="sc">%&gt;%</span></span>
<span id="cb155-4"><a href="inference-for-numerical-data.html#cb155-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">specify</span>(base <span class="sc">~</span> degree) <span class="sc">%&gt;%</span></span>
<span id="cb155-5"><a href="inference-for-numerical-data.html#cb155-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;diff in means&quot;</span>, <span class="at">order =</span> <span class="fu">c</span>(<span class="st">&quot;MA&quot;</span>, <span class="st">&quot;BA&quot;</span>)) )</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##    stat
##   &lt;dbl&gt;
## 1  352.</code></pre>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="inference-for-numerical-data.html#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create the null sampling distribution</span></span>
<span id="cb157-2"><a href="inference-for-numerical-data.html#cb157-2" aria-hidden="true" tabindex="-1"></a>null_dist <span class="ot">&lt;-</span> teachers <span class="sc">%&gt;%</span></span>
<span id="cb157-3"><a href="inference-for-numerical-data.html#cb157-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">specify</span>(base <span class="sc">~</span> degree) <span class="sc">%&gt;%</span></span>
<span id="cb157-4"><a href="inference-for-numerical-data.html#cb157-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hypothesize</span>(<span class="at">null =</span> <span class="st">&quot;independence&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb157-5"><a href="inference-for-numerical-data.html#cb157-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">generate</span>(<span class="at">reps =</span> <span class="dv">1000</span>, <span class="at">type =</span><span class="st">&quot;permute&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb157-6"><a href="inference-for-numerical-data.html#cb157-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;diff in means&quot;</span>, <span class="at">order =</span> <span class="fu">c</span>(<span class="st">&quot;MA&quot;</span>, <span class="st">&quot;BA&quot;</span>)) </span>
<span id="cb157-7"><a href="inference-for-numerical-data.html#cb157-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-8"><a href="inference-for-numerical-data.html#cb157-8" aria-hidden="true" tabindex="-1"></a><span class="co"># visualize the null sampling distribution</span></span>
<span id="cb157-9"><a href="inference-for-numerical-data.html#cb157-9" aria-hidden="true" tabindex="-1"></a><span class="fu">visualize</span>(null_dist) <span class="sc">+</span></span>
<span id="cb157-10"><a href="inference-for-numerical-data.html#cb157-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">shade_p_value</span>(<span class="at">obs_stat =</span> diff_x_bar_base, <span class="at">direction =</span> <span class="st">&quot;greater&quot;</span>)</span></code></pre></div>
<p><img src="04-InfNum_files/figure-html/unnamed-chunk-8-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="inference-for-numerical-data.html#cb158-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the p-value</span></span>
<span id="cb158-2"><a href="inference-for-numerical-data.html#cb158-2" aria-hidden="true" tabindex="-1"></a>null_dist <span class="sc">%&gt;%</span></span>
<span id="cb158-3"><a href="inference-for-numerical-data.html#cb158-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">get_p_value</span>(<span class="at">obs_stat =</span> diff_x_bar_base, <span class="at">direction =</span> <span class="st">&quot;greater&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1   0.454</code></pre>
</div>
</div>
<div id="nba-salaries-example-from-iscam-inv-4.2" class="section level3" number="6.4.3">
<h3><span class="header-section-number">6.4.3</span> NBA Salaries example from ISCAM Inv 4.2</h3>
<p>There is R code in the ISCAM book. I’ve written the series of steps in a slightly different way with the same results.</p>
<div id="eda" class="section level4" number="6.4.3.1">
<h4><span class="header-section-number">6.4.3.1</span> EDA</h4>
<p>Before thinking about inference, let’s look at the population (for 2017-18). The information for today is the population because it includes the salaries of all NBA players in 2017. We can see that in this particular year, the average salary in the Western conference is slightly higher.</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="inference-for-numerical-data.html#cb160-1" aria-hidden="true" tabindex="-1"></a>NBAsalary <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(<span class="st">&quot;http://www.rossmanchance.com/iscam3/data/NBASalaries2017.txt&quot;</span>, <span class="at">delim =</span> <span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>, <span class="at">escape_double =</span> <span class="cn">FALSE</span>, <span class="at">trim_ws =</span> <span class="cn">TRUE</span>)</span>
<span id="cb160-2"><a href="inference-for-numerical-data.html#cb160-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-3"><a href="inference-for-numerical-data.html#cb160-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-4"><a href="inference-for-numerical-data.html#cb160-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(NBAsalary) <span class="sc">+</span></span>
<span id="cb160-5"><a href="inference-for-numerical-data.html#cb160-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>conference, <span class="at">y =</span> salary))</span></code></pre></div>
<p><img src="04-InfNum_files/figure-html/unnamed-chunk-9-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="inference-for-numerical-data.html#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(NBAsalary) <span class="sc">+</span></span>
<span id="cb161-2"><a href="inference-for-numerical-data.html#cb161-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">fill =</span> conference, <span class="at">x =</span> salary))</span></code></pre></div>
<p><img src="04-InfNum_files/figure-html/unnamed-chunk-9-2.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="inference-for-numerical-data.html#cb162-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(NBAsalary) <span class="sc">+</span></span>
<span id="cb162-2"><a href="inference-for-numerical-data.html#cb162-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> salary)) <span class="sc">+</span> </span>
<span id="cb162-3"><a href="inference-for-numerical-data.html#cb162-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> conference)</span></code></pre></div>
<p><img src="04-InfNum_files/figure-html/unnamed-chunk-9-3.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="inference-for-numerical-data.html#cb163-1" aria-hidden="true" tabindex="-1"></a>NBAsalary <span class="sc">%&gt;%</span></span>
<span id="cb163-2"><a href="inference-for-numerical-data.html#cb163-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(conference) <span class="sc">%&gt;%</span></span>
<span id="cb163-3"><a href="inference-for-numerical-data.html#cb163-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mu =</span> <span class="fu">mean</span>(salary), <span class="at">sigma =</span> <span class="fu">sd</span>(salary), <span class="at">N =</span> <span class="fu">n</span>(), <span class="fu">min</span>(salary), <span class="fu">max</span>(salary), <span class="fu">median</span>(salary))</span></code></pre></div>
<pre><code>## # A tibble: 2 x 7
##   conference    mu sigma     N `min(salary)` `max(salary)` `median(salary)`
##   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;         &lt;dbl&gt;         &lt;dbl&gt;            &lt;dbl&gt;
## 1 eastern     6.61  7.01   227        0.0577          33.3             3.81
## 2 western     7.42  7.76   221        0.0320          34.4             4</code></pre>
</div>
<div id="sampling-distribution-for-one-mean" class="section level4" number="6.4.3.2">
<h4><span class="header-section-number">6.4.3.2</span> Sampling distribution for one mean</h4>
<p>Before considering how the sample means vary, let’s visualize samples from each conference.</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="inference-for-numerical-data.html#cb165-1" aria-hidden="true" tabindex="-1"></a>NBAsalary <span class="sc">%&gt;%</span></span>
<span id="cb165-2"><a href="inference-for-numerical-data.html#cb165-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(conference <span class="sc">==</span> <span class="st">&quot;eastern&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb165-3"><a href="inference-for-numerical-data.html#cb165-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sample_n</span>(<span class="at">size =</span> <span class="dv">20</span>, <span class="at">replace =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb165-4"><a href="inference-for-numerical-data.html#cb165-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb165-5"><a href="inference-for-numerical-data.html#cb165-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> salary)) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;eastern salary&quot;</span>)</span>
<span id="cb165-6"><a href="inference-for-numerical-data.html#cb165-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb165-7"><a href="inference-for-numerical-data.html#cb165-7" aria-hidden="true" tabindex="-1"></a>NBAsalary <span class="sc">%&gt;%</span></span>
<span id="cb165-8"><a href="inference-for-numerical-data.html#cb165-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(conference <span class="sc">==</span> <span class="st">&quot;western&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb165-9"><a href="inference-for-numerical-data.html#cb165-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sample_n</span>(<span class="at">size =</span> <span class="dv">20</span>, <span class="at">replace =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb165-10"><a href="inference-for-numerical-data.html#cb165-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb165-11"><a href="inference-for-numerical-data.html#cb165-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> salary)) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&quot;western salary&quot;</span>)</span></code></pre></div>
<p><img src="04-InfNum_files/figure-html/unnamed-chunk-10-1.png" width="768" style="display: block; margin: auto;" /><img src="04-InfNum_files/figure-html/unnamed-chunk-10-2.png" width="768" style="display: block; margin: auto;" /></p>
<p>One way to think about how the difference in means varies is to first visualize the variability in the distribution for a single mean (i.e., from one conference). Let’s look at the variability in the Eastern conference as well as the variability in the Western conference.</p>
<p>Note that from the population analysis above (full set of observations), we see that <span class="math inline">\(\sigma \approx 7\)</span>. So the histograms below should have a standard deviation of close to <span class="math inline">\(\sigma / \sqrt{20} = 1.5\)</span>. Do they?</p>
<p>Are the two histograms centered at the same place? Should they be?</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="inference-for-numerical-data.html#cb166-1" aria-hidden="true" tabindex="-1"></a>NBAsalary <span class="sc">%&gt;%</span></span>
<span id="cb166-2"><a href="inference-for-numerical-data.html#cb166-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(conference <span class="sc">==</span> <span class="st">&quot;eastern&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb166-3"><a href="inference-for-numerical-data.html#cb166-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rep_sample_n</span>(<span class="at">size =</span> <span class="dv">20</span>, <span class="at">replace =</span> <span class="cn">FALSE</span>, <span class="at">reps =</span> <span class="dv">500</span>) <span class="sc">%&gt;%</span></span>
<span id="cb166-4"><a href="inference-for-numerical-data.html#cb166-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_sal =</span> <span class="fu">mean</span>(salary)) <span class="sc">%&gt;%</span></span>
<span id="cb166-5"><a href="inference-for-numerical-data.html#cb166-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb166-6"><a href="inference-for-numerical-data.html#cb166-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x=</span>mean_sal))</span></code></pre></div>
<p><img src="04-InfNum_files/figure-html/unnamed-chunk-11-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="inference-for-numerical-data.html#cb167-1" aria-hidden="true" tabindex="-1"></a>NBAsalary <span class="sc">%&gt;%</span></span>
<span id="cb167-2"><a href="inference-for-numerical-data.html#cb167-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(conference <span class="sc">==</span> <span class="st">&quot;western&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb167-3"><a href="inference-for-numerical-data.html#cb167-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rep_sample_n</span>(<span class="at">size =</span> <span class="dv">20</span>, <span class="at">replace =</span> <span class="cn">FALSE</span>, <span class="at">reps =</span> <span class="dv">500</span>) <span class="sc">%&gt;%</span></span>
<span id="cb167-4"><a href="inference-for-numerical-data.html#cb167-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_sal =</span> <span class="fu">mean</span>(salary)) <span class="sc">%&gt;%</span></span>
<span id="cb167-5"><a href="inference-for-numerical-data.html#cb167-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb167-6"><a href="inference-for-numerical-data.html#cb167-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x=</span>mean_sal))</span></code></pre></div>
<p><img src="04-InfNum_files/figure-html/unnamed-chunk-11-2.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<div id="sampling-distribution-for-two-means" class="section level4" number="6.4.3.3">
<h4><span class="header-section-number">6.4.3.3</span> Sampling distribution for two means</h4>
<p>Note: the code selects 20 random salaries from the Eastern NBA conference and 20 random salaries from the Western NBA conference. Using those two different samples, a t-statistic is selected. The whole process is repeated 1000 times.</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="inference-for-numerical-data.html#cb168-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4747</span>)</span>
<span id="cb168-2"><a href="inference-for-numerical-data.html#cb168-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb168-3"><a href="inference-for-numerical-data.html#cb168-3" aria-hidden="true" tabindex="-1"></a>t_salaries <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">meandiff =</span> <span class="fu">double</span>(), <span class="at">tstat =</span> <span class="fu">double</span>())</span>
<span id="cb168-4"><a href="inference-for-numerical-data.html#cb168-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>){</span>
<span id="cb168-5"><a href="inference-for-numerical-data.html#cb168-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb168-6"><a href="inference-for-numerical-data.html#cb168-6" aria-hidden="true" tabindex="-1"></a>  one_t<span class="ot">&lt;-</span> NBAsalary <span class="sc">%&gt;%</span></span>
<span id="cb168-7"><a href="inference-for-numerical-data.html#cb168-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(conference) <span class="sc">%&gt;%</span></span>
<span id="cb168-8"><a href="inference-for-numerical-data.html#cb168-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sample_n</span>(<span class="at">size =</span> <span class="dv">20</span>, <span class="at">replace =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb168-9"><a href="inference-for-numerical-data.html#cb168-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">mn =</span> <span class="fu">mean</span>(salary), <span class="at">sd =</span> <span class="fu">sd</span>(salary), <span class="at">n =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb168-10"><a href="inference-for-numerical-data.html#cb168-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> conference, <span class="at">values_from =</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>) <span class="sc">%&gt;%</span></span>
<span id="cb168-11"><a href="inference-for-numerical-data.html#cb168-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">meandiff =</span> (mn_eastern <span class="sc">-</span> mn_western), </span>
<span id="cb168-12"><a href="inference-for-numerical-data.html#cb168-12" aria-hidden="true" tabindex="-1"></a>              <span class="at">tstat =</span> (mn_eastern <span class="sc">-</span> mn_western) <span class="sc">/</span> </span>
<span id="cb168-13"><a href="inference-for-numerical-data.html#cb168-13" aria-hidden="true" tabindex="-1"></a>                <span class="fu">sqrt</span>(sd_eastern<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> n_eastern <span class="sc">+</span> sd_western<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> n_western)) </span>
<span id="cb168-14"><a href="inference-for-numerical-data.html#cb168-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb168-15"><a href="inference-for-numerical-data.html#cb168-15" aria-hidden="true" tabindex="-1"></a>  t_salaries[i,] <span class="ot">&lt;-</span> one_t</span>
<span id="cb168-16"><a href="inference-for-numerical-data.html#cb168-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb168-17"><a href="inference-for-numerical-data.html#cb168-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb168-18"><a href="inference-for-numerical-data.html#cb168-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb168-19"><a href="inference-for-numerical-data.html#cb168-19" aria-hidden="true" tabindex="-1"></a>t_salaries <span class="sc">%&gt;%</span></span>
<span id="cb168-20"><a href="inference-for-numerical-data.html#cb168-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb168-21"><a href="inference-for-numerical-data.html#cb168-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x=</span>meandiff)) <span class="sc">+</span></span>
<span id="cb168-22"><a href="inference-for-numerical-data.html#cb168-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="04-InfNum_files/figure-html/unnamed-chunk-12-1.png" width="480" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="inference-for-numerical-data.html#cb169-1" aria-hidden="true" tabindex="-1"></a>t_salaries <span class="sc">%&gt;%</span></span>
<span id="cb169-2"><a href="inference-for-numerical-data.html#cb169-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb169-3"><a href="inference-for-numerical-data.html#cb169-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x=</span>tstat)) <span class="sc">+</span></span>
<span id="cb169-4"><a href="inference-for-numerical-data.html#cb169-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>)</span></code></pre></div>
<p><img src="04-InfNum_files/figure-html/unnamed-chunk-12-2.png" width="480" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
<div id="reflection-questions-2" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Reflection Questions</h2>
<p>In the interest of pairing down topics for Spring 2020, the following topics will not be covered:</p>
<ul>
<li>all of the computational tests associated with two means (e.g., bootstrapping, randomization test, etc.). This includes the following sections in the books that we will not cover: ISCAM Inv 2.9, 4.4, 4.9, 4.11 &amp; ISRS 4.5.</li>
<li>we will not discussed paired samples (e.g., “before and after,” “left and right car tires,” etc.). This includes the following sections in the books that we will not cover: ISCAM Inv 4.8, 4.9, 4.10, 4.11 &amp; ISRS 4.2.</li>
<li>we will not cover ANVOA. This includes the following sections in the books that we will not cover: ISCAM Inv 5.4, 5.5 &amp; ISRS 4.4.</li>
</ul>
<p>The reflection questions below that we will not cover are marked with an asterisk *.</p>
<div id="quantitative-variable-chapter-4-section-1" class="section level3" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> 1 quantitative variable: Chapter 4, Section 1</h3>
<ol style="list-style-type: decimal">
<li>What changed about the studies (data structure) from Chapters 2 &amp; 3?</li>
<li>What is the statistic of interest now? What is the parameter of interest?</li>
<li>What is the difference between the distribution of the data and the distribution of the statistic? There is a theoretical difference as well as a computational difference.</li>
<li>What is the limiting sampling distribution of the statistic? (Note, the answer here is for big samples, that is the Central <strong>Limit</strong> Theorem works only where there is a limit… i.e., the sample size is big.)</li>
<li>If interest is in a statistics other than the sample mean, what is a tool we can use for finding the alternative statistic’s sampling distribution?</li>
<li><ul>
<li>Explain the intuition behind bootstrapping.</li>
</ul></li>
<li><ul>
<li>Explain how the SE for the statistic is calculated using bootstrapping.</li>
</ul></li>
<li>What is the difference between a normal distribution and a t distribution?</li>
<li>When do we use a z and when do we use a t?</li>
<li>When would you use a confidence interval and when would you use a hypothesis test?</li>
<li>What different information does a boxplot give versus a histogram?</li>
</ol>
</div>
<div id="means-1-quantitative-variable-1-binary-variable-chapter-4-section-3" class="section level3" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> 2 means (1 quantitative variable, 1 binary variable): Chapter 4, Section 3</h3>
<ol style="list-style-type: decimal">
<li>What changed about the studies (data structure) from section 4.1?</li>
<li>What is the statistic of interest now? What is the parameter of interest?</li>
<li>What is the sampling distribution for the statistic of interest?</li>
<li>How is the t-distribution become relevant?</li>
<li>What are degrees of freedom in general? What are the actual degrees of freedom for the test in section 4.3?</li>
<li><ul>
<li>How is the null mechanism different across the three analysis methods in section 3.2: randomization test, two-sample t-test, random sampling test (n.b. this is also called the parametric bootstrap)?</li>
</ul></li>
<li>How do you create a CI? How do you interpret the CI?</li>
<li>What if your data are NOT normal? What strategies can you try out?</li>
</ol>
<div id="paired-sample-difference-in-means" class="section level4" number="6.5.2.1">
<h4><span class="header-section-number">6.5.2.1</span> Paired sample, difference in means</h4>
<ol style="list-style-type: decimal">
<li>What changed about the studies (data structure) in section 4.2 as compared with 4.1 or 4.3?</li>
<li>What is the statistic of interest now? What is the parameter of interest?</li>
<li>What is the sampling distribution for the statistic of interest?</li>
<li>What benefit does pairing have on the analysis?</li>
<li>What happens if a paired study is analyzed as if it were an independent two sample study? (What happens to the p-value? What happens to the CI?)</li>
<li>What is the easiest way to think of / analyze paired data?</li>
</ol>
</div>
<div id="not-covering-in-spring-2021-anova" class="section level4" number="6.5.2.2">
<h4><span class="header-section-number">6.5.2.2</span> * (not covering in Spring 2021) ANOVA</h4>
<ol style="list-style-type: decimal">
<li>Why are these tests called ANalysis Of VAriance (ANOVA)?</li>
<li>Describe the variability in the numerator and the variability in the denominator. What does each measure?</li>
<li>What are the null and alternative hypotheses for ANOVA?</li>
<li>What features of the data affect the power of the test? What does power mean here?</li>
<li>What are the technical conditions? Why do we need equal variances here?</li>
</ol>

</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="18">
<li id="fn18"><p>Inv 2.5, Chance &amp; Rossman, ISCAM<a href="inference-for-numerical-data.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>Conventional wisdom says that the reason 98.6 has hung around is because it translates to 35 C. Indeed, it it agreed that, to the nearest integer, the average healthy human body temperature is 37 C. But there is also some consensus that it is slightly lower than 37 C (if we are willing to use more significant digits). The idea is that we have hung on to 98.6 because the decimal <em>feels</em> like a precise measurement. In reality, it is just the conversion from 37 C to F.<a href="inference-for-numerical-data.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>Mackowiak, Wasserman, &amp; Levine, <em>Journal of the American Medical Association</em>, 1992<a href="inference-for-numerical-data.html#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p>Inv 2.6, Chance &amp; Rossman, ISCAM<a href="inference-for-numerical-data.html#fnref21" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="interlude-in-spring-2020.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="correlation-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-InfNum.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Math-58-Notes.pdf", "Math-58-Notes.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
