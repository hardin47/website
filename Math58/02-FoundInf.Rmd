# Foundations for Inference

## 1/23/20 Agenda {#Jan23}
1. Example: gender discrimination
2. `infer` again
3. Hypothesis testing structure




## Example: Gender Discrimination {#ex:gend}

> We consider a study investigating gender discrimination in the 1970s, which is set in the context of personnel decisions within a bank.^[Rosen B and Jerdee T. 1974. Influence of sex role stereotypes on personnel decisions. Journal of Applied Psychology 59(1):9-14.] The research question we hope to answer is, "Are females discriminated against in promotion decisions made by male managers?"

> The participants in this study were 48 male bank supervisors attending a management institute at the University of North Carolina in 1972. They were asked to assume the role of the personnel director of a bank and were given a personnel file to judge whether the person should be promoted to a branch manager position. The files given to the participants were identical, except that half of them indicated the candidate was male and the other half indicated the candidate was female. These files were randomly assigned to the subjects.

> For each supervisor we recorded the gender associated with the assigned file and the promotion decision. Using the results of the study summarized in Table 2.1, we would like to evaluate if females are unfairly discriminated against in promotion decisions. In this study, a smaller proportion of females are promoted than males (0.583 versus 0.875), but it is unclear whether the difference provides convincing evidence that females are unfairly discriminated against.   (@isrs, pg 61) 

|   |        |          | decision     |       |
|---|--------|----------|--------------|-------|
|   |        | promoted | not promoted | total |
|   | male   | 21       | 3            | 24    |
|   | female | 14       | 10           | 24    |
|   | total  | 35       | 13           | 48    |


#### Always Ask {-}

* What are the observational units?
    - supervisor
* What are the variables?  What type of variables?
    - (1) whether the resume was male or female (categorical)
    - (2) decision to promote or not promote (categorical)
* What is the statistic?
    - $\hat{p}_m - \hat{p}_f$ = 21/24 - 14/24 = 0.292  (the difference between the proportion of men who were promoted and the proportion of women who were promoted)
* What is the parameter?
    - $p_m - p_f$ = the true difference in the probability of a man being promoted minus the probability of a woman being promoted.
    
#### Hypotheses {-}

H0: Null hypothesis. The variables gender and decision are independent. They have no relationship, and therefore any observed difference between the proportion of males and females who were promoted is due to chance.

HA: Alternative hypothesis. The variables gender and decision are not independent. Any observed difference between the proportion of males and females who were promoted is **not** due to chance.

#### Computation {-}

```{r echo=TRUE, eval=TRUE}
library(infer)

# to control the randomness
set.seed(47)

# first create a data frame with the discrimination data
discrim <- data.frame(gender = c(rep("male", 24), rep("female", 24)),
                      decision = c(rep("promote", 21), rep("not", 3), 
                                   rep("promote", 14), rep("not", 10)))

discrim %>% head()


# then find the difference in proportion who are promoted
(diff_obs <- discrim %>%
    specify(decision ~ gender, success = "promote") %>%
    calculate(stat = "diff in props", order = c("male", "female")) )
    

# now apply the infer framework to get the null differences in proportions
null_discrim <- discrim %>%
  specify(decision ~ gender, success = "promote") %>%
  hypothesize(null = "independence") %>%
  generate(reps = 10000, type = "permute") %>%
  calculate(stat = "diff in props", order = c("male", "female"))

# then visualize the null sampling distribution & p-value
visualize(null_discrim, bins = 10) +
  shade_p_value(obs_stat = diff_obs, direction = "greater")

# calculate the actual p-value
null_discrim %>%
  get_p_value(obs_stat = diff_obs, direction = "greater")
```

#### Logic for what we believe {-}

1. We know that the study was an experiment, so there should be no **systematic** differences between the group who received "male" applications and "female" applications.

2. We've ruled out random chance as the reason for the huge difference in proportions.  (We reject the null hypothesis.)  if we lived in the null reality, we'd only see data like these about 2.5% of the time.

3. We conclude that gender and decision are not independent.  That is, knowing the gender changes the probability of promotion.



## Structure of Hypothesis testing

### Hypotheses

* **Hypothesis Testing** compares data to the expectation of a specific null hypothesis.  If the data are unusual, assuming that the null hypothesis is true, then the null hypothesis is rejected.  

* The **Null Hypothesis**, $H_0$, is a specific statement about a population made for the purposes of argument.  A good null hypothesis is a statement that would be interesting to reject. 

* The **Alternative Hypothesis**, $H_A$, is a specific statement about a population that is in the researcher's interest to demonstrate.  Typically, the alternative hypothesis contains all the values of the population that are not included in the null hypothesis. 

* In a **two-sided** (or two-tailed) test, the alternative hypothesis includes values on both sides of the value specified by the null hypothesis.

* In a **one-sided** (or one-tailed) test, the alternative hypothesis includes parameter values on only one side of the value specified by the null hypothesis. $H_0$ is rejected only if the data depart from it in the direction stated by $H_A$.


### Other pieces of the process

* A  **statistic** is a numerical measurement we get from the sample, a function of the data. [Also sometimes called an **estimate**.]

* A  **parameter** is a numerical measurement of the population.  We never know the true value of the parameter.

* The **test statistic** is a quantity calculated from the data that is used to evaluate how compatible the data are with the result expected under the null hypothesis.

* The **null distribution** is the sampling distribution of outcomes for a test statistic under the assumption that the null hypothesis is true. 

* The **p-value** is the probability of obtaining the data (or data showing as great or greater difference from the null hypothesis) if the null hypothesis is true.  *The p-value is a number calculated from the dataset.*


#### Examples of Hypotheses {-}
Identify whether each of the following statements is more appropriate as the null hypothesis or as the alternative hypothesis in a test:

* The number of hours preschool children spend watching TV affects how they behave with other children when at day care.  *Alternative*

* Most genetic mutations are deleterious.  *Alternative*

* A diet of fast foods has no effect on liver function.  *Null*

* Cigarette smoking influences risk of suicide.  *Alternative*

* Growth rates of forest trees are unaffected by increases in carbon dioxide levels in the atmosphere.  *Null*

* The number of hours that grade-school children spend doing homework predicts their future success on standardized tests.  *Alternative*

* King cheetahs on average run the same speed as standard spotted cheetahs. *Null*

* The risk of facial clefts is equal for babies born to mothers who take folic acid supplements compared with those from mothers who do not.  *Null*

* The mean length of African elephant tusks has changed over the last 100 years.  *Alternative*

* Caffeine intake during pregnancy affects mean birth weight.  *Alternative*

#### What is an Alternative Hypothesis? {-}

Consider the brief video from the movie Slacker, an early movie by Richard Linklater (director of Boyhood, School of Rock, Before Sunrise, etc.). You can view the video here from starting at 2:22 and ending at 4:30:  https://www.youtube.com/watch?v=b-U_I1DCGEY

In the video, a rider in the back of a taxi (played by Linklater himself) muses about alternate realities that could have happened as he arrived in Austin on the bus. What if instead of taking a taxi, he had found a ride with a woman at the bus station? He could have take a different road into a different alternate reality, and in that reality his current reality would be an alternate reality. And so on.

What is the point?  Why did we see the video?  How does it relate the to the material from class?  What is the relationship to sampling distributions?


###  All together:  structure of a hypothesis test

* collect data, **specify** the variables of interest
* provide the null (and alternative) **hypothesis** values (often statements about parameters)
* **generate** a (null) sampling distribution to describe the variability of the statistic that was **calculated** along the way
* **visualize** the distribution of the statistics under the null model
* **get_p_value** to measure the consistency of the observed statistic and the possible values of the statistic under the null model
* make a conclusion using words that describe the research setting

## 1/28/20 Agenda {#Jan28}
1. Central Limit Theorm
2. Mathematical approximation for one proportion

## Normal Model


### Central Limit Theorm {#CLT}


#### Example: Reese's Pieces {-}

As with many of the examples, the Reese's Pieces example comes from @iscam.  The example focuses on how the samples of orange Reese's Pieces vary from sample to sample.  Today we aren't particularly interested in a specific research question, instead we are trying to understand the details of the model which describes how $\hat{p}$ varies from sample to sample.  [Spoiler: the distribution is going to look like a bell!  and the mathematical model which describes the variability is called the normal distribution.]

Notes from the applet: http://www.rossmanchance.com/applets/OneProp/OneProp.htm?candy=1

* How does the sampling distribution change as a function of $p$ and $n$?
* When a normal distribution is placed on top of the empirical (computational) distribution, does it fit well?




A *sampling distribution* is the probability distribution of all possible values of the *statistic* in all possible samples of the same size from the same population.  Note: increasing the sample size reduces the spread of the sampling distribution of a statistic (i.e., increases the precision).

##### Normal Probability Curve {-}

* symmetric
* bell-shaped
* centered at $\mu$
* $\sigma$ shows the point of inflection
* draw a picture **every** time you start a normal problem!

The Central Limit Theorem

> **The Central Limit Theorem** says that the sampling distribution of an  *average* will have a bell shaped distribution if $n$ is big enough.


The sampling distribution of $\hat{p} = X/n$ can be thought of as taking lots of random samples from a population, calculating $\hat{p}$, and creating a histogram.  We can easily calculate what we'd expect from that sampling distribution if we know $p$, the true population proportion.  In fact, we saw two different sampling distributions (under two different hypotheses) in the Baseball example.



Because $\hat{p}$ is actually an average (we talked about that with the birth data), the sampling distribution of $\hat{p}$ can be described by a normal distribution (as long as $n$ is big enough).

\begin{eqnarray*}
\hat{p} &=& \frac{X}{n}\\
SD(\hat{p}) = \sigma_{\hat{p}} &=& \sqrt{\frac{p (1-p)}{n}}\\
SE(\hat{p}) &=& \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\\
\hat{p} &\sim& N\bigg(p, \frac{p(1-p)}{n} \bigg) \ \ \ \ \ \mbox{ (if the sample size is large enough)}\\
\end{eqnarray*}


We would expect 95% of our $\hat{p}$ values to be within 2 standard deviations of the mean.  That is, 95% of $\hat{p}$ are:
\begin{eqnarray*}
p \pm 2 \sqrt{\frac{p(1-p)}{n}}
\end{eqnarray*}
Or put differently, when referring to a randomly selected $\hat{p}$,
\begin{eqnarray*}
P\bigg( - 2 \sqrt{\frac{p(1-p)}{n}} \leq \hat{p} - p \leq 2 \sqrt{\frac{p(1-p)}{n}}\bigg) = 0.95\\
P\bigg(\hat{p} - 2 \sqrt{\frac{p(1-p)}{n}} \leq  p \leq \hat{p} + 2 \sqrt{\frac{p(1-p)}{n}}\bigg) = 0.95
\end{eqnarray*}

We'd love to create our interval for $p$ using $\hat{p} \pm 2 \sqrt{\frac{p(1-p)}{n}}$, but we don't know $p$!  One option is to use $SE(\hat{p})$ in the estimate of the variability.

##### The Empirical Rule {-}

In a bell-shaped, symmetric distribution,

| % of data | in what interval   |
|:-------------|:----------------------------|
|$\approx 68\%$ | of the observations fall within 1 st dev of the mean |
|$\approx 95\%$ | of the observations fall within 2 st dev of the mean |
|$\approx 99.7\%$ | of the observations fall within 3 st dev of the mean |




<!--
%Show gorilla move:
%\url{viscog.beckman.uiuc.edu/flashmovie/15.php}
-->



## 1/30/20 Agenda {#Jan30}
1. Normal distribution (no q-q plots)
2. Calculting normal probabilities


### Normal Probabilities & z-scores {#norm}

## Confidence Intervals
