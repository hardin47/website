<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Poisson Regression | Methods in Biostatistics</title>
  <meta name="description" content="Class notes for Math 150 at Pomona College: Methods in Biostatistics. The notes are based primarily on the text Practicing Statistics, Kuiper and Sklar" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Poisson Regression | Methods in Biostatistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Class notes for Math 150 at Pomona College: Methods in Biostatistics. The notes are based primarily on the text Practicing Statistics, Kuiper and Sklar" />
  <meta name="github-repo" content="hardin47/website/Math150/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Poisson Regression | Methods in Biostatistics" />
  
  <meta name="twitter:description" content="Class notes for Math 150 at Pomona College: Methods in Biostatistics. The notes are based primarily on the text Practicing Statistics, Kuiper and Sklar" />
  

<meta name="author" content="Jo Hardin" />


<meta name="date" content="2020-12-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multiple-comparisons.html"/>
<link rel="next" href="references.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Methods in Biostatistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Class Information</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#course-goals"><i class="fa fa-check"></i><b>1.1</b> Course Goals</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#using-r"><i class="fa fa-check"></i><b>1.2</b> Using R</a>
<ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#experimental-design"><i class="fa fa-check"></i>Experimental Design</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html"><i class="fa fa-check"></i><b>2</b> t-tests vs. SLR</a>
<ul>
<li class="chapter" data-level="" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#surgery-timing"><i class="fa fa-check"></i>Surgery Timing</a></li>
<li class="chapter" data-level="2.1" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#ttest"><i class="fa fa-check"></i><b>2.1</b> t-test (book: 2.1)</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#what-is-an-alternative-hypothesis"><i class="fa fa-check"></i><b>2.1.1</b> What is an Alternative Hypothesis?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#anova"><i class="fa fa-check"></i>ANOVA</a></li>
<li class="chapter" data-level="2.2" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#tslr"><i class="fa fa-check"></i><b>2.2</b> Simple Linear Regression (book: 2.3)</a>
<ul>
<li class="chapter" data-level="" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#why-are-they-the-same"><i class="fa fa-check"></i>Why are they the same?</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#confidence-intervals-section-2.11"><i class="fa fa-check"></i><b>2.3</b> Confidence Intervals (section 2.11)</a></li>
<li class="chapter" data-level="2.4" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#random-sample-vs.-random-allocation"><i class="fa fa-check"></i><b>2.4</b> Random Sample vs. Random allocation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="SLR.html"><a href="SLR.html"><i class="fa fa-check"></i><b>3</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="SLR.html"><a href="SLR.html#transformations"><i class="fa fa-check"></i><b>3.1</b> Transformations</a>
<ul>
<li class="chapter" data-level="" data-path="SLR.html"><a href="SLR.html#model-assumptions"><i class="fa fa-check"></i>Model assumptions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="SLR.html"><a href="SLR.html#fitting-the-regression-line"><i class="fa fa-check"></i><b>3.2</b> Fitting the regression line</a></li>
<li class="chapter" data-level="3.3" data-path="SLR.html"><a href="SLR.html#correlation"><i class="fa fa-check"></i><b>3.3</b> Correlation</a></li>
<li class="chapter" data-level="3.4" data-path="SLR.html"><a href="SLR.html#errors"><i class="fa fa-check"></i><b>3.4</b> Errors</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="SLR.html"><a href="SLR.html#testing-beta_1"><i class="fa fa-check"></i><b>3.4.1</b> Testing <span class="math inline">\(\beta_1\)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="SLR.html"><a href="SLR.html#intervals"><i class="fa fa-check"></i><b>3.5</b> Intervals</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="SLR.html"><a href="SLR.html#confidence-intervals"><i class="fa fa-check"></i><b>3.5.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="3.5.2" data-path="SLR.html"><a href="SLR.html#slope"><i class="fa fa-check"></i><b>3.5.2</b> Slope</a></li>
<li class="chapter" data-level="3.5.3" data-path="SLR.html"><a href="SLR.html#mean-response"><i class="fa fa-check"></i><b>3.5.3</b> Mean Response</a></li>
<li class="chapter" data-level="3.5.4" data-path="SLR.html"><a href="SLR.html#prediction-of-an-individual-response"><i class="fa fa-check"></i><b>3.5.4</b> Prediction of an Individual Response</a></li>
<li class="chapter" data-level="3.5.5" data-path="SLR.html"><a href="SLR.html#outlying-high-leverage-and-influential-points"><i class="fa fa-check"></i><b>3.5.5</b> Outlying, High Leverage, and Influential Points</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="SLR.html"><a href="SLR.html#r-example-slr-happy-planet"><i class="fa fa-check"></i><b>3.6</b> R Example (SLR): Happy Planet</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="SLR.html"><a href="SLR.html#reading-the-data-into-r"><i class="fa fa-check"></i><b>3.6.1</b> Reading the data into R</a></li>
<li class="chapter" data-level="3.6.2" data-path="SLR.html"><a href="SLR.html#running-the-linear-model-lm"><i class="fa fa-check"></i><b>3.6.2</b> Running the linear model (lm)</a></li>
<li class="chapter" data-level="3.6.3" data-path="SLR.html"><a href="SLR.html#ouptut"><i class="fa fa-check"></i><b>3.6.3</b> Ouptut</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html"><i class="fa fa-check"></i><b>4</b> Analysis of Categorical Data (section 6.3)</a>
<ul>
<li class="chapter" data-level="4.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#cat"><i class="fa fa-check"></i><b>4.1</b> Categorical Inference</a></li>
<li class="chapter" data-level="4.2" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#fisher"><i class="fa fa-check"></i><b>4.2</b> Fisher’s Exact Test (section 6.4)</a></li>
<li class="chapter" data-level="4.3" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#chisq"><i class="fa fa-check"></i><b>4.3</b> Testing independence of two categorical variables (sections 6.5, 6.6, 6.7)</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#chi2-tests-section-6.6"><i class="fa fa-check"></i><b>4.3.1</b> <span class="math inline">\(\chi^2\)</span> tests (section 6.6)</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#catest"><i class="fa fa-check"></i><b>4.4</b> Parameter Estimation (section 6.8)</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#ci-for-differences-in-proportions"><i class="fa fa-check"></i><b>4.4.1</b> CI for differences in proportions</a></li>
<li class="chapter" data-level="4.4.2" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#relative-risk"><i class="fa fa-check"></i><b>4.4.2</b> Relative Risk</a></li>
<li class="chapter" data-level="4.4.3" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#odds-ratios"><i class="fa fa-check"></i><b>4.4.3</b> Odds Ratios</a></li>
<li class="chapter" data-level="4.4.4" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#confidence-interval-for-or"><i class="fa fa-check"></i><b>4.4.4</b> Confidence Interval for OR</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#studies"><i class="fa fa-check"></i><b>4.5</b> Types of Studies (section 6.9)</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#retrospective-versus-prospective-studies"><i class="fa fa-check"></i><b>4.5.1</b> Retrospective versus Prospective Studies</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#r-example-categorical-data-botox-and-back-pain"><i class="fa fa-check"></i><b>4.6</b> R Example (categorical data): Botox and back pain</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#entering-and-visualizing-the-data"><i class="fa fa-check"></i><b>4.6.1</b> Entering and visualizing the data</a></li>
<li class="chapter" data-level="4.6.2" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#fishers-exact-test"><i class="fa fa-check"></i><b>4.6.2</b> Fisher’s Exact Test</a></li>
<li class="chapter" data-level="4.6.3" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#chi-squared-analysis"><i class="fa fa-check"></i><b>4.6.3</b> Chi-squared Analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>5</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logmodel"><i class="fa fa-check"></i><b>5.1</b> Motivation for Logistic Regression</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#the-logistic-model"><i class="fa fa-check"></i><b>5.1.1</b> The logistic model</a></li>
<li class="chapter" data-level="5.1.2" data-path="logistic-regression.html"><a href="logistic-regression.html#constant-or-varying-rr"><i class="fa fa-check"></i><b>5.1.2</b> constant OR, varying RR</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="logistic-regression.html"><a href="logistic-regression.html#logMLE"><i class="fa fa-check"></i><b>5.2</b> Estimating coefficients in logistic regression</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>5.2.1</b> Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="logistic-regression.html"><a href="logistic-regression.html#loginf"><i class="fa fa-check"></i><b>5.3</b> Formal Inference</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#wald-tests-intervals"><i class="fa fa-check"></i><b>5.3.1</b> Wald Tests &amp; Intervals</a></li>
<li class="chapter" data-level="5.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#likelihood-ratio-tests"><i class="fa fa-check"></i><b>5.3.2</b> Likelihood Ratio Tests</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="logistic-regression.html"><a href="logistic-regression.html#multlog"><i class="fa fa-check"></i><b>5.4</b> Multiple Logistic Regression</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#interaction"><i class="fa fa-check"></i><b>5.4.1</b> Interaction</a></li>
<li class="chapter" data-level="5.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#simpsons-paradox"><i class="fa fa-check"></i><b>5.4.2</b> Simpson’s Paradox</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="logistic-regression.html"><a href="logistic-regression.html#multicol"><i class="fa fa-check"></i><b>5.5</b> Multicolinearity</a></li>
<li class="chapter" data-level="5.6" data-path="logistic-regression.html"><a href="logistic-regression.html#logstep"><i class="fa fa-check"></i><b>5.6</b> Model Building</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="logistic-regression.html"><a href="logistic-regression.html#formal-model-building"><i class="fa fa-check"></i><b>5.6.1</b> Formal Model Building</a></li>
<li class="chapter" data-level="5.6.2" data-path="logistic-regression.html"><a href="logistic-regression.html#getting-the-model-right"><i class="fa fa-check"></i><b>5.6.2</b> Getting the Model Right</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="logistic-regression.html"><a href="logistic-regression.html#model-assessment"><i class="fa fa-check"></i><b>5.7</b> Model Assessment</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="logistic-regression.html"><a href="logistic-regression.html#measures-of-association"><i class="fa fa-check"></i><b>5.7.1</b> Measures of Association</a></li>
<li class="chapter" data-level="5.7.2" data-path="logistic-regression.html"><a href="logistic-regression.html#roc"><i class="fa fa-check"></i><b>5.7.2</b> Receiver Operating Characteristic Curves</a></li>
<li class="chapter" data-level="5.7.3" data-path="logistic-regression.html"><a href="logistic-regression.html#cv"><i class="fa fa-check"></i><b>5.7.3</b> Cross Validation</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="logistic-regression.html"><a href="logistic-regression.html#birdexamp"><i class="fa fa-check"></i><b>5.8</b> R: Birdnest Example</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="logistic-regression.html"><a href="logistic-regression.html#drop-in-deviance-likelihood-ratio-test-lrt"><i class="fa fa-check"></i><b>5.8.1</b> Drop-in-deviance (Likelihood Ratio Test, LRT)</a></li>
<li class="chapter" data-level="5.8.2" data-path="logistic-regression.html"><a href="logistic-regression.html#difference-between-tidy-and-augment-and-glance"><i class="fa fa-check"></i><b>5.8.2</b> Difference between <code>tidy</code> and <code>augment</code> and <code>glance</code></a></li>
<li class="chapter" data-level="5.8.3" data-path="logistic-regression.html"><a href="logistic-regression.html#looking-at-variables-in-a-few-different-ways."><i class="fa fa-check"></i><b>5.8.3</b> Looking at variables in a few different ways.</a></li>
<li class="chapter" data-level="5.8.4" data-path="logistic-regression.html"><a href="logistic-regression.html#predicting-response"><i class="fa fa-check"></i><b>5.8.4</b> Predicting Response</a></li>
<li class="chapter" data-level="5.8.5" data-path="logistic-regression.html"><a href="logistic-regression.html#measues-of-association"><i class="fa fa-check"></i><b>5.8.5</b> Measues of association</a></li>
<li class="chapter" data-level="5.8.6" data-path="logistic-regression.html"><a href="logistic-regression.html#roc-curves"><i class="fa fa-check"></i><b>5.8.6</b> ROC curves</a></li>
<li class="chapter" data-level="5.8.7" data-path="logistic-regression.html"><a href="logistic-regression.html#drawing-interactions"><i class="fa fa-check"></i><b>5.8.7</b> Drawing interactions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>6</b> Survival Analysis</a>
<ul>
<li class="chapter" data-level="6.1" data-path="survival-analysis.html"><a href="survival-analysis.html#timedata"><i class="fa fa-check"></i><b>6.1</b> Time-to-event data</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="survival-analysis.html"><a href="survival-analysis.html#survival-function"><i class="fa fa-check"></i><b>6.1.1</b> Survival Function</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="survival-analysis.html"><a href="survival-analysis.html#KM"><i class="fa fa-check"></i><b>6.2</b> Kaplan-Meier Curves</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="survival-analysis.html"><a href="survival-analysis.html#KMCI"><i class="fa fa-check"></i><b>6.2.1</b> CI for KM curve</a></li>
<li class="chapter" data-level="6.2.2" data-path="survival-analysis.html"><a href="survival-analysis.html#logrank"><i class="fa fa-check"></i><b>6.2.2</b> Log-rank Test</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="survival-analysis.html"><a href="survival-analysis.html#hazfunc"><i class="fa fa-check"></i><b>6.3</b> Hazard Functions</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="survival-analysis.html"><a href="survival-analysis.html#estimating-ht-ala-kaplan-meier"><i class="fa fa-check"></i><b>6.3.1</b> Estimating <span class="math inline">\(h(t)\)</span> ala Kaplan-Meier</a></li>
<li class="chapter" data-level="6.3.2" data-path="survival-analysis.html"><a href="survival-analysis.html#proportional-hazards"><i class="fa fa-check"></i><b>6.3.2</b> Proportional Hazards</a></li>
<li class="chapter" data-level="6.3.3" data-path="survival-analysis.html"><a href="survival-analysis.html#coxph"><i class="fa fa-check"></i><b>6.3.3</b> Cox PH Regression Analysis</a></li>
<li class="chapter" data-level="6.3.4" data-path="survival-analysis.html"><a href="survival-analysis.html#testingph"><i class="fa fa-check"></i><b>6.3.4</b> Testing Proportional Hazards</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="survival-analysis.html"><a href="survival-analysis.html#othersurv"><i class="fa fa-check"></i><b>6.4</b> Other stuff</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="survival-analysis.html"><a href="survival-analysis.html#sample-size-calculation"><i class="fa fa-check"></i><b>6.4.1</b> Sample Size Calculation</a></li>
<li class="chapter" data-level="6.4.2" data-path="survival-analysis.html"><a href="survival-analysis.html#study-design"><i class="fa fa-check"></i><b>6.4.2</b> Study Design</a></li>
<li class="chapter" data-level="6.4.3" data-path="survival-analysis.html"><a href="survival-analysis.html#simulating-survival-data"><i class="fa fa-check"></i><b>6.4.3</b> Simulating survival data</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="survival-analysis.html"><a href="survival-analysis.html#Rsurv"><i class="fa fa-check"></i><b>6.5</b> R example: ProPublica Analysis</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="survival-analysis.html"><a href="survival-analysis.html#recidivism-in-florida"><i class="fa fa-check"></i><b>6.5.1</b> Recidivism in Florida</a></li>
<li class="chapter" data-level="6.5.2" data-path="survival-analysis.html"><a href="survival-analysis.html#kaplan-meier-survival-curve"><i class="fa fa-check"></i><b>6.5.2</b> Kaplan-Meier survival curve</a></li>
<li class="chapter" data-level="6.5.3" data-path="survival-analysis.html"><a href="survival-analysis.html#log-rank-test-rho0-and-the-wilcoxon-test-rho1"><i class="fa fa-check"></i><b>6.5.3</b> Log-rank test [rho=0] and the Wilcoxon test [rho=1]</a></li>
<li class="chapter" data-level="6.5.4" data-path="survival-analysis.html"><a href="survival-analysis.html#cox-proportional-hazards-models"><i class="fa fa-check"></i><b>6.5.4</b> Cox Proportional Hazards models</a></li>
<li class="chapter" data-level="6.5.5" data-path="survival-analysis.html"><a href="survival-analysis.html#checking-proportional-hazards-with-the-plot-of-ln-lnst"><i class="fa fa-check"></i><b>6.5.5</b> Checking proportional hazards with the plot of <span class="math inline">\(\ln(-\ln(S(t)))\)</span></a></li>
<li class="chapter" data-level="6.5.6" data-path="survival-analysis.html"><a href="survival-analysis.html#checking-proportional-hazards-with-cox.zph"><i class="fa fa-check"></i><b>6.5.6</b> Checking proportional hazards with cox.zph</a></li>
<li class="chapter" data-level="6.5.7" data-path="survival-analysis.html"><a href="survival-analysis.html#coxph-diagnostics-look-into-all-the-different-arguments-of-the-function"><i class="fa fa-check"></i><b>6.5.7</b> Coxph diagnostics … look into all the different arguments of the function!</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html"><i class="fa fa-check"></i><b>7</b> Multiple Comparisons</a>
<ul>
<li class="chapter" data-level="7.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#Ioannidis"><i class="fa fa-check"></i><b>7.1</b> Why Most Published Research Findings are False</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#positive-predictive-value-ppv"><i class="fa fa-check"></i><b>7.1.1</b> Positive Predictive Value (PPV)</a></li>
<li class="chapter" data-level="7.1.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#bias"><i class="fa fa-check"></i><b>7.1.2</b> Bias</a></li>
<li class="chapter" data-level="7.1.3" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#multiple-studies"><i class="fa fa-check"></i><b>7.1.3</b> Multiple Studies</a></li>
<li class="chapter" data-level="7.1.4" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#corollaries"><i class="fa fa-check"></i><b>7.1.4</b> Corollaries</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#multcomp"><i class="fa fa-check"></i><b>7.2</b> Multiple Comparisons</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#bonferroni"><i class="fa fa-check"></i><b>7.2.1</b> Bonferroni</a></li>
<li class="chapter" data-level="7.2.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#holm"><i class="fa fa-check"></i><b>7.2.2</b> Holm</a></li>
<li class="chapter" data-level="7.2.3" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#benjamini-hochberg"><i class="fa fa-check"></i><b>7.2.3</b> Benjamini-Hochberg</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#qvals"><i class="fa fa-check"></i><b>7.3</b> Storey &amp; q-values</a></li>
<li class="chapter" data-level="7.4" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#interim-analyses"><i class="fa fa-check"></i><b>7.4</b> Interim Analyses</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#pocock"><i class="fa fa-check"></i><b>7.4.1</b> Pocock</a></li>
<li class="chapter" data-level="7.4.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#obrien-flemming"><i class="fa fa-check"></i><b>7.4.2</b> O’Brien-Flemming</a></li>
<li class="chapter" data-level="7.4.3" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#some-parting-thoughts"><i class="fa fa-check"></i><b>7.4.3</b> Some parting thoughts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>8</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="poisson-regression.html"><a href="poisson-regression.html#regPois"><i class="fa fa-check"></i><b>8.1</b> Regression Models</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="poisson-regression.html"><a href="poisson-regression.html#the-poisson-regression-model"><i class="fa fa-check"></i><b>8.1.1</b> The Poisson Regression Model</a></li>
<li class="chapter" data-level="8.1.2" data-path="poisson-regression.html"><a href="poisson-regression.html#comparison-to-linear-regression"><i class="fa fa-check"></i><b>8.1.2</b> Comparison to Linear Regression</a></li>
<li class="chapter" data-level="8.1.3" data-path="poisson-regression.html"><a href="poisson-regression.html#interpreting-poisson-regression-coefficients"><i class="fa fa-check"></i><b>8.1.3</b> Interpreting Poisson Regression Coefficients</a></li>
<li class="chapter" data-level="8.1.4" data-path="poisson-regression.html"><a href="poisson-regression.html#assessing-model-validity"><i class="fa fa-check"></i><b>8.1.4</b> Assessing Model Validity</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="poisson-regression.html"><a href="poisson-regression.html#inferPois"><i class="fa fa-check"></i><b>8.2</b> Inference in Poisson Regression</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="poisson-regression.html"><a href="poisson-regression.html#maximum-likelihood"><i class="fa fa-check"></i><b>8.2.1</b> Maximum Likelihood</a></li>
<li class="chapter" data-level="8.2.2" data-path="poisson-regression.html"><a href="poisson-regression.html#wald-tests"><i class="fa fa-check"></i><b>8.2.2</b> Wald Tests</a></li>
<li class="chapter" data-level="8.2.3" data-path="poisson-regression.html"><a href="poisson-regression.html#drop-in-deviance-tests"><i class="fa fa-check"></i><b>8.2.3</b> Drop-in-Deviance Tests</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="poisson-regression.html"><a href="poisson-regression.html#r-poisson-example"><i class="fa fa-check"></i><b>8.3</b> R Poisson Example</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="poisson-regression.html"><a href="poisson-regression.html#glm"><i class="fa fa-check"></i><b>8.3.1</b> glm</a></li>
<li class="chapter" data-level="8.3.2" data-path="poisson-regression.html"><a href="poisson-regression.html#drop-in-deviance"><i class="fa fa-check"></i><b>8.3.2</b> drop in deviance</a></li>
<li class="chapter" data-level="8.3.3" data-path="poisson-regression.html"><a href="poisson-regression.html#residuals-1"><i class="fa fa-check"></i><b>8.3.3</b> residuals</a></li>
<li class="chapter" data-level="8.3.4" data-path="poisson-regression.html"><a href="poisson-regression.html#quasipoisson"><i class="fa fa-check"></i><b>8.3.4</b> quasiPoisson</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://st47s.com/Math150" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Methods in Biostatistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="poisson-regression" class="section level1" number="8">
<h1><span class="header-section-number">Chapter 8</span> Poisson Regression</h1>
<div id="regPois" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Regression Models</h2>
<p>Consider the following example from <span class="citation"><a href="references.html#ref-poole" role="doc-biblioref">Poole</a> (<a href="references.html#ref-poole" role="doc-biblioref">1989</a>)</span> (described in <span class="citation"><a href="references.html#ref-sleuth" role="doc-biblioref">Ramsey and Schafer</a> (<a href="references.html#ref-sleuth" role="doc-biblioref">2012</a>)</span>) on age and mating success (number of successful matings) in male African Elephants.</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="poisson-regression.html#cb202-1" aria-hidden="true" tabindex="-1"></a>elephants <span class="ot">&lt;-</span> readr<span class="sc">::</span><span class="fu">read_csv</span>(<span class="st">&quot;elephants.csv&quot;</span>)</span>
<span id="cb202-2"><a href="poisson-regression.html#cb202-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb202-3"><a href="poisson-regression.html#cb202-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(elephants, <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">jitter</span>(AGE), <span class="at">y=</span>MATINGS)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>While it does seem like there is an increasing trend in the two variables, there are some concerns with directly applying linear regression. Indeed, the example above acts as a proxy for many regression examples where the response variable is a count with particular properties:</p>
<ol style="list-style-type: decimal">
<li><p>The response variable is a count (in particular, it cannot be negative).</p></li>
<li><p>The model may or may not be linear in X.</p></li>
<li><p>The model appears to have increasing variance as a function of X.</p></li>
</ol>
<p>For the setting above, it is often preferable to use Poisson regression instead of the normal errors linear regression.</p>
<div id="the-poisson-regression-model" class="section level3" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> The Poisson Regression Model</h3>
<p>The Poisson distribution is given by a probability function of the form:</p>
<p><span class="math display">\[P(Y = y) = \frac{e^{-\mu} \mu^y}{y!} \ \ \ \ \ y=0, 1, 2, \ldots\]</span></p>
<p>Which gives: <span class="math inline">\(E(Y) = \mu\)</span> and <span class="math inline">\(Var(Y) = \mu\)</span>. That is, the Poisson model is characterized by a mean and variance given by the same value.</p>
<p>Recall that with linear regression, <span class="math inline">\(E(Y_i) = \beta_0 + \beta_1 X_i\)</span> which might be a reasonable idea to apply to the count data; however, as seen above, if the mean of the distribution is modeled strictly as a linear function in <span class="math inline">\(X\)</span>, then the line has the potential to predict negative counts and the variability will not be a function of <span class="math inline">\(X\)</span> if normal errors regression is used.</p>
<p>An alternative the normal errors regression is to use a <span class="math inline">\(\ln\)</span> transformation to describe the relationship between the predicted value of the response and the explanatory variables of interest:</p>
<p><span class="math display">\[\ln(E(Y_i)) = \ln(\mu_i) = \beta_0 + \beta_1 X_i.\]</span>
where the observed counts come from a Poisson model: <span class="math inline">\(Y_i \sim Pois(\mu_i)\)</span> and the Poisson parameter is given as a function of the explanatory variable(s). [Note that Poisson regression contains no error term like linear regression because the Poisson distribution has inherent variability which is determined by the mean which equals the variance.]</p>
<div id="technical-conditions" class="section level4" number="8.1.1.1">
<h4><span class="header-section-number">8.1.1.1</span> Technical Conditions</h4>
<p>Like every model, there are technical conditions associated with Poisson Regression. The closer the data (population) conform to the conditions, the more useful the model will be at describing the context at hand. Remember,
&gt; All models are wrong, but some models are useful." -George Box.</p>
<p>So, assessing whether the technical conditions are reasonable will help in determining whether the analysis performed under a particular model was a good thing to do.</p>
<ol style="list-style-type: decimal">
<li>Line: The log of the mean is a linear function of <span class="math inline">\(X\)</span>: <span class="math inline">\(\ln(\mu_i) = \beta_0 + \beta_1 X_i.\)</span></li>
<li>Independence: The observations are independent (often characterized by a simple random sample or something approximating a simple random sample).</li>
<li>Poisson: The response variable is a count.</li>
<li>Error: The mean of the response variables is equal to the variance of the response variable for each combination of explanatory variables in the model.</li>
</ol>
<div class="figure">
<img src="NormPoisReg1.jpg" alt="" />
<p class="caption">Visualizing Normal vs Poisson Error Regression from <span class="citation"><a href="references.html#ref-bysh" role="doc-biblioref">Legler and Roback</a> (<a href="references.html#ref-bysh" role="doc-biblioref">2019</a>)</span></p>
</div>
</div>
</div>
<div id="comparison-to-linear-regression" class="section level3" number="8.1.2">
<h3><span class="header-section-number">8.1.2</span> Comparison to Linear Regression</h3>
<p>One question that might come to mind is whether there is any difference in the Poisson log-linear model and a normal errors regression model with a log transformation on the response??? The short answer is that yes, there is a difference.</p>
<ul>
<li><p><strong>Poisson Log-Linear:</strong> <span class="math inline">\(\ln(E(Y_i)) = \beta_0 + \beta_1 X_i, Y_i \sim Pois(e^{\beta_0 + \beta_1 X_i})\)</span></p></li>
<li><p><strong>Normal w Log Transformation:</strong> <span class="math inline">\(E(\ln(Y_i)) = \beta_0 + \beta_1 X_i, \ln(Y_i) \sim N(\beta_0 + \beta_1 X_i, \sigma^2)\)</span></p></li>
</ul>
<p>There are two main differences with the models.</p>
<ol style="list-style-type: decimal">
<li>The first is to remember that the average (i.e., expected value) of the logs is not the log of the averages. So in the Poisson model, the linear function measures the log of the average, and in the normal model, the linear function measures the average of the logs.</li>
</ol>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="poisson-regression.html#cb203-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">47</span>)</span>
<span id="cb203-2"><a href="poisson-regression.html#cb203-2" aria-hidden="true" tabindex="-1"></a>example <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">rcauchy</span>(<span class="dv">10</span>))</span>
<span id="cb203-3"><a href="poisson-regression.html#cb203-3" aria-hidden="true" tabindex="-1"></a>example</span></code></pre></div>
<pre><code>##  [1]  0.07250266  2.39114995  0.93022166  0.62369321  4.25084018  1.45750156
##  [7]  2.75212953 10.21765703  7.30420453  0.24043747</code></pre>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="poisson-regression.html#cb205-1" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="fu">mean</span>(example))</span></code></pre></div>
<pre><code>## [1] 1.106592</code></pre>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="poisson-regression.html#cb207-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">log</span>(example))</span></code></pre></div>
<pre><code>## [1] 0.3426701</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>The second difference to note across the two regression set-ups is that the variability is modeled differently. Indeed, the likelihood functions are quite different and will produce different maximum likelihood estimates of the parameter values.</li>
</ol>
<div class="figure">
<img src="NormPoisReg2.jpg" alt="" />
<p class="caption">Differences in Normal vs Poisson Error Regression from <span class="citation"><a href="references.html#ref-bysh" role="doc-biblioref">Legler and Roback</a> (<a href="references.html#ref-bysh" role="doc-biblioref">2019</a>)</span></p>
</div>
</div>
<div id="interpreting-poisson-regression-coefficients" class="section level3" number="8.1.3">
<h3><span class="header-section-number">8.1.3</span> Interpreting Poisson Regression Coefficients</h3>
<p>As we’ve done with other generalized linear models (linear regression, logistic regression, even survival analysis!), in order to understand the model more completely, we look at the impact on the response variable for a one unit change in <span class="math inline">\(X\)</span>.</p>
<p>Consider <span class="math inline">\(X\)</span> and <span class="math inline">\(X+1\)</span>.</p>
<p><span class="math display">\[\frac{E(Y|X+1)}{E(Y|X)} = \frac{e^{\beta_0 + \beta_1 (X+1)}}{e^{\beta_0 + \beta_1 (X)}} = e^{\beta_1}\]</span></p>
<p>That is, <span class="math inline">\(e^{\beta_1}\)</span> represents the ratio of means for a one unit increase in <span class="math inline">\(X\)</span>. In the elephant example, for every additional year of life, we expect the elephant’s mating success, on average, to change by a factor of <span class="math inline">\(e^{\beta_1}\)</span>. [For the savvy consumer, you might note that this is an additional contrast to normal error regression on the log transformed Y where it was required to interpret the multiplicative change in <em>median</em>. Because with Poisson, the log is taken after the average, taking the inverse of the log gives the mean directly. Previously, it was necessary to use the identity: <span class="math inline">\(median(\ln(Y)) = \ln(median(Y))\)</span>.]</p>
</div>
<div id="assessing-model-validity" class="section level3" number="8.1.4">
<h3><span class="header-section-number">8.1.4</span> Assessing Model Validity</h3>
<p>Just as with linear regression we used scatterplots to give a sense of whether or not a linear regression was appropriate, we can use exploratory data analysis (including scatterplot!) to give a sense of whether or not Poisson regression is an appropriate model. <span class="citation">(The EDA steps here are based on excellent descriptions of Poisson model building in <a href="references.html#ref-bysh" role="doc-biblioref">Legler and Roback 2019</a>.)</span></p>
<p><strong>Technical Condition 3, Poisson:</strong> Let’s first look at the response variable. A histogram of the number of successful matings shows a right skew which is typically not acceptable for normal errors regression (although, remember, the value of the response variable is dependent on the value of the explanatory variable!)
<img src="08-PoisReg_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Likely, it makes more sense to look at the distribution of the response variable at each value of the explanatory variables. Because the sample size is limited, we group the age variable into 5 year increments. Looking at the plot below, again it seems as though, even when conditioning on the explanatory variable, the response is right skewed with variance dependent on the mean. It might also be good to find the sample mean per group and plot the Poisson probabilities onto each bar.</p>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><strong>Technical Condition 4, Error:</strong> To check whether the mean and variance are similar, we can calculate the values per group (with more data we would probably have more groups of the explanatory variable, and the following analysis would be done with a scatterplot of means on the x-axis and variance on the y-axis). Note that the mean and variance are reasonably similar! When the “mean=variance” condition is violated, it is almost always violated in such that the variance is even <em>bigger</em> than would have been expected by the Poisson model. Large variance is called overdispersion, and methods for measuring and accounting for overdispersion are given in the following section <a href="poisson-regression.html#overdis">8.2.1.2</a>.</p>
<pre><code>## # A tibble: 3 x 5
##   AGEgroups  mean variance stdev     n
##   &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;
## 1 (20,30]    1.08    0.992 0.996    12
## 2 (30,40]    2.71    2.85  1.69     17
## 3 (40,55]    4.25    7.84  2.80     12</code></pre>
<p><strong>Technical Condition 1, Line:</strong> The Poisson model implies that the log of the mean will be a linear function of the explanatory variable:</p>
<p><span class="math display">\[\ln(\mu_i) = \beta_0 + \beta_1 X_i,\]</span>
which means we’d really like to plot <span class="math inline">\(\mu_i\)</span> as a function of the explanatory variable. Unfortunately, <span class="math inline">\(\mu_i\)</span> is unknown, and so cannot be plotted. We can, however, plot the log of the average value of the response for a group of x values which are close to one another. In the plot below, we’ve grouped observations based on the age of the elephants being within 3 years of years of each other. It is actually quite linear! The points that don’t follow the linear relationship are based on age groups with very few observations.</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="poisson-regression.html#cb210-1" aria-hidden="true" tabindex="-1"></a>matelogmean <span class="ot">&lt;-</span> elephants <span class="sc">%&gt;%</span></span>
<span id="cb210-2"><a href="poisson-regression.html#cb210-2" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">agecut =</span> <span class="fu">cut</span>(AGE, <span class="at">breaks=</span><span class="fu">seq</span>(<span class="fl">26.5</span>,<span class="fl">53.5</span>,<span class="at">by=</span><span class="dv">3</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb210-3"><a href="poisson-regression.html#cb210-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(agecut) <span class="sc">%&gt;%</span></span>
<span id="cb210-4"><a href="poisson-regression.html#cb210-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">meanmate =</span> <span class="fu">mean</span>(MATINGS), <span class="at">logmate =</span> <span class="fu">log</span>(<span class="fu">mean</span>(MATINGS)), <span class="at">n =</span> <span class="fu">n</span>() )</span>
<span id="cb210-5"><a href="poisson-regression.html#cb210-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb210-6"><a href="poisson-regression.html#cb210-6" aria-hidden="true" tabindex="-1"></a>elephantsGRP <span class="ot">&lt;-</span> <span class="fu">cbind</span>(matelogmean, <span class="at">age =</span> <span class="fu">c</span>(<span class="fu">seq</span>(<span class="fl">26.5</span>,<span class="fl">52.5</span>,<span class="at">by=</span><span class="dv">3</span>)<span class="sc">+</span><span class="fl">1.5</span> ))</span>
<span id="cb210-7"><a href="poisson-regression.html#cb210-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb210-8"><a href="poisson-regression.html#cb210-8" aria-hidden="true" tabindex="-1"></a>elephantsGRP</span></code></pre></div>
<pre><code>##        agecut meanmate    logmate  n age
## 1 (26.5,29.5] 1.090909 0.08701138 11  28
## 2 (29.5,32.5] 1.500000 0.40546511  2  31
## 3 (32.5,35.5] 2.444444 0.89381788  9  34
## 4 (35.5,38.5] 3.500000 1.25276297  6  37
## 5 (38.5,41.5] 2.000000 0.69314718  2  40
## 6 (41.5,44.5] 3.571429 1.27296568  7  43
## 7 (44.5,47.5] 6.000000 1.79175947  2  46
## 8 (47.5,50.5] 2.000000 0.69314718  1  49
## 9 (50.5,53.5] 9.000000 2.19722458  1  52</code></pre>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="poisson-regression.html#cb212-1" aria-hidden="true" tabindex="-1"></a>elephantsGRP <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>age, <span class="at">y=</span>logmate)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="inferPois" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> Inference in Poisson Regression</h2>
<p>Recall that in Poisson regression, <span class="math inline">\(E(Y_i) = \mu_i = e^{\beta_0 + \beta_1 X_i}\)</span>. Therefore, the probability function for the <span class="math inline">\(i^{th}\)</span> observation is:</p>
<p><span class="math display">\[f(y_i) = \frac{e^{-\mu_i} \mu_i^{y_i}}{y_i!} = \frac{e^{-e^{\beta_0 + \beta_1 X_i}} \bigg(e^{\beta_0 + \beta_1 X_i}\bigg)^{y_i}}{y_i!}.\]</span>
Which gives the resulting likelihood of:</p>
<p><span class="math display">\[L(\beta_0, \beta_1) = \prod_{i=1}^n f(y_i) = \prod_{i=1}^n \frac{e^{-\mu_i} \mu_i^{y_i}}{y_i!} = \prod_{i=1}^n \frac{e^{-e^{\beta_0 + \beta_1 X_i}} \bigg(e^{\beta_0 + \beta_1 X_i}\bigg)^{y_i}}{y_i!}.\]</span></p>
<p>And the log likelihood becomes:</p>
<p><span class="math display">\[\begin{eqnarray*}
l(\beta_0, \beta_1) &amp;=&amp; \ln L(\beta_0, \beta_1) = \sum_{i=1}^n \bigg(-\mu_i + y_i \ln(\mu_i) - \ln(y_i!) \bigg) \\
&amp;=&amp; \sum_{i=1}^n \bigg(-e^{\beta_0 + \beta_1 X_i} + y_i (\beta_0 + \beta_1 X_i) - \ln(y_i!) \bigg).
\end{eqnarray*}\]</span></p>
<div id="maximum-likelihood" class="section level3" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> Maximum Likelihood</h3>
<p>As with other probabilistic models we’ve encountered, the joint likelihood of the entire sample represents the product of the individual likelihoods for each data value. The likelihood (or more typically, the <span class="math inline">\(\ln\)</span>-likelihood) is maximized to find estimates for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p>
<p>The parameter estimates maximize the <span class="math inline">\(\ln\)</span>-likelihood, and the SE of the estimates are given by the Fisher Information from the likelihood (roughly the second derivative).</p>
<p>Given <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> as estimates of the parameter values, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, we can estimate the average count value:</p>
<p><span class="math display">\[\hat{\mu}_i = e^{b_0 + b_1 X_i}\]</span></p>
<div id="residuals" class="section level4" number="8.2.1.1">
<h4><span class="header-section-number">8.2.1.1</span> Residuals</h4>
<p>Note that we <em>expect</em> the residuals of a Poisson model to have larger variability for larger values of the prediction. That makes interpreting the residuals slightly different that previously for a linear regression model.</p>
<p>Pearson residual:</p>
<p><span class="math display">\[res_{pi} = \frac{y_i - \hat{\mu}_i}{\hat{\mu}_i}\]</span></p>
<p>Deviance residual:</p>
<p><span class="math display">\[\begin{eqnarray*}
res_{di} &amp;=&amp; [-\hat{\mu}_i + y_i \ln(\hat{\mu}_i) - \ln(y_i!) ] - [-y_i + y_i \ln(y_i) - \ln(y_i!) ] \\
&amp;=&amp; y_i-\hat{\mu}_i + y_i \ln\bigg(\frac{\hat{\mu}_i}{y_i}\bigg)
\end{eqnarray*}\]</span></p>
<p>Along with giving information about individual residual values, the sum of the Deviance residuals is also a way to test for goodness-of-fit of the model. Given the null hypothesis that the Poisson is the appropriate model, the test of goodness-of-fit for the Poisson model is given by:</p>
<p><span class="math display">\[\sum_{i=1}^n res_{di} \stackrel{H_0}{\sim} \chi_{n-p}^2.\]</span></p>
</div>
<div id="overdis" class="section level4" number="8.2.1.2">
<h4><span class="header-section-number">8.2.1.2</span> Dealing with Overdispersion</h4>
<p>A probability structure that is given by a variance which is larger than the mean, may end up with:</p>
<p><span class="math display">\[\begin{eqnarray*}
E(Y_i) &amp;=&amp; \mu_i\\
Var(Y_i) &amp;=&amp; \phi \mu_i\\
\end{eqnarray*}\]</span></p>
<p>If we can estimate <span class="math inline">\(\phi\)</span>, then a more appropriate SE to use is adjusted by <span class="math inline">\(\phi\)</span>: <span class="math inline">\(SE_Q(\hat{\beta}) = \sqrt{\phi} SE(\hat{\beta})\)</span>. (<span class="math inline">\(Q\)</span> stands for “quasiPoisson.”)</p>
<p>When <span class="math inline">\(Y\)</span> comes from a setting where the sample size is large, then we can use normal (sums of standard normal random variables are distributed according to a <span class="math inline">\(\chi^2\)</span> distribution) theory to assess the residuals:</p>
<p><span class="math display">\[\sum_{i=1}^n res_{pi}^2 = \sum_{i=1}^n \frac{(Y_i - \mu_i)^2}{Var(Y_i)} = \sum_{i=1}^n \frac{(Y_i - \mu_i)^2}{\phi \mu_i} \sim \chi^2_{n-p}\]</span></p>
<p>The expected value of <span class="math inline">\(\chi^2_{n-p}\)</span> is <span class="math inline">\(n-p\)</span>, which gives an estimator of <span class="math inline">\(\phi\)</span> to be:</p>
<p><span class="math display">\[\hat{\phi} =  \sum_{i=1}^n \frac{(Y_i - \mu_i)^2}{\mu_i} /(n-p).\]</span></p>
<p>Note that your text uses the Deviance residual instead of the Pearson residual to estimate <span class="math inline">\(\phi\)</span>. Both are reasonable things to do.</p>
</div>
</div>
<div id="wald-tests" class="section level3" number="8.2.2">
<h3><span class="header-section-number">8.2.2</span> Wald Tests</h3>
<p>As before, Wald tests are given by standardizing the coefficients and finding p-values using normal theory:</p>
<p><span class="math display">\[\frac{b_i - 0}{SE(b_i)} \stackrel{H_0}{\sim} N(0,1).\]</span></p>
<p>If overdispersion is expected, then the SE is adjusted and the t-distribution is used for calculating p-values:</p>
<p><span class="math display">\[\frac{b_i - 0}{SE_Q(b_i)} =  \frac{b_i - 0}{\sqrt{\hat{\phi}} SE(b_i)} \stackrel{H_0}{\sim} t_{n-p}.\]</span></p>
</div>
<div id="drop-in-deviance-tests" class="section level3" number="8.2.3">
<h3><span class="header-section-number">8.2.3</span> Drop-in-Deviance Tests</h3>
<p>The deviance for a Poisson is reasonably straightforward and comes directly from the likelihood, it is twice the sum of the deviance residuals:</p>
<p><span class="math display">\[D = 2 \sum_{i=1}^n [Y_i \ln(Y_i / \hat{\mu_i}) - (Y_i - \hat{\mu_i})].\]</span></p>
<p>For two nested models (that is, the smaller one is obtained by forcing some of the coefficients in the larger model to be zero), a drop-in-deviance test can be calculated using:</p>
<p><span class="math display">\[D_{reduced} - D_{full} \stackrel{H_0}{\sim} \chi^2_{d}\]</span></p>
<p>where <span class="math inline">\(d\)</span> is the difference in the number of parameters estimated in the two models.</p>
<p>The drop-in-deviance test can also be adjusted for overdispersion: <span class="math inline">\(F_Q = (D_{reduced} - D_{full}) / \hat{\phi} \sim F_{d, n-p}\)</span> where <span class="math inline">\(d\)</span> is the difference in the number of parameters estimated in the two models, and <span class="math inline">\(p\)</span> is the total number of parameters estimated in the full model.</p>
</div>
</div>
<div id="r-poisson-example" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> R Poisson Example</h2>
<p>The R example is taken from data given in the textbook. The scientific question relates to predicting the total number of observed <code>species</code> on the Galapagos archipelago related to island <code>area</code> (km<span class="math inline">\(^2\)</span>), <code>elevation</code> (m), distance (km) to the <code>nearest</code> neighbor and to the largest island (km<span class="math inline">\(^2\)</span>) in the archipelago Santa Cruz (<code>scruz</code>), and the area of the <code>adjacent</code> island (km<span class="math inline">\(^2\)</span>). We could also consider an additional response variable which is the island <code>endemic</code> species count.</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="poisson-regression.html#cb213-1" aria-hidden="true" tabindex="-1"></a>galap <span class="ot">&lt;-</span> readr<span class="sc">::</span><span class="fu">read_csv</span>(<span class="st">&quot;Galapagos.csv&quot;</span>)</span>
<span id="cb213-2"><a href="poisson-regression.html#cb213-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(galap)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 8
##   island      species endemics  area elevation nearest scruz adjacent
##   &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;
## 1 Baltra           58       23 25.1        346     0.6   0.6     1.84
## 2 Bartolome        31       21  1.24       109     0.6  26.3   572.  
## 3 Caldwell          3        3  0.21       114     2.8  58.7     0.78
## 4 Champion         25        9  0.1         46     1.9  47.4     0.18
## 5 Coamano           2        1  0.05        77     1.9   1.9   904.  
## 6 DaphneMajor      18       11  0.34       119     8     8       1.84</code></pre>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="poisson-regression.html#cb215-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(galap, <span class="fu">aes</span>(<span class="at">y=</span>species, <span class="at">x =</span> <span class="fu">log</span>(area), <span class="at">color =</span> adjacent)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<div id="glm" class="section level3" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> glm</h3>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="poisson-regression.html#cb216-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> <span class="fu">log</span>(elevation) <span class="sc">+</span> nearest <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb216-2"><a href="poisson-regression.html#cb216-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;poisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 6 x 5
##   term            estimate std.error statistic  p.value
##   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)     3.02     0.303         9.96  2.28e-23
## 2 log(area)       0.315    0.0185       17.1   2.20e-65
## 3 log(elevation)  0.0977   0.0604        1.62  1.06e- 1
## 4 nearest        -0.00106  0.00169      -0.626 5.32e- 1
## 5 scruz          -0.00314  0.000597     -5.26  1.40e- 7
## 6 adjacent       -0.000243 0.0000281    -8.65  5.31e-18</code></pre>
</div>
<div id="drop-in-deviance" class="section level3" number="8.3.2">
<h3><span class="header-section-number">8.3.2</span> drop in deviance</h3>
<p>It seems like we might not need either <code>log(elevation)</code> or <code>nearest</code>. A drop in deviance test will help:</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="poisson-regression.html#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> <span class="fu">log</span>(elevation) <span class="sc">+</span> nearest <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb218-2"><a href="poisson-regression.html#cb218-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;poisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span></code></pre></div>
<pre><code>## # A tibble: 1 x 8
##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs
##           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;
## 1         3511.      29  -294.  600.  609.     427.          24    30</code></pre>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="poisson-regression.html#cb220-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb220-2"><a href="poisson-regression.html#cb220-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;poisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span></code></pre></div>
<pre><code>## # A tibble: 1 x 8
##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs
##           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;
## 1         3511.      29  -296.  600.  606.     431.          26    30</code></pre>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="poisson-regression.html#cb222-1" aria-hidden="true" tabindex="-1"></a><span class="fl">431.11</span> <span class="sc">-</span> <span class="fl">427.48</span></span></code></pre></div>
<pre><code>## [1] 3.63</code></pre>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="poisson-regression.html#cb224-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pchisq</span>(<span class="fl">3.63</span>, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.1628379</code></pre>
<p>The relatively large p-value suggests that we do not need either of the variables <code>log(elevation)</code> or <code>nearest</code></p>
</div>
<div id="residuals-1" class="section level3" number="8.3.3">
<h3><span class="header-section-number">8.3.3</span> residuals</h3>
<p>Keep in mind that the expectation of a Poisson model is that the residuals will be more variable for larger predicted values. The <code>broom</code> package provides <code>.resid</code>uals which are the observed value minus the fitted value. I <em>think</em> that <code>.std.resid</code> is the Pearson residual.</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="poisson-regression.html#cb226-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb226-2"><a href="poisson-regression.html#cb226-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;poisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">augment</span>() <span class="sc">%&gt;%</span> <span class="fu">head</span>()</span></code></pre></div>
<pre><code>## # A tibble: 6 x 10
##   species `log(area)` scruz adjacent .fitted .resid .std.resid   .hat .sigma
##     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1      58       3.22    0.6     1.84    4.61 -4.57      -4.83  0.105    4.04
## 2      31       0.215  26.3   572.      3.36  0.414      0.427 0.0605   4.15
## 3       3      -1.56   58.7     0.78    2.76 -3.96      -4.05  0.0417   4.07
## 4      25      -2.30   47.4     0.18    2.55  3.01       3.08  0.0413   4.11
## 5       2      -3.00    1.9   904.      2.27 -3.01      -3.10  0.0559   4.11
## 6      18      -1.08    8       1.84    3.11 -0.953     -0.986 0.0661   4.15
## # … with 1 more variable: .cooksd &lt;dbl&gt;</code></pre>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="poisson-regression.html#cb228-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb228-2"><a href="poisson-regression.html#cb228-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;poisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">augment</span>() <span class="sc">%&gt;%</span></span>
<span id="cb228-3"><a href="poisson-regression.html#cb228-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span>.resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-12-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="poisson-regression.html#cb229-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb229-2"><a href="poisson-regression.html#cb229-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;poisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">augment</span>() <span class="sc">%&gt;%</span></span>
<span id="cb229-3"><a href="poisson-regression.html#cb229-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span>.std.resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-12-2.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="quasipoisson" class="section level3" number="8.3.4">
<h3><span class="header-section-number">8.3.4</span> quasiPoisson</h3>
<p>Note that all of the above analyses can be done using the overdispersed quasiPoisson model.</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="poisson-regression.html#cb230-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> <span class="fu">log</span>(elevation) <span class="sc">+</span> nearest <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb230-2"><a href="poisson-regression.html#cb230-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;quasipoisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 6 x 5
##   term            estimate std.error statistic  p.value
##   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)     3.02      1.29         2.34  0.0278  
## 2 log(area)       0.315     0.0786       4.02  0.000507
## 3 log(elevation)  0.0977    0.257        0.381 0.707   
## 4 nearest        -0.00106   0.00720     -0.147 0.884   
## 5 scruz          -0.00314   0.00254     -1.24  0.228   
## 6 adjacent       -0.000243  0.000120    -2.03  0.0532</code></pre>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="poisson-regression.html#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb232-2"><a href="poisson-regression.html#cb232-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;quasipoisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 4 x 5
##   term         estimate std.error statistic  p.value
##   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)  3.50      0.203        17.3  8.76e-16
## 2 log(area)    0.342     0.0304       11.3  1.63e-11
## 3 scruz       -0.00354   0.00197      -1.80 8.36e- 2
## 4 adjacent    -0.000221  0.000104     -2.12 4.35e- 2</code></pre>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="poisson-regression.html#cb234-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb234-2"><a href="poisson-regression.html#cb234-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;quasipoisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">augment</span>() <span class="sc">%&gt;%</span> <span class="fu">head</span>()</span></code></pre></div>
<pre><code>## # A tibble: 6 x 10
##   species `log(area)` scruz adjacent .fitted .resid .std.resid   .hat .sigma
##     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1      58       3.22    0.6     1.84    4.61 -4.57      -1.18  0.105    4.04
## 2      31       0.215  26.3   572.      3.36  0.414      0.104 0.0605   4.15
## 3       3      -1.56   58.7     0.78    2.76 -3.96      -0.989 0.0417   4.07
## 4      25      -2.30   47.4     0.18    2.55  3.01       0.752 0.0413   4.11
## 5       2      -3.00    1.9   904.      2.27 -3.01      -0.758 0.0559   4.11
## 6      18      -1.08    8       1.84    3.11 -0.953     -0.241 0.0661   4.15
## # … with 1 more variable: .cooksd &lt;dbl&gt;</code></pre>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="poisson-regression.html#cb236-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb236-2"><a href="poisson-regression.html#cb236-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;quasipoisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">augment</span>() <span class="sc">%&gt;%</span></span>
<span id="cb236-3"><a href="poisson-regression.html#cb236-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span>.resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="poisson-regression.html#cb237-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb237-2"><a href="poisson-regression.html#cb237-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;quasipoisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">augment</span>() <span class="sc">%&gt;%</span></span>
<span id="cb237-3"><a href="poisson-regression.html#cb237-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span>.std.resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-14-2.png" width="672" style="display: block; margin: auto;" /></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multiple-comparisons.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/08-PoisReg.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Math-150-Notes.pdf", "Math-150-Notes.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
