<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Simple Linear Regression | Methods in Biostatistics</title>
  <meta name="description" content="Class notes for Math 150 at Pomona College: Methods in Biostatistics. The notes are based primarily on the text Practicing Statistics, Kuiper and Sklar" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Simple Linear Regression | Methods in Biostatistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Class notes for Math 150 at Pomona College: Methods in Biostatistics. The notes are based primarily on the text Practicing Statistics, Kuiper and Sklar" />
  <meta name="github-repo" content="hardin47/website/Math150/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Simple Linear Regression | Methods in Biostatistics" />
  
  <meta name="twitter:description" content="Class notes for Math 150 at Pomona College: Methods in Biostatistics. The notes are based primarily on the text Practicing Statistics, Kuiper and Sklar" />
  

<meta name="author" content="Jo Hardin" />


<meta name="date" content="2020-04-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="t-tests-vs-slr.html"/>
<link rel="next" href="analysis-of-categorical-data-section-6-3.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Methods in Biostatistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Class Information</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#course-goals"><i class="fa fa-check"></i><b>1.1</b> Course Goals</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#using-r"><i class="fa fa-check"></i><b>1.2</b> Using R</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#experimental-design"><i class="fa fa-check"></i>Experimental Design</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html"><i class="fa fa-check"></i><b>2</b> t-tests vs. SLR</a><ul>
<li class="chapter" data-level="" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#surgery-timing"><i class="fa fa-check"></i>Surgery Timing</a></li>
<li class="chapter" data-level="2.1" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#ttest"><i class="fa fa-check"></i><b>2.1</b> t-test (book: 2.1)</a><ul>
<li class="chapter" data-level="2.1.1" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#what-is-an-alternative-hypothesis"><i class="fa fa-check"></i><b>2.1.1</b> What is an Alternative Hypothesis?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#anova"><i class="fa fa-check"></i>ANOVA</a></li>
<li class="chapter" data-level="2.2" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#tslr"><i class="fa fa-check"></i><b>2.2</b> Simple Linear Regression (book: 2.3)</a><ul>
<li class="chapter" data-level="" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#why-are-they-the-same"><i class="fa fa-check"></i>Why are they the same?</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#confidence-intervals-section-2.11"><i class="fa fa-check"></i><b>2.3</b> Confidence Intervals (section 2.11)</a></li>
<li class="chapter" data-level="2.4" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#random-sample-vs.random-allocation"><i class="fa fa-check"></i><b>2.4</b> Random Sample vs. Random allocation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="SLR.html"><a href="SLR.html"><i class="fa fa-check"></i><b>3</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="SLR.html"><a href="SLR.html#transformations"><i class="fa fa-check"></i><b>3.1</b> Transformations</a><ul>
<li class="chapter" data-level="" data-path="SLR.html"><a href="SLR.html#model-assumptions"><i class="fa fa-check"></i>Model assumptions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="SLR.html"><a href="SLR.html#fitting-the-regression-line"><i class="fa fa-check"></i><b>3.2</b> Fitting the regression line</a></li>
<li class="chapter" data-level="3.3" data-path="SLR.html"><a href="SLR.html#correlation"><i class="fa fa-check"></i><b>3.3</b> Correlation</a></li>
<li class="chapter" data-level="3.4" data-path="SLR.html"><a href="SLR.html#errors"><i class="fa fa-check"></i><b>3.4</b> Errors</a><ul>
<li class="chapter" data-level="3.4.1" data-path="SLR.html"><a href="SLR.html#testing-beta_1"><i class="fa fa-check"></i><b>3.4.1</b> Testing <span class="math inline">\(\beta_1\)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="SLR.html"><a href="SLR.html#intervals"><i class="fa fa-check"></i><b>3.5</b> Intervals</a><ul>
<li class="chapter" data-level="3.5.1" data-path="SLR.html"><a href="SLR.html#confidence-intervals"><i class="fa fa-check"></i><b>3.5.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="3.5.2" data-path="SLR.html"><a href="SLR.html#slope"><i class="fa fa-check"></i><b>3.5.2</b> Slope</a></li>
<li class="chapter" data-level="3.5.3" data-path="SLR.html"><a href="SLR.html#mean-response"><i class="fa fa-check"></i><b>3.5.3</b> Mean Response</a></li>
<li class="chapter" data-level="3.5.4" data-path="SLR.html"><a href="SLR.html#prediction-of-an-individual-response"><i class="fa fa-check"></i><b>3.5.4</b> Prediction of an Individual Response</a></li>
<li class="chapter" data-level="3.5.5" data-path="SLR.html"><a href="SLR.html#outlying-high-leverage-and-influential-points"><i class="fa fa-check"></i><b>3.5.5</b> Outlying, High Leverage, and Influential Points</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="SLR.html"><a href="SLR.html#r-example-slr-happy-planet"><i class="fa fa-check"></i><b>3.6</b> R Example (SLR): Happy Planet</a><ul>
<li class="chapter" data-level="3.6.1" data-path="SLR.html"><a href="SLR.html#reading-the-data-into-r"><i class="fa fa-check"></i><b>3.6.1</b> Reading the data into R</a></li>
<li class="chapter" data-level="3.6.2" data-path="SLR.html"><a href="SLR.html#running-the-linear-model-lm"><i class="fa fa-check"></i><b>3.6.2</b> Running the linear model (lm)</a></li>
<li class="chapter" data-level="3.6.3" data-path="SLR.html"><a href="SLR.html#ouptut"><i class="fa fa-check"></i><b>3.6.3</b> Ouptut</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html"><i class="fa fa-check"></i><b>4</b> Analysis of Categorical Data (section 6.3)</a><ul>
<li class="chapter" data-level="4.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#cat"><i class="fa fa-check"></i><b>4.1</b> Categorical Inference</a></li>
<li class="chapter" data-level="4.2" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#fisher"><i class="fa fa-check"></i><b>4.2</b> Fisher’s Exact Test (section 6.4)</a></li>
<li class="chapter" data-level="4.3" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#chisq"><i class="fa fa-check"></i><b>4.3</b> Testing independence of two categorical variables (sections 6.5, 6.6, 6.7)</a><ul>
<li class="chapter" data-level="4.3.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#chi2-tests-section-6.6"><i class="fa fa-check"></i><b>4.3.1</b> <span class="math inline">\(\chi^2\)</span> tests (section 6.6)</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#catest"><i class="fa fa-check"></i><b>4.4</b> Parameter Estimation (section 6.8)</a><ul>
<li class="chapter" data-level="4.4.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#ci-for-differences-in-proportions"><i class="fa fa-check"></i><b>4.4.1</b> CI for differences in proportions</a></li>
<li class="chapter" data-level="4.4.2" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#relative-risk"><i class="fa fa-check"></i><b>4.4.2</b> Relative Risk</a></li>
<li class="chapter" data-level="4.4.3" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#odds-ratios"><i class="fa fa-check"></i><b>4.4.3</b> Odds Ratios</a></li>
<li class="chapter" data-level="4.4.4" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#confidence-interval-for-or"><i class="fa fa-check"></i><b>4.4.4</b> Confidence Interval for OR</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#studies"><i class="fa fa-check"></i><b>4.5</b> Types of Studies (section 6.9)</a><ul>
<li class="chapter" data-level="4.5.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#retrospective-versus-prospective-studies"><i class="fa fa-check"></i><b>4.5.1</b> Retrospective versus Prospective Studies</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#r-example-categorical-data-botox-and-back-pain"><i class="fa fa-check"></i><b>4.6</b> R Example (categorical data): Botox and back pain</a><ul>
<li class="chapter" data-level="4.6.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#entering-and-visualizing-the-data"><i class="fa fa-check"></i><b>4.6.1</b> Entering and visualizing the data</a></li>
<li class="chapter" data-level="4.6.2" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#fishers-exact-test"><i class="fa fa-check"></i><b>4.6.2</b> Fisher’s Exact Test</a></li>
<li class="chapter" data-level="4.6.3" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#chi-squared-analysis"><i class="fa fa-check"></i><b>4.6.3</b> Chi-squared Analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>5</b> Logistic Regression</a><ul>
<li class="chapter" data-level="5.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logmodel"><i class="fa fa-check"></i><b>5.1</b> Motivation for Logistic Regression</a><ul>
<li class="chapter" data-level="5.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#the-logistic-model"><i class="fa fa-check"></i><b>5.1.1</b> The logistic model</a></li>
<li class="chapter" data-level="5.1.2" data-path="logistic-regression.html"><a href="logistic-regression.html#constant-or-varying-rr"><i class="fa fa-check"></i><b>5.1.2</b> constant OR, varying RR</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="logistic-regression.html"><a href="logistic-regression.html#logMLE"><i class="fa fa-check"></i><b>5.2</b> Estimating coefficients in logistic regression</a><ul>
<li class="chapter" data-level="5.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>5.2.1</b> Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="logistic-regression.html"><a href="logistic-regression.html#loginf"><i class="fa fa-check"></i><b>5.3</b> Formal Inference</a><ul>
<li class="chapter" data-level="5.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#wald-tests-intervals"><i class="fa fa-check"></i><b>5.3.1</b> Wald Tests &amp; Intervals</a></li>
<li class="chapter" data-level="5.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#likelihood-ratio-tests"><i class="fa fa-check"></i><b>5.3.2</b> Likelihood Ratio Tests</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="logistic-regression.html"><a href="logistic-regression.html#multlog"><i class="fa fa-check"></i><b>5.4</b> Multiple Logistic Regression</a><ul>
<li class="chapter" data-level="5.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#interaction"><i class="fa fa-check"></i><b>5.4.1</b> Interaction</a></li>
<li class="chapter" data-level="5.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#simpsons-paradox"><i class="fa fa-check"></i><b>5.4.2</b> Simpson’s Paradox</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="logistic-regression.html"><a href="logistic-regression.html#multicol"><i class="fa fa-check"></i><b>5.5</b> Multicolinearity</a></li>
<li class="chapter" data-level="5.6" data-path="logistic-regression.html"><a href="logistic-regression.html#logstep"><i class="fa fa-check"></i><b>5.6</b> Model Building</a><ul>
<li class="chapter" data-level="5.6.1" data-path="logistic-regression.html"><a href="logistic-regression.html#formal-model-building"><i class="fa fa-check"></i><b>5.6.1</b> Formal Model Building</a></li>
<li class="chapter" data-level="5.6.2" data-path="logistic-regression.html"><a href="logistic-regression.html#getting-the-model-right"><i class="fa fa-check"></i><b>5.6.2</b> Getting the Model Right</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="logistic-regression.html"><a href="logistic-regression.html#model-assessment"><i class="fa fa-check"></i><b>5.7</b> Model Assessment</a><ul>
<li class="chapter" data-level="5.7.1" data-path="logistic-regression.html"><a href="logistic-regression.html#measures-of-association"><i class="fa fa-check"></i><b>5.7.1</b> Measures of Association</a></li>
<li class="chapter" data-level="5.7.2" data-path="logistic-regression.html"><a href="logistic-regression.html#roc"><i class="fa fa-check"></i><b>5.7.2</b> Receiver Operating Characteristic Curves</a></li>
<li class="chapter" data-level="5.7.3" data-path="logistic-regression.html"><a href="logistic-regression.html#cv"><i class="fa fa-check"></i><b>5.7.3</b> Cross Validation</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="logistic-regression.html"><a href="logistic-regression.html#birdexamp"><i class="fa fa-check"></i><b>5.8</b> R: Birdnest Example</a><ul>
<li class="chapter" data-level="5.8.1" data-path="logistic-regression.html"><a href="logistic-regression.html#drop-in-deviance-likelihood-ratio-test-lrt"><i class="fa fa-check"></i><b>5.8.1</b> Drop-in-deviance (Likelihood Ratio Test, LRT)</a></li>
<li class="chapter" data-level="5.8.2" data-path="logistic-regression.html"><a href="logistic-regression.html#difference-between-tidy-and-augment-and-glance"><i class="fa fa-check"></i><b>5.8.2</b> Difference between <code>tidy</code> and <code>augment</code> and <code>glance</code></a></li>
<li class="chapter" data-level="5.8.3" data-path="logistic-regression.html"><a href="logistic-regression.html#looking-at-variables-in-a-few-different-ways."><i class="fa fa-check"></i><b>5.8.3</b> Looking at variables in a few different ways.</a></li>
<li class="chapter" data-level="5.8.4" data-path="logistic-regression.html"><a href="logistic-regression.html#predicting-response"><i class="fa fa-check"></i><b>5.8.4</b> Predicting Response</a></li>
<li class="chapter" data-level="5.8.5" data-path="logistic-regression.html"><a href="logistic-regression.html#measues-of-association"><i class="fa fa-check"></i><b>5.8.5</b> Measues of association</a></li>
<li class="chapter" data-level="5.8.6" data-path="logistic-regression.html"><a href="logistic-regression.html#roc-curves"><i class="fa fa-check"></i><b>5.8.6</b> ROC curves</a></li>
<li class="chapter" data-level="5.8.7" data-path="logistic-regression.html"><a href="logistic-regression.html#drawing-interactions"><i class="fa fa-check"></i><b>5.8.7</b> Drawing interactions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>6</b> Survival Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="survival-analysis.html"><a href="survival-analysis.html#timedata"><i class="fa fa-check"></i><b>6.1</b> Time-to-event data</a><ul>
<li class="chapter" data-level="6.1.1" data-path="survival-analysis.html"><a href="survival-analysis.html#survival-function"><i class="fa fa-check"></i><b>6.1.1</b> Survival Function</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="survival-analysis.html"><a href="survival-analysis.html#KM"><i class="fa fa-check"></i><b>6.2</b> Kaplan-Meier Curves</a><ul>
<li class="chapter" data-level="6.2.1" data-path="survival-analysis.html"><a href="survival-analysis.html#KMCI"><i class="fa fa-check"></i><b>6.2.1</b> CI for KM curve</a></li>
<li class="chapter" data-level="6.2.2" data-path="survival-analysis.html"><a href="survival-analysis.html#logrank"><i class="fa fa-check"></i><b>6.2.2</b> Log-rank Test</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="survival-analysis.html"><a href="survival-analysis.html#hazfunc"><i class="fa fa-check"></i><b>6.3</b> Hazard Functions</a><ul>
<li class="chapter" data-level="6.3.1" data-path="survival-analysis.html"><a href="survival-analysis.html#estimating-ht-ala-kaplan-meier"><i class="fa fa-check"></i><b>6.3.1</b> Estimating <span class="math inline">\(h(t)\)</span> ala Kaplan-Meier</a></li>
<li class="chapter" data-level="6.3.2" data-path="survival-analysis.html"><a href="survival-analysis.html#proportional-hazards"><i class="fa fa-check"></i><b>6.3.2</b> Proportional Hazards</a></li>
<li class="chapter" data-level="6.3.3" data-path="survival-analysis.html"><a href="survival-analysis.html#coxph"><i class="fa fa-check"></i><b>6.3.3</b> Cox PH Regression Analysis</a></li>
<li class="chapter" data-level="6.3.4" data-path="survival-analysis.html"><a href="survival-analysis.html#testingph"><i class="fa fa-check"></i><b>6.3.4</b> Testing Proportional Hazards</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="survival-analysis.html"><a href="survival-analysis.html#othersurv"><i class="fa fa-check"></i><b>6.4</b> Other stuff</a><ul>
<li class="chapter" data-level="6.4.1" data-path="survival-analysis.html"><a href="survival-analysis.html#sample-size-calculation"><i class="fa fa-check"></i><b>6.4.1</b> Sample Size Calculation</a></li>
<li class="chapter" data-level="6.4.2" data-path="survival-analysis.html"><a href="survival-analysis.html#study-design"><i class="fa fa-check"></i><b>6.4.2</b> Study Design</a></li>
<li class="chapter" data-level="6.4.3" data-path="survival-analysis.html"><a href="survival-analysis.html#simulating-survival-data"><i class="fa fa-check"></i><b>6.4.3</b> Simulating survival data</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="survival-analysis.html"><a href="survival-analysis.html#Rsurv"><i class="fa fa-check"></i><b>6.5</b> R example: ProPublica Analysis</a><ul>
<li class="chapter" data-level="6.5.1" data-path="survival-analysis.html"><a href="survival-analysis.html#recidivism-in-florida"><i class="fa fa-check"></i><b>6.5.1</b> Recidivism in Florida</a></li>
<li class="chapter" data-level="6.5.2" data-path="survival-analysis.html"><a href="survival-analysis.html#kaplan-meier-survival-curve"><i class="fa fa-check"></i><b>6.5.2</b> Kaplan-Meier survival curve</a></li>
<li class="chapter" data-level="6.5.3" data-path="survival-analysis.html"><a href="survival-analysis.html#log-rank-test-rho0-and-the-wilcoxon-test-rho1"><i class="fa fa-check"></i><b>6.5.3</b> Log-rank test [rho=0] and the Wilcoxon test [rho=1]</a></li>
<li class="chapter" data-level="6.5.4" data-path="survival-analysis.html"><a href="survival-analysis.html#cox-proportional-hazards-models"><i class="fa fa-check"></i><b>6.5.4</b> Cox Proportional Hazards models</a></li>
<li class="chapter" data-level="6.5.5" data-path="survival-analysis.html"><a href="survival-analysis.html#checking-proportional-hazards-with-the-plot-of-ln-lnst"><i class="fa fa-check"></i><b>6.5.5</b> Checking proportional hazards with the plot of <span class="math inline">\(\ln(-\ln(S(t)))\)</span></a></li>
<li class="chapter" data-level="6.5.6" data-path="survival-analysis.html"><a href="survival-analysis.html#checking-proportional-hazards-with-cox.zph"><i class="fa fa-check"></i><b>6.5.6</b> Checking proportional hazards with cox.zph</a></li>
<li class="chapter" data-level="6.5.7" data-path="survival-analysis.html"><a href="survival-analysis.html#coxph-diagnostics-look-into-all-the-different-arguments-of-the-function"><i class="fa fa-check"></i><b>6.5.7</b> Coxph diagnostics … look into all the different arguments of the function!</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html"><i class="fa fa-check"></i><b>7</b> Multiple Comparisons</a><ul>
<li class="chapter" data-level="7.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#Ioannidis"><i class="fa fa-check"></i><b>7.1</b> Why Most Published Research Findings are False</a><ul>
<li class="chapter" data-level="7.1.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#positive-predictive-value-ppv"><i class="fa fa-check"></i><b>7.1.1</b> Positive Predictive Value (PPV)</a></li>
<li class="chapter" data-level="7.1.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#bias"><i class="fa fa-check"></i><b>7.1.2</b> Bias</a></li>
<li class="chapter" data-level="7.1.3" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#multiple-studies"><i class="fa fa-check"></i><b>7.1.3</b> Multiple Studies</a></li>
<li class="chapter" data-level="7.1.4" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#corollaries"><i class="fa fa-check"></i><b>7.1.4</b> Corollaries</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#multcomp"><i class="fa fa-check"></i><b>7.2</b> Multiple Comparisons</a><ul>
<li class="chapter" data-level="7.2.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#bonferroni"><i class="fa fa-check"></i><b>7.2.1</b> Bonferroni</a></li>
<li class="chapter" data-level="7.2.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#holm"><i class="fa fa-check"></i><b>7.2.2</b> Holm</a></li>
<li class="chapter" data-level="7.2.3" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#benjamini-hochberg"><i class="fa fa-check"></i><b>7.2.3</b> Benjamini-Hochberg</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#qvals"><i class="fa fa-check"></i><b>7.3</b> Storey &amp; q-values</a></li>
<li class="chapter" data-level="7.4" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#interim-analyses"><i class="fa fa-check"></i><b>7.4</b> Interim Analyses</a><ul>
<li class="chapter" data-level="7.4.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#pocock"><i class="fa fa-check"></i><b>7.4.1</b> Pocock</a></li>
<li class="chapter" data-level="7.4.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#obrien-flemming"><i class="fa fa-check"></i><b>7.4.2</b> O’Brien-Flemming</a></li>
<li class="chapter" data-level="7.4.3" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#some-parting-thoughts"><i class="fa fa-check"></i><b>7.4.3</b> Some parting thoughts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>8</b> Poisson Regression</a><ul>
<li class="chapter" data-level="8.1" data-path="poisson-regression.html"><a href="poisson-regression.html#regPois"><i class="fa fa-check"></i><b>8.1</b> Regression Models</a><ul>
<li class="chapter" data-level="8.1.1" data-path="poisson-regression.html"><a href="poisson-regression.html#the-poisson-regression-model"><i class="fa fa-check"></i><b>8.1.1</b> The Poisson Regression Model</a></li>
<li class="chapter" data-level="8.1.2" data-path="poisson-regression.html"><a href="poisson-regression.html#comparison-to-linear-regression"><i class="fa fa-check"></i><b>8.1.2</b> Comparison to Linear Regression</a></li>
<li class="chapter" data-level="8.1.3" data-path="poisson-regression.html"><a href="poisson-regression.html#interpreting-poisson-regression-coefficients"><i class="fa fa-check"></i><b>8.1.3</b> Interpreting Poisson Regression Coefficients</a></li>
<li class="chapter" data-level="8.1.4" data-path="poisson-regression.html"><a href="poisson-regression.html#assessing-model-validity"><i class="fa fa-check"></i><b>8.1.4</b> Assessing Model Validity</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="poisson-regression.html"><a href="poisson-regression.html#inferPois"><i class="fa fa-check"></i><b>8.2</b> Inference in Poisson Regression</a><ul>
<li class="chapter" data-level="8.2.1" data-path="poisson-regression.html"><a href="poisson-regression.html#maximum-likelihood"><i class="fa fa-check"></i><b>8.2.1</b> Maximum Likelihood</a></li>
<li class="chapter" data-level="8.2.2" data-path="poisson-regression.html"><a href="poisson-regression.html#wald-tests"><i class="fa fa-check"></i><b>8.2.2</b> Wald Tests</a></li>
<li class="chapter" data-level="8.2.3" data-path="poisson-regression.html"><a href="poisson-regression.html#drop-in-deviance-tests"><i class="fa fa-check"></i><b>8.2.3</b> Drop-in-Deviance Tests</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="poisson-regression.html"><a href="poisson-regression.html#r-poisson-example"><i class="fa fa-check"></i><b>8.3</b> R Poisson Example</a><ul>
<li class="chapter" data-level="8.3.1" data-path="poisson-regression.html"><a href="poisson-regression.html#glm"><i class="fa fa-check"></i><b>8.3.1</b> glm</a></li>
<li class="chapter" data-level="8.3.2" data-path="poisson-regression.html"><a href="poisson-regression.html#drop-in-deviance"><i class="fa fa-check"></i><b>8.3.2</b> drop in deviance</a></li>
<li class="chapter" data-level="8.3.3" data-path="poisson-regression.html"><a href="poisson-regression.html#residuals-1"><i class="fa fa-check"></i><b>8.3.3</b> residuals</a></li>
<li class="chapter" data-level="8.3.4" data-path="poisson-regression.html"><a href="poisson-regression.html#quasipoisson"><i class="fa fa-check"></i><b>8.3.4</b> quasiPoisson</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://st47s.com/Math150" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Methods in Biostatistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="SLR" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Simple Linear Regression</h1>
<p>Though we’ve discussed the relationship between tests of means and simple linear regression, we will really consider simple linear regression in a much broader context (one where both the explanatory and response variables are quantitative).</p>
<p>The data below represents 10 different variables on health of a country measured on 143 countries. Data taken from <span class="citation">(Lock et al. <a href="#ref-Lock5">2016</a>)</span>, originally from the Happy Planet Index Project [<a href="http://www.happyplanetindex.org/" class="uri">http://www.happyplanetindex.org/</a>]. Region of the world is coded as 1 = Latin America, 2 = Western nations, 3 = Middle East, 4 = Sub-Saharan Africa, 5 = South Asia, 6 = East Asia, 7 = former Communist countries. We are going to investigate happiness and life expectancy.</p>
<div id="transformations" class="section level2">
<h2><span class="header-section-number">3.1</span> Transformations</h2>
<div id="model-assumptions" class="section level3 unnumbered">
<h3>Model assumptions</h3>
<ul>
<li>The average value for the response variable is a linear function of the explanatory variable.</li>
<li>The error terms follow a normal distribution around the linear model.</li>
<li>The error terms have a mean of zero.</li>
<li>The error terms have a constant variance of <span class="math inline">\(\sigma^2\)</span>.</li>
<li>The error terms are independent (and identically distributed).</li>
<li>[<a href="http://www.rossmanchance.com/applets/RegSim/RegCoeff.html" class="uri">http://www.rossmanchance.com/applets/RegSim/RegCoeff.html</a>]</li>
</ul>
<p>How do we tell whether the assumptions are met? We can’t always. But it’s good to look at plots: scatter plot, residual plot, histograms of residuals. We denote the residuals for this model as:</p>
<p><span class="math display">\[\begin{align}
r_i = \hat{e}_i = y_i - \hat{y}_i
\end{align}\]</span></p>
<div class="figure">
<img src="transfor.jpg" alt="Figs 3.13 and 3.15 taken from Kutner et al. (2004)" />
<p class="caption">Figs 3.13 and 3.15 taken from <span class="citation">Kutner et al. (<a href="#ref-kutner">2004</a>)</span></p>
</div>
<p><strong>important note!!</strong> The idea behind transformations is to make the model as appropriate as possible for the data at hand. We want to find the correct <strong>linear</strong> model; we want our assumptions to hold. We are not trying to find the most <em>significant</em> model or big <span class="math inline">\(R^2\)</span>.</p>
<p>See section 2.9 in your text. No normal probability plots (qq-plots); use histograms or boxplots to assess the symmetry and normality of the residuals.</p>
</div>
</div>
<div id="fitting-the-regression-line" class="section level2">
<h2><span class="header-section-number">3.2</span> Fitting the regression line</h2>
<p>How do we fit a regression line? Find <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> that minimize the sum of squared distance of the points to the line (called ordinary least squares):</p>
<p><span class="math display">\[\begin{align}
\min \sum (y_i \hat{y}_i)^2 &amp;=&amp; \min RSS \mbox{ residual sum of squares}\\
RSS &amp;=&amp; \sum (y_i - b_0 - b_1 x_i)^2\\
\frac{\partial RSS}{\partial b_0} = 0\\
\frac{\partial RSS}{\partial b_1} = 0\\
b_0 &amp;=&amp; \overline{y} - b_1 \overline{x}\\
b_1 &amp;=&amp; r(x,y) \frac{s_x}{s_y}\\
\end{align}\]</span></p>
<ul>
<li>Is that the only way to find values for <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>? (absolute distances, maximum likelihood,…)</li>
<li>Resistance to outliers?</li>
<li>What is <span class="math inline">\(\hat{y}\)</span> at <span class="math inline">\(\overline{x}\)</span>?</li>
</ul>
<p><span class="math display">\[\begin{align}
\hat{y} &amp;=&amp; b_0 + b_1 \overline{x}\\
&amp;=&amp; \overline{y} - b_1 \overline{x} + b_1 \overline{x}\\
&amp;=&amp; \overline{y}
\end{align}\]</span></p>
<p>The regression line will always pass through the point <span class="math inline">\((\overline{x}, \overline{y})\)</span>.</p>

<div class="definition">
<span id="def:unnamed-chunk-2" class="definition"><strong>Definition 3.1  </strong></span>An estimate is <em>unbiased</em> if, over many repeated samples drawn from the population, the average value of the estimates based on the different samples would equal the population value of the parameter being estimated. That is, a statistic is unbiased if the mean of its sampling distribution is the population parameter.
</div>

</div>
<div id="correlation" class="section level2">
<h2><span class="header-section-number">3.3</span> Correlation</h2>
<p>Consider a scatterplot, you’ll have variability in both directions: <span class="math inline">\((x_i - \overline{x}) \&amp; (y_i - \overline{y})\)</span>.</p>
<p><span class="math display">\[\begin{align}
\mbox{sample covariance}&amp;&amp;\\
cov(x,y) &amp;=&amp; \frac{1}{n-1}\sum (x_i - \overline{x}) (y_i - \overline{y})\\
\mbox{sample correlation}&amp;&amp;\\
r(x,y) &amp;=&amp; \frac{cov(x,y)}{s_x s_y}\\
&amp;=&amp; \frac{\frac{1}{n-1} \sum (x_i - \overline{x}) (y_i - \overline{y})}{\sqrt{\frac{\sum(x_i - \overline{x})^2}{n-1} \frac{\sum(y_i - \overline{y})^2}{n-1}}}\\
\mbox{pop cov} &amp;=&amp; \sigma_{xy}\\
\mbox{pop cor} &amp;=&amp; \rho = \frac{\sigma_{xy}}{\sigma_x \sigma_y}\\
\end{align}\]</span></p>
<ul>
<li><span class="math inline">\(-1 \leq r \leq 1 \&amp; -1 \leq \rho \leq 1\)</span>.<br />
</li>
<li>No Spearman’s rank correlation or Kendall’s <span class="math inline">\(\tau\)</span>.<br />
</li>
<li><span class="math inline">\(b_1 = r \frac{s_y}{s_x}\)</span>
<ul>
<li>if <span class="math inline">\(r=0, b_1=0\)</span><br />
</li>
<li>if <span class="math inline">\(r=1, b_1 &gt; 0\)</span> but can be anything!<br />
</li>
<li><span class="math inline">\(r &lt; 0 \leftrightarrow b &lt; 0, r &gt; 0 \leftrightarrow b &gt; 0\)</span><br />
</li>
</ul></li>
<li>Recall that <span class="math inline">\(R^2\)</span> is the proportion of variability explained by the line.</li>
</ul>
</div>
<div id="errors" class="section level2">
<h2><span class="header-section-number">3.4</span> Errors</h2>
<p>Recall, <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2)\)</span>. How do we estimate <span class="math inline">\(\sigma^2\)</span>?</p>
<p><span class="math display">\[\begin{align}
RSS &amp;=&amp; \sum (y_i - \hat{y}_i)^2 \ \ \ \mbox{ residual sum of squares}\\
MSS &amp;=&amp; \sum (\hat{y}_i - \overline{y})^2 \ \ \ \mbox{ model sum of squares}\\
TSS &amp;=&amp; \sum (y_i - \overline{y})^2 \ \ \ \mbox{ total sum of squares}\\
s_{y|x}^2 &amp;=&amp; \hat{\sigma^2} = \frac{1}{n-2} RSS\\
s_x^2 &amp;=&amp; \frac{1}{n-1} \sum (x_i - \overline{x})^2\\
s_y^2 &amp;=&amp; \frac{1}{n-1} \sum (y_i - \overline{y})^2\\
var(\epsilon) &amp;=&amp; s_{y|x}^2 = \frac{RSS}{n-2} = \frac{\sum(y_i - \hat{y}_i)^2}{n-2} = SE(\epsilon)\\
var(b_1) &amp;=&amp; \frac{s_{y|x}^2}{(n-1) s_x^2}\\
SE(b_1) &amp;=&amp; \frac{s_{y|x}}{\sqrt{(n-1)} s_x}\\
&amp;=&amp; \frac{\hat{\sigma}}{\sqrt{\sum(x_i - \overline{x})^2}} = \frac{\sqrt{\sum(y_i - \hat{y}_i)^2/(n-2)}}{\sqrt{\sum(x_i - \overline{x})^2}}\\
\end{align}\]</span></p>
<ul>
<li><span class="math inline">\(SE(b_1) \downarrow\)</span> as <span class="math inline">\(\sigma \downarrow\)</span></li>
<li><span class="math inline">\(SE(b_1) \downarrow\)</span> as <span class="math inline">\(n \uparrow\)</span></li>
<li><span class="math inline">\(SE(b_1) \downarrow\)</span> as <span class="math inline">\(s_x \uparrow\)</span></li>
<li>WHY?</li>
<li>What do we mean by <span class="math inline">\(SE(b_1)\)</span>?</li>
</ul>
<p>As we saw above, the correlation and the slope estimates are intimately related. They are also both related to the <em>coefficient of determination</em>.
<span class="math display">\[\begin{align}
R^2 = r^2 = \frac{MSS}{TSS}
\end{align}\]</span></p>
<p><span class="math inline">\(R^2\)</span> is the proportion of total variability explained by the regression line (the linear relationship between the explanatory and response variables).</p>
<ul>
<li>If <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are not at all correlated, <span class="math inline">\(\hat{y}_i \approx \overline{y}\)</span>, MSS = 0, <span class="math inline">\(R^2=0\)</span>.</li>
<li>If <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are perfectly correlated, <span class="math inline">\(\hat{y}_i = y_i\)</span>, MSS=TSS, <span class="math inline">\(R^2 = 1\)</span>.</li>
</ul>
<div id="testing-beta_1" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Testing <span class="math inline">\(\beta_1\)</span></h3>
<p>If <span class="math inline">\(H_0: \beta=0\)</span> is true, then
<span class="math display">\[\begin{align}
\frac{b_1 - 0}{SE(b_1)} \sim t_{n-2}
\end{align}\]</span>
Note that the degrees of freedom are now <span class="math inline">\(n-2\)</span> because we are estimating two parameters (<span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>). We can also find a <span class="math inline">\((1-\alpha)100\%\)</span> confidence interval for <span class="math inline">\(\beta_1\)</span>:
<span class="math display">\[\begin{align}
b_1 \pm t_{\alpha/2, n-2} SE(b_1)
\end{align}\]</span></p>
</div>
</div>
<div id="intervals" class="section level2">
<h2><span class="header-section-number">3.5</span> Intervals</h2>
<p>As with anything that has some type of standard error, we can create intervals that give us some confidence in the statements we are making.</p>
<div id="confidence-intervals" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Confidence Intervals</h3>
<p>In general, confidence intervals are of the form:</p>
<pre><code>point estimate +/- multiplier * SE(point estimate)</code></pre>
</div>
<div id="slope" class="section level3">
<h3><span class="header-section-number">3.5.2</span> Slope</h3>
<p>We can create a CI for the slope parameter, <span class="math inline">\(\beta_1\)</span>:
<span class="math display">\[\begin{align}
b_1 &amp;\pm&amp; t_{\alpha/2,n-2} SE(b_1)\\
b_1 &amp;\pm&amp; t_{\alpha/2, n-2} \frac{s_{y|x}}{\sqrt{(n-1)}s_x}\\
6.693 &amp;\pm&amp; t_{.025, 141} 0.375\\
t_{.025,141} &amp;=&amp; qt(0.025, 141) = -1.977\\
\mbox{CI} &amp;&amp; (5.95 \mbox{ years/unit of happy}, 7.43 \mbox{ years/unit of happy})
\end{align}\]</span>
How can we interpret the CI? Does it make sense to talk about a unit of happiness?</p>
</div>
<div id="mean-response" class="section level3">
<h3><span class="header-section-number">3.5.3</span> Mean Response</h3>
<p>We can also create a CI for the mean response, <span class="math inline">\(E[Y|x^*] = \beta_0 + \beta_1 x^*\)</span>. Note that the standard error of the point estimate (<span class="math inline">\(\hat{y}=b_0 + b_1 x^*\)</span>) now depends on the variability associated with two things (<span class="math inline">\(b_0, b_1\)</span>).
<span class="math display">\[\begin{align}
SE(\hat{y(x^*)}) &amp;=&amp; \sqrt{ \frac{s^2_{y|x}}{n} + (x^* - \overline{x})^2 SE(b_1)^2}\\
SE(\hat{y}(\overline{x})) &amp;=&amp; s_{y|x}/\sqrt{n}\\
SE(\hat{y}(x)) &amp;\geq&amp; s_{y|x}/\sqrt{n} \ \ \ \forall x
\end{align}\]</span>
How would you interpret the associated interval?</p>
</div>
<div id="prediction-of-an-individual-response" class="section level3">
<h3><span class="header-section-number">3.5.4</span> Prediction of an Individual Response</h3>
<p>As should be obvious, predicting an individual is more variable than predicting a mean.</p>
<p><span class="math display">\[\begin{align}
SE(y(x^*)) &amp;=&amp; \sqrt{ \frac{s^2_{y|x}}{n} + (x^* - \overline{x})^2 SE(b_1)^2 + s^2_{y|x}}\\
SE(y(x^*)) &amp;=&amp; \sqrt{ SE(\hat{y}(x^*))^2 + s^2_{y|x}}\\
\end{align}\]</span>
How would you interpret the associated interval?</p>
</div>
<div id="outlying-high-leverage-and-influential-points" class="section level3">
<h3><span class="header-section-number">3.5.5</span> Outlying, High Leverage, and Influential Points</h3>
<p><strong>We are skipping the rest of this section in the notes. You are not responsible for it.</strong></p>
<p>Read section 4.7 (no loess, ignore the multiple predictors part, )</p>

<div class="theorem">
<span id="thm:unnamed-chunk-3" class="theorem"><strong>Theorem 3.1  </strong></span><em>High leverage points</em> are x-outliers with the potential to exert undue influence on regression coefficient estimates. <em>Influential points</em> are points that have exerted undue influence on the regression coefficient estimates.
</div>

<p>Note: typically we think of more data as better; more values will tend to decrease the sampling variability of our statistic. But if I give you a lot more data and put it all at <span class="math inline">\(\overline{x}\)</span>, <span class="math inline">\(SE(b_1)\)</span> stays exactly the same. Why??</p>
<p>Recall
<span class="math display">\[\begin{align}
y_{i} &amp;=&amp; \beta_0 + \beta_1 x_i \ \ \ \epsilon_i \sim N(0,\sigma^2)\\
e_i &amp;=&amp; y_i - \hat{y}_i
\end{align}\]</span></p>
<p>We plot <span class="math inline">\(e_i\)</span> versus <span class="math inline">\(\hat{y}_i\)</span>. (Why? Typically, we want the <span class="math inline">\(e_i\)</span> to be constant at each value of <span class="math inline">\(x_i\)</span>. Note that <span class="math inline">\(\hat{y}_i\)</span> is a simple linear transformation of <span class="math inline">\(x_i\)</span>, so the plot is identical.) We want to see if the distributions of the residuals is different across the fitted line (we look for patterns).\</p>
<p><strong>Not all residuals have an equal effect on the regression line!!</strong></p>
<div id="leverage" class="section level4">
<h4><span class="header-section-number">3.5.5.1</span> leverage</h4>
<p><span class="math display">\[\begin{align}
h_i = \frac{1}{n} +\frac{(x_i - \overline{x})^2}{\sum_{j=1}^n (x_j - \overline{x})^2}\\
\frac{1}{n} \leq h_i \leq 1\\
\end{align}\]</span>
Leverage represents the effect of point <span class="math inline">\(x_i\)</span> on the line. We need large leverage for a particular value to have a large effect.</p>
<p>Note:
<span class="math display">\[\begin{align}
SE(\hat{y}(x_i)) &amp;=&amp; s_{y|x} \sqrt{h_i}\\
SE(y(x_i)) &amp;=&amp; s_{y|x} \sqrt{(h_i + 1)}\\
SE(e_i) &amp;=&amp; s_{y|x} \sqrt{(1-h_i)}\\
\hat{y}(x^*) &amp;\pm&amp; t_{n-2, .025} (s_{y|x} \sqrt{h(x^*)+1})\\
\end{align}\]</span>
is a 95% prediction interval at <span class="math inline">\(x^*\)</span>. High leverage reduces the variability because the line gets pulled toward the point.</p>
</div>
<div id="standardized-residuals" class="section level4">
<h4><span class="header-section-number">3.5.5.2</span> standardized residuals</h4>
<p><span class="math display">\[\begin{align}
\frac{e_i}{s_{y|x} \sqrt{1-h_i}} \sim t_{n-2}\\
\end{align}\]</span></p>
</div>
<div id="studentized-residuals" class="section level4">
<h4><span class="header-section-number">3.5.5.3</span> studentized residuals</h4>
<p><span class="math display">\[\begin{align}
\frac{e_i}{s_{y|x, (i)} \sqrt{1-h_i}} &amp;\sim&amp; t_{n-3}\\
s_{y|x, (i)} &amp;=&amp; \frac{1}{n-3} \sum_{j \ne i} (y_j - \hat{y}_{j(i)})^2
\end{align}\]</span></p>
<p>Where do we predict 90% of residuals? <span class="math inline">\(\pm t_{n-2,3 , .05}\)</span>. About <span class="math inline">\(\pm 2\)</span>.</p>
</div>
<div id="dfbetas" class="section level4">
<h4><span class="header-section-number">3.5.5.4</span> DFBETAs</h4>
<p>DFBETAs represent the change in the parameter estimate due to one observation.</p>
<p><span class="math display">\[\begin{align}
DFBETAS_i &amp;=&amp; \frac{b_1 - b_{1(i)}}{\frac{s_{y|x, (i)}}{\sqrt{(n-1)} s_x}}\\
\end{align}\]</span></p>
</div>
</div>
</div>
<div id="r-example-slr-happy-planet" class="section level2">
<h2><span class="header-section-number">3.6</span> R Example (SLR): Happy Planet</h2>
<p>The data below represents 10 different variables on health of a country measured on 143 countries. Data taken from <span class="citation">(Lock et al. <a href="#ref-Lock5">2016</a>)</span>, originally from the Happy Planet Index Project [<a href="http://www.happyplanetindex.org/" class="uri">http://www.happyplanetindex.org/</a>]. Region of the world is coded as 1 = Latin America, 2 = Western nations, 3 = Middle East, 4 = Sub-Saharan Africa, 5 = South Asia, 6 = East Asia, 7 = former Communist countries. We are going to investigate happiness and life expectancy.</p>
<div id="reading-the-data-into-r" class="section level3">
<h3><span class="header-section-number">3.6.1</span> Reading the data into R</h3>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">happy &lt;-<span class="st"> </span><span class="kw">read_delim</span>(<span class="st">&quot;~/Dropbox/teaching/math150/spring17/happyPlanet.txt&quot;</span>, <span class="dt">delim=</span><span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2"><span class="kw">glimpse</span>(happy)  </a></code></pre></div>
<pre><code>## Observations: 143
## Variables: 11
## $ Country        &lt;chr&gt; &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argentina&quot;, &quot;Arm…
## $ Region         &lt;dbl&gt; 7, 3, 4, 1, 7, 2, 2, 7, 5, 7, 2, 1, 4, 5, 1, 7, 4…
## $ Happiness      &lt;dbl&gt; 5.5, 5.6, 4.3, 7.1, 5.0, 7.9, 7.8, 5.3, 5.3, 5.8,…
## $ LifeExpectancy &lt;dbl&gt; 76.2, 71.7, 41.7, 74.8, 71.7, 80.9, 79.4, 67.1, 6…
## $ Footprint      &lt;dbl&gt; 2.2, 1.7, 0.9, 2.5, 1.4, 7.8, 5.0, 2.2, 0.6, 3.9,…
## $ HLY            &lt;dbl&gt; 41.7, 40.1, 17.8, 53.4, 36.1, 63.7, 61.9, 35.4, 3…
## $ HPI            &lt;dbl&gt; 47.91, 51.23, 26.78, 58.95, 48.28, 36.64, 47.69, …
## $ HPIRank        &lt;dbl&gt; 54, 40, 130, 15, 48, 102, 57, 85, 31, 104, 64, 27…
## $ GDPperCapita   &lt;dbl&gt; 5316, 7062, 2335, 14280, 4945, 31794, 33700, 5016…
## $ HDI            &lt;dbl&gt; 0.801, 0.733, 0.446, 0.869, 0.775, 0.962, 0.948, …
## $ Population     &lt;dbl&gt; 3.15, 32.85, 16.10, 38.75, 3.02, 20.40, 8.23, 8.3…</code></pre>
</div>
<div id="running-the-linear-model-lm" class="section level3">
<h3><span class="header-section-number">3.6.2</span> Running the linear model (lm)</h3>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1">happy.lm =<span class="st"> </span><span class="kw">lm</span>(LifeExpectancy <span class="op">~</span><span class="st"> </span>Happiness, <span class="dt">data=</span>happy) </a>
<a class="sourceLine" id="cb13-2" data-line-number="2"></a>
<a class="sourceLine" id="cb13-3" data-line-number="3">happy.lm <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</a></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)    28.2      2.28       12.4 2.76e-24
## 2 Happiness       6.69     0.375      17.8 5.78e-38</code></pre>
</div>
<div id="ouptut" class="section level3">
<h3><span class="header-section-number">3.6.3</span> Ouptut</h3>
<p>Some analyses will need the residuals, fitted values, or coefficients individually.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1">happy.lm <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span>()</a></code></pre></div>
<pre><code>## # A tibble: 143 x 9
##    LifeExpectancy Happiness .fitted .se.fit  .resid    .hat .sigma .cooksd
##             &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
##  1           76.2       5.5    65.0   0.537  11.2   0.00765   6.09 1.28e-2
##  2           71.7       5.6    65.7   0.527   6.00  0.00737   6.14 3.57e-3
##  3           41.7       4.3    57.0   0.796 -15.3   0.0168    6.02 5.39e-2
##  4           74.8       7.1    75.7   0.678  -0.944 0.0122    6.16 1.48e-4
##  5           71.7       5      61.7   0.619  10.0   0.0101    6.10 1.38e-2
##  6           80.9       7.9    81.1   0.904  -0.198 0.0216    6.16 1.18e-5
##  7           79.4       7.8    80.4   0.873  -1.03  0.0202    6.16 2.95e-4
##  8           67.1       5.3    63.7   0.564   3.40  0.00842   6.16 1.32e-3
##  9           63.1       5.3    63.7   0.564  -0.596 0.00842   6.16 4.04e-5
## 10           68.7       5.8    67.0   0.515   1.66  0.00705   6.16 2.60e-4
## # … with 133 more rows, and 1 more variable: .std.resid &lt;dbl&gt;</code></pre>
<p>We can plot the main relationship, or we can plot the residuals (to check that technical conditions hold):</p>
<pre><code>ggplot(happy, aes(x=Happiness, y=LifeExpectancy)) + geom_point() + 
         geom_smooth(method=&quot;lm&quot;, se=FALSE) 
happy.lm %&gt;% augment %&gt;% ggplot(aes(x = .fitted, y = .resid)) + geom_point() + 
         geom_hline(yintercept=0)</code></pre>
<p><img src="03-SLR_files/figure-html/unnamed-chunk-8-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Intervals of interest: mean response, individual response, and parameter(s).</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="kw">predict.lm</span>(happy.lm, <span class="dt">newdata=</span><span class="kw">list</span>(<span class="dt">Happiness=</span><span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">7</span>)),<span class="dt">interval=</span><span class="kw">c</span>(<span class="st">&quot;conf&quot;</span>), <span class="dt">level=</span>.<span class="dv">95</span>)</a></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 54.99531 53.24675 56.74387
## 2 75.07444 73.78057 76.36830</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="kw">predict.lm</span>(happy.lm, <span class="dt">newdata=</span><span class="kw">list</span>(<span class="dt">Happiness=</span><span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">7</span>)),<span class="dt">interval=</span><span class="kw">c</span>(<span class="st">&quot;pred&quot;</span>), <span class="dt">level=</span>.<span class="dv">95</span>)</a></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 54.99531 42.72945 67.26117
## 2 75.07444 62.86510 87.28377</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1">happy.lm <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<pre><code>## # A tibble: 2 x 7
##   term        estimate std.error statistic  p.value conf.low conf.high
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)    28.2      2.28       12.4 2.76e-24    23.7      32.7 
## 2 Happiness       6.69     0.375      17.8 5.78e-38     5.95      7.43</code></pre>
<div id="residuals-in-r" class="section level4">
<h4><span class="header-section-number">3.6.3.1</span> Residuals in R</h4>
<p>We skipped the residuals section, so you are not responsible for finding residuals in R, but the R code is here for completion in case you are interested:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1">happy.lm <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span>()</a></code></pre></div>
<pre><code>## # A tibble: 143 x 9
##    LifeExpectancy Happiness .fitted .se.fit  .resid    .hat .sigma .cooksd
##             &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;
##  1           76.2       5.5    65.0   0.537  11.2   0.00765   6.09 1.28e-2
##  2           71.7       5.6    65.7   0.527   6.00  0.00737   6.14 3.57e-3
##  3           41.7       4.3    57.0   0.796 -15.3   0.0168    6.02 5.39e-2
##  4           74.8       7.1    75.7   0.678  -0.944 0.0122    6.16 1.48e-4
##  5           71.7       5      61.7   0.619  10.0   0.0101    6.10 1.38e-2
##  6           80.9       7.9    81.1   0.904  -0.198 0.0216    6.16 1.18e-5
##  7           79.4       7.8    80.4   0.873  -1.03  0.0202    6.16 2.95e-4
##  8           67.1       5.3    63.7   0.564   3.40  0.00842   6.16 1.32e-3
##  9           63.1       5.3    63.7   0.564  -0.596 0.00842   6.16 4.04e-5
## 10           68.7       5.8    67.0   0.515   1.66  0.00705   6.16 2.60e-4
## # … with 133 more rows, and 1 more variable: .std.resid &lt;dbl&gt;</code></pre>

</div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-kutner">
<p>Kutner, Nachtsheim, Neter, and Li. 2004. <em>Applied Linear Statistical Models</em>. 5th ed. McGraw-Hill.</p>
</div>
<div id="ref-Lock5">
<p>Lock, R., P.F. Lock, K. Lock Morgan, E. Lock, and D. Lock. 2016. <em>Unlocking the Power of Data</em>. Wiley. <a href="http://www.lock5stat.com/StatKey/">http://www.lock5stat.com/StatKey/</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="t-tests-vs-slr.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="analysis-of-categorical-data-section-6-3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-SLR.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Math-150-Notes.pdf", "Math-150-Notes.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
