<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 6 Survival Analysis | Methods in Biostatistics</title>
  <meta name="description" content="Class notes for Math 150 at Pomona College: Methods in Biostatistics. The notes are based primarily on the text Practicing Statistics, Kuiper and Sklar">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 6 Survival Analysis | Methods in Biostatistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Class notes for Math 150 at Pomona College: Methods in Biostatistics. The notes are based primarily on the text Practicing Statistics, Kuiper and Sklar" />
  <meta name="github-repo" content="hardin47/website/Math150/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Survival Analysis | Methods in Biostatistics" />
  
  <meta name="twitter:description" content="Class notes for Math 150 at Pomona College: Methods in Biostatistics. The notes are based primarily on the text Practicing Statistics, Kuiper and Sklar" />
  

<meta name="author" content="Jo Hardin">


<meta name="date" content="2019-04-01">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="logistic-regression.html">
<link rel="next" href="multiple-comparisons.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Methods in Biostatistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Class Information</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#course-goals"><i class="fa fa-check"></i><b>1.1</b> Course Goals</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#experimental-design"><i class="fa fa-check"></i>Experimental Design</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html"><i class="fa fa-check"></i><b>2</b> t-tests vs. SLR</a><ul>
<li class="chapter" data-level="" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#surgery-timing"><i class="fa fa-check"></i>Surgery Timing</a></li>
<li class="chapter" data-level="2.1" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#ttest"><i class="fa fa-check"></i><b>2.1</b> t-test (book: 2.1)</a><ul>
<li class="chapter" data-level="2.1.1" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#what-is-an-alternative-hypothesis"><i class="fa fa-check"></i><b>2.1.1</b> What is an Alternative Hypothesis?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#anova"><i class="fa fa-check"></i>ANOVA</a></li>
<li class="chapter" data-level="2.2" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#tslr"><i class="fa fa-check"></i><b>2.2</b> Simple Linear Regression (book: 2.3)</a><ul>
<li class="chapter" data-level="" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#why-are-they-the-same"><i class="fa fa-check"></i>Why are they the same?</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#confidence-intervals-section-2.11"><i class="fa fa-check"></i><b>2.3</b> Confidence Intervals (section 2.11)</a></li>
<li class="chapter" data-level="2.4" data-path="t-tests-vs-slr.html"><a href="t-tests-vs-slr.html#random-sample-vs.random-allocation"><i class="fa fa-check"></i><b>2.4</b> Random Sample vs. Random allocation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="SLR.html"><a href="SLR.html"><i class="fa fa-check"></i><b>3</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="SLR.html"><a href="SLR.html#transformations"><i class="fa fa-check"></i><b>3.1</b> Transformations</a><ul>
<li class="chapter" data-level="" data-path="SLR.html"><a href="SLR.html#model-assumptions"><i class="fa fa-check"></i>Model assumptions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="SLR.html"><a href="SLR.html#fitting-the-regression-line"><i class="fa fa-check"></i><b>3.2</b> Fitting the regression line</a></li>
<li class="chapter" data-level="3.3" data-path="SLR.html"><a href="SLR.html#correlation"><i class="fa fa-check"></i><b>3.3</b> Correlation</a></li>
<li class="chapter" data-level="3.4" data-path="SLR.html"><a href="SLR.html#errors"><i class="fa fa-check"></i><b>3.4</b> Errors</a><ul>
<li class="chapter" data-level="3.4.1" data-path="SLR.html"><a href="SLR.html#testing-beta_1"><i class="fa fa-check"></i><b>3.4.1</b> Testing <span class="math inline">\(\beta_1\)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="SLR.html"><a href="SLR.html#intervals"><i class="fa fa-check"></i><b>3.5</b> Intervals</a><ul>
<li class="chapter" data-level="3.5.1" data-path="SLR.html"><a href="SLR.html#confidence-intervals"><i class="fa fa-check"></i><b>3.5.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="3.5.2" data-path="SLR.html"><a href="SLR.html#slope"><i class="fa fa-check"></i><b>3.5.2</b> Slope</a></li>
<li class="chapter" data-level="3.5.3" data-path="SLR.html"><a href="SLR.html#mean-response"><i class="fa fa-check"></i><b>3.5.3</b> Mean Response</a></li>
<li class="chapter" data-level="3.5.4" data-path="SLR.html"><a href="SLR.html#prediction-of-an-individual-response"><i class="fa fa-check"></i><b>3.5.4</b> Prediction of an Individual Response</a></li>
<li class="chapter" data-level="3.5.5" data-path="SLR.html"><a href="SLR.html#outlying-high-leverage-and-influential-points"><i class="fa fa-check"></i><b>3.5.5</b> Outlying, High Leverage, and Influential Points</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="SLR.html"><a href="SLR.html#r-example-slr-happy-planet"><i class="fa fa-check"></i><b>3.6</b> R Example (SLR): Happy Planet</a><ul>
<li class="chapter" data-level="3.6.1" data-path="SLR.html"><a href="SLR.html#reading-the-data-into-r"><i class="fa fa-check"></i><b>3.6.1</b> Reading the data into R</a></li>
<li class="chapter" data-level="3.6.2" data-path="SLR.html"><a href="SLR.html#running-the-linear-model-lm"><i class="fa fa-check"></i><b>3.6.2</b> Running the linear model (lm)</a></li>
<li class="chapter" data-level="3.6.3" data-path="SLR.html"><a href="SLR.html#ouptut"><i class="fa fa-check"></i><b>3.6.3</b> Ouptut</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html"><i class="fa fa-check"></i><b>4</b> Analysis of Categorical Data (section 6.3)</a><ul>
<li class="chapter" data-level="4.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#cat"><i class="fa fa-check"></i><b>4.1</b> Categorical Inference</a></li>
<li class="chapter" data-level="4.2" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#fisher"><i class="fa fa-check"></i><b>4.2</b> Fisher’s Exact Test (section 6.4)</a></li>
<li class="chapter" data-level="4.3" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#chisq"><i class="fa fa-check"></i><b>4.3</b> Testing independence of two categorical variables (sections 6.5, 6.6, 6.7)</a><ul>
<li class="chapter" data-level="4.3.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#chi2-tests-section-6.6"><i class="fa fa-check"></i><b>4.3.1</b> <span class="math inline">\(\chi^2\)</span> tests (section 6.6)</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#catest"><i class="fa fa-check"></i><b>4.4</b> Parameter Estimation (section 6.8)</a><ul>
<li class="chapter" data-level="4.4.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#ci-for-differences-in-proportions"><i class="fa fa-check"></i><b>4.4.1</b> CI for differences in proportions</a></li>
<li class="chapter" data-level="4.4.2" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#relative-risk"><i class="fa fa-check"></i><b>4.4.2</b> Relative Risk</a></li>
<li class="chapter" data-level="4.4.3" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#odds-ratios"><i class="fa fa-check"></i><b>4.4.3</b> Odds Ratios</a></li>
<li class="chapter" data-level="4.4.4" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#confidence-interval-for-or"><i class="fa fa-check"></i><b>4.4.4</b> Confidence Interval for OR</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#studies"><i class="fa fa-check"></i><b>4.5</b> Types of Studies (section 6.9)</a><ul>
<li class="chapter" data-level="4.5.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#retrospective-versus-prospective-studies"><i class="fa fa-check"></i><b>4.5.1</b> Retrospective versus Prospective Studies</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#r-example-categorical-data-botox-and-back-pain"><i class="fa fa-check"></i><b>4.6</b> R Example (categorical data): Botox and back pain</a><ul>
<li class="chapter" data-level="4.6.1" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#entering-and-visualizing-the-data"><i class="fa fa-check"></i><b>4.6.1</b> Entering and visualizing the data</a></li>
<li class="chapter" data-level="4.6.2" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#fishers-exact-test"><i class="fa fa-check"></i><b>4.6.2</b> Fisher’s Exact Test</a></li>
<li class="chapter" data-level="4.6.3" data-path="analysis-of-categorical-data-section-6-3.html"><a href="analysis-of-categorical-data-section-6-3.html#chi-squared-analysis"><i class="fa fa-check"></i><b>4.6.3</b> Chi-squared Analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>5</b> Logistic Regression</a><ul>
<li class="chapter" data-level="5.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logmodel"><i class="fa fa-check"></i><b>5.1</b> Motivation for Logistic Regression</a><ul>
<li class="chapter" data-level="5.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#the-logistic-model"><i class="fa fa-check"></i><b>5.1.1</b> The logistic model</a></li>
<li class="chapter" data-level="5.1.2" data-path="logistic-regression.html"><a href="logistic-regression.html#constant-or-varying-rr"><i class="fa fa-check"></i><b>5.1.2</b> constant OR, varying RR</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="logistic-regression.html"><a href="logistic-regression.html#logMLE"><i class="fa fa-check"></i><b>5.2</b> Estimating coefficients in logistic regression</a><ul>
<li class="chapter" data-level="5.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>5.2.1</b> Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="logistic-regression.html"><a href="logistic-regression.html#loginf"><i class="fa fa-check"></i><b>5.3</b> Formal Inference</a><ul>
<li class="chapter" data-level="5.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#wald-tests-intervals"><i class="fa fa-check"></i><b>5.3.1</b> Wald Tests &amp; Intervals</a></li>
<li class="chapter" data-level="5.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#likelihood-ratio-tests"><i class="fa fa-check"></i><b>5.3.2</b> Likelihood Ratio Tests</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="logistic-regression.html"><a href="logistic-regression.html#multlog"><i class="fa fa-check"></i><b>5.4</b> Multiple Logistic Regression</a><ul>
<li class="chapter" data-level="5.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#interaction"><i class="fa fa-check"></i><b>5.4.1</b> Interaction</a></li>
<li class="chapter" data-level="5.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#simpsons-paradox"><i class="fa fa-check"></i><b>5.4.2</b> Simpson’s Paradox</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="logistic-regression.html"><a href="logistic-regression.html#multicol"><i class="fa fa-check"></i><b>5.5</b> Multicolinearity</a></li>
<li class="chapter" data-level="5.6" data-path="logistic-regression.html"><a href="logistic-regression.html#logstep"><i class="fa fa-check"></i><b>5.6</b> Model Building</a><ul>
<li class="chapter" data-level="5.6.1" data-path="logistic-regression.html"><a href="logistic-regression.html#formal-model-building"><i class="fa fa-check"></i><b>5.6.1</b> Formal Model Building</a></li>
<li class="chapter" data-level="5.6.2" data-path="logistic-regression.html"><a href="logistic-regression.html#getting-the-model-right"><i class="fa fa-check"></i><b>5.6.2</b> Getting the Model Right</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="logistic-regression.html"><a href="logistic-regression.html#model-assessment"><i class="fa fa-check"></i><b>5.7</b> Model Assessment</a><ul>
<li class="chapter" data-level="5.7.1" data-path="logistic-regression.html"><a href="logistic-regression.html#measures-of-association"><i class="fa fa-check"></i><b>5.7.1</b> Measures of Association</a></li>
<li class="chapter" data-level="5.7.2" data-path="logistic-regression.html"><a href="logistic-regression.html#roc"><i class="fa fa-check"></i><b>5.7.2</b> Receiver Operating Characteristic Curves</a></li>
<li class="chapter" data-level="5.7.3" data-path="logistic-regression.html"><a href="logistic-regression.html#cv"><i class="fa fa-check"></i><b>5.7.3</b> Cross Validation</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="logistic-regression.html"><a href="logistic-regression.html#birdexamp"><i class="fa fa-check"></i><b>5.8</b> R: Birdnest Example</a><ul>
<li class="chapter" data-level="5.8.1" data-path="logistic-regression.html"><a href="logistic-regression.html#drop-in-deviance-likelihood-ratio-test-lrt"><i class="fa fa-check"></i><b>5.8.1</b> Drop-in-deviance (Likelihood Ratio Test, LRT)</a></li>
<li class="chapter" data-level="5.8.2" data-path="logistic-regression.html"><a href="logistic-regression.html#difference-between-tidy-and-augment-and-glance"><i class="fa fa-check"></i><b>5.8.2</b> Difference between <code>tidy</code> and <code>augment</code> and <code>glance</code></a></li>
<li class="chapter" data-level="5.8.3" data-path="logistic-regression.html"><a href="logistic-regression.html#looking-at-variables-in-a-few-different-ways."><i class="fa fa-check"></i><b>5.8.3</b> Looking at variables in a few different ways.</a></li>
<li class="chapter" data-level="5.8.4" data-path="logistic-regression.html"><a href="logistic-regression.html#predicting-response"><i class="fa fa-check"></i><b>5.8.4</b> Predicting Response</a></li>
<li class="chapter" data-level="5.8.5" data-path="logistic-regression.html"><a href="logistic-regression.html#measues-of-association"><i class="fa fa-check"></i><b>5.8.5</b> Measues of association</a></li>
<li class="chapter" data-level="5.8.6" data-path="logistic-regression.html"><a href="logistic-regression.html#roc-curves"><i class="fa fa-check"></i><b>5.8.6</b> ROC curves</a></li>
<li class="chapter" data-level="5.8.7" data-path="logistic-regression.html"><a href="logistic-regression.html#drawing-interactions"><i class="fa fa-check"></i><b>5.8.7</b> Drawing interactions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i><b>6</b> Survival Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="survival-analysis.html"><a href="survival-analysis.html#timedata"><i class="fa fa-check"></i><b>6.1</b> Time-to-event data</a><ul>
<li class="chapter" data-level="6.1.1" data-path="survival-analysis.html"><a href="survival-analysis.html#survival-function"><i class="fa fa-check"></i><b>6.1.1</b> Survival Function</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="survival-analysis.html"><a href="survival-analysis.html#KM"><i class="fa fa-check"></i><b>6.2</b> Kaplan-Meier Curves</a><ul>
<li class="chapter" data-level="6.2.1" data-path="survival-analysis.html"><a href="survival-analysis.html#KMCI"><i class="fa fa-check"></i><b>6.2.1</b> CI for KM curve</a></li>
<li class="chapter" data-level="6.2.2" data-path="survival-analysis.html"><a href="survival-analysis.html#logrank"><i class="fa fa-check"></i><b>6.2.2</b> Log-rank Test</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="survival-analysis.html"><a href="survival-analysis.html#hazfunc"><i class="fa fa-check"></i><b>6.3</b> Hazard Functions</a><ul>
<li class="chapter" data-level="6.3.1" data-path="survival-analysis.html"><a href="survival-analysis.html#estimating-ht-ala-kaplan-meier"><i class="fa fa-check"></i><b>6.3.1</b> Estimating <span class="math inline">\(h(t)\)</span> ala Kaplan-Meier</a></li>
<li class="chapter" data-level="6.3.2" data-path="survival-analysis.html"><a href="survival-analysis.html#proportional-hazards"><i class="fa fa-check"></i><b>6.3.2</b> Proportional Hazards</a></li>
<li class="chapter" data-level="6.3.3" data-path="survival-analysis.html"><a href="survival-analysis.html#coxph"><i class="fa fa-check"></i><b>6.3.3</b> Cox PH Regression Analysis</a></li>
<li class="chapter" data-level="6.3.4" data-path="survival-analysis.html"><a href="survival-analysis.html#testingph"><i class="fa fa-check"></i><b>6.3.4</b> Testing Proportional Hazards</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="survival-analysis.html"><a href="survival-analysis.html#othersurv"><i class="fa fa-check"></i><b>6.4</b> Other stuff</a><ul>
<li class="chapter" data-level="6.4.1" data-path="survival-analysis.html"><a href="survival-analysis.html#sample-size-calculation"><i class="fa fa-check"></i><b>6.4.1</b> Sample Size Calculation</a></li>
<li class="chapter" data-level="6.4.2" data-path="survival-analysis.html"><a href="survival-analysis.html#study-design"><i class="fa fa-check"></i><b>6.4.2</b> Study Design</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="survival-analysis.html"><a href="survival-analysis.html#Rsurv"><i class="fa fa-check"></i><b>6.5</b> R example: ProPublica Analysis</a><ul>
<li class="chapter" data-level="6.5.1" data-path="survival-analysis.html"><a href="survival-analysis.html#recidivism-in-florida"><i class="fa fa-check"></i><b>6.5.1</b> Recidivism in Florida</a></li>
<li class="chapter" data-level="6.5.2" data-path="survival-analysis.html"><a href="survival-analysis.html#kaplan-meier-survival-curve"><i class="fa fa-check"></i><b>6.5.2</b> Kaplan-Meier survival curve</a></li>
<li class="chapter" data-level="6.5.3" data-path="survival-analysis.html"><a href="survival-analysis.html#log-rank-test-rho0-and-the-wilcoxon-test-rho1"><i class="fa fa-check"></i><b>6.5.3</b> Log-rank test [rho=0] and the Wilcoxon test [rho=1]</a></li>
<li class="chapter" data-level="6.5.4" data-path="survival-analysis.html"><a href="survival-analysis.html#cox-proportional-hazards-models"><i class="fa fa-check"></i><b>6.5.4</b> Cox Proportional Hazards models</a></li>
<li class="chapter" data-level="6.5.5" data-path="survival-analysis.html"><a href="survival-analysis.html#checking-proportional-hazards-with-the-plot-of-ln-lnst"><i class="fa fa-check"></i><b>6.5.5</b> Checking proportional hazards with the plot of <span class="math inline">\(\ln(-\ln(S(t)))\)</span></a></li>
<li class="chapter" data-level="6.5.6" data-path="survival-analysis.html"><a href="survival-analysis.html#checking-proportional-hazards-with-cox.zph"><i class="fa fa-check"></i><b>6.5.6</b> Checking proportional hazards with cox.zph</a></li>
<li class="chapter" data-level="6.5.7" data-path="survival-analysis.html"><a href="survival-analysis.html#coxph-diagnostics-look-into-all-the-different-arguments-of-the-function"><i class="fa fa-check"></i><b>6.5.7</b> Coxph diagnostics … look into all the different arguments of the function!</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html"><i class="fa fa-check"></i><b>7</b> Multiple Comparisons</a></li>
<li class="chapter" data-level="8" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>8</b> Poisson Regression</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://st47s.com/Math150" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Methods in Biostatistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="survival-analysis" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Survival Analysis</h1>
<p>To motivate the technical details which are vital to understanding survival analysis, consider the following example <span class="citation">(Gerds <a href="#ref-gerds">2016</a>)</span>.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-2" class="example"><strong>Example 4.1  </strong></span>In class – experience the Titanic going down.</p>
<ul>
<li>The Titanic is sinking. How long can you hold your breath?<br />
</li>
<li>Every person is sinking and will also be their own time keeper (number of seconds the sinker can hold their breath).<br />
</li>
<li>Because the Titanic is sinking slowly, the participants go under water asynchronously (i.e., at different times).<br />
</li>
<li>Accrual period will last about a minute.<br />
</li>
<li>When I say “stop” (about another minute), everyone should end their time clocks (this is the end of the follow-up period).<br />
</li>
<li>Each participant will have a recorded time as well as an indicator as to whether or not they have died.</li>
</ul>
Based on the data, we would like to calculate:<br />
1. What is the probability of surviving 40 seconds?<br />
2. What is the median survival time?<br />
3. What is the average survival time?
</div>

<span class="math display">\[\begin{eqnarray*}
&amp; &amp;\\
&amp; &amp; \\
\end{eqnarray*}\]</span>
<p>The next example is given in your text <span class="citation">(Kuiper and Sklar <a href="#ref-KuiperSklar">2013</a> (chapter 9))</span> as part of the motivation for survival analysis. [I can’t figure out why it insists on being numbered wrong.]</p>

<div class="example">
<p><span id="exm:unnamed-chunk-3" class="example"><strong>Example 6.1  </strong></span> Class chocolate melting activity</p>
<ul>
<li>Each student should be randomly assigned to a white or milk chocolate chip (flip a coin)<br />
</li>
<li>When the instructor gives approval, students should place either a white or milk chocolate chip into their mouths and record the time until it completely melts.<br />
</li>
<li>Treat the study as if it could only be done for a specified period of time (this may require some experimenting, but 60 seconds has worked well). If the actual time is less than 60 seconds, then the actual time will be complete. The student should submit the data (chip color, actual time, censoring status); 1=observed, 0=censored. Any chips that are “swallowed” prior to 60 seconds should be regarded as censored.
</div>
</li>
</ul>
<p>Survival analysis is typically done with a prospective study (see censoring below) on a cohort of patients (observational or experimental) to determine some clinical outcome. We will also usually measure covariates of interest: treatment, clinical variables measured at recruitment, etc.</p>
<blockquote>
<p><strong>Key Point</strong>: the outcome of interest (death, recurrence, etc.) may <em>not</em> occur</p>
</blockquote>
<p>Possible responses:</p>
<ul>
<li>Outcome of interest occurs<br />
</li>
<li>Study ends<br />
</li>
<li><p>The individual can no longer be measured (moves away, etc.)</p></li>
<li><strong>response</strong> fate <em>and</em> length of follow-up<br />
</li>
<li><strong>data</strong> suppose we are following n patients<br />

<span class="math display">\[\begin{eqnarray*}
t_i &amp;=&amp; \mbox{time the } i^{th} \mbox{ person dies}\\
m(t) &amp;=&amp; \mbox{number of patients for whom } t_i &gt; t \mbox{ (die later)}\\
d(t) &amp;=&amp; \mbox{number of patients for whom } t_i \leq t \mbox{ (die sooner)}\\
\end{eqnarray*}\]</span></li>
</ul>
<div id="timedata" class="section level2">
<h2><span class="header-section-number">6.1</span> Time-to-event data</h2>
<div id="survival-function" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Survival Function</h3>
<p>The two main quantities of interest (i.e., <em>parameters</em>) are:</p>
<span class="math display">\[\begin{eqnarray*}
S(t) &amp;=&amp; P(T &gt; t) = \mbox{ probability of surviving until after time } t\\
D(t) &amp;=&amp; P(T \leq t) = \mbox{ probability of dying by time } t (= F(t) )\\
\end{eqnarray*}\]</span>
<p>Where <span class="math inline">\(T\)</span> is a random variable representing the time to event; t is a number.</p>
If <span class="math inline">\(t_i\)</span> is known for all i (no censoring), we can estimate <span class="math inline">\(S(t)\)</span> and <span class="math inline">\(D(t)\)</span> with
<span class="math display">\[\begin{eqnarray*}
\hat{S}(t)_E &amp;=&amp; m(t)/n = \mbox{ proportion alive at time } t\\
\hat{D}(t)_E &amp;=&amp; d(t)/n = \mbox{ proportion who have died by time } t\\
\end{eqnarray*}\]</span>
<div id="censoring" class="section level4">
<h4><span class="header-section-number">6.1.1.1</span> censoring</h4>
<ul>
<li><strong>right</strong> censoring: when the observation on an individual begins at a defined starting time and ends before the outcome of interest happens (this is the censoring for our model)<br />
</li>
<li><strong>left</strong> censoring: when the outcome of interest is known to have occurred before the study begins (infection of a disease, learning to count). Note that the event of interest <em>has happened</em>, unlike in right censoring where the event of interest has not happened.<br />
</li>
<li><strong>interval</strong> censoring; when the event of interest is only known to have occurred between two time points, but the precise time is not known.</li>
</ul>
<p><strong>Important Assumption</strong>: survival time must be independent of any mechanism which causes censoring (called non-informative censoring). Censoring should be random: a person who is censored has the same probability of dying as non-censored people at given explanatory variables <span class="math inline">\(\underline{X}\)</span>.</p>
<p>Said differently: within any subgroup of interest, the subjects who are censored at time <span class="math inline">\(t\)</span> should be representative of all the subjects in that subgroup who remained at risk at time <span class="math inline">\(t\)</span> with respect to their survival experience.</p>
<ul>
<li>Not independent
<ul>
<li>Subjects who drop out because they are extremely ill<br />
</li>
<li>Subjects who drop out because of adverse effects of the treatment regimen<br />
</li>
</ul></li>
<li>Independent
<ul>
<li>Subjects who drop out because the study ends<br />
</li>
<li>Subjects who drop out because they move away</li>
</ul></li>
</ul>

<div class="example">
<p><span id="exm:unnamed-chunk-4" class="example"><strong>Example 6.2  </strong></span> Suppose we have the following melting times (in seconds) of milk chocolate chips for 7 students where the maximum time allowed for the experiment was 60 seconds:</p>

To find the estimated proportion of chocolate chips that have not melted after 45 seconds we use the <strong>empirical survival function</strong>, <span class="math inline">\(\hat{S}(45)_E\)</span>.
<span class="math display">\[\begin{eqnarray*}
\hat{S}(45)_E &amp;=&amp; \frac{\mbox{number of chips that have not melted after 45 seconds}}{\mbox{total number of chips in the sample}}\\
&amp;=&amp; 2/7 = 0.286\\
\hat{S}(t)_E &amp;=&amp; \frac{\mbox{number of individuals yet to experience the event at time } t}{\mbox{number of individuals in the study}}\\
&amp;=&amp; \frac{\mbox{number of event times greater than } t}{\mbox{number of individuals in the study}}\\
\end{eqnarray*}\]</span>
<p>What if some of the observations are incomplete (i.e., censored)?</p>
<table>
<thead>
<tr class="header">
<th align="right">Student</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
<th align="center">7</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">Time</td>
<td align="center"><span class="math inline">\(35^+\)</span></td>
<td align="center">30</td>
<td align="center"><span class="math inline">\(60^+\)</span></td>
<td align="center">45</td>
<td align="center">25</td>
<td align="center">55</td>
<td align="center"><span class="math inline">\(30^+\)</span></td>
</tr>
</tbody>
</table>
<p>One way to deal with censored observations is to remove them from the study. We would consider our sample to be only those observations that have complete information.</p>
<table>
<thead>
<tr class="header">
<th align="right">Student</th>
<th align="center">2</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">Time</td>
<td align="center">30</td>
<td align="center">45</td>
<td align="center">25</td>
<td align="center">55</td>
</tr>
</tbody>
</table>
<span class="math display">\[\begin{eqnarray*}
\hat{S}(45)_E &amp;=&amp; \frac{\mbox{number of chips that have not melted after 45 seconds}}{\mbox{total number of chips in the sample}}\\
&amp;=&amp; 1/4 = 0.25\\
\end{eqnarray*}\]</span>
</div>

<p>By treating censored observations as complete, we assume that the event times are shorter than what they actually are (thereby underestimating the true probability of survival). By removing the censored observations from the data, we lose information. By treating censored observations as complete we bias the estimate based on the remaining times; by ignoring censored observations, we reduce the power of the inferential model.</p>
</div>
</div>
</div>
<div id="KM" class="section level2">
<h2><span class="header-section-number">6.2</span> Kaplan-Meier Curves</h2>
<p>When a data set contains incomplete observations, the best estimator of the survival function is the Kaplan-Meier estimator, <span class="math inline">\(\hat{S}(t)_{KM}\)</span>. We’ll create a few curves by hand, and then we’ll let R make them for us.</p>
<span class="math display">\[\begin{eqnarray*}
t_1 &lt; t_2 &lt; \cdots &lt; t_n &amp; &amp; \mbox{are the ordered completed times}\\
n_k &amp;=&amp; \mbox{number of patients known to be at risk at time (day) } t_i, \mbox{ just before } [t_i, t_{i+1})\\
d_k &amp;=&amp; \mbox{number of patients who die at time (day) } t_i, \mbox{ in } [t_i, t_{i+1})\\
\end{eqnarray*}\]</span>
For the patients alive at the beginning of the <span class="math inline">\(t_i^{th}\)</span> day, the probability of surviving that day is
<span class="math display">\[\begin{eqnarray*}
p_i = \frac{n_i - d_i}{n_i}
\end{eqnarray*}\]</span>
The probability that a patient survives to day 2 given that they survived to day 1 is
<span class="math display">\[\begin{eqnarray*}
p_2 = \frac{n_2 - d_2}{n_2}
\end{eqnarray*}\]</span>
The probability that (at the outset) a patient survives to day 2 is:
<span class="math display">\[\begin{eqnarray*}
P(T &gt; t_2) &amp;=&amp; P(T &gt; t_2 | T &gt; t_1) P(T &gt; t_1)\\
&amp;=&amp; \frac{n_1 - d_1}{n_1} \frac{n_2 - d_2}{n_2}
\end{eqnarray*}\]</span>
The probability of surviving the first t days is:
<span class="math display">\[\begin{eqnarray*}
\hat{S}(t)_{KM} &amp;=&amp; \prod_{i:t_i &lt; t} \frac{n_i - d_i}{n_i}\\
&amp;=&amp; \prod_{i:t_i &lt; t} p_i\\
\hat{D}(t)_{KM} = 1 - \hat{S}(t)_{KM}\\
\end{eqnarray*}\]</span>
<p>If there are no deaths at time <span class="math inline">\(t_i\)</span>, then <span class="math inline">\((n_i -d_i) / n_i = 1\)</span>.</p>
<p>If there is no censoring at time <span class="math inline">\(t_i\)</span>, then <span class="math inline">\(n_i - d_i = n_{i+1}\)</span>. The Kaplan-Meier survival curve will be equivalent to the empirical survival curve:</p>
<span class="math display">\[\begin{eqnarray*}
\hat{S}(t)_{KM} &amp;=&amp; \prod_{i:t_i &lt; t} \frac{n_i - d_i}{n_i}\\
&amp;=&amp; \frac{n_1 - d_1}{n_1} \frac{n_2 - d_2}{n_2} \cdots \frac{n_k - d_k}{n_k}\\
&amp;=&amp; \frac{m(t)}{n}
\end{eqnarray*}\]</span>

<div class="example">
<p><span id="exm:unnamed-chunk-5" class="example"><strong>Example 6.3  </strong></span>milk chocolate times by hand.</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(t_i\)</span></th>
<th align="center"><span class="math inline">\(n_i\)</span></th>
<th align="center"><span class="math inline">\(d_i\)</span></th>
<th align="center"><span class="math inline">\(n_i - d_i\)</span></th>
<th align="center"><span class="math inline">\(\frac{n_i - d_i}{n_i}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">25</td>
<td align="center">7</td>
<td align="center">1</td>
<td align="center">6</td>
<td align="center">6/7= 0.857</td>
</tr>
<tr class="even">
<td align="center">30</td>
<td align="center">6</td>
<td align="center">1</td>
<td align="center">5</td>
<td align="center">5/6 = 0.833</td>
</tr>
<tr class="odd">
<td align="center">35</td>
<td align="center">4</td>
<td align="center">0</td>
<td align="center">4</td>
<td align="center">4/4 = 1</td>
</tr>
<tr class="even">
<td align="center">45</td>
<td align="center">3</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2/3 = 0.667</td>
</tr>
<tr class="odd">
<td align="center">55</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1/2=0.5</td>
</tr>
<tr class="even">
<td align="center">60</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1/1=1</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="center">time interval</th>
<th align="center"><span class="math inline">\(\hat{S}(t)_{KM}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\([0,25)\)</span></td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\([25,30)\)</span></td>
<td align="center">0.857</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\([30, 35)\)</span></td>
<td align="center">0.857 <span class="math inline">\(\cdot\)</span> 0.833 = 0.714</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\([35,45)\)</span></td>
<td align="center">0.714 <span class="math inline">\(\cdot\)</span> 1 = 0.714</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\([45,55)\)</span></td>
<td align="center">0.714 <span class="math inline">\(\cdot\)</span> 0.667 = 0.476</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\([55,60)\)</span></td>
<td align="center">0.476 <span class="math inline">\(\cdot\)</span> 0.5 = 0.238</td>
</tr>
</tbody>
</table>
</div>

<div id="KMCI" class="section level3">
<h3><span class="header-section-number">6.2.1</span> CI for KM curve</h3>
<p>Recall: <span class="math inline">\(\hat{S}(t)_{KM} = \prod_{k:t_k &lt; t} [ (n_k - d_k) / n_k]\)</span>.</p>
Because <span class="math inline">\(\hat{S}(t)_{KM}\)</span> is just a product of counts, we can “easily” estimate the SE:
<span class="math display">\[\begin{eqnarray*}
s^2 _{\hat{S}(t)_{KM}} = \hat{S}(t)_{KM}^2 \sum_{k:t_k &lt; t} \frac{d_k}{n_k(n_k - d_k)}
\end{eqnarray*}\]</span>
<p>Your book uses the above SE and normal theory which does work, particularly with large sample sizes. However, with smaller sample sizes and at the ends of the survival curve (close to zero or one), the sampling distribution of the estimated KM curve will not be normal. Additionally if we try to apply normal theory, we’ll get something meaningless because the CI will go outside the bounds of 0 and 1. Fortunately, someone figured out a transformation for us!</p>
<p><span class="math inline">\(l l \hat{S}(t) = \ln (-\ln \hat{S}(t)_{KM})\)</span> has a much more normal sampling distribution.</p>
<span class="math display">\[\begin{eqnarray*}
\hat{\sigma}^2(t) &amp;=&amp; SE( l l \hat{S}(t))\\
&amp;=&amp; \frac{\sum_{k:t_k &lt; t} \frac{d_k}{n_k(n_k - d_k)}}{\bigg[\sum_{k:t_k &lt; t} \ln ( (n_k - d_k) / n_k) \bigg]^2}
\end{eqnarray*}\]</span>
A 95 % CI for <span class="math inline">\(\ln ( -\ln S(t))\)</span> is
<span class="math display">\[\begin{eqnarray*}
ll\hat{S}(t) \pm 1.96 \hat{\sigma}(t) \ \ \ \mbox{(a function of t!!!)}
\end{eqnarray*}\]</span>
A 95 % CI for <span class="math inline">\(S(t)\)</span> is
<span class="math display">\[\begin{eqnarray*}
\bigg(\hat{S}(t)_{KM}^{ \exp(1.96\hat{\sigma}(t))}, \hat{S}(t)_{KM}^{\exp(-1.96\hat{\sigma}(t))} \bigg)
\end{eqnarray*}\]</span>
We can also find a CI for <span class="math inline">\(D(t) = 1- S(t)\)</span> using:
<span class="math display">\[\begin{eqnarray*}
\bigg(1 - \hat{S}(t)_{KM}^{\exp(-1.96\hat{\sigma}(t))}, 1 - \hat{S}(t)_{KM}^{\exp(1.96\hat{\sigma}(t))} \bigg)
\end{eqnarray*}\]</span>
<div id="derivation-of-the-above-confidence-intervals." class="section level5 unnumbered">
<h5>Derivation of the above confidence intervals.</h5>
<p>Remember that <span class="math inline">\(\exp(a \cdot b) = (\exp(a))^b\)</span>, we’ll need that below. A CI is an interval of values that captures the true parameter in 95 of samples. Let’s say that the complementary log-log interval from above happens to catch the true value of <span class="math inline">\(S(t)\)</span>. Then,</p>
<span class="math display">\[\begin{eqnarray*}
ll\hat{S}(t) - 1.96 \hat{\sigma}(t) \leq &amp; llS(t) &amp; \leq ll\hat{S}(t) + 1.96 \hat{\sigma}(t) \\
\exp(ll\hat{S}(t) - 1.96 \hat{\sigma}(t)) \leq &amp; -lS(t) &amp; \leq \exp(ll\hat{S}(t) + 1.96 \hat{\sigma}(t)) \\
-l\hat{S}(t)\exp(- 1.96 \hat{\sigma}(t))\leq &amp; -lS(t) &amp; \leq -l\hat{S}(t)\exp(1.96 \hat{\sigma}(t)) \\
l\hat{S}(t)\exp(- 1.96 \hat{\sigma}(t))\geq &amp; lS(t) &amp; \geq l\hat{S}(t)\exp(1.96 \hat{\sigma}(t)) \\
l\hat{S}(t)\exp(1.96 \hat{\sigma}(t))\leq &amp; lS(t) &amp; \leq l\hat{S}(t)\exp(-1.96 \hat{\sigma}(t)) \\
\exp(l\hat{S}(t)\exp(1.96 \hat{\sigma}(t))) \leq &amp; S(t) &amp; \leq \exp(l\hat{S}(t)\exp(-1.96 \hat{\sigma}(t))) \\
\exp(l\hat{S}(t)\exp(1.96 \hat{\sigma}(t))) \leq &amp; S(t) &amp; \leq \exp(l\hat{S}(t)\exp(-1.96 \hat{\sigma}(t))) \\
\exp(l\hat{S}(t))^{\exp(1.96 \hat{\sigma}(t))} \leq &amp; S(t) &amp; \leq \exp(l\hat{S}(t))^{\exp(-1.96 \hat{\sigma}(t))} \\
(\hat{S}(t))^{\exp(1.96 \hat{\sigma}(t))} \leq &amp; S(t) &amp; \leq (\hat{S}(t))^{\exp(-1.96 \hat{\sigma}(t))}
\end{eqnarray*}\]</span>
</div>
<div id="mean-and-median-values" class="section level4">
<h4><span class="header-section-number">6.2.1.1</span> Mean and Median values</h4>
<p><strong>Mean</strong></p>
<blockquote>
<p>Mean survival time is estimated as the area under the survival curve. The estimator is based upon the entire range of data. Some software uses only the data up to the last observed event <span class="citation">(Hosmer, Lemeshow, and May <a href="#ref-SurvHL">2008</a>)</span> point out that this biases the estimate of the mean downwards, and they recommend that the entire range of data be used. A large sample method is used to estimate the variance of the mean survival time and thus to construct a confidence interval <span class="citation">(Andersen et al. <a href="#ref-Andersen">1996</a>)</span>. <span class="citation">(StatsDirect Limited <a href="#ref-KMmean">2016</a>)</span></p>
</blockquote>
<p>In some ways, it is easier to conceptualize the mean as the average under the curve by thinking about calculating average as horizontal bars instead of vertical bars. The jumps along the y-axis are approximately 1/n, so each horizontal bar represents one of the individual deaths. See the example here: <a href="http://blog.data-miners.com/2010/06/why-is-area-under-survival-curve-equal.html" class="uri">http://blog.data-miners.com/2010/06/why-is-area-under-survival-curve-equal.html</a></p>
<span class="math display">\[\begin{eqnarray*}
\hat{\mu} = \left\{
    \begin{array}{ll}
    \sum_{i=0}^{m-1} \hat{S}(t_i)_{KM} (t_{i+1} - t_i) &amp; \mbox{if } t_n = t_m  \mbox{ (last obs is complete)}\\
    \sum_{i=0}^{m-1} \hat{S}(t_i)_{KM} (t_{i+1} - t_i) + \hat{S}(t_m)_{KM}(t_n-t_m) &amp; \mbox{if last obs is censored}
    \end{array}
\right.
\end{eqnarray*}\]</span>
<p>Each entry can be rearranged to be thought of as the proportion of people who die in the interval times the width of the interval: <span class="math inline">\([\hat{S}(t_{i-1})_{KM} - \hat{S}(t_{i})_{KM}]t_i\)</span>. The difference, <span class="math inline">\([\hat{S}(t_{i-1})_{KM} - \hat{S}(t_{i})_{KM}]\)</span>, gives the proportion of individuals who die in that time interval. Therefore, our estimate is a weighted average of the time points <span class="math inline">\(t_i\)</span> where the weight is <span class="math inline">\([\hat{S}(t_{i-1})_{KM} - \hat{S}(t_{i})_{KM}]\)</span>.</p>
<span class="math display">\[\begin{eqnarray*}
\hat{\mu} &amp;=&amp; \sum_{i=0}^{m-1} \hat{S}(t_i)_{KM}(t_{i+1} - t_i)\\
&amp;=&amp; \hat{S}(t_0)_{KM}(t_1 - t_0) + \hat{S}(t_1)_{KM}(t_2 - t_1) + \hat{S}(t_2)_{KM} (t_3 - t_2) + \cdots + \hat{S}(t_{m-1})_{KM} (t_m - t_{m-1}) \\
&amp;=&amp; -t_0  \hat{S}(t_0)_{KM} + t_1 ( \hat{S}(t_0)_{KM} -  \hat{S}(t_1)_{KM}) + \cdots + t_{m-1}( \hat{S}(t_{m-2})_{KM} -  \hat{S}(t_{m-1})_{KM}) + t_m  \hat{S}(t_{m-1})_{KM}\\
&amp;=&amp; 0 + t_1 ( \hat{S}(t_0)_{KM} -  \hat{S}(t_1)_{KM}) + \cdots + t_{m-1}( \hat{S}(t_{m-2})_{KM} -  \hat{S}(t_{m-1})_{KM}) + t_m ( \hat{S}(t_{m-1})_{KM} - 0)\\
&amp;=&amp; \mbox{a weighted average of the times}
\end{eqnarray*}\]</span>
<p><strong>Median</strong><br />
Since the distribution of survival times tend to be positively skewed, the median is often the preferred summary measure of location of the distribution. Once the survivor function has been estimated, it is straightforward to obtain an estimate of the <em>median survival time</em>. That is, the time beyond which 50 % of the individuals in the population under study are expected to survive, and is given by the value <span class="math inline">\(t_{(50)}\)</span> such that <span class="math inline">\(S(t_{(50)}) = 0.5\)</span>.</p>
<span class="math display">\[\begin{eqnarray*}
\hat{t}_{(p)} = \mbox{smallest complete event time, } t_i, \mbox{ in the sample such that } \hat{S}(t_i)_{KM} \leq 1-p/100
\end{eqnarray*}\]</span>
<p><span class="math inline">\(\hat{S}(t_i)_{KM}\)</span> then gives the time at which at least p % of events have occurred. There are also ways of compute confidence intervals for percentiles. We won’t cover those here.</p>
</div>
</div>
<div id="logrank" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Log-rank Test</h3>
As before, we’d like to know if two treatments produce the same probability of survival (how did we do that with logistic regression? significance of the <span class="math inline">\(\beta\)</span> coefficient). Here:
<span class="math display">\[\begin{eqnarray*}
H_0: &amp;&amp; S_1(t) = S_2(t) \ \ \ \ \ \forall t \mbox{ parameters!}\\
H_1: &amp;&amp; S_1(t) \ne S_2(t) \ \ \ \ \ \mbox{ for some } t\\
\end{eqnarray*}\]</span>
<p>We want to test whether the curves are the same over all <span class="math inline">\(t\)</span> (or different at any <span class="math inline">\(t\)</span>). Let’s consider a particular time, the <span class="math inline">\(j^{th}\)</span> time point:</p>
<table>
<thead>
<tr class="header">
<th align="right">died</th>
<th align="center"><span class="math inline">\(d_{1j}\)</span></th>
<th align="center"><span class="math inline">\(d_{2j}\)</span></th>
<th><span class="math inline">\(D_j\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">survived</td>
<td align="center"><span class="math inline">\(n_{1j} - d_{1j}\)</span></td>
<td align="center"><span class="math inline">\(n_{2j} - d_{2j}\)</span></td>
<td><span class="math inline">\(N_j - D_j\)</span></td>
</tr>
<tr class="even">
<td align="right"></td>
<td align="center"><span class="math inline">\(n_{1j}\)</span></td>
<td align="center"><span class="math inline">\(n_{2j}\)</span></td>
<td><span class="math inline">\(N_j\)</span></td>
</tr>
</tbody>
</table>
Because it’s a <span class="math inline">\(2x2\)</span> table with fixed margins, we only need to consider one group. If survival is similar for the two groups, we’d expect:
<span class="math display">\[\begin{eqnarray*}
d_{ij} &amp;\approx&amp; \frac{D_j}{N_j}n_{1j}\\
d_{ij} &amp;=&amp; \mbox{observed}\\
\frac{D_j}{N_j} n_{1j} &amp;=&amp; E(d_{1j} | D_j) \\
var(d_{ij}) &amp;=&amp; \frac{n_{1j} n_{2j} D_j (N_j - D_j)}{N_j^2(N_j-1)}\\
\end{eqnarray*}\]</span>
<p>where the variance is derived from the hypergeometric distribution.</p>
To estimate the overall difference between the observed and expected death counts:
<span class="math display">\[\begin{eqnarray*}
\sum_j d_{1j} - \sum_j E(d_{1j} | D_j) = \sum_j d_{1j} - \sum_j \frac{D_j}{N_j}n_{1j}
\end{eqnarray*}\]</span>
The overall variability:
<span class="math display">\[\begin{eqnarray*}
\sum_j var(d_{1j}|D_j)
\end{eqnarray*}\]</span>
The test statistic we use to compare the observed and expected frequency of deaths. (Sum over all of the death (or recurrence) times.)
<span class="math display">\[\begin{eqnarray*}
T = \frac{(|\sum_j d_{1j} - \sum_j E(d_{1j} | D_j)| - 0.5)^2}{\sum_j var(d_{1j}|D_j)} \sim \chi^2_1
\end{eqnarray*}\]</span>
<p>What if we had had <span class="math inline">\(g\)</span> groups (instead of 2)? We’ll have <span class="math inline">\(g-1\)</span> “death” values. Consider the test statistic above, call it <span class="math inline">\(T_1\)</span>. We want to sum <span class="math inline">\(T_i, i=1,2, \ldots, g-1\)</span>, but the variances are now correlated (values have to sum to <span class="math inline">\(D_k\)</span>)… so the whole thing is slightly more complicated. <span class="citation">(Collett <a href="#ref-Collett">2015</a> (section 2.6))</span></p>
<ul>
<li>The Wilcoxon test is very similar to the log-rank test, but it uses a different derivation for the variance, and therefore a different denominator and test statistic.<br />
</li>
<li>The log-rank test is more powerful than the Wilcoxon, but the log-rank test requires the proportional hazards assumption.<br />
</li>
<li>Wilcoxon test does not require the proportional hazards assumption, but it does require that one curve is always bigger than the other.<br />
</li>
<li>Neither work if the curves cross.<br />
</li>
<li>Other technical conditions are that the sample size should be “big enough.” The sample size is dependent on the number of deaths. No specific criteria, but the results are asymptotic, so the p-values converge to the actual probabilities as the number of deaths gets larger.</li>
</ul>
</div>
</div>
<div id="hazfunc" class="section level2">
<h2><span class="header-section-number">6.3</span> Hazard Functions</h2>
<p>Another important idea in survival analysis is the hazard function or instantaneous death rate. Let T be the random variable representing death time. [Your text implicitly redefines <span class="math inline">\(S(t) = P(T \geq t)\)</span> which is inconsistent but not fundamentally problematic.]</p>
<span class="math display">\[\begin{eqnarray*}
h(t)&amp;=&amp; \lim_{\Delta t \rightarrow 0} \frac{P(\mbox{patient dies by time } t + \Delta t | \mbox{alive at } t)}{\Delta t}\\
 &amp;=&amp; \lim_{\Delta t \rightarrow 0} \frac{P(T &lt; t + \Delta t | T \geq t)}{\Delta t}\\
 &amp;=&amp; \lim_{\Delta t \rightarrow 0} \frac{P(t \leq T &lt; t + \Delta t | T \geq t)}{\Delta t}\\
 &amp;=&amp; \lim_{\Delta t \rightarrow 0} \frac{P(t \leq T &lt; t + \Delta t )}{P(T \geq t) \Delta t}\\
 &amp;=&amp; \lim_{\Delta t \rightarrow 0} \frac{S(t) - S(t + \Delta t)}{S(t) \Delta t}\\
 &amp;=&amp; \lim_{\Delta t \rightarrow 0} -\frac{S(t + \Delta t) - S(t)}{\Delta t}\frac{1}{S(t)}\\
 &amp;=&amp; -S&#39;(t) \frac{1}{S(t)}\\
 &amp;=&amp; -\frac{d}{dt} \ln(S(t))\\
S(t) &amp;=&amp; \exp \{ - \int^t_0 h(x) dx  \}\\
\end{eqnarray*}\]</span>
How do different functions of <span class="math inline">\(h\)</span> affect the survival curve, <span class="math inline">\(S\)</span>?
<span class="math display">\[\begin{eqnarray*}
h(t) = 0 &amp;&amp;\Rightarrow \mbox{ no risk of death at time } t\\
&amp;&amp; \Rightarrow S(t) \mbox{ is flat at } t\\
h(t)  &gt; &gt;&amp;&amp;  \Rightarrow S(t) \mbox{ is rapidly declining in } t\\
h(t) =k &amp;&amp; \Rightarrow S(t) = e^{-kt}
\end{eqnarray*}\]</span>
<div id="hazard-function-as-a-constant" class="section level4">
<h4><span class="header-section-number">6.3.0.1</span> hazard function as a constant</h4>
<p>If <span class="math inline">\(h(t) =k \rightarrow S(t) = e^{-kt}\)</span>.</p>
<p>Plots of different hazard functions and their corresponding survival functions. <img src="06-surv_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="estimating-ht-ala-kaplan-meier" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Estimating <span class="math inline">\(h(t)\)</span> ala Kaplan-Meier</h3>
<p><span class="math inline">\(h(t)\)</span> is the rate at which individuals in the population experience the event in the next <em>instant</em> of time, conditional on surviving to time <span class="math inline">\(t\)</span>. The estimated hazard curve can only extend to the last complete event time, otherwise the denominator is infinitely large. Also, keep in mind that <span class="math inline">\(h(t)\)</span> is very hard to estimate, and <span class="math inline">\(\hat{h}_{KM}(t)\)</span> can be erratic.</p>
<span class="math display">\[\begin{eqnarray*}
\hat{P}(t_i \leq T &lt; t_{i+1} | T \geq t_i) &amp;=&amp; \frac{d_i}{n_i} = \hat{p}_i\\
\hat{h}_{KM}(t) &amp;=&amp; \frac{\hat{p}_i}{t_{i+1} - t_i}  \ \ \ \ \ \ t_{i+1} \leq t &lt; t_i\\
\end{eqnarray*}\]</span>
</div>
<div id="proportional-hazards" class="section level3">
<h3><span class="header-section-number">6.3.2</span> Proportional Hazards</h3>
Suppose that <span class="math inline">\(h_0(t)\)</span> and <span class="math inline">\(h_1(t)\)</span> are the hazard functions for patients on control and experimental treatments. The two groups have {proportional hazards} if <span class="math inline">\(h_1(t) = R h_0(t)\)</span> for some constant R:
<span class="math display">\[\begin{eqnarray*}
\frac{h_1(t)}{h_0(t)} = R \ \ \ \ \ \forall t
\end{eqnarray*}\]</span>
<p>R is called the <strong>hazard ratio</strong>. <span class="math inline">\(h_0(t)\)</span> can be anything as long as <span class="math inline">\(h_1(t)\)</span> is proportional. Note in the pictures below that no one dies between 3 and 7 days, the survival curves are flat over that interval.</p>
<p><img src="06-surv_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" /></p>
Consider the notion of risk of death:
<span class="math display">\[\begin{eqnarray*}
\mbox{risk of death by } t + \Delta t \mbox{ given alive at } t= \left\{
    \begin{array}{ll}
   h_0(t) \Delta t &amp; \mbox{control}\\
   h_1(t) \Delta t &amp; \mbox{experiment}
   \end{array}
\right.
\end{eqnarray*}\]</span>
<span class="math display">\[\begin{eqnarray*}
\frac{\mbox{risk of dying for experim}}{\mbox{risk of dying control}} = \frac{h_1(t) \Delta t}{h_0(t) \Delta t} = \frac{h_1(t) }{h_0(t) } = R
\end{eqnarray*}\]</span>
<p>Ratio of hazard functions can be thought of as the  (i.e., at a time <span class="math inline">\(t\)</span>).</p>
</div>
<div id="coxph" class="section level3">
<h3><span class="header-section-number">6.3.3</span> Cox PH Regression Analysis</h3>
<div id="simple-proportional-hazards-model" class="section level4">
<h4><span class="header-section-number">6.3.3.1</span> Simple proportional hazards model</h4>
<p>ASSUMING proportional hazards! Let <span class="math inline">\(h_0(t)\)</span> be the hazard function for the control group. <span class="math inline">\(x_i\)</span> =1 if the <span class="math inline">\(i^{th}\)</span> patient receives treatment; 0 if the <span class="math inline">\(i^{th}\)</span> patient receives the control. A big value of <span class="math inline">\(\beta\)</span> means that the event is more likely to happen.</p>
<span class="math display">\[\begin{eqnarray*}
h_i(t) &amp;=&amp; h_0(t) e^{\beta x_i} = \left\{
\begin{array}{ll}
h_0(t) e^\beta &amp; \mbox{experim}\\
h_0(t) &amp; \mbox{control}
\end{array}
\right.\\
\mbox{inst. RR} &amp;=&amp; \frac{h_0(t) e^\beta}{h_0(t)} = e^\beta\\
S_i(t) &amp;=&amp; (S_0(t))^{e^\beta}\\
\end{eqnarray*}\]</span>
<p>We don’t yet know how to run this model and estimate the parameters, but still, we can probably do it. Right? We run a <strong>Cox proportional hazards model</strong>, get <span class="math inline">\(b\)</span>, and estimate the RR using: <span class="math inline">\(\hat{RR} = e^{b}\)</span>! It turns out that for large samples (as with logistic regression, the CI and tests below are again called Wald CI and tests),</p>
<span class="math display">\[\begin{eqnarray*}
b \sim N: &amp;&amp; \\
&amp;&amp; 95\% \mbox{ CI for } \beta: b \pm 1.96 SE(b)\\
&amp;&amp; 95\% \mbox{ CI for } RR: (e^{b - 1.96 SE(b)}, e^{b + 1.96 SE(b)})\\
\end{eqnarray*}\]</span>
And we can test RR by using <span class="math inline">\(\beta\)</span>:
<span class="math display">\[\begin{eqnarray*}
H_0:&amp;&amp; \beta=0 \iff RR = 1\\
Z &amp;=&amp; \frac{b - 0 }{SE(b)}
\end{eqnarray*}\]</span>
</div>
<div id="estimating-the-proportional-hazards-coefficients" class="section level4">
<h4><span class="header-section-number">6.3.3.2</span> Estimating the proportional hazards coefficients</h4>
<p>The main point of proportional hazards is that if we have proportional hazards, then we don’t actually need to know the hazard function in order to estimate the coefficients which affect the survival function. [We divide out the hazard function.]</p>
<p>Intervals between death times convey no information about the relationship between hazard and explanatory variables (including treatment). We are also assuming that we have no ties for our death times. [Importantly, we assume that the proportional hazards assumption holds over <em>all</em> <span class="math inline">\(t\)</span>.]</p>
<span class="math display">\[\begin{eqnarray*}
P(i^{th} \mbox{ indiv, w/}x_i, \mbox{ dies at } t_i | \mbox{one death at } t_i) &amp;=&amp; \frac{P(i^{th} \mbox{ indiv w/}x_i \mbox{ dies at } t_i )}{P(\mbox{at least one death at } t_i)}\\
&amp;=&amp; \frac{\mbox{hazard at } t_i}{\mbox{sum over all patients at risk at time } t_i}\\
&amp;=&amp; \frac{h_i(t_i)}{\sum_{k:t_k \geq t_i} h_k (t_i)} \\
&amp;=&amp; \frac{e^{\beta x_i}}{\sum_{k:t_k \geq t_i} e^{\beta x_k}}
\end{eqnarray*}\]</span>
<p>As with logistic regression (and linear regression!) we’ll use maximum likelihood to estimate the parameter(s). (The product is over only patients who have death times recorded, not censored times).</p>
<span class="math display">\[\begin{eqnarray*}
L(\beta) &amp;=&amp; \prod_{i=1}^r \frac{e^{\beta x_i}}{\sum_{k:t_k \geq t_i} e^{\beta x_k}}\\
\delta_i &amp;=&amp; \left\{\begin{array}{ll}
1 &amp; \mbox{death}\\
0 &amp; \mbox{censored}
\end{array}
\right.\\
L(\beta) &amp;=&amp;  \prod_{i=1}^n \Bigg( \frac{e^{\beta x_i}}{\sum_{k:t_k \geq t_i} e^{\beta x_k}} \Bigg)^{\delta_i}\\
\ln L(\beta) &amp;=&amp; \sum_{i=1}^n \delta_i \bigg[ \beta x_i - \ln (\sum_{k:t_k \geq t_i} e^{\beta x_k}) \bigg]
\end{eqnarray*}\]</span>
<p><span class="math inline">\(b\)</span> is found using numerical methods (as it was with logistic regression).</p>

<div class="example">
<span id="exm:unnamed-chunk-8" class="example"><strong>Example 4.3  </strong></span>Consider the following data from a prostate cancer study. The study was performed as a randomized clinical trail to compare treatments for prostatic cancer, and was begun in 1967 by the Veteran’s Administration Cooperative Urological Research Group. The trial was double blind and two of the treatments used were a placebo and 1.0 mg of diethylstilbestrol (DES). The time origin of the study is the date on which a patient was randomized to a treatment, and the end-point is the death of the patient from prostate cancer. The full data set is given in <span class="citation">Andrews and Herzberg (<a href="#ref-AndHerz">1985</a>)</span>, but the data used in this example are from patients presenting with Stage III cancer and given in <span class="citation">Collett (<a href="#ref-Collett">2015</a>)</span> (page 8).
</div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(survival)
prostate &lt;-<span class="st"> </span>readr<span class="op">::</span><span class="kw">read_csv</span>(<span class="st">&quot;~/Dropbox/teaching/math150/PROSTATE.csv&quot;</span>)
<span class="kw">head</span>(prostate)</code></pre></div>
<pre><code>## # A tibble: 6 x 7
##   Treatment  Time Status   Age  Haem  Size Gleason
##       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
## 1         1    65      0    67  13.4    34       8
## 2         2    61      0    60  14.6     4      10
## 3         2    60      0    77  15.6     3       8
## 4         1    58      0    64  16.2     6       9
## 5         2    51      0    65  14.1    21       9
## 6         1    51      0    61  13.5     8       8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coxph</span>(<span class="kw">Surv</span>(Time,Status) <span class="op">~</span><span class="st"> </span>Treatment, <span class="dt">data =</span> prostate)</code></pre></div>
<pre><code>## Call:
## coxph(formula = Surv(Time, Status) ~ Treatment, data = prostate)
## 
##              coef exp(coef) se(coef)      z      p
## Treatment -1.9780    0.1384   1.0982 -1.801 0.0717
## 
## Likelihood ratio test=4.55  on 1 df, p=0.03293
## n= 38, number of events= 6</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coxph</span>(<span class="kw">Surv</span>(Time,Status) <span class="op">~</span><span class="st"> </span>Treatment, <span class="dt">data =</span> prostate) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</code></pre></div>
<pre><code>## # A tibble: 1 x 7
##   term      estimate std.error statistic p.value conf.low conf.high
##   &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1 Treatment    -1.98      1.10     -1.80  0.0717    -4.13     0.175</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coxph</span>(<span class="kw">Surv</span>(Time,Status) <span class="op">~</span><span class="st"> </span>Treatment, <span class="dt">data =</span> prostate) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">glance</span>()</code></pre></div>
<pre><code>## # A tibble: 1 x 15
##       n nevent statistic.log p.value.log statistic.sc p.value.sc
##   &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
## 1    38      6          4.55      0.0329         4.42     0.0355
## # … with 9 more variables: statistic.wald &lt;dbl&gt;, p.value.wald &lt;dbl&gt;,
## #   r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;, concordance &lt;dbl&gt;,
## #   std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;, BIC &lt;dbl&gt;</code></pre>
<ul>
<li><strong>Note 1</strong>: There is no intercept in the model. The intercept is contained within the <span class="math inline">\(h_0(t)\)</span> parameter.<br />
</li>
<li><strong>Note 2</strong>: Nowhere have we made any assumptions about the form of <span class="math inline">\(h_0(t)\)</span>.<br />
</li>
<li><strong>Note 3</strong>: To estimate <span class="math inline">\(h_0(t)\)</span>, we use the pointwise values, just like Kaplan-Meier plots (<span class="math inline">\(\tau_j = t_{(j+1)} - t_j):\)</span>
<span class="math display">\[\begin{eqnarray*}
h_0(t_j) = \frac{d_j}{n_j \tau_j}
\end{eqnarray*}\]</span>
If there are covariates, the estimation gets much more complicated.<br />
</li>
<li><strong>Note 4</strong>: The logrank statistic can be derived as the score test for the Cox proportional hazards model comparing two groups. It is therefore approximately equivalent to the likelihood ratio test statistics from that model <span class="citation">(Collett <a href="#ref-Collett">2015</a> (section 3.9, page 102-106))</span>. Additionally, the log-rank test is most powerful against the alternative that the hazard of death at any given time for an individual in one group is proportional to the hazard at that time for a similar individual in the other group (i.e., the proportional hazards assumption). <span class="citation">(Collett <a href="#ref-Collett">2015</a> (section 2.5.4, pg 44-45))</span>
<span class="math display">\[\begin{eqnarray*}
H_0: h_1(t) = h_2(t)\\
H_1: h_1(t) = R h_2(t)
\end{eqnarray*}\]</span></li>
<li><strong>Note 5</strong>: You need proportional hazards to do the <em>inference</em> (otherwise your p-values are meaningless!). The technical assumptions for the Cox Proportional Hazards model are:
<ul>
<li>Observations are independent (this is almost always an important assumption in all of statistical inference)<br />
</li>
<li>Proportional hazards: the hazard ratios are not dependent on time.<br />
</li>
<li>Independent censoring: the censored observations have the same survival prospects as the non-censored participants.</li>
</ul></li>
</ul>
</div>
<div id="multcoxph" class="section level4">
<h4><span class="header-section-number">6.3.3.3</span> Cox PH Multiple Regression Analysis</h4>
<p>Extending the simple proportional hazards model to include multiple covariates.</p>
Let <span class="math inline">\(x_{i1}, x_{i2}, \ldots, x_{iq}\)</span> be the <span class="math inline">\(q\)</span> covariates for person <span class="math inline">\(i\)</span>. We define the baseline hazard as:
<span class="math display">\[\begin{eqnarray*}
h_0(t) &amp;=&amp; \mbox{hazard for patients with covariates } x_{i1}=x_{i2}=\cdots=x_{iq} = 0\\
h_i(t) &amp;=&amp; h_0(t) e^{\beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_q x_{iq}}\\
\end{eqnarray*}\]</span>
<p>is the hazard function for the <span class="math inline">\(i^{th}\)</span> patient.</p>
As before, we can consider nested models and compare their likelihoods.
<span class="math display">\[\begin{eqnarray*}
-2 \ln \frac{L_{\mbox{reduced model}}}{L_{\mbox{full model}}} &amp;\sim&amp; \chi^2_{\Delta p}\\
&amp;&amp; \\
2 ( \ln L_{\mbox{full model}} - \ln L_{\mbox{reduced model}} ) &amp;=&amp; \mbox{test stat}\\
\end{eqnarray*}\]</span>

<div class="example">
<p><span id="exm:unnamed-chunk-10" class="example"><strong>Example 5.2  </strong></span> <strong>Framingham Heart Study</strong> <span class="citation">(Dupont <a href="#ref-Dupont">2009</a> (section 3.10))</span> Long-term follow-up and cardiovascular risk factor data on almost 5000 residents of the town of Framingham, MA. Recruitment started in 1948 (went for 40+ years). These data are 4699 patients who were free of coronary heart disease at their baseline exam:</p>
<table>
<thead>
<tr class="header">
<th>variable</th>
<th align="center"></th>
<th>code</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>sex</td>
<td align="center">=</td>
<td>gender coded as</td>
</tr>
<tr class="even">
<td></td>
<td align="center"></td>
<td>1=if subject is male</td>
</tr>
<tr class="odd">
<td></td>
<td align="center"></td>
<td>0= if subject is female</td>
</tr>
<tr class="even">
<td>sbp</td>
<td align="center">=</td>
<td>systolic blood pressure (SBP) in mm Hg</td>
</tr>
<tr class="odd">
<td>dbp</td>
<td align="center">=</td>
<td>diastolic blood pressure (DBP) in mm Hg</td>
</tr>
<tr class="even">
<td>scl</td>
<td align="center">=</td>
<td>serum cholesterol (SCL) in mg/100ml</td>
</tr>
<tr class="odd">
<td>chdfate</td>
<td align="center">=</td>
<td>1= if the patient develops CHD at the end of follow-up</td>
</tr>
<tr class="even">
<td></td>
<td align="center"></td>
<td>0= otherwise</td>
</tr>
<tr class="odd">
<td>followup</td>
<td align="center">=</td>
<td>the subject’s follow-up in days</td>
</tr>
<tr class="even">
<td>age</td>
<td align="center">=</td>
<td>age in years</td>
</tr>
<tr class="odd">
<td>bmi</td>
<td align="center">=</td>
<td>body mass index (BMI) =weight/height<span class="math inline">\(^2\)</span> in kg/m<span class="math inline">\(^2\)</span></td>
</tr>
<tr class="even">
<td>month</td>
<td align="center">=</td>
<td>month of year in which baseline exam occurred</td>
</tr>
<tr class="odd">
<td>id</td>
<td align="center">=</td>
<td>a patient identification variable (numbered 1 to 4699)</td>
</tr>
</tbody>
</table>
We look at the K-M survival curves broken down by diastolic blood pressure. The logrank statistic comparing all 7 groups is highly significant (<span class="math inline">\(p &lt; 10^{-52}\)</span>), and the pairwise logrank tests for adjacent pairs of risk groups are also all significant (though be careful with multiple comparisons!).
</div>

<span class="math display">\[\begin{eqnarray*}
dbp_{ij} &amp;=&amp; \left\{
\begin{array}{ll}
1 &amp; \mbox{if the } i^{th} \mbox{ patient is in DBP group } j\\
0 &amp; \mbox{otherwise}
\end{array}
\right.\\
male_i &amp;=&amp; \left\{
\begin{array}{ll}
1 &amp; \mbox{if the } i^{th} \mbox{ patient is male}\\
0 &amp; \mbox{if the } i^{th} \mbox{ patient is female}\\
\end{array}
\right.\\
\end{eqnarray*}\]</span>
<ul>
<li><strong>Table 7.1</strong><br />
Using a proportional hazards model for estimating the hazard ratio associated with each blood pressure group, we get:
<span class="math display">\[\begin{eqnarray*}
h_i(t) &amp;=&amp; h_0(t) \exp \bigg\{ \beta_2 dbp_{i2} + \beta_3 dbp_{i3} + \beta_4 dbp_{i4} + \beta_5 dbp_{i5} + \beta_6 dbp_{i6} + \beta_7 dbp_{i7} \bigg\}\\
h_i(t) &amp;=&amp; h_0(t) \exp \bigg\{ \sum_{j=2}^7 \beta_j dbp_{ij} \bigg\}
\end{eqnarray*}\]</span></li>
</ul>
<p>We can use the model with dbp as categorical to check whether dbp could be used as a continuous variable. Indeed, it seems that the model is linear (in ln(HR)) with respect to dbp. One reason, however, to keep the variable broken into groups is because of the way the results are nicely laid out for each group.</p>
<ul>
<li><strong>Table 7.2</strong><br />
As our next step, we can consider adding gender as a <em>multiplicative effect</em> to our model.
<span class="math display">\[\begin{eqnarray*}
h_i(t) &amp;=&amp; h_0(t) \exp \bigg\{ \sum_{j=2}^7 \beta_j dbp_{ij} + \gamma male_i \bigg\}
\end{eqnarray*}\]</span>
<p>We say the effects are multiplicative because we are adding in the exponent, so any effect due to gender will be multiplied with the effect due to dbp. How do we tell - from the results - that interaction wasn’t modeled? Look at the hazard ratios, are they consistent when comparing one variable and keeping the other one constant? That is, check to see if the HR for two different levels of dbp is the same regardless of whether men or women are considered.</p>
<ul>
<li>The change in deviance is 133 (<span class="math inline">\(H_0: \gamma =0\)</span>), so with one degree of freedom, the p-value is very small. We do not think that <span class="math inline">\(\gamma=0\)</span>, so we need gender in the model.</li>
</ul></li>
<li><strong>Table 7.3</strong> Considering gender and dbp interacting.
<span class="math display">\[\begin{eqnarray*}
h_i(t) &amp;=&amp; h_0(t) \exp \bigg\{ \sum_{j=2}^7 \beta_j dbp_{ij} + \gamma male_i + \sum_{j=2}^7 \delta_j dbp_{ij} male_i \bigg\}
\end{eqnarray*}\]</span>
8 The change in deviance is 21.23 (<span class="math inline">\(H_0: \delta_j =0\)</span>), so with six degrees of freedom, the p-value is 0.002. The evidence of interaction is statistically significant.
<ul>
<li>Note the marked differences between the estimates in table 7.2 and 7.3. The interactive model indicates that the effect of gender on the risk of CHD is greatest for people with low or moderate blood pressure and diminishes as blood pressure rises. Gender appears to have no effect on CHD for people with a DBP above 110 mm Hg.</li>
</ul></li>
<li><p><strong>Table 7.4</strong><br />
Adjusting for confounding variables. Of particular interest is age at baseline exam. We know that age varied widely among study subjects, and both DBP and risk of CHD increase with age. We will also consider the effect of body mass index and serum cholesterol.</p></li>
</ul>
<span class="math display">\[\begin{eqnarray*}
h_i(t) &amp;=&amp; h_0(t) \exp \bigg\{ \sum_{j=2}^7 \beta_j dbp_{ij} + \gamma male_i + \sum_{j=2}^7 \delta_j dbp_{ij} male_i \\
&amp;&amp; \theta_1 age_i + \theta_2 bmi_i + \theta_3 scl_i \bigg\}
\end{eqnarray*}\]</span>
<ul>
<li>We need <span class="math inline">\(\theta_1, \theta_2, \theta_3\)</span>, as they are all statistically significant.
<ul>
<li>The HR in Table 7.4 are substantially smaller than those in Table 7.3. It is important to realize that the HR in Table 7.4 compare people of the same age, body mass index, and serum cholesterol, while those of Table 7.3 compare people without regard to other variables. It is not surprising that the unadjusted HR are inflated due to the confounding variables.<br />
</li>
<li>Goal: to predict CHD <span class="math inline">\(\rightarrow\)</span> because it’s easier to measure blood pressure than cholesterol, we may just prefer to use the unadjusted model.<br />
</li>
<li>Goal: to establish a causal link <span class="math inline">\(\rightarrow\)</span> we <em>must</em> adjust for all possible confounding variables.</li>
</ul></li>
</ul>
<p>When should we transform a continuous variable into a factor variable?</p>
<ul>
<li><strong>continuous</strong> If we believe that the relationship is linear in log(HR)<br />
</li>
<li><strong>factor</strong> There are lots of coefficients to estimate, so we lose df</li>
</ul>
</div>
</div>
<div id="testingph" class="section level3">
<h3><span class="header-section-number">6.3.4</span> Testing Proportional Hazards</h3>
<!-- Note: in my yellow notes from 2008 I've covered all the residual analysis stuff.  The notes aren't particularly organized or well thought-out.  The topic probably isn't relevant for this class. -->
<p>We’ve discussed that proportional hazards means that the hazard in one group is a constant multiple of the hazard in another group. What does that mean in terms of the survival function?</p>
<span class="math display">\[\begin{eqnarray*}
h_1 (t) &amp;=&amp; h_0 (t) e^\beta\\
S(t) &amp;=&amp; e^{-\int_0^t h(x) dx}\\
S_0(t) &amp;=&amp; e^{-\int_0^t h_0(x) dx}\\
S_1(t) &amp;=&amp; e^{-\int_0^t h_0(x)e^\beta dx}\\
S_1(t) &amp;=&amp; e^{- e^\beta \int_0^t h_0(x) dx}\\
S_1(t) &amp;=&amp; \bigg[ e^{- \int_0^t h_0(x) dx} \bigg]^{e^\beta}\\
\ln(S_1(t)) &amp;=&amp; e^\beta \ln [e^{- \int_0^t h_0(x) dx}]\\
-\ln(S_1(t)) &amp;=&amp; e^\beta  [-\ln(S_0(t))]\\
\ln(-\ln(S_1(t))) &amp;=&amp; \beta + \ln [-\ln(S_0(t))]\\
\end{eqnarray*}\]</span>
<p>That is to say, the <span class="math inline">\(\ln (- \ln\)</span> survival curves) should be parallel and differ only by a y-intercept constant of <span class="math inline">\(\beta\)</span>.</p>
<div id="time-dependent-covariates" class="section level4">
<h4><span class="header-section-number">6.3.4.1</span> Time dependent covariates</h4>
If the PH assumption is violated, then we have:
<span class="math display">\[\begin{eqnarray*}
\frac{h_i(t)}{h_0(t)} = g(t)
\end{eqnarray*}\]</span>
<p>some function of <span class="math inline">\(t\)</span>. Consider the following model (the function of time is completely specified, but it is just one possibility for the dependence relationship):</p>
<span class="math display">\[\begin{eqnarray*}
x_{i1}  &amp;=&amp; \left\{
\begin{array}{ll}
1 &amp; treatment\\
0 &amp; control
\end{array}
\right.\\
x_{i2} &amp;=&amp; \left\{
\begin{array}{ll}
t &amp; treatment\\
0 &amp; control\\
\end{array}
\right.\\
\end{eqnarray*}\]</span>
The relative hazard becomes:
<span class="math display">\[\begin{eqnarray*}
h_i(t) = e^{\beta_1 x_{i1} + \beta_2 x_{i2}} h_0(t)\\
\frac{h_1(t)}{h_0(t)} = e^{\beta_1 +\beta_2 t}\\
\end{eqnarray*}\]</span>
<p>If <span class="math inline">\(\beta_2 &lt; 0\)</span>, the relative hazard decreases with time. If <span class="math inline">\(\beta_2 &gt; 0\)</span>, the relative hazard increases with time.</p>
The test of interest will be:
<span class="math display">\[\begin{eqnarray*}
H_0: \beta_2 = 0
\end{eqnarray*}\]</span>
<p>It isn’t a Wald test, but it is the same general idea (in R: <code>cox.zph</code>). [The variable in the denominator of the likelihood (for calculating the MLE) will have different values at different times.] An alternative form of the test is to call: <span class="math inline">\(x_{i2} = t \ \ \forall t\)</span> and let <span class="math display">\[h_i(t) = e^{\beta_1 x_{i1} + \beta_2 x_{i1} x_{i2}} h_0(t).\]</span></p>
<p>If there is time dependency in the model, then the <code>coxph</code> analysis won’t be accurate.</p>
<!-- One idea is to transform time, possibly the model is proportional with respect to $ln(t)$??  
 Not true:  working on the transformed data will not give a different model at all
In that case, rerunning `coxph` on the *transformed* time variable will give interpretable results.

 https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-10-20
 Also see Kleinman and Klein for more on the cox.zph model  
-->
</div>
<div id="schoenfeld-residuals" class="section level4">
<h4><span class="header-section-number">6.3.4.2</span> Schoenfeld Residuals</h4>
Recall: under the Cox model, the probability that any particular member <span class="math inline">\(i\)</span> fails at time <span class="math inline">\(t_j\)</span> is:
<span class="math display">\[\begin{eqnarray*}
P(i^{th} \mbox{ indiv w/}x_i \mbox{ dies at } t_j | \mbox{at least one death at } t_j) &amp;=&amp; \frac{P(i^{th} \mbox{ indiv w/}x_i \mbox{ dies at } t_j )}{P(\mbox{at least one death at } t_j)}\\
&amp;=&amp; \frac{\mbox{hazard at } t_i}{\mbox{sum over all patients at risk at time } t_j}\\
&amp;=&amp; \frac{h_i(t_j)}{\sum_{k:t_k \geq t_j} h_k (t_j)} \\
&amp;=&amp; \frac{e^{\beta x_i}}{\sum_{k:t_k \geq t_j} e^{\beta x_k}}\\
w_j(\beta, t_j) &amp;=&amp; \frac{e^{\beta x_i}}{\sum_{k:t_k \geq t_j} e^{\beta x_k}}
\end{eqnarray*}\]</span>
Using the weights above, we can calculate the average value for the <span class="math inline">\(l^{th}\)</span> covariate (i.e., explanatory variable):
<span class="math display">\[\begin{eqnarray*}
\bar{x}_l (\beta,t_j) &amp;=&amp; \sum_{k: t_k \geq t_j} x_{kl} w_j(\beta, t_j)
\end{eqnarray*}\]</span>
The Schoenfeld Residual for <span class="math inline">\(x_l\)</span> and any subject <span class="math inline">\(i\)</span> who is still alive at time <span class="math inline">\(t_j\)</span>, is the <em>difference</em> between the covariate <span class="math inline">\(x_{il}\)</span> for that subject and the weighted average of the covariates in the risk set:
<span class="math display">\[\begin{eqnarray*}
\mbox{Schoenfeld resid } = x_{il} - \bar{x}_l(\beta, t_j)
\end{eqnarray*}\]</span>
<p>The idea is for the plot to be flat. What if there is a strong linear trend for the residuals? What would that say about the time dependency?</p>
</div>
<div id="solutions" class="section level4">
<h4><span class="header-section-number">6.3.4.3</span> Solutions</h4>
<ul>
<li><strong>crossing</strong> If the hazard functions (or survivor functions!) cross over time, the PH assumption is violated.<br />
</li>
<li><strong>help</strong> What should we do?<br />
</li>
</ul>
<ol style="list-style-type: decimal">
<li>Don’t do coxph, just fit K-M curves separately and perform a log-rank test.<br />
</li>
<li>Start at <span class="math inline">\(t^*\)</span>, the crossing point.<br />
</li>
<li>Fit different models for before <span class="math inline">\(t^*\)</span> and after <span class="math inline">\(t^*\)</span>.<br />
</li>
<li>Fit a model with a time dependent covariate.<br />
</li>
<li>Creative analysis: instead of tumor size, use % change over a set period of time.</li>
</ol>
<ul>
<li><strong>examples</strong> of PH violations
<ul>
<li>over time, effect lessens (short term benefits)<br />
</li>
<li>tumor size at endpoint is more predictive than tumor size at entrance.<br />
</li>
<li>clinical variables that change over time (lung capacity, weight, white blood cell count)<br />
</li>
<li>exposure variables (pollution, UV rays, etc.)<br />
</li>
<li>age, temperature</li>
</ul></li>
</ul>
</div>
<div id="log-linearity" class="section level4">
<h4><span class="header-section-number">6.3.4.4</span> Log linearity</h4>
<p>We’ve also assumed that the log of the hazard ratio is linear in the covariates. That a one unit change in any covariate has the same effect on the log of the HR (at any level of the covariate). Just like with logistic regression, this assumption is hard to check. However, we can see how the modeling performs by checking to see if quadratic (or other higher order terms) are significant in the model. Another possibility is to categorize a continuous predictor to check PH assumptions as above.</p>
</div>
</div>
</div>
<div id="othersurv" class="section level2">
<h2><span class="header-section-number">6.4</span> Other stuff</h2>
<div id="sample-size-calculation" class="section level3">
<h3><span class="header-section-number">6.4.1</span> Sample Size Calculation</h3>
<div id="sample-size-for-two-independent-sample-means-inference" class="section level4">
<h4><span class="header-section-number">6.4.1.1</span> Sample Size for Two Independent Sample Means Inference</h4>
<p>Taking a step back to consider a slightly simpler inference (two sample mean), let’s say we want a size of <span class="math inline">\(\alpha=0.05\)</span> and a power of <span class="math inline">\(1-\beta=0.8\)</span>. What does that mean? How do they relate to the type I and type II errors? Draw some pictures. We’re talking about the only thing we can control: the sample size. We cannot actually control the truth of the hypotheses, the extent of the difference in in <span class="math inline">\(H_0\)</span> versus <span class="math inline">\(H_A\)</span>, or the variability of the underlying population. We <strong>can</strong> control the sample size. The larger your sample size, the easier it is to identify a true alternative hypothesis (that is, the higher the power).</p>
<p>In order to estimate the needed sample size, you need to know how often you are willing to make type I errors, how often you are willing to make type II errors, and how big of a difference between <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_A\)</span> you would like to determine. Without all three of those components, it is <strong>impossible</strong> to determine the sample size. If you read that a sample size calculation has been done, they <strong>must</strong> report the associated size, power, and difference (or their calculation will be meaningless).</p>
<span class="math display">\[\begin{eqnarray*}
H_0: \mu_1 - \mu_2 = 0\\
H_A: \mu_1 - \mu_2 \ne 0
\end{eqnarray*}\]</span>
We have to make some assumptions. We assume that the size is 0.05, the power is 0.8, and the alternative hypothesis is <span class="math inline">\(D = \mu_1 - \mu_2\)</span>. For this case, let’s also assume that <span class="math inline">\(\sigma_1=\sigma_2=\sigma\)</span> and <span class="math inline">\(n_1=n_2=n\)</span>. Without loss of generality, let’s say <span class="math inline">\(\overline{Y}_1 - \overline{Y}_2 &gt; 0\)</span>.
<span class="math display">\[\begin{eqnarray*}
P\bigg(\frac{\overline{Y}_1 - \overline{Y}_2 - 0}{\sigma \sqrt{1/n + 1/n}} &gt; 1.96 \bigg| \mu_1 - \mu_2 = 0 \bigg) &amp;=&amp; 0.025\\
P(\overline{Y}_1 - \overline{Y}_2 &gt; 1.96 \sigma \sqrt{1/n + 1/n} \bigg| \mu_1 - \mu_2 = 0) &amp;=&amp; 0.025\\
P(\overline{Y}_1 - \overline{Y}_2 &gt; 1.96 \sigma \sqrt{1/n + 1/n} \bigg| \mu_1 - \mu_2 = D) &amp;\geq&amp; 0.8\\
P\bigg(\frac{\overline{Y}_1 - \overline{Y}_2 - D}{\sigma \sqrt{1/n + 1/n}} &gt; \frac{1.96 \sigma \sqrt{1/n + 1/n}-D}{\sigma \sqrt{1/n + 1/n}} \bigg| \mu_1 - \mu_2 = D \bigg) &amp;\geq&amp; 0.8\\
P\bigg(Z &gt; \frac{1.96 \sigma \sqrt{1/n + 1/n}-D}{\sigma \sqrt{1/n + 1/n}} \bigg) &amp;\geq&amp; 0.8\\
\frac{1.96 \sigma \sqrt{1/n + 1/n}-D}{\sigma \sqrt{1/n + 1/n}} &amp;\leq&amp; Z_{0.8}\\
1.96 \sigma \sqrt{2/n} - D &amp;\leq&amp; Z_{0.8} \sigma \sqrt{2/n}\\
2.845 \sigma \sqrt{2/n} &amp;\leq&amp; D\\
n &amp;\geq&amp; \frac{16 \sigma^2}{D^2}
\end{eqnarray*}\]</span>
Again, if we want to be able to find a 2 point difference in unrestricted versus deprived mean visual acuity scores, (<span class="math inline">\(\sigma=14\)</span>, equal sample sizes):
<span class="math display">\[\begin{eqnarray*}
n &amp;\geq&amp; \frac{16 \cdot 14^2}{4}\\
&amp;\geq&amp; 784
\end{eqnarray*}\]</span>
</div>
<div id="sample-size-for-survival-model" class="section level4">
<h4><span class="header-section-number">6.4.1.2</span> Sample Size for Survival model</h4>
The sample size calculations below are derived from the inference done with a log-rank statistics comparing two groups. The total number of deaths required to detect a difference in groups with a size of <span class="math inline">\(\alpha\)</span> and a power of <span class="math inline">\(1-\beta\)</span> is
<span class="math display">\[\begin{eqnarray*}
d = \frac{(z_{\alpha/2} + z_\beta)^2}{\pi_1 \pi_2 \theta^2_R}
\end{eqnarray*}\]</span>
<p>where <span class="math inline">\(\pi_1\)</span> is the proportion of the sample in group 1, <span class="math inline">\(\pi_2\)</span> is the proportion of the sample in group 2, and <span class="math inline">\(\theta_R\)</span> is the log hazard ratio to detect.</p>
<p>(Derivation in <span class="citation">Collett (<a href="#ref-Collett">2015</a>)</span> pg 256.)</p>
<p>Consider the following sample size calculator. The variables included are slightly different, but give the same general structure to the calculation. For example, the equation above calculates the number of deaths. The applet calculates the number of samples (where <span class="math inline">\(d = p_E \cdot n\)</span>). <a href="http://powerandsamplesize.com/Calculators/Test-Time-To-Event-Data/Cox-PH-Equivalence" class="uri">http://powerandsamplesize.com/Calculators/Test-Time-To-Event-Data/Cox-PH-Equivalence</a></p>
</div>
<div id="significance-level-vs.power-vs.sample-size" class="section level4">
<h4><span class="header-section-number">6.4.1.3</span> Significance level vs. Power vs. Sample Size</h4>
<ul>
<li><strong>Sig level</strong> <span class="math inline">\(\alpha\)</span>: we <em>set</em> our type I error rate<br />
</li>
<li><strong>power</strong> <span class="math inline">\(1-\beta\)</span>: probability of not making a type II error. To set the power, we would need to know the sample size, significance level, and the clinically important difference that we wish to detect (effect size).<br />
</li>
<li><strong>sample size</strong> n: To set the sample size, we need <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and effect size<br />
</li>
</ul>
<ol style="list-style-type: decimal">
<li>“The trial has 90% power” is meaningless<br />
</li>
<li>“With 500 subjects per group, the trial has 90% power to detect a decrease of 10mmHg in blood pressure due to the new treatment at a 0.05 significance level.”</li>
</ol>
</div>
</div>
<div id="study-design" class="section level3">
<h3><span class="header-section-number">6.4.2</span> Study Design</h3>
<ul>
<li><p>Randomized, controlled trial</p></li>
<li>Factorial design
<ul>
<li>Random allocation (within a factorial design) allows for estimation of interaction between treatments<br />
</li>
<li>Physicians’ health study was factorial with aspirin (to measure myocardial infarction) and beta carotene (cancer)<br />
</li>
<li>Can include 3 or more treatments (but would need large sample sizes to measure anything)</li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th align="center">treatment A</th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="center">Yes</td>
<td align="center">No</td>
</tr>
<tr class="even">
<td></td>
<td>Yes</td>
<td align="center">Both A &amp; B</td>
<td align="center">only B</td>
</tr>
<tr class="odd">
<td><strong>treatment B</strong></td>
<td>No</td>
<td align="center">only A</td>
<td align="center">neither</td>
</tr>
</tbody>
</table>
<ul>
<li>Cross-over design: all participants receive <em>both</em> treatments (e.g., surgery and chemotherapy)
<ul>
<li>Each patient serves as their own control (need fewer samples)<br />
</li>
<li>Often cross-over effect from the initial treatment</li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(\swarrow\)</span></th>
<th align="center"></th>
<th align="center"><span class="math inline">\(\searrow\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Group 1</td>
<td align="center"></td>
<td align="center">Group 2</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\downarrow\)</span> (1)</td>
<td align="center"></td>
<td align="center"><span class="math inline">\(\downarrow\)</span> (1)</td>
</tr>
<tr class="odd">
<td align="center">Drug A</td>
<td align="center"><span class="math inline">\(\stackrel{(2)}{\rightarrow}\)</span></td>
<td align="center">Drug B</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center"><span class="math inline">\(\stackrel{(2)}{\hookleftarrow}\)</span></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<ul>
<li>Noncompliance
<ul>
<li>Patients will switch on their own! How do you analyze the data?<br />
</li>
<li>Analyze according to assigned treatment (intent-to-treat). Crossover does not happen randomly and is well known to be associated to outcome.<br />
</li>
<li>Can perform a secondary analysis on only those patients who stayed on treatment.<br />
</li>
<li>Example: surgery and radiation</li>
</ul></li>
</ul>
<div id="subgroup-analysis" class="section level4">
<h4><span class="header-section-number">6.4.2.1</span> subgroup analysis</h4>
<ul>
<li>Refers to analyzing a subset of patients in a trial separately (e.g., gender, race, family background, etc.)<br />
</li>
<li>Important for: clinical decision making, regulatory requirements, hypothesis generation<br />
</li>
<li>Problems:
<ul>
<li>insufficient power. If powered for overall treatment effect, it will be underpowered to detect similar effects in subgroups.<br />
</li>
<li>multiple comparisons. If you torture your data long enough, eventually it will confess to anything.<br />
</li>
<li>whenever possible, subgroup analysis should be defined <em>a priori</em> in the protocol</li>
</ul></li>
</ul>
</div>
<div id="some-topics-worth-investigating" class="section level4">
<h4><span class="header-section-number">6.4.2.2</span> Some topics worth investigating</h4>
<ul>
<li>Meta Analysis <span class="citation">(Green et al. <a href="#ref-crowley">2016</a>)</span><br />
</li>
<li>General Thoughts on Clinical Trials for cancer <span class="citation">(Green et al. <a href="#ref-crowley">2016</a>)</span><br />
</li>
<li>Stratified Cox Model <span class="citation">(E. Vittinghoff et al. <a href="#ref-vittinghoff">2012</a>)</span><br />
</li>
<li>Interim analyses / stopping rules<br />
</li>
<li>Intent-to-treat (missing data)<br />
</li>
<li>Investigating time-varying effects <span class="citation">(Bellera et al. <a href="#ref-timevar">2010</a>)</span></li>
</ul>
</div>
</div>
</div>
<div id="Rsurv" class="section level2">
<h2><span class="header-section-number">6.5</span> R example: ProPublica Analysis</h2>
<div id="recidivism-in-florida" class="section level3">
<h3><span class="header-section-number">6.5.1</span> Recidivism in Florida</h3>
<blockquote>
<p>[The ProPublica] analysis of Northpointe’s tool, called COMPAS (which stands for Correctional Offender Management Profiling for Alternative Sanctions), found that black defendants were far more likely than white defendants to be incorrectly judged to be at a higher risk of recidivism, while white defendants were more likely than black defendants to be incorrectly flagged as low risk.</p>
</blockquote>
<blockquote>
<p>[ProPublica] looked at more than 10,000 criminal defendants in Broward County, Florida, and compared their predicted recidivism rates with the rate that actually occurred over a two-year period. When most defendants are booked in jail, they respond to a COMPAS questionnaire. Their answers are fed into the COMPAS software to generate several scores including predictions of “Risk of Recidivism” and “Risk of Violent Recidivism.” <span class="citation">(Larson et al. {May 23, 2016})</span></p>
</blockquote>
<p>The original article is here: <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" class="uri">https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing</a></p>
<p>The data analysis is here: <a href="https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm" class="uri">https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm</a></p>
<p>The GitHub repo with data and code is here: <a href="https://github.com/propublica/compas-analysis" class="uri">https://github.com/propublica/compas-analysis</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(survival)
recid &lt;-<span class="st"> </span>readr<span class="op">::</span><span class="kw">read_csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv&quot;</span>)

recid &lt;-<span class="st"> </span>dplyr<span class="op">::</span><span class="kw">select</span>(recid, age, c_charge_degree, race, age_cat, score_text, sex, priors_count, 
                    days_b_screening_arrest, decile_score, is_recid, two_year_recid, 
                    c_jail_in, c_jail_out) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">filter</span>(days_b_screening_arrest <span class="op">&lt;=</span><span class="st"> </span><span class="dv">30</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">filter</span>(days_b_screening_arrest <span class="op">&gt;=</span><span class="st"> </span><span class="op">-</span><span class="dv">30</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">filter</span>(is_recid <span class="op">!=</span><span class="st"> </span><span class="op">-</span><span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">filter</span>(c_charge_degree <span class="op">!=</span><span class="st"> &quot;O&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">filter</span>(score_text <span class="op">!=</span><span class="st"> &#39;N/A&#39;</span>)
        
recid &lt;-<span class="st"> </span>recid <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">length_of_stay =</span> <span class="kw">as.numeric</span>(<span class="kw">as.Date</span>(c_jail_out) <span class="op">-</span><span class="st"> </span><span class="kw">as.Date</span>(c_jail_in))) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">mutate</span>(<span class="dt">crime_factor =</span> <span class="kw">factor</span>(c_charge_degree)) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">mutate</span>(<span class="dt">age_factor =</span> <span class="kw">as.factor</span>(age_cat)) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">within</span>(age_factor &lt;-<span class="st"> </span><span class="kw">relevel</span>(age_factor, <span class="dt">ref =</span> <span class="dv">1</span>)) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">mutate</span>(<span class="dt">race_factor =</span> <span class="kw">factor</span>(race,
                                  <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;African-American&quot;</span>, 
                                             <span class="st">&quot;Asian&quot;</span>,
                                             <span class="st">&quot;Caucasian&quot;</span>, 
                                             <span class="st">&quot;Hispanic&quot;</span>, 
                                             <span class="st">&quot;Native American&quot;</span>,
                                             <span class="st">&quot;Other&quot;</span>))) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">within</span>(race_factor &lt;-<span class="st"> </span><span class="kw">relevel</span>(race_factor, <span class="dt">ref =</span> <span class="dv">3</span>)) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">mutate</span>(<span class="dt">gender_factor =</span> <span class="kw">factor</span>(sex, <span class="dt">labels=</span> <span class="kw">c</span>(<span class="st">&quot;Female&quot;</span>,<span class="st">&quot;Male&quot;</span>))) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">within</span>(gender_factor &lt;-<span class="st"> </span><span class="kw">relevel</span>(gender_factor, <span class="dt">ref =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">mutate</span>(<span class="dt">score_factor =</span> <span class="kw">factor</span>(score_text <span class="op">!=</span><span class="st"> &quot;Low&quot;</span>, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;LowScore&quot;</span>,<span class="st">&quot;HighScore&quot;</span>)))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">recidKM &lt;-<span class="st"> </span><span class="kw">filter</span>(<span class="kw">filter</span>(<span class="kw">read_csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/propublica/compas-analysis/master/cox-parsed.csv&quot;</span>), score_text <span class="op">!=</span><span class="st"> &quot;N/A&quot;</span>), end <span class="op">&gt;</span><span class="st"> </span>start) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">race_factor =</span> <span class="kw">factor</span>(race,
                                  <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;African-American&quot;</span>, 
                                             <span class="st">&quot;Asian&quot;</span>,
                                             <span class="st">&quot;Caucasian&quot;</span>, 
                                             <span class="st">&quot;Hispanic&quot;</span>, 
                                             <span class="st">&quot;Native American&quot;</span>,
                                             <span class="st">&quot;Other&quot;</span>))) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">within</span>(race_factor &lt;-<span class="st"> </span><span class="kw">relevel</span>(race_factor, <span class="dt">ref =</span> <span class="dv">3</span>)) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">score_factor =</span> <span class="kw">factor</span>(score_text)) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">within</span>(score_factor &lt;-<span class="st"> </span><span class="kw">relevel</span>(score_factor, <span class="dt">ref=</span><span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">timefollow =</span> end <span class="op">-</span><span class="st"> </span>start) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">filter</span>(race <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;African-American&quot;</span>, <span class="st">&quot;Caucasian&quot;</span>))

recidKMV &lt;-<span class="st"> </span><span class="kw">filter</span>(<span class="kw">filter</span>(<span class="kw">read_csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/propublica/compas-analysis/master/cox-violent-parsed.csv&quot;</span>), score_text <span class="op">!=</span><span class="st"> &quot;N/A&quot;</span>), end <span class="op">&gt;</span><span class="st"> </span>start) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">race_factor =</span> <span class="kw">factor</span>(race,
                                  <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;African-American&quot;</span>, 
                                             <span class="st">&quot;Asian&quot;</span>,
                                             <span class="st">&quot;Caucasian&quot;</span>, 
                                             <span class="st">&quot;Hispanic&quot;</span>, 
                                             <span class="st">&quot;Native American&quot;</span>,
                                             <span class="st">&quot;Other&quot;</span>))) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">within</span>(race_factor &lt;-<span class="st"> </span><span class="kw">relevel</span>(race_factor, <span class="dt">ref =</span> <span class="dv">3</span>)) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">score_factor =</span> <span class="kw">factor</span>(score_text)) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">within</span>(score_factor &lt;-<span class="st"> </span><span class="kw">relevel</span>(score_factor, <span class="dt">ref=</span><span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">timefollow =</span> end <span class="op">-</span><span class="st"> </span>start) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">filter</span>(race <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;African-American&quot;</span>, <span class="st">&quot;Caucasian&quot;</span>))</code></pre></div>
</div>
<div id="kaplan-meier-survival-curve" class="section level3">
<h3><span class="header-section-number">6.5.2</span> Kaplan-Meier survival curve</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">recid.surv &lt;-<span class="st"> </span><span class="kw">survfit</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM)
<span class="kw">plot</span>(recid.surv, <span class="dt">lty=</span><span class="dv">2</span><span class="op">:</span><span class="dv">4</span>, <span class="dt">xlab=</span><span class="st">&quot;time&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;survival function&quot;</span>)
<span class="kw">legend</span>(<span class="dv">10</span>,.<span class="dv">4</span>, <span class="kw">c</span>(<span class="st">&quot;low&quot;</span>, <span class="st">&quot;high&quot;</span>, <span class="st">&quot;medium&quot;</span>),<span class="dt">lty=</span><span class="dv">2</span><span class="op">:</span><span class="dv">4</span>)

survminer<span class="op">::</span><span class="kw">ggsurvplot</span>(recid.surv, <span class="dt">conf.int=</span><span class="ot">TRUE</span>, <span class="dt">censor=</span>F) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Overall&quot;</span>)</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-13-1.png" width="672" style="display: block; margin: auto;" /><img src="06-surv_files/figure-html/unnamed-chunk-13-2.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggsurvplot</span>(recid.surv[<span class="dv">1</span>], <span class="dt">conf.int=</span><span class="ot">TRUE</span>, <span class="dt">censor=</span>F) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Low Only&quot;</span>)</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggsurvplot</span>(recid.surv, <span class="dt">conf.int=</span><span class="ot">TRUE</span>, <span class="dt">censor=</span>F, <span class="dt">risk.table =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-14-2.png" width="672" style="display: block; margin: auto;" /></p>
<p>different options for CI</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">4747</span>)
recidKM2 &lt;-<span class="st"> </span>recidKM <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sample_n</span>(<span class="dv">200</span>)  <span class="co"># CI on a smaller random sample just to see the different CIs</span>
<span class="kw">ggsurvplot</span>(<span class="kw">survfit</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM2), 
           <span class="dt">censor=</span>F, <span class="dt">conf.int=</span>F) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;No CI&quot;</span>)</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggsurvplot</span>(<span class="kw">survfit</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM2,
                   <span class="dt">conf.type=</span><span class="st">&quot;log&quot;</span>), <span class="dt">censor=</span>F, <span class="dt">conf.int=</span>T) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Log CI&quot;</span>)</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-15-2.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggsurvplot</span>(<span class="kw">survfit</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM2,
                   <span class="dt">conf.type=</span><span class="st">&quot;log-log&quot;</span>), <span class="dt">censor=</span>F, <span class="dt">conf.int=</span>T) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Log-Log CI&quot;</span>)</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-15-3.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggsurvplot</span>(<span class="kw">survfit</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM2,
                   <span class="dt">conf.type=</span><span class="st">&quot;plain&quot;</span>), <span class="dt">censor=</span>F, <span class="dt">conf.int=</span>T) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Plain CI&quot;</span>)</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-15-4.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggsurvplot_facet</span>(<span class="kw">survfit</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM2), 
                 <span class="dt">data=</span>recidKM2, <span class="dt">facet.by =</span> <span class="st">&quot;race&quot;</span>)</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-15-5.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="log-rank-test-rho0-and-the-wilcoxon-test-rho1" class="section level3">
<h3><span class="header-section-number">6.5.3</span> Log-rank test [rho=0] and the Wilcoxon test [rho=1]</h3>
<p>General recidivism</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">survdiff</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM2, <span class="dt">rho=</span><span class="dv">0</span>)</code></pre></div>
<pre><code>## Call:
## survdiff(formula = Surv(timefollow, event) ~ score_factor, data = recidKM2, 
##     rho = 0)
## 
##                       N Observed Expected (O-E)^2/E (O-E)^2/V
## score_factor=Low    106       16    32.66      8.50     22.70
## score_factor=High    31       13     5.94      8.39      9.53
## score_factor=Medium  63       24    14.40      6.41      8.93
## 
##  Chisq= 23.9  on 2 degrees of freedom, p= 7e-06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">survdiff</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM2, <span class="dt">rho=</span><span class="dv">1</span>)</code></pre></div>
<pre><code>## Call:
## survdiff(formula = Surv(timefollow, event) ~ score_factor, data = recidKM2, 
##     rho = 1)
## 
##                       N Observed Expected (O-E)^2/E (O-E)^2/V
## score_factor=Low    106     13.6    27.70      7.22     21.61
## score_factor=High    31     11.6     5.21      7.73      9.97
## score_factor=Medium  63     20.4    12.59      4.83      7.72
## 
##  Chisq= 23.1  on 2 degrees of freedom, p= 1e-05</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggsurvplot</span>(<span class="kw">survfit</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM2), 
           <span class="dt">censor=</span>F, <span class="dt">conf.int=</span>F, <span class="dt">pval=</span><span class="ot">TRUE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;No CI&quot;</span>)</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-16-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Violent recidivism</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">4747</span>)
recidKMV2 &lt;-<span class="st"> </span>recidKMV <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sample_n</span>(<span class="dv">500</span>)

recidKMV2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(race <span class="op">==</span><span class="st"> &quot;Caucasian&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">survdiff</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>., <span class="dt">rho=</span><span class="dv">0</span>)</code></pre></div>
<pre><code>## Call:
## survdiff(formula = Surv(timefollow, event) ~ score_factor, data = ., 
##     rho = 0)
## 
##                       N Observed Expected (O-E)^2/E (O-E)^2/V
## score_factor=Low    111        3    3.554    0.0862     0.214
## score_factor=High    31        2    0.759    2.0263     2.334
## score_factor=Medium  64        1    1.687    0.2798     0.390
## 
##  Chisq= 2.4  on 2 degrees of freedom, p= 0.3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">recidKMV2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(race <span class="op">==</span><span class="st"> &quot;African-American&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">survdiff</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>., <span class="dt">rho=</span><span class="dv">0</span>)</code></pre></div>
<pre><code>## Call:
## survdiff(formula = Surv(timefollow, event) ~ score_factor, data = ., 
##     rho = 0)
## 
##                       N Observed Expected (O-E)^2/E (O-E)^2/V
## score_factor=Low     97        4     6.49     0.954     1.626
## score_factor=High   107        6     4.44     0.550     0.776
## score_factor=Medium  90        6     5.07     0.169     0.247
## 
##  Chisq= 1.7  on 2 degrees of freedom, p= 0.4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">survdiff</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKMV2, <span class="dt">rho=</span><span class="dv">1</span>)</code></pre></div>
<pre><code>## Call:
## survdiff(formula = Surv(timefollow, event) ~ score_factor, data = recidKMV2, 
##     rho = 1)
## 
##                       N Observed Expected (O-E)^2/E (O-E)^2/V
## score_factor=Low    208     6.77    10.43     1.284    2.6070
## score_factor=High   138     7.85     4.45     2.585    3.3914
## score_factor=Medium 154     6.78     6.51     0.011    0.0163
## 
##  Chisq= 4  on 2 degrees of freedom, p= 0.1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggsurvplot</span>(<span class="kw">survfit</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKMV2), 
           <span class="dt">censor=</span>F, <span class="dt">conf.int=</span>T, <span class="dt">pval=</span><span class="ot">TRUE</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Violent Recidivism&quot;</span>)</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-17-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggsurvplot</span>(<span class="kw">survfit</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKMV2), 
                 <span class="dt">data=</span>recidKMV, <span class="dt">censor =</span> <span class="ot">FALSE</span>, <span class="dt">conf.int =</span> <span class="ot">TRUE</span>, <span class="dt">facet.by =</span> <span class="st">&quot;race&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Violent Recidivism&quot;</span>)</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-17-2.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">as.data.frame</span>(recidKMV2) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># must be a data.frame see &quot;.&quot; below:</span>
<span class="kw">ggsurvplot</span>(<span class="kw">survfit</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span> .), 
                 <span class="dt">data =</span> ., <span class="dt">censor =</span> <span class="ot">FALSE</span>, <span class="dt">conf.int =</span> <span class="ot">TRUE</span>, <span class="dt">pval=</span><span class="ot">TRUE</span>, <span class="dt">facet.by =</span> <span class="st">&quot;race&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Violent Recidivism&quot;</span>)</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-17-3.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="cox-proportional-hazards-models" class="section level3">
<h3><span class="header-section-number">6.5.4</span> Cox Proportional Hazards models</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Just score_factor</span>
<span class="kw">coxph</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</code></pre></div>
<pre><code>## # A tibble: 2 x 7
##   term            estimate std.error statistic   p.value conf.low conf.high
##   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1 score_factorHi…    1.08     0.0446      24.1 7.67e-129    0.990     1.16 
## 2 score_factorMe…    0.704    0.0439      16.0 9.78e- 58    0.617     0.790</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coxph</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">glance</span>()</code></pre></div>
<pre><code>## # A tibble: 1 x 15
##       n nevent statistic.log p.value.log statistic.sc p.value.sc
##   &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
## 1 11426   3058          617.   9.39e-135         654.  1.15e-142
## # … with 9 more variables: statistic.wald &lt;dbl&gt;, p.value.wald &lt;dbl&gt;,
## #   r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;, concordance &lt;dbl&gt;,
## #   std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;, BIC &lt;dbl&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># score_factor and race</span>
<span class="kw">coxph</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor <span class="op">+</span><span class="st"> </span>race, <span class="dt">data=</span>recidKM) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</code></pre></div>
<pre><code>## # A tibble: 3 x 7
##   term            estimate std.error statistic   p.value conf.low conf.high
##   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1 score_factorHi…    1.03     0.0460     22.3  3.96e-110    0.936    1.12  
## 2 score_factorMe…    0.674    0.0445     15.2  7.45e- 52    0.586    0.761 
## 3 raceCaucasian     -0.170    0.0396     -4.29 1.78e-  5   -0.248   -0.0924</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coxph</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor <span class="op">+</span><span class="st"> </span>race, <span class="dt">data=</span>recidKM) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">glance</span>()</code></pre></div>
<pre><code>## # A tibble: 1 x 15
##       n nevent statistic.log p.value.log statistic.sc p.value.sc
##   &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
## 1 11426   3058          636.   1.65e-137         671.  3.72e-145
## # … with 9 more variables: statistic.wald &lt;dbl&gt;, p.value.wald &lt;dbl&gt;,
## #   r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;, concordance &lt;dbl&gt;,
## #   std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;, BIC &lt;dbl&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># score_factor, race, age, sex</span>
<span class="kw">coxph</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sex, <span class="dt">data=</span>recidKM) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">tidy</span>()</code></pre></div>
<pre><code>## # A tibble: 5 x 7
##   term             estimate std.error statistic  p.value conf.low conf.high
##   &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1 score_factorHigh   0.926    0.0471      19.6  7.63e-86   0.833     1.02  
## 2 score_factorMed…   0.611    0.0452      13.5  1.54e-41   0.522     0.699 
## 3 raceCaucasian     -0.120    0.0398      -3.01 2.63e- 3  -0.198    -0.0417
## 4 age               -0.0137   0.00175     -7.82 5.38e-15  -0.0171   -0.0103
## 5 sexMale            0.411    0.0502       8.19 2.53e-16   0.313     0.510</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coxph</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sex, <span class="dt">data=</span>recidKM) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">glance</span>()</code></pre></div>
<pre><code>## # A tibble: 1 x 15
##       n nevent statistic.log p.value.log statistic.sc p.value.sc
##   &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;
## 1 11426   3058          768.   8.91e-164         787.  7.45e-168
## # … with 9 more variables: statistic.wald &lt;dbl&gt;, p.value.wald &lt;dbl&gt;,
## #   r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;, concordance &lt;dbl&gt;,
## #   std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;, BIC &lt;dbl&gt;</code></pre>
</div>
<div id="checking-proportional-hazards-with-the-plot-of-ln-lnst" class="section level3">
<h3><span class="header-section-number">6.5.5</span> Checking proportional hazards with the plot of <span class="math inline">\(\ln(-\ln(S(t)))\)</span></h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggsurvplot</span>(<span class="kw">survfit</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM), 
           <span class="dt">censor=</span>F, <span class="dt">conf.int=</span>T, <span class="dt">fun=</span><span class="st">&quot;cloglog&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Complementary Log-Log&quot;</span>)</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-19-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The cox.zph function will test proportionality of all the predictors in the model by creating interactions with time using the transformation of time specified in the transform option. In this example we are testing proportionality by looking at the interactions with log(time). The column rho is the Pearson product-moment correlation between the scaled Schoenfeld residuals and log(time) for each covariate. The last row contains the global test for all the interactions tested at once. A p-value less than 0.05 indicates a violation of the proportionality assumption.</p>
</div>
<div id="checking-proportional-hazards-with-cox.zph" class="section level3">
<h3><span class="header-section-number">6.5.6</span> Checking proportional hazards with cox.zph</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cox.zph</span>(<span class="kw">coxph</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM))</code></pre></div>
<pre><code>##                          rho    chisq     p
## score_factorHigh    0.010310 3.26e-01 0.568
## score_factorMedium -0.000149 6.79e-05 0.993
## GLOBAL                    NA 4.28e-01 0.807</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cox.zph</span>(<span class="kw">coxph</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor, <span class="dt">data=</span>recidKM), <span class="dt">transform=</span><span class="st">&quot;log&quot;</span>)</code></pre></div>
<pre><code>##                        rho chisq      p
## score_factorHigh   0.03092 2.930 0.0869
## score_factorMedium 0.00944 0.272 0.6019
## GLOBAL                  NA 3.045 0.2182</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cox.zph</span>(<span class="kw">coxph</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sex, <span class="dt">data=</span>recidKM))</code></pre></div>
<pre><code>##                        rho   chisq      p
## score_factorHigh   -0.0113  0.3962 0.5291
## score_factorMedium -0.0174  0.9433 0.3314
## raceCaucasian      -0.0454  6.3353 0.0118
## age                -0.0429  5.6270 0.0177
## sexMale            -0.0056  0.0958 0.7570
## GLOBAL                  NA 13.7513 0.0173</code></pre>
<p>Note the big p-values. We do not reject the null hypothesis, so we conclude that there is no evidence of non-proportional hazards. If for example, the model seemed to be non-proportional on time but proportional on log(time), you might consider transforming the time variable (i.e., taking the natural log) in your original model.</p>
<p>The function cox.zph creates a cox.zph object that contains a list of the scaled Schoenfeld residuals. The ordering of the residuals in the list is the same order as the predictors were entered in the cox model. So, the first element of the list corresponds to the scaled Schoenfeld residuals for married, the second element corresponds to the scaled Schoenfeld residuals for person, and so forth. The cox.zph object can be used in a plot function. By specifying a particular element of the list it is possible to generate plots of residuals for individual predictors. Leaving out the list number results in plots for all the predictors being generated at one time. In the plots a non-zero slope is evidence against proportionality. The horizontal line at y=0 has been added for reference.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggcoxzph</span>(<span class="kw">cox.zph</span>(<span class="kw">coxph</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sex, <span class="dt">data=</span>recidKM))) </code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-21-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="coxph-diagnostics-look-into-all-the-different-arguments-of-the-function" class="section level3">
<h3><span class="header-section-number">6.5.7</span> Coxph diagnostics … look into all the different arguments of the function!</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggcoxdiagnostics</span>(<span class="kw">coxph</span>(<span class="kw">Surv</span>(timefollow,event) <span class="op">~</span><span class="st"> </span>score_factor <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sex, <span class="dt">data=</span>recidKM))</code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-22-1.png" width="672" style="display: block; margin: auto;" /></p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-gerds">
<p>Gerds, Thomas. 2016. “The Kaplan-Meier Theater.” <em>Teaching Statistics</em> 38: 45–49.</p>
</div>
<div id="ref-KuiperSklar">
<p>Kuiper, Shonda, and Jeff Sklar. 2013. <em>Practicing Statistics</em>. Pearson. <a href="http://web.grinnell.edu/individuals/kuipers/stat2labs/" class="uri">http://web.grinnell.edu/individuals/kuipers/stat2labs/</a>.</p>
</div>
<div id="ref-SurvHL">
<p>Hosmer, David W., Stanley Lemeshow, and Susanne May. 2008. <em>Applied Survival Analysis: Regression Modeling of Time-to-Event Data</em>. Wiley-Interscience.</p>
</div>
<div id="ref-Andersen">
<p>Andersen, Per K., Ornulf Borgan, Richard D. Gill, and Niels Keiding. 1996. <em>Statistical Models Based on Counting Processes</em>. Springer Series in Statistics.</p>
</div>
<div id="ref-KMmean">
<p>StatsDirect Limited. 2016. <em>Kaplan-Meier Survival Estimates</em>. <a href="https://www.statsdirect.com/help/survival_analysis/kaplan.htm" class="uri">https://www.statsdirect.com/help/survival_analysis/kaplan.htm</a>.</p>
</div>
<div id="ref-Collett">
<p>Collett, David. 2015. <em>Modelling Survival Data in Medical Research</em>. Chapman; Hall.</p>
</div>
<div id="ref-AndHerz">
<p>Andrews, D.F., and A.M. Herzberg. 1985. <em>Data</em>. Springer-Verlag.</p>
</div>
<div id="ref-Dupont">
<p>Dupont, William D. 2009. <em>Statistical Modeling for Biomedical Researchers</em>. Cambridge University Press.</p>
</div>
<div id="ref-crowley">
<p>Green, Stephanie, Jacqueline Benedetti, Angela Smith, and John Crowley. 2016. <em>Clinical Trials in Oncology</em>. CRC Press.</p>
</div>
<div id="ref-vittinghoff">
<p>Vittinghoff, Eric, David V. Glidden, Stephen C. Shiboski, and Charles E. McCulloch. 2012. <em>Regression Methods in Biostatistics</em>. Springer-Verlag.</p>
</div>
<div id="ref-timevar">
<p>Bellera, Carine A, Gaetan MacGrogan, Marc Debled, Christine Tunon de Lara, Veronique Brouste, and Simone Mathoulin-Pelissier. 2010. “Variables with Time-Varying Effects and the Cox Model: Some Statistical Concepts Illustrated with a Prognostic Factor Study in Breast Cancer.” <em>BMC Medical Research Methodology</em> 10: 20. <a href="https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-10-20" class="uri">https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-10-20</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="logistic-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple-comparisons.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/06-surv.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Math-150-Notes.pdf", "Math-150-Notes.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
