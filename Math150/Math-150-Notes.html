<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Methods in Biostatistics</title>

    <meta name="author" content="Jo Hardin" />
  
  <!-- JS -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script>
  <script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script>
    <script src="libs/header-attrs-2.7.6/header-attrs.js"></script>
    <script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet" />
    <script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script>
    <script src="libs/bs3compat-0.2.4.9000/tabs.js"></script>
    <script src="libs/bs3compat-0.2.4.9000/bs3compat.js"></script>
    <link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet" />
    <script src="libs/bs4_book-1.0.0/bs4_book.js"></script>
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
    <script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>
    <script type="text/x-mathjax-config">
    const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
    for (let popover of popovers){
      const div = document.createElement('div');
      div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
      div.innerHTML = popover.getAttribute('data-content');
      
      // Will this work with TeX on its own line?
      var has_math = div.querySelector("span.math");
      if (has_math) {
        document.body.appendChild(div);
      	MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
      	MathJax.Hub.Queue(function(){
          popover.setAttribute('data-content', div.innerHTML);
      	})
      }
    }
    </script>
    <script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script>

  <!-- CSS -->
    <link rel="stylesheet" href="style.css" />
    
</head>

<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<!--bookdown:title:start-->
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book">
    <a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Methods in Biostatistics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
      </form>

      <nav aria-label="Table of contents">
        <h2>Table of contents</h2>
        <div id="book-toc"></div>

        <div class="book-extra">
          <p><a id="book-repo" href="#">View book source <i class="fab fa-github"></i></a></li></p>
        </div>
      </nav>
    </div>
  </header>

  <main class="col-sm-12 col-md-9 col-lg-7" id="content">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="class-information" class="section level1 unnumbered">
<h1 class="unnumbered">Class Information</h1>
<p>Class notes for Math 150 at Pomona College: Methods in Biostatistics. The notes are based primarily on the text <strong>Practicing Statistics</strong>, <span class="citation">(<a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar 2013</a>)</span>.</p>
<p>You are responsible for reading your text. Your text is very good &amp; readable, so you should use it. Your text is not, however, overly technical. You should make sure you are coming to class and asking lots of questions.</p>
<table>
<colgroup>
<col width="13%" />
<col width="37%" />
<col width="24%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Week</th>
<th align="left">Topic</th>
<th align="center">Book Chp</th>
<th align="center">Notes Section</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1/25/21</td>
<td align="left">t-tests / SLR</td>
<td align="center">2</td>
<td align="center">@ref(intro), @ref(ttest), @ref(tslr): t-test</td>
</tr>
<tr class="even">
<td align="left">1/27/21</td>
<td align="left">SLR</td>
<td align="center">2</td>
<td align="center">@ref(tslr): t-test as SLR</td>
</tr>
<tr class="odd">
<td align="left">2/1/21</td>
<td align="left">SLR</td>
<td align="center">2</td>
<td align="center">@ref(SLR): SLR</td>
</tr>
<tr class="even">
<td align="left">2/3/21</td>
<td align="left">Contingency Analysis</td>
<td align="center">6</td>
<td align="center">@ref(fisher) &amp; @ref(catest): Fisher’s Exact Test</td>
</tr>
<tr class="odd">
<td align="left">2/8/21</td>
<td align="left">Contingency Analysis</td>
<td align="center">6</td>
<td align="center">@ref(studies): Types of studies; @ref(catest): RR and OR</td>
</tr>
<tr class="even">
<td align="left">2/10/21</td>
<td align="left">Contingency Analysis</td>
<td align="center">6</td>
<td align="center">@ref(ciOR): Conf Int</td>
</tr>
<tr class="odd">
<td align="left">2/15/21</td>
<td align="left">Logistic Regression</td>
<td align="center">7</td>
<td align="center">@ref(logmodel): Log Reg</td>
</tr>
<tr class="even">
<td align="left">2/17/21</td>
<td align="left"></td>
<td align="center"></td>
<td align="center">@ref(logMLE): MLE</td>
</tr>
<tr class="odd">
<td align="left">2/22/21</td>
<td align="left">Logistic Regression</td>
<td align="center">7</td>
<td align="center">@ref(loginf): Inference</td>
</tr>
<tr class="even">
<td align="left">2/24/21</td>
<td align="left"></td>
<td align="center"></td>
<td align="center">@ref(multlog), @ref(multicol): Multiple Log Reg</td>
</tr>
<tr class="odd">
<td align="left">3/1/21</td>
<td align="left">Logistic Regression</td>
<td align="center">7</td>
<td align="center">@ref(logstep): Model Build</td>
</tr>
<tr class="even">
<td align="left">3/3/21</td>
<td align="left"></td>
<td align="center"></td>
<td align="center">@ref(roc): ROC</td>
</tr>
<tr class="odd">
<td align="left">3/8/21</td>
<td align="left">Spring Break</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">3/10/21</td>
<td align="left">Spring Break</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">3/15/21</td>
<td align="left">Cross Validation</td>
<td align="center"></td>
<td align="center">@ref(cv): Cross Validation;</td>
</tr>
<tr class="even">
<td align="left">3/17/21</td>
<td align="left">Review / Exam 1 (Wednesday)</td>
<td align="center">(2, 6, 7)</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">3/22/21</td>
<td align="left">Survival Analysis</td>
<td align="center">9</td>
<td align="center">@ref(timedata), @ref(KM): KM curves</td>
</tr>
<tr class="even">
<td align="left">3/24/21</td>
<td align="left"></td>
<td align="center"></td>
<td align="center">@ref(KMCI): KM CI</td>
</tr>
<tr class="odd">
<td align="left">3/29/21</td>
<td align="left">Survival Analysis</td>
<td align="center">9</td>
<td align="center">@ref(logrank): Log Rank test</td>
</tr>
<tr class="even">
<td align="left">3/31/21</td>
<td align="left"></td>
<td align="center"></td>
<td align="center">@ref(hazfunc): hazard functions</td>
</tr>
<tr class="odd">
<td align="left">4/5/21</td>
<td align="left">Survival Analysis</td>
<td align="center">9</td>
<td align="center">@ref(coxph): Cox PH model</td>
</tr>
<tr class="even">
<td align="left">4/7/21</td>
<td align="left"></td>
<td align="center"></td>
<td align="center">@ref(multcoxph): Multiple Cox PH</td>
</tr>
<tr class="odd">
<td align="left">4/12/21</td>
<td align="left">Survival Analysis</td>
<td align="center">9</td>
<td align="center">@ref(testingph): Assessing PH</td>
</tr>
<tr class="even">
<td align="left">4/14/21</td>
<td align="left">Ioannidis &amp; mult. compar.</td>
<td align="center">1.13</td>
<td align="center">@ref(Ioannidis): False Published</td>
</tr>
<tr class="odd">
<td align="left">4/19/21</td>
<td align="left"></td>
<td align="center"></td>
<td align="center">@ref(multcomp): Mult Comp</td>
</tr>
<tr class="even">
<td align="left">4/26/21</td>
<td align="left">Ioannidis &amp; mult. compar.</td>
<td align="center">1.13</td>
<td align="center">@ref(qvals): qvalues</td>
</tr>
<tr class="odd">
<td align="left">4/28/21</td>
<td align="left">Exam 2 (Wednesday)</td>
<td align="center">(9, multiple comparisons)</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">5/3/21</td>
<td align="left">Poisson Regression</td>
<td align="center">8</td>
<td align="center">@ref(regPois): Poisson model</td>
</tr>
<tr class="odd">
<td align="left">5/5/21</td>
<td align="left">Poisson Regression</td>
<td align="center">8</td>
<td align="center">@ref(inferPois): Poisson inference</td>
</tr>
</tbody>
</table>
<!--chapter:end:index.Rmd-->
</div>
<div id="intro" class="section level1" number="1">
<h1 number="1"><span class="header-section-number">1</span> Introduction</h1>
<div class="figure" style="text-align: center">
<img src="figs/covidvaccine.png" alt="We reject the null hypothesis based on the 'hot damn, check out this chart' test. https://xkcd.com/2400/" width="60%" />
<p class="caption">
(#fig:unnamed-chunk-1)We reject the null hypothesis based on the ‘hot damn, check out this chart’ test. <a href="https://xkcd.com/2400/" class="uri">https://xkcd.com/2400/</a>
</p>
</div>
<div id="course-goals" class="section level2" number="1.1">
<h2 number="1.1"><span class="header-section-number">1.1</span> Course Goals</h2>
<p>Our goals in this course are:</p>
<ul>
<li>to better evaluate quantitative information with regards to clinical and biological data. We’ll be sure to keep in mind:
<ul>
<li>Careful presentation of data<br />
</li>
<li>Consideration of variability<br />
</li>
<li>Meaningful comparisons</li>
</ul></li>
<li>to be able to critically evaluate the medical literature with respect to design, analysis, and interpretation of results.<br />
</li>
<li>to understand the role of inherent variability and keep it in perspective when inferring results to a population.<br />
</li>
<li>to critically evaluate medical results given in the mainstream media.<br />
</li>
<li>to read published studies with skepticism. Some people (in all fields!) wrongly believe that all studies published in a peer review publication must be 100% accurate and/or well designed studies. In this course, you will learn the tools to recognize, interpret, and critique statistical results in medical literature.</li>
</ul>
<div class="figure" style="text-align: center">
<img src="figs/probstat.jpg" alt="Probability vs. Statistics" width="95%" />
<p class="caption">
(#fig:unnamed-chunk-2)Probability vs. Statistics
</p>
</div>
</div>
<div id="using-r" class="section level2" number="1.2">
<h2 number="1.2"><span class="header-section-number">1.2</span> Using R</h2>
<p>Much work will be done in R using RStudio as a front end. You will need to either download R and RStudio (both are free) onto your own computer or use them on Pomona’s server.</p>
<ul>
<li><p>You may use R on the Pomona server: <a href="https://rstudio.campus.pomona.edu/" class="uri">https://rstudio.campus.pomona.edu/</a> (All Pomona students will be able to log in immediately. Non-Pomona students need to go to ITS at Pomona to get Pomona login information.)</p></li>
<li><p>If you want to use R on your own machine, you may. Please make sure all components are updated:
R is freely available at <a href="http://www.r-project.org/" class="uri">http://www.r-project.org/</a> and is already installed on college computers. Additionally, installing R Studio is required <a href="http://rstudio.org/" class="uri">http://rstudio.org/</a>.</p></li>
<li><p><a href="http://swirlstats.com/" class="uri">http://swirlstats.com/</a> is a great way to walk through learning the basics of R.</p></li>
<li><p>All computing assignments should be turned in using R Markdown compiled to pdf.</p></li>
</ul>
<div class="figure" style="text-align: center">
<img src="figs/RRstudio.jpg" alt="Taken from [Modern Drive: An introduction to statistical and data sciences via R](https://ismayc.github.io/moderndiver-book/), by Ismay and Kim" width="95%" />
<p class="caption">
(#fig:unnamed-chunk-3)Taken from <a href="https://ismayc.github.io/moderndiver-book/">Modern Drive: An introduction to statistical and data sciences via R</a>, by Ismay and Kim
</p>
</div>
<div class="figure" style="text-align: center">
<img src="figs/cookingRstudio.jpg" alt="[Jessica Ward](https://jkrward.github.io/), PhD student at Newcastle University" width="95%" />
<p class="caption">
(#fig:unnamed-chunk-4)<a href="https://jkrward.github.io/">Jessica Ward</a>, PhD student at Newcastle University
</p>
</div>
<div id="experimental-design" class="section level3 unnumbered">
<h3 class="unnumbered">Experimental Design</h3>
<p>In this class we’ll talk about techniques used to analyze data from medical studies. Along with the computational methods, however, we’ll continue to think about issues of experimental design and interpretation.</p>
<p><strong>Descriptive statistics</strong> describe the sample at hand with no intent on making generalizations.<br />
<strong>Inferential statistics</strong> use a sample to make claims about a population<br />
<strong>Simple Random Sample</strong> is an unbiased sample. Sample is selected in such a way that every possible sample of size <span class="math inline">\(n\)</span> is equally likely.<br />
<strong>Blind / double blind</strong> when the patient and/or doctor do not know which patient is receiving which treatment.<br />
<strong>Placebo</strong> mock treatment<br />
<strong>Sample size</strong> reduces variability (large samples make small effects easier to discern)<br />
<strong>Experiment vs. Observational Study</strong> whether the treatment was assigned by the researchers; randomized experiments make concluding causation possible<br />
<strong>Funding of study</strong> goals, bias</p>
<!--chapter:end:01-intro.Rmd-->
</div>
</div>
</div>
<div id="t-tests-vs-slr" class="section level1" number="2">
<h1 number="2"><span class="header-section-number">2</span> t-tests vs SLR</h1>
<p>We are going to build on a very basic model of the following form:</p>
<pre><code>data = deterministic model + random error</code></pre>
<p><strong>planned variability</strong> your experimental conditions, hopefully represented by an interesting deterministic model<br />
<strong>random error</strong> natural variability due to individuals.<br />
<strong>systematic error</strong> error that is not contained within the model. It can happen because of poor sampling or poor experimental conditions.</p>
<div id="surgery-timing" class="section level3 unnumbered">
<h3 class="unnumbered">Surgery Timing</h3>
<p>The study, “Operation Timing and 30-Day Mortality After Elective General Surgery,” tested the hypotheses that the risk of 30-day mortality associated with elective general surgery: 1) increases from morning to evening throughout the routine workday; 2) increases from Monday to Friday through the workweek; and 3) is more frequent in July and August than during other months of the year. As a presumed negative control, the investigators also evaluated mortality as a function of the phase of the moon. Secondarily, they evaluated these hypotheses as they pertain to a composite in-hospital morbidity endpoint.</p>
<p>The related data set contains 32,001 elective general surgical patients. Age, gender, race, BMI, several comorbidities, several surgical risk indices, the surgical timing predictors (hour, day of week, month,moon phase) and the outcomes (30-day mortality and in-hospital complication) are provided. The dataset is cleaned and complete (no missing data except for BMI). There are no outliers or data problems. The data are from <span class="citation">(<a href="#ref-Sessler2011" role="doc-biblioref">Sessler et al. 2011</a>)</span></p>
<p>Note that in the example, mortality rates are compared for patients electing to have surgery in July vs August. We’d like to compare the average age of the participants from the July group to the August group. Even if the mortality difference is significant, we can’t conclude causation because it was an observational study. However, the more similar the groups are based on clinical variables, the more likely any differences in mortality are due to timing. How different are the groups based on clinical variables?</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>surgeryurl <span class="ot">&lt;-</span> <span class="fu">url</span>(<span class="st">&quot;https://www.causeweb.org/tshs/datasets/surgery_timing.Rdata&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(surgeryurl)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>surgery <span class="ot">&lt;-</span> stata_data</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(surgery)  <span class="sc">%&gt;%</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(age, gender, race, hour, dow, month, complication, bmi, <span class="fu">everything</span>(), <span class="sc">-</span>ahrq_ccs) <span class="sc">%&gt;%</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>(<span class="at">caption =</span> <span class="st">&quot;Varibles associated with the surgery data.&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a> <span class="fu">kable_styling</span>()</span></code></pre></div>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
(#tab:unnamed-chunk-2)Varibles associated with the surgery data.
</caption>
<thead>
<tr>
<th style="text-align:right;">
age
</th>
<th style="text-align:left;">
gender
</th>
<th style="text-align:left;">
race
</th>
<th style="text-align:right;">
hour
</th>
<th style="text-align:left;">
dow
</th>
<th style="text-align:left;">
month
</th>
<th style="text-align:left;">
complication
</th>
<th style="text-align:right;">
bmi
</th>
<th style="text-align:left;">
asa_status
</th>
<th style="text-align:left;">
baseline_cancer
</th>
<th style="text-align:left;">
baseline_cvd
</th>
<th style="text-align:left;">
baseline_dementia
</th>
<th style="text-align:left;">
baseline_diabetes
</th>
<th style="text-align:left;">
baseline_digestive
</th>
<th style="text-align:left;">
baseline_osteoart
</th>
<th style="text-align:left;">
baseline_psych
</th>
<th style="text-align:left;">
baseline_pulmonary
</th>
<th style="text-align:right;">
baseline_charlson
</th>
<th style="text-align:right;">
mortality_rsi
</th>
<th style="text-align:right;">
complication_rsi
</th>
<th style="text-align:right;">
ccsmort30rate
</th>
<th style="text-align:right;">
ccscomplicationrate
</th>
<th style="text-align:left;">
moonphase
</th>
<th style="text-align:left;">
mort30
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
67.8
</td>
<td style="text-align:left;">
M
</td>
<td style="text-align:left;">
Caucasian
</td>
<td style="text-align:right;">
9.03
</td>
<td style="text-align:left;">
Mon
</td>
<td style="text-align:left;">
Nov
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
28.0
</td>
<td style="text-align:left;">
I-II
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.63
</td>
<td style="text-align:right;">
-0.26
</td>
<td style="text-align:right;">
0.004
</td>
<td style="text-align:right;">
0.072
</td>
<td style="text-align:left;">
Full Moon
</td>
<td style="text-align:left;">
No
</td>
</tr>
<tr>
<td style="text-align:right;">
39.5
</td>
<td style="text-align:left;">
F
</td>
<td style="text-align:left;">
Caucasian
</td>
<td style="text-align:right;">
18.48
</td>
<td style="text-align:left;">
Wed
</td>
<td style="text-align:left;">
Sep
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
37.9
</td>
<td style="text-align:left;">
I-II
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.63
</td>
<td style="text-align:right;">
-0.26
</td>
<td style="text-align:right;">
0.004
</td>
<td style="text-align:right;">
0.072
</td>
<td style="text-align:left;">
New Moon
</td>
<td style="text-align:left;">
No
</td>
</tr>
<tr>
<td style="text-align:right;">
56.5
</td>
<td style="text-align:left;">
F
</td>
<td style="text-align:left;">
Caucasian
</td>
<td style="text-align:right;">
7.88
</td>
<td style="text-align:left;">
Fri
</td>
<td style="text-align:left;">
Aug
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
19.6
</td>
<td style="text-align:left;">
I-II
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.49
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.004
</td>
<td style="text-align:right;">
0.072
</td>
<td style="text-align:left;">
Full Moon
</td>
<td style="text-align:left;">
No
</td>
</tr>
<tr>
<td style="text-align:right;">
71.0
</td>
<td style="text-align:left;">
M
</td>
<td style="text-align:left;">
Caucasian
</td>
<td style="text-align:right;">
8.80
</td>
<td style="text-align:left;">
Wed
</td>
<td style="text-align:left;">
Jun
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
32.2
</td>
<td style="text-align:left;">
III
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-1.38
</td>
<td style="text-align:right;">
-1.15
</td>
<td style="text-align:right;">
0.004
</td>
<td style="text-align:right;">
0.072
</td>
<td style="text-align:left;">
Last Quarter
</td>
<td style="text-align:left;">
No
</td>
</tr>
<tr>
<td style="text-align:right;">
56.3
</td>
<td style="text-align:left;">
M
</td>
<td style="text-align:left;">
African American
</td>
<td style="text-align:right;">
12.20
</td>
<td style="text-align:left;">
Thu
</td>
<td style="text-align:left;">
Aug
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
24.3
</td>
<td style="text-align:left;">
I-II
</td>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.004
</td>
<td style="text-align:right;">
0.072
</td>
<td style="text-align:left;">
Last Quarter
</td>
<td style="text-align:left;">
No
</td>
</tr>
<tr>
<td style="text-align:right;">
57.7
</td>
<td style="text-align:left;">
F
</td>
<td style="text-align:left;">
Caucasian
</td>
<td style="text-align:right;">
7.67
</td>
<td style="text-align:left;">
Thu
</td>
<td style="text-align:left;">
Dec
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
40.3
</td>
<td style="text-align:left;">
I-II
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:left;">
Yes
</td>
<td style="text-align:left;">
No
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.77
</td>
<td style="text-align:right;">
-0.84
</td>
<td style="text-align:right;">
0.004
</td>
<td style="text-align:right;">
0.072
</td>
<td style="text-align:left;">
First Quarter
</td>
<td style="text-align:left;">
No
</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>surgery <span class="sc">%&gt;%</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a> dplyr<span class="sc">::</span><span class="fu">filter</span>(month <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Jul&quot;</span>, <span class="st">&quot;Aug&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a> dplyr<span class="sc">::</span><span class="fu">group_by</span>(month) <span class="sc">%&gt;%</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a> dplyr<span class="sc">::</span><span class="fu">summarize</span>(<span class="at">agemean =</span> <span class="fu">mean</span>(age, <span class="at">na.rm=</span><span class="cn">TRUE</span>), <span class="at">agesd =</span> <span class="fu">sd</span>(age, <span class="at">na.rm=</span><span class="cn">TRUE</span>), <span class="at">agen =</span> <span class="fu">sum</span>(<span class="sc">!</span><span class="fu">is.na</span>(age)))</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 4</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   month agemean agesd  agen</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 Aug      58.1  15.2  3176</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 Jul      57.6  15.5  2325</span></span></code></pre></div>
</div>
<div id="ttest" class="section level2" number="2.1">
<h2 number="2.1"><span class="header-section-number">2.1</span> t-test</h2>
<p>(Section 2.1 in <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>.)</p>
<p>A t-test is a test of means. For the surgery timing data, the groups would ideally have similar age distributions. Why? What are the advantages and disadvantages of running a retrospective cohort study?</p>
<p>The two-sample t-test starts with the assumption that the population means of the two groups are equal, <span class="math inline">\(H_0: \mu_1 = \mu_2\)</span>. The sample means <span class="math inline">\(\overline{y}_1\)</span> and <span class="math inline">\(\overline{y}_2\)</span> will always be different. How different must the <span class="math inline">\(\overline{y}\)</span> values be in order to reject the null hypothesis?</p>
<div id="model-1" class="section level5 unnumbered">
<h5 class="unnumbered">Model 1:</h5>
<p><span class="math display">\[\begin{align}
y_{1j} &amp;= \mu_{1} + \epsilon_{1j} \ \ \ \ j=1, 2, \ldots, n_1\\
y_{2j} &amp;= \mu_{2} + \epsilon_{2j} \ \ \ \ j=1, 2, \ldots, n_2\\
\epsilon_{ij} &amp;\sim N(0,\sigma^2)\\
E[Y_i] &amp;= \mu_i
\end{align}\]</span></p>
<p>That is, we are assuming that for each group the true population <em>average</em> is fixed and an individual that is randomly selected will have some amount of <em>random error</em> away from the true population mean. Note that we have assumed that the variances of the two groups are equal. We have also assumed that there is independence between and within the groups.</p>
<p>Note: we will assume the <em>population variances</em> are equal if neither <em>sample variance</em> is more than twice as big as the other.</p>
<div class="example">
<p><span id="exm:unlabeled-div-1" class="example"><strong>(#exm:unlabeled-div-1) </strong></span>Are the mean ages of the July vs August patients statistically different? (why two sided?)</p>
<p><span class="math display">\[\begin{align}
H_0: \mu_1 = \mu_2\\
H_1: \mu_1 \ne \mu_2
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
t &amp;= \frac{(\overline{y}_1 - \overline{y}_2) - 0}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}\\
s_p &amp;= \sqrt{ \frac{(n_1 - 1)s_1^2 + (n_2-1) s_2^2}{n_1 + n_2 -2}}\\
df &amp;= n_1 + n_2 -2\\
&amp;\\
t &amp;= \frac{(58.05 - 57.57) - 0}{15.34 \sqrt{\frac{1}{3176} + \frac{1}{2325}}}\\
&amp;= 1.15\\  
s_p &amp;= \sqrt{ \frac{(3176-1)15.22^2 + (2325-1) 15.5^2}{3176 + 2325 -2}}\\
&amp;= 15.34\\
df &amp;= n_1 + n_2 -2\\
&amp;= 5499\\
\mbox{p-value} &amp;= 2 \cdot (1-pt(1.15,5499)) = 0.25\\
\end{align}\]</span></p>
</div>
<p>The same analysis can be done in R (with and without tidying the output):</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>surgery <span class="sc">%&gt;%</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(month <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Jul&quot;</span>, <span class="st">&quot;Aug&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">t.test</span>(age <span class="sc">~</span> month, <span class="at">data =</span> .)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Welch Two Sample t-test</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; data:  age by month</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; t = 1, df = 4954, p-value = 0.2</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; alternative hypothesis: true difference in means is not equal to 0</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 95 percent confidence interval:</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  -0.337  1.309</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; sample estimates:</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; mean in group Aug mean in group Jul </span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;              58.1              57.6</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>surgery <span class="sc">%&gt;%</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(month <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Jul&quot;</span>, <span class="st">&quot;Aug&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">t.test</span>(age <span class="sc">~</span> month, <span class="at">data =</span> .) <span class="sc">%&gt;%</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>()</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 10</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1    0.486      58.1      57.6      1.16   0.247     4954.   -0.337      1.31</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;</span></span></code></pre></div>
<ul>
<li>Look at SD and SEM</li>
<li>What is the statistic? What is the sampling distribution of the statistic?</li>
<li>Why do we use the t-distribution?</li>
<li>Why is the big p-value important? (It’s a good thing!) How do we interpret the p-value?</li>
<li>What can we conclude?</li>
<li>applet from <span class="citation">(<a href="#ref-iscam" role="doc-biblioref">Chance and Rossman 2018</a>)</span>: [<a href="http://www.rossmanchance.com/applets/2021/sampling/OneSample.html" class="uri">http://www.rossmanchance.com/applets/2021/sampling/OneSample.html</a>]</li>
<li>What are the model assumptions? (basically all the assumptions are given in the original linear model: independence between &amp; within groups, random sample, pop values don’t change, additive error, <span class="math inline">\(\epsilon_{i,j} \ \sim \ iid \  N(0, \sigma^2))\)</span></li>
</ul>
<p>Considerations when running a t-test:</p>
<ul>
<li>one-sample vs two-sample t-test<br />
</li>
<li>one-sided vs. two-sided hypotheses<br />
</li>
<li>t-test with unequal variance (less powerful, more conservative)<br />
<span class="math display">\[\begin{align}
t &amp;= \frac{(\overline{y}_1 - \overline{y}_2) - (\mu_1 - \mu_2)}{ \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}\\
df &amp;= \min(n_1-1, n_2-1)\\
\end{align}\]</span></li>
<li>two dependent (paired) samples – one sample t-test!</li>
</ul>
<div class="example">
<p><span id="exm:unlabeled-div-2" class="example"><strong>(#exm:unlabeled-div-2) </strong></span>Assume we have two very small <strong>samples</strong>: <span class="math inline">\((y_{11}=3, y_{12} = 9, y_{21} = 5, y_{22}=1, y_{23}=9).\)</span> Find <span class="math inline">\(\hat{\mu}_1, \hat{\mu}_2, \hat{\epsilon}_{11}, \hat{\epsilon}_{12}, \hat{\epsilon}_{21}, \hat{\epsilon}_{22}, \hat{\epsilon}_{23}, n_1, n_2\)</span>.</p>
</div>
</div>
<div id="what-is-an-alternative-hypothesis" class="section level3" number="2.1.1">
<h3 number="2.1.1"><span class="header-section-number">2.1.1</span> What is an Alternative Hypothesis?</h3>
<p>Consider the brief video from the movie Slacker, an early movie by Richard Linklater (director of Boyhood, School of Rock, Before Sunrise, etc.). You can view the video here from starting at 2:22 and ending at 4:30: [<a href="https://www.youtube.com/watch?v=b-U_I1DCGEY" class="uri">https://www.youtube.com/watch?v=b-U_I1DCGEY</a>]</p>
<p>In the video, a rider in the back of a taxi (played by Linklater himself) muses about alternate realities that could have happened as he arrived in Austin on the bus. What if instead of taking a taxi, he had found a ride with a woman at the bus station? He could have take a different road into a different alternate reality, and in that reality his current reality would be an alternate reality. And so on.</p>
<p>What is the point? Why watch the video? How does it relate the to the material from class? What is the relationship to sampling distributions? [Thanks to Ben Baumer at Smith College for the pointer to the specific video.]</p>
</div>
</div>
<div id="anova" class="section level2 unnumbered">
<h2 class="unnumbered">ANOVA</h2>
<p>Skip ANOVA in your text (2.4 and part of 2.9 in <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>).</p>
</div>
<div id="tslr" class="section level2" number="2.2">
<h2 number="2.2"><span class="header-section-number">2.2</span> Simple Linear Regression</h2>
<p>(Section 2.3 in <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>.)</p>
<p>Simple Linear Regression is a model (hopefully discussed in introductory statistics) used for describing a {linear} relationship between two variables. It typically has the form of:</p>
<p><span class="math display">\[\begin{align}
y_i &amp;= \beta_0 + \beta_1 x_i + \epsilon_i  \ \ \ \ i = 1, 2, \ldots, n\\
\epsilon_i &amp;\sim N(0, \sigma^2)\\
E(Y|x) &amp;= \beta_0 + \beta_1 x
\end{align}\]</span></p>
<p>For this model, the deterministic component (<span class="math inline">\(\beta_0 + \beta_1 x\)</span>) is a linear function of the two parameters, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, and the explanatory variable <span class="math inline">\(x\)</span>. <strong>The random error terms, <span class="math inline">\(\epsilon_i\)</span>, are assumed to be independent and to follow a normal distribution with mean 0 and variance <span class="math inline">\(\sigma^2\)</span>.</strong></p>
<p>How can we use this model to describe the two sample means case we discussed on the esophageal data? Consider <span class="math inline">\(x\)</span> to be a dummy variable that takes on the <strong>value 0 if the observation is a control and 1 if the observation is a case</strong>. Assume we have <span class="math inline">\(n_1\)</span> controls and <span class="math inline">\(n_2\)</span> cases. It turns out that, coded in this way, the regression model and the two-sample t-test model are mathematically equivalent!</p>
<p>(For the color game in the text, the natural way to code is 1 for the color distracter and 0 for the standard game. Why? What does <span class="math inline">\(\beta_0\)</span> represent? What does <span class="math inline">\(\beta_1\)</span> represent?)</p>
<p><span class="math display">\[\begin{align}
\mu_1 &amp;= \beta_0 + \beta_1 (0) = \beta_0 \\
\mu_2 &amp;= \beta_0 +  \beta_1 (1) = \beta_0 + \beta_1\\
\mu_2 - \mu_1 &amp;= \beta_1
\end{align}\]</span></p>
<div id="why-are-they-the-same" class="section level3 unnumbered">
<h3 class="unnumbered">Why are they the same?</h3>
<p><span class="math display">\[\begin{align}
b_1= \hat{\beta}_1 &amp;= \frac{n \sum x_i y_i - \sum x_i \sum y_i}{n \sum x_i^2 - (\sum x_i )^2}\\
&amp;= \frac{n \sum_2 y_i - n_2 \sum y_i}{(n n_2-n_2^2)}\\
&amp;= \frac{ n \sum_2 y_i - n_2 (\sum_1 y_i + \sum_2 y_i)}{n_2(n-n_2)}\\
&amp;= \frac{(n_1 + n_2) \sum_2 y_i - n_2 \sum_1 y_i - n_2 \sum_2 y_i}{n_1 n_2}\\
&amp;= \frac{n_1 \sum_2 y_i - n_2 \sum_1 y_i}{n_1 n_2}\\
&amp;= \frac{n_1 n_2 \overline{y}_2 - n_2 n_1 \overline{y}_1}{n_1 n_2}\\
&amp;= \overline{y}_2 - \overline{y}_1\\
b_0 = \hat{\beta}_0 &amp;= \frac{\sum y_i - b_1 \sum x_i}{n}\\
&amp;= \frac{\sum_1 y_i + \sum_2 y_i - b_1 n_2}{n}\\
&amp;= \frac{n_1 \overline{y}_1 + n_2 \overline{y}_2 - n_2 \overline{y}_2 + n_2 \overline{y}_1}{n}\\
&amp;= \frac{n \overline{y}_1 + n_2 \overline{y}_2 - n_2 \overline{y}_2 + n_2 \overline{y}_1}{n}\\
&amp;= \frac{n \overline{y}_1}{n} = \overline{y}_1
\end{align}\]</span></p>
<div id="model-2" class="section level5 unnumbered">
<h5 class="unnumbered">Model 2:</h5>
<p><span class="math display">\[\begin{align}
y_{i} &amp;= \beta_0 + \beta_1 x_i + \epsilon_i \ \ \ \ i=1, 2, \ldots, n\\
\epsilon_{i} &amp;\sim N(0,\sigma^2)\\
E[Y_i] &amp;= \beta_0 + \beta_1 x_i\\
\hat{y}_i &amp;= b_0 + b_1 x_i
\end{align}\]</span></p>
<p>That is, we are assuming that for each observation the true population <em>average</em> is fixed and an individual that is randomly selected will have some amount of <em>random error</em> away from the true population mean at their value for the explanatory variable, <span class="math inline">\(x_i\)</span>. Note that we have assumed that the variance is constant across any level of the explanatory variable. We have also assumed that there is independence across individuals. <strong>[Note: there are no assumptions about the distribution of the explanatory variable, <span class="math inline">\(X\)</span>]</strong>.</p>
<p>Note the similarity in running a <code>t.test()</code> and a linear model (<code>lm()</code>):</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>surgery <span class="sc">%&gt;%</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(month <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Jul&quot;</span>, <span class="st">&quot;Aug&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">t.test</span>(age <span class="sc">~</span> month, <span class="at">data =</span> .) <span class="sc">%&gt;%</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 10</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1    0.486      58.1      57.6      1.16   0.247     4954.   -0.337      1.31</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>surgery <span class="sc">%&gt;%</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">filter</span>(month <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Jul&quot;</span>, <span class="st">&quot;Aug&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lm</span>(age <span class="sc">~</span> month, <span class="at">data =</span> .) <span class="sc">%&gt;%</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>()</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic p.value</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   58.1       0.272    213.     0    </span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 monthJul      -0.486     0.419     -1.16   0.245</span></span></code></pre></div>
<ul>
<li>What are the similarities in the t-test vs. SLR models?
<ul>
<li>predicting average</li>
<li>assuming independent, constant errors</li>
<li>errors follow a normal distribution with zero mean and variance <span class="math inline">\(\sigma^2\)</span></li>
</ul></li>
<li>What are the differences in the two models?
<ul>
<li>one subscript versus two (or similarly, two models for the t-test)</li>
<li>two samples for the t-test (two variables for the regression… or is that a similarity??)</li>
<li>both variables are quantitative in SLR</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="confidence-intervals" class="section level2" number="2.3">
<h2 number="2.3"><span class="header-section-number">2.3</span> Confidence Intervals</h2>
<p>(Section 2.11 in <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>.)</p>
<p>A fantastic applet for visualizing what it means to have 95% confidence: [<a href="http://www.rossmanchance.com/applets/2021/confsim/ConfSim.html" class="uri">http://www.rossmanchance.com/applets/2021/confsim/ConfSim.html</a>]</p>
<p>In general, the format of a confidence interval is give below… what is the interpretation? Remember, the interval is for a given parameter and the “coverage” happens in alternative universes with repeated sampling. We’re 95% confident that the interval captures the parameter.</p>
<pre><code>estimate +/- critical value x standard error of the estimate</code></pre>
<p>Age data:
<span class="math display">\[\begin{align}
90\% \mbox{ CI for } \mu_1: &amp; \overline{y}_1 \pm t^*_{3176-1} \times \hat{\sigma}_{\overline{y}_1}\\
&amp; 58.05 \pm 1.645 \times 15.22/\sqrt{3176}\\
&amp; (57.61, 58.49)\\
95\% \mbox{ CI for }\mu_1 - \mu_2: &amp; \overline{y}_1 - \overline{y}_2 \pm t^*_{5499} s_p \sqrt{1/n_1 + 1/n_2}\\
&amp; 0.48 \pm 1.96 \times 0.42\\
&amp; (-0.34, 1.30)
\end{align}\]</span></p>
<p>Note the CI on pgs 54/55, there is a typo. The correct interval for <span class="math inline">\(\mu_1 - \mu_2\)</span> for the games data should be:</p>
<p><span class="math display">\[\begin{align}
95\% \mbox{ CI for } \mu_1 - \mu_2: &amp; \overline{y}_1 - \overline{y}_2 \pm t^*_{38} \hat{\sigma}_{\overline{y}_1 - \overline{y}_2}\\
&amp; \overline{y}_1 - \overline{y}_2 \pm t^*_{38} s_p \sqrt{1/n_1 + 1/n_2}\\
&amp; 38.1 - 35.55 \pm 2.02 \times \sqrt{\frac{(19)3.65^2 + (19)3.39^2}{20+20-2}} \sqrt{\frac{1}{20} + \frac{1}{20}}\\
&amp; (0.29 s, 4.81 s)
\end{align}\]</span></p>
</div>
<div id="random-sample-vs.-random-allocation" class="section level2" number="2.4">
<h2 number="2.4"><span class="header-section-number">2.4</span> Random Sample vs. Random allocation</h2>
<p>Recall what you’ve learned about how good random samples lead to inference about a population. On the other hand, in order to make a causal conclusion, you need a randomized experiment with random allocation of the treatments (impossible to happen in many settings). Random sampling and random allocation are DIFFERENT ideas that should be clear in your mind.</p>
<div class="figure" style="text-align: center">
<img src="figs/randsampValloc.jpg" alt="Figure taken from [@iscam]" width="95%" />
<p class="caption">
(#fig:unnamed-chunk-6)Figure taken from <span class="citation">(<a href="#ref-iscam" role="doc-biblioref">Chance and Rossman 2018</a>)</span>
</p>
</div>
<p>Note: no ANOVA (section 2.4 in <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>) or normal probability plots (section 2.8 in <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>).</p>
<!--chapter:end:02-ttest.Rmd-->
</div>
</div>
<div id="SLR" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> Simple Linear Regression</h1>
<p>Though we’ve discussed the relationship between tests of means and simple linear regression, we will really consider simple linear regression in a much broader context (one where both the explanatory and response variables are quantitative).</p>
<p>The data below represents 10 different variables on health of a country measured on 143 countries. Data taken from <span class="citation">(<a href="#ref-Lock5" role="doc-biblioref">Lock et al. 2016</a>)</span>, originally from the Happy Planet Index Project [<a href="http://www.happyplanetindex.org/" class="uri">http://www.happyplanetindex.org/</a>]. Region of the world is coded as 1 = Latin America, 2 = Western nations, 3 = Middle East, 4 = Sub-Saharan Africa, 5 = South Asia, 6 = East Asia, 7 = former Communist countries. We are going to investigate happiness and life expectancy.</p>
<div id="inference-on-the-linear-model" class="section level2" number="3.1">
<h2 number="3.1"><span class="header-section-number">3.1</span> Inference on the Linear Model</h2>
<p>In order to make an inferential claims on a linear regression model (e.g., p-values on hypotheses about coefficients, confidence intervals for coefficients, confidence interval for the line, prediction interval for the points, …), we have a set of technical conditions that provide the mathematical structure leading to the t-procedures (e.g., t-test). A course more focused on linear regression would spend time discussing how robust the model is to various deviations from the following technical conditions. For now, we will say that sometimes transformations of either the explanatory or response variables can be an effective way to mitigate deviations from the model.</p>
<p>As with any measurement of the data / population, regression models are built from either statistics (Roman letters to describe a sample) or parameters (Greek letters to describe a population). For linear regression, we have one additional differentiation due to whether the observed values (<span class="math inline">\(y_i\)</span>) or the average values (<span class="math inline">\(\hat{y}_i\)</span> or <span class="math inline">\(E[Y_i]\)</span>) are being modeled.</p>
<p><span class="math display">\[\begin{eqnarray*}
E[Y_i|x_i] &amp;=&amp; \beta_0 + \beta_1 x_i \\
y_i &amp;=&amp; \beta_0 + \beta_1 x_i + \epsilon_i\\
&amp;&amp; \epsilon_i = y_i -  (\beta_0 + \beta_1 x_i)\\
\hat{y}_i &amp;=&amp; b_0 + b_1 x_i\\
y_i &amp;=&amp; b_0 + b_1 x_i + e_i\\
&amp;&amp; e_i = y_i - \hat{y}_i = y_i -  (b_0 + b_1 x_i)\\
\end{eqnarray*}\]</span></p>
<div id="technical-conditions" class="section level3" number="3.1.1">
<h3 number="3.1.1"><span class="header-section-number">3.1.1</span> Technical Conditions</h3>
<ul>
<li>The average value for the response variable is a linear function of the explanatory variable.</li>
<li>The error terms follow a normal distribution around the linear model.</li>
<li>The error terms have a mean of zero.</li>
<li>The error terms have a constant variance of <span class="math inline">\(\sigma^2\)</span>.</li>
<li>The error terms are independent (and identically distributed).</li>
<li>[<a href="http://www.rossmanchance.com/applets/2021/regshuffle/regshuffle.htm" class="uri">http://www.rossmanchance.com/applets/2021/regshuffle/regshuffle.htm</a>]</li>
</ul>
<p>How do we tell whether the assumptions are met? We can’t always. But it’s good to look at plots: scatter plot, residual plot, histograms of residuals. We denote the residuals for this model as:</p>
<p><span class="math display">\[\begin{align}
r_i = \hat{e}_i = y_i - \hat{y}_i
\end{align}\]</span></p>
<div class="figure" style="text-align: center">
<img src="figs/transfor.jpg" alt="Figs 3.13 and 3.15 taken from @kutner." width="95%" />
<p class="caption">
(#fig:unnamed-chunk-2)Figs 3.13 and 3.15 taken from <span class="citation"><a href="#ref-kutner" role="doc-biblioref">Kutner et al.</a> (<a href="#ref-kutner" role="doc-biblioref">2004</a>)</span>.
</p>
</div>
<p><strong>important note!!</strong> The idea behind transformations is to make the model as appropriate as possible for the data at hand. We want to find the correct <strong>linear</strong> model; we want our assumptions to hold. We are not trying to find the most <em>significant</em> model or big <span class="math inline">\(R^2\)</span>.</p>
<p>See section 2.9 in <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>. No normal probability plots (qq-plots); use histograms or boxplots to assess the symmetry and normality of the residuals.</p>
</div>
</div>
<div id="fitting-the-regression-line" class="section level2" number="3.2">
<h2 number="3.2"><span class="header-section-number">3.2</span> Fitting the regression line</h2>
<p>How do we fit a regression line? Find <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> that minimize the sum of squared distance of the points to the line (called ordinary least squares):</p>
<p><span class="math display">\[\begin{align}
\min \sum (y_i \hat{y}_i)^2 &amp;= \min RSS \mbox{ residual sum of squares}\\
RSS &amp;= \sum (y_i - b_0 - b_1 x_i)^2\\
\frac{\partial RSS}{\partial b_0} &amp;= 0\\
\frac{\partial RSS}{\partial b_1} &amp;= 0\\
b_0 &amp;= \overline{y} - b_1 \overline{x}\\
b_1 &amp;= r(x,y) \frac{s_x}{s_y}\\
\end{align}\]</span></p>
<ul>
<li>Is that the only way to find values for <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>? (absolute distances, maximum likelihood,…)</li>
<li>Resistance to outliers?</li>
<li>What is <span class="math inline">\(\hat{y}\)</span> at <span class="math inline">\(\overline{x}\)</span>?</li>
</ul>
<p><span class="math display">\[\begin{align}
\hat{y} &amp;= b_0 + b_1 \overline{x}\\
&amp;= \overline{y} - b_1 \overline{x} + b_1 \overline{x}\\
&amp;= \overline{y}
\end{align}\]</span></p>
<p>The regression line will always pass through the point <span class="math inline">\((\overline{x}, \overline{y})\)</span>.</p>
<div class="definition">
<p><span id="def:unlabeled-div-3" class="definition"><strong>(#def:unlabeled-div-3) </strong></span>An estimate is <em>unbiased</em> if, over many repeated samples drawn from the population, the average value of the estimates based on the different samples would equal the population value of the parameter being estimated. That is, a statistic is unbiased if the mean of its sampling distribution is the population parameter.</p>
</div>
</div>
<div id="correlation" class="section level2" number="3.3">
<h2 number="3.3"><span class="header-section-number">3.3</span> Correlation</h2>
<p>Consider a scatterplot, you’ll have variability in both directions: <span class="math inline">\((x_i - \overline{x}) \&amp; (y_i - \overline{y})\)</span>.</p>
<p><span class="math display">\[\begin{align}
\mbox{sample covariance}&amp;\\
cov(x,y) &amp;= \frac{1}{n-1}\sum (x_i - \overline{x}) (y_i - \overline{y})\\
\mbox{sample correlation}&amp;\\
r(x,y) &amp;= \frac{cov(x,y)}{s_x s_y}\\
&amp;= \frac{\frac{1}{n-1} \sum (x_i - \overline{x}) (y_i - \overline{y})}{\sqrt{\frac{\sum(x_i - \overline{x})^2}{n-1} \frac{\sum(y_i - \overline{y})^2}{n-1}}}\\
\mbox{pop cov} &amp;= \sigma_{xy}\\
\mbox{pop cor} &amp;= \rho = \frac{\sigma_{xy}}{\sigma_x \sigma_y}\\
\end{align}\]</span></p>
<ul>
<li><span class="math inline">\(-1 \leq r \leq 1 \ \ \ \ \ \&amp; \ \ \ -1 \leq \rho \leq 1\)</span>.<br />
</li>
<li>No Spearman’s rank correlation or Kendall’s <span class="math inline">\(\tau\)</span>.<br />
</li>
<li><span class="math inline">\(b_1 = r \frac{s_y}{s_x}\)</span>
<ul>
<li>if <span class="math inline">\(r=0, b_1=0\)</span><br />
</li>
<li>if <span class="math inline">\(r=1, b_1 &gt; 0\)</span> but can be anything!<br />
</li>
<li><span class="math inline">\(r &lt; 0 \leftrightarrow b_1 &lt; 0, r &gt; 0 \leftrightarrow b_1 &gt; 0\)</span><br />
</li>
</ul></li>
<li>Recall that <span class="math inline">\(R^2\)</span> is the proportion of variability explained by the line.</li>
</ul>
</div>
<div id="errors-residuals" class="section level2" number="3.4">
<h2 number="3.4"><span class="header-section-number">3.4</span> Errors / Residuals</h2>
<p>Recall, part of the technical conditions required that <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2)\)</span>. How do we estimate <span class="math inline">\(\sigma^2\)</span>?</p>
<p><span class="math display">\[\begin{align}
RSS &amp;= \sum (y_i - \hat{y}_i)^2 \ \ \ \mbox{ residual sum of squares}\\
MSS &amp;= \sum (\hat{y}_i - \overline{y})^2 \ \ \ \mbox{ model sum of squares}\\
TSS &amp;= \sum (y_i - \overline{y})^2 \ \ \ \mbox{ total sum of squares}\\
s_{y|x}^2 &amp;= \hat{\sigma^2} = \frac{1}{n-2} RSS\\
s_x^2 &amp;= \frac{1}{n-1} \sum (x_i - \overline{x})^2\\
s_y^2 &amp;= \frac{1}{n-1} \sum (y_i - \overline{y})^2\\
var(\epsilon) &amp;= s_{y|x}^2 = \frac{RSS}{n-2} = \frac{\sum(y_i - \hat{y}_i)^2}{n-2} = SE(\epsilon)\\
var(b_1) &amp;= \frac{s_{y|x}^2}{(n-1) s_x^2}\\
SE(b_1) &amp;= \frac{s_{y|x}}{\sqrt{(n-1)} s_x}\\
&amp;= \frac{\hat{\sigma}}{\sqrt{\sum(x_i - \overline{x})^2}} = \frac{\sqrt{\sum(y_i - \hat{y}_i)^2/(n-2)}}{\sqrt{\sum(x_i - \overline{x})^2}}\\
\end{align}\]</span></p>
<ul>
<li><span class="math inline">\(SE(b_1) \downarrow\)</span> as <span class="math inline">\(\sigma \downarrow\)</span></li>
<li><span class="math inline">\(SE(b_1) \downarrow\)</span> as <span class="math inline">\(n \uparrow\)</span></li>
<li><span class="math inline">\(SE(b_1) \downarrow\)</span> as <span class="math inline">\(s_x \uparrow\)</span></li>
<li>WHY?</li>
<li>What do we mean by <span class="math inline">\(SE(b_1)\)</span>?</li>
</ul>
<p>As we saw above, the correlation and the slope estimates are intimately related. They are also both related to the <em>coefficient of determination</em>.
<span class="math display">\[\begin{align}
R^2 = r^2 = \frac{MSS}{TSS}
\end{align}\]</span></p>
<p><span class="math inline">\(R^2\)</span> is the proportion of total variability explained by the regression line (the linear relationship between the explanatory and response variables).</p>
<ul>
<li>If <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are not at all correlated, <span class="math inline">\(\hat{y}_i \approx \overline{y}\)</span>, MSS = 0, <span class="math inline">\(R^2=0\)</span>.</li>
<li>If <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are perfectly correlated, <span class="math inline">\(\hat{y}_i = y_i\)</span>, MSS=TSS, <span class="math inline">\(R^2 = 1\)</span>.</li>
</ul>
<div id="testing-beta_1" class="section level3" number="3.4.1">
<h3 number="3.4.1"><span class="header-section-number">3.4.1</span> Testing <span class="math inline">\(\beta_1\)</span></h3>
<p>If the technical conditions hold, the mathematics describing the sampling distribution of <span class="math inline">\(b_1\)</span> are well defined. That is:</p>
<p>If <span class="math inline">\(H_0: \beta=0\)</span> is true, then
<span class="math display">\[\begin{align}
\frac{b_1 - 0}{SE(b_1)} \sim t_{n-2}
\end{align}\]</span>
Note that the degrees of freedom are now <span class="math inline">\(n-2\)</span> because we are estimating two parameters (<span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>). We can also find a <span class="math inline">\((1-\alpha)100\%\)</span> confidence interval for <span class="math inline">\(\beta_1\)</span>:
<span class="math display">\[\begin{align}
b_1 \pm t_{\alpha/2, n-2} SE(b_1)
\end{align}\]</span></p>
</div>
</div>
<div id="intervals" class="section level2" number="3.5">
<h2 number="3.5"><span class="header-section-number">3.5</span> Intervals</h2>
<p>As with anything that has some type of standard error, we can create intervals that give us some confidence in the statements we are making.</p>
<div id="confidence-intervals-1" class="section level3" number="3.5.1">
<h3 number="3.5.1"><span class="header-section-number">3.5.1</span> Confidence Intervals</h3>
<p>In general, confidence intervals are of the form:</p>
<pre><code>point estimate +/- multiplier * SE(point estimate)</code></pre>
</div>
<div id="slope" class="section level3" number="3.5.2">
<h3 number="3.5.2"><span class="header-section-number">3.5.2</span> Slope</h3>
<p>We can create a CI for the slope parameter, <span class="math inline">\(\beta_1\)</span>:
<span class="math display">\[\begin{align}
b_1 &amp;\pm t_{\alpha/2,n-2} SE(b_1)\\
b_1 &amp;\pm t_{\alpha/2, n-2} \frac{s_{y|x}}{\sqrt{(n-1)}s_x}\\
6.693 &amp;\pm t_{.025, 141} 0.375\\
t_{.025,141} &amp;= qt(0.025, 141) = -1.977\\
\mbox{CI} &amp; (5.95 \mbox{ years/unit of happy}, 7.43 \mbox{ years/unit of happy})
\end{align}\]</span>
How can we interpret the CI? Does it make sense to talk about a unit of happiness?</p>
</div>
<div id="mean-response" class="section level3" number="3.5.3">
<h3 number="3.5.3"><span class="header-section-number">3.5.3</span> Mean Response</h3>
<p>We can also create a CI for the mean response, <span class="math inline">\(E[Y|x^*] = \beta_0 + \beta_1 x^*\)</span>. Note that the standard error of the point estimate (<span class="math inline">\(\hat{y}=b_0 + b_1 x^*\)</span>) now depends on the variability associated with two things (<span class="math inline">\(b_0, b_1\)</span>).
<span class="math display">\[\begin{align}
SE(\hat{y(x^*)}) &amp;= \sqrt{ \frac{s^2_{y|x}}{n} + (x^* - \overline{x})^2 SE(b_1)^2}\\
SE(\hat{y}(\overline{x})) &amp;= s_{y|x}/\sqrt{n}\\
SE(\hat{y}(x)) &amp;\geq s_{y|x}/\sqrt{n} \ \ \ \forall x
\end{align}\]</span>
How would you interpret the associated interval?</p>
</div>
<div id="prediction-of-an-individual-response" class="section level3" number="3.5.4">
<h3 number="3.5.4"><span class="header-section-number">3.5.4</span> Prediction of an Individual Response</h3>
<p>As should be obvious, predicting an individual is more variable than predicting a mean.</p>
<p><span class="math display">\[\begin{align}
SE(y(x^*)) &amp;= \sqrt{ \frac{s^2_{y|x}}{n} + (x^* - \overline{x})^2 SE(b_1)^2 + s^2_{y|x}}\\
SE(y(x^*)) &amp;= \sqrt{ SE(\hat{y}(x^*))^2 + s^2_{y|x}}\\
\end{align}\]</span>
How would you interpret the associated interval?</p>
</div>
</div>
<div id="infl" class="section level2" number="3.6">
<h2 number="3.6"><span class="header-section-number">3.6</span> Influential Points</h2>
<p><strong>We are skipping Section @ref(infl); you are not responsible for it.</strong></p>
<div class="theorem">
<p><span id="thm:unlabeled-div-4" class="theorem"><strong>(#thm:unlabeled-div-4) </strong></span><em>High leverage points</em> are x-outliers with the potential to exert undue influence on regression coefficient estimates. <em>Influential points</em> are points that have exerted undue influence on the regression coefficient estimates.</p>
</div>
<p>Note: typically we think of more data as better; more values will tend to decrease the sampling variability of our statistic. But if I give you a lot more data and put it all at <span class="math inline">\(\overline{x}\)</span>, <span class="math inline">\(SE(b_1)\)</span> stays exactly the same. Why??</p>
<p>Recall
<span class="math display">\[\begin{align}
y_{i} &amp;= \beta_0 + \beta_1 x_i \ \ \ \epsilon_i \sim N(0,\sigma^2)\\
e_i &amp;= y_i - \hat{y}_i
\end{align}\]</span></p>
<p>We plot <span class="math inline">\(e_i\)</span> versus <span class="math inline">\(\hat{y}_i\)</span>. (Why? Typically, we want the <span class="math inline">\(e_i\)</span> to be constant at each value of <span class="math inline">\(x_i\)</span>. Note that <span class="math inline">\(\hat{y}_i\)</span> is a simple linear transformation of <span class="math inline">\(x_i\)</span>, so the plot is identical.) We want to see if the distributions of the residuals is different across the fitted line (we look for patterns).</p>
<p><strong>Not all residuals have an equal effect on the regression line!!</strong></p>
<div id="leverage" class="section level3" number="3.6.1">
<h3 number="3.6.1"><span class="header-section-number">3.6.1</span> leverage</h3>
<p><span class="math display">\[\begin{align}
h_i = \frac{1}{n} +\frac{(x_i - \overline{x})^2}{\sum_{j=1}^n (x_j - \overline{x})^2}\\
\frac{1}{n} \leq h_i \leq 1\\
\end{align}\]</span>
Leverage represents the effect of point <span class="math inline">\(x_i\)</span> on the line. We need large leverage for a particular value to have a large effect.</p>
<p>Note:
<span class="math display">\[\begin{align}
SE(\hat{y}(x_i)) &amp;= s_{y|x} \sqrt{h_i}\\
SE(y(x_i)) &amp;= s_{y|x} \sqrt{(h_i + 1)}\\
SE(e_i) &amp;= s_{y|x} \sqrt{(1-h_i)}\\
\hat{y}(x^*) &amp;\pm t_{n-2, .025} (s_{y|x} \sqrt{h(x^*)+1})\\
\end{align}\]</span>
is a 95% prediction interval at <span class="math inline">\(x^*\)</span>. High leverage reduces the variability because the line gets pulled toward the point.</p>
</div>
<div id="standardized-residuals" class="section level3" number="3.6.2">
<h3 number="3.6.2"><span class="header-section-number">3.6.2</span> standardized residuals</h3>
<p><span class="math display">\[\begin{align}
\frac{e_i}{s_{y|x} \sqrt{1-h_i}} \sim t_{n-2}\\
\end{align}\]</span></p>
</div>
<div id="studentized-residuals" class="section level3" number="3.6.3">
<h3 number="3.6.3"><span class="header-section-number">3.6.3</span> studentized residuals</h3>
<p><span class="math display">\[\begin{align}
\frac{e_i}{s_{y|x, (i)} \sqrt{1-h_i}} &amp;\sim t_{n-3}\\
s_{y|x, (i)} &amp;= \frac{1}{n-3} \sum_{j \ne i} (y_j - \hat{y}_{j(i)})^2
\end{align}\]</span></p>
<p>Where do we predict 90% of residuals? <span class="math inline">\(\pm t_{n-2,3 , .05}\)</span>. About <span class="math inline">\(\pm 2\)</span>.</p>
</div>
<div id="dfbetas" class="section level3" number="3.6.4">
<h3 number="3.6.4"><span class="header-section-number">3.6.4</span> DFBETAs</h3>
<p>DFBETAs represent the change in the parameter estimate due to one observation.</p>
<p><span class="math display">\[\begin{align}
DFBETAS_i &amp;= \frac{b_1 - b_{1(i)}}{\frac{s_{y|x, (i)}}{\sqrt{(n-1)} s_x}}\\
\end{align}\]</span></p>
</div>
</div>
<div id="r-example-slr-happy-planet" class="section level2" number="3.7">
<h2 number="3.7"><span class="header-section-number">3.7</span> R Example (SLR): Happy Planet</h2>
<p>The data below represents 10 different variables on health of a country measured on 143 countries. Data taken from <span class="citation">(<a href="#ref-Lock5" role="doc-biblioref">Lock et al. 2016</a>)</span>, originally from the Happy Planet Index Project [<a href="http://www.happyplanetindex.org/" class="uri">http://www.happyplanetindex.org/</a>]. Region of the world is coded as 1 = Latin America, 2 = Western nations, 3 = Middle East, 4 = Sub-Saharan Africa, 5 = South Asia, 6 = East Asia, 7 = former Communist countries. We are going to investigate happiness and life expectancy.</p>
<div id="reading-the-data-into-r" class="section level3" number="3.7.1">
<h3 number="3.7.1"><span class="header-section-number">3.7.1</span> Reading the data into R</h3>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>happy <span class="ot">&lt;-</span> <span class="fu">read_delim</span>(<span class="st">&quot;~/Dropbox/teaching/MA150/spring17/happyPlanet.txt&quot;</span>, <span class="at">delim=</span><span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(happy)  </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Rows: 143</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Columns: 11</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ Country        &lt;chr&gt; &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Argentina&quot;, &quot;Armenia&quot;,…</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ Region         &lt;dbl&gt; 7, 3, 4, 1, 7, 2, 2, 7, 5, 7, 2, 1, 4, 5, 1, 7, 4, 1, 7…</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ Happiness      &lt;dbl&gt; 5.5, 5.6, 4.3, 7.1, 5.0, 7.9, 7.8, 5.3, 5.3, 5.8, 7.6, …</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ LifeExpectancy &lt;dbl&gt; 76.2, 71.7, 41.7, 74.8, 71.7, 80.9, 79.4, 67.1, 63.1, 6…</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ Footprint      &lt;dbl&gt; 2.2, 1.7, 0.9, 2.5, 1.4, 7.8, 5.0, 2.2, 0.6, 3.9, 5.1, …</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ HLY            &lt;dbl&gt; 41.7, 40.1, 17.8, 53.4, 36.1, 63.7, 61.9, 35.4, 33.1, 4…</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ HPI            &lt;dbl&gt; 47.9, 51.2, 26.8, 59.0, 48.3, 36.6, 47.7, 41.2, 54.1, 3…</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ HPIRank        &lt;dbl&gt; 54, 40, 130, 15, 48, 102, 57, 85, 31, 104, 64, 27, 134,…</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ GDPperCapita   &lt;dbl&gt; 5316, 7062, 2335, 14280, 4945, 31794, 33700, 5016, 2053…</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ HDI            &lt;dbl&gt; 0.801, 0.733, 0.446, 0.869, 0.775, 0.962, 0.948, 0.746,…</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $ Population     &lt;dbl&gt; 3.15, 32.85, 16.10, 38.75, 3.02, 20.40, 8.23, 8.39, 153…</span></span></code></pre></div>
</div>
<div id="running-the-linear-model-lm" class="section level3" number="3.7.2">
<h3 number="3.7.2"><span class="header-section-number">3.7.2</span> Running the linear model (lm)</h3>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>happy.lm <span class="ot">=</span> <span class="fu">lm</span>(LifeExpectancy <span class="sc">~</span> Happiness, <span class="at">data=</span>happy) </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>happy.lm <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)    28.2      2.28       12.4 2.76e-24</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 Happiness       6.69     0.375      17.8 5.78e-38</span></span></code></pre></div>
</div>
<div id="ouptut" class="section level3" number="3.7.3">
<h3 number="3.7.3"><span class="header-section-number">3.7.3</span> Ouptut</h3>
<p>Some analyses will need the residuals, fitted values, or coefficients individually.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>happy.lm <span class="sc">%&gt;%</span> <span class="fu">augment</span>()</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 143 x 8</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   LifeExpectancy Happiness .fitted  .resid    .hat .sigma   .cooksd .std.resid</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;            &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1           76.2       5.5    65.0  11.2   0.00765   6.09 0.0128        1.83  </span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2           71.7       5.6    65.7   6.00  0.00737   6.14 0.00357       0.980 </span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3           41.7       4.3    57.0 -15.3   0.0168    6.02 0.0539       -2.51  </span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4           74.8       7.1    75.7  -0.944 0.0122    6.16 0.000148     -0.155 </span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5           71.7       5      61.7  10.0   0.0101    6.10 0.0138        1.64  </span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6           80.9       7.9    81.1  -0.198 0.0216    6.16 0.0000118    -0.0326</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 137 more rows</span></span></code></pre></div>
<p>We can plot the main relationship, or we can plot the residuals (to check that technical conditions hold):</p>
<pre><code>happy %&gt;%
         ggplot(aes(x=Happiness, y=LifeExpectancy)) + 
         geom_point() + 
         geom_smooth(method=&quot;lm&quot;, se=FALSE) 

happy.lm %&gt;% 
         augment() %&gt;% 
         ggplot(aes(x = .fitted, y = .resid)) + 
         geom_point() + 
         geom_hline(yintercept=0)</code></pre>
<p><img src="03-SLR_files/figure-html/unnamed-chunk-6-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Intervals of interest: mean response, individual response, and parameter(s).</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.lm</span>(happy.lm, <span class="at">newdata=</span><span class="fu">list</span>(<span class="at">Happiness=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">7</span>)),<span class="at">interval=</span><span class="fu">c</span>(<span class="st">&quot;conf&quot;</span>), <span class="at">level=</span>.<span class="dv">95</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    fit  lwr  upr</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 55.0 53.2 56.7</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 75.1 73.8 76.4</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.lm</span>(happy.lm, <span class="at">newdata=</span><span class="fu">list</span>(<span class="at">Happiness=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">7</span>)),<span class="at">interval=</span><span class="fu">c</span>(<span class="st">&quot;pred&quot;</span>), <span class="at">level=</span>.<span class="dv">95</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    fit  lwr  upr</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 55.0 42.7 67.3</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 75.1 62.9 87.3</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>happy.lm <span class="sc">%&gt;%</span> <span class="fu">tidy</span>(<span class="at">conf.int =</span> <span class="cn">TRUE</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 7</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value conf.low conf.high</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)    28.2      2.28       12.4 2.76e-24    23.7      32.7 </span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 Happiness       6.69     0.375      17.8 5.78e-38     5.95      7.43</span></span></code></pre></div>
<div id="residuals-in-r" class="section level4" number="3.7.3.1">
<h4 number="3.7.3.1"><span class="header-section-number">3.7.3.1</span> Residuals in R</h4>
<p>We skipped the residuals section, so you are not responsible for finding residuals in R, but the R code is here for completion in case you are interested:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>happy.lm <span class="sc">%&gt;%</span> <span class="fu">augment</span>()</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 143 x 8</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   LifeExpectancy Happiness .fitted  .resid    .hat .sigma   .cooksd .std.resid</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;            &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1           76.2       5.5    65.0  11.2   0.00765   6.09 0.0128        1.83  </span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2           71.7       5.6    65.7   6.00  0.00737   6.14 0.00357       0.980 </span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3           41.7       4.3    57.0 -15.3   0.0168    6.02 0.0539       -2.51  </span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4           74.8       7.1    75.7  -0.944 0.0122    6.16 0.000148     -0.155 </span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5           71.7       5      61.7  10.0   0.0101    6.10 0.0138        1.64  </span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6           80.9       7.9    81.1  -0.198 0.0216    6.16 0.0000118    -0.0326</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 137 more rows</span></span></code></pre></div>
<!--chapter:end:03-SLR.Rmd-->
</div>
</div>
</div>
</div>
<div id="analysis-of-categorical-data" class="section level1" number="4">
<h1 number="4"><span class="header-section-number">4</span> Analysis of Categorical Data</h1>
<p>(Section 6.3 in <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>.)</p>
<div id="cat" class="section level2" number="4.1">
<h2 number="4.1"><span class="header-section-number">4.1</span> Categorical Inference</h2>
<p>In either an observational study or a randomized experiment, we are often interested in assessing the statistical significance of the differences we see: Is the observed difference too big to have reasonably occurred just due to chance? To answer the question, we will use</p>
<ul>
<li>simulation</li>
<li>mathematical probability models.</li>
</ul>
<div class="example">
<p><span id="exm:unlabeled-div-5" class="example"><strong>(#exm:unlabeled-div-5) </strong></span><strong>Back Pain &amp; Botox</strong>, <span class="citation"><a href="#ref-iscam" role="doc-biblioref">Chance and Rossman</a> (<a href="#ref-iscam" role="doc-biblioref">2018</a>)</span>, <span class="citation"><a href="#ref-botox" role="doc-biblioref">Foster et al.</a> (<a href="#ref-botox" role="doc-biblioref">2001</a>)</span><br />
The randomized clinical trial examined whether the drug botulinum toxin A (Botox) is helpful for reducing pain among patients who suffer from chronic low back pain. The 31 subjects who participated in the study were randomly assigned to one of two treatment groups: 16 received a placebo of normal saline and the other 15 received the drug itself. The subjects’ pain levels were evaluated at the beginning of the study and again after eight weeks. The researchers found that 2 of the 16 subjects who received the saline experienced a substantial reduction in pain, compared to 9 of the 15 subjects who received the actual drug.</p>
<ol style="list-style-type: decimal">
<li>Is this an experiment or an observational study?<br />
</li>
<li>Explain the importance of using the “placebo” treatment of saline.<br />
</li>
<li>Create the two-way table for summarizing the data, putting the explanatory variable as the rows and the response variable as the columns<br />
</li>
<li>Calculate the conditional proportions of pain reduction in the two groups. Display the results as a segmented bar graph. Comment on the preliminary analysis.</li>
</ol>
<table>
<thead>
<tr class="header">
<th></th>
<th>pain reduction</th>
<th>no pain reduction</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Botox</td>
<td>9</td>
<td>6</td>
<td>15</td>
</tr>
<tr class="even">
<td>placebo</td>
<td>2</td>
<td>14</td>
<td>16</td>
</tr>
<tr class="odd">
<td></td>
<td>11</td>
<td>20</td>
<td>31</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\begin{eqnarray*}
\mbox{risk}_{\mbox{placebo}} = \frac{2}{16} &amp;=&amp; 0.125\\
\mbox{risk}_{\mbox{Botox}} = \frac{9}{15} &amp;=&amp; 0.6\\
RR &amp;=&amp; 4.8
\end{eqnarray*}\]</span></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>backpain <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">treatment =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;placebo&quot;</span>, <span class="dv">16</span>), <span class="fu">rep</span>(<span class="st">&quot;Botox&quot;</span>, <span class="dv">15</span>)),</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">outcome =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;reduction&quot;</span>, <span class="dv">2</span>), <span class="fu">rep</span>(<span class="st">&quot;no_reduction&quot;</span>, <span class="dv">14</span>), </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>                                 <span class="fu">rep</span>(<span class="st">&quot;reduction&quot;</span>, <span class="dv">9</span>), <span class="fu">rep</span>(<span class="st">&quot;no_reduction&quot;</span>, <span class="dv">6</span>)))</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>backpain <span class="sc">%&gt;%</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>()</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          outcome</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; treatment no_reduction reduction</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Botox              6         9</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   placebo           14         2</span></span></code></pre></div>
<p>Note that sometimes it makes sense for the y-axis to be count and sometimes it makes sense for the y-axis to be percent. Probably doesn’t matter much here, you should choose the bar plot that seems most informative to you.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>backpain <span class="sc">%&gt;%</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> treatment)) <span class="sc">+</span> </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="fu">aes</span>(<span class="at">fill =</span> outcome), <span class="at">position =</span> <span class="st">&quot;fill&quot;</span>) <span class="sc">+</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;percentage&quot;</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>backpain <span class="sc">%&gt;%</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> treatment)) <span class="sc">+</span> </span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="fu">aes</span>(<span class="at">fill =</span> outcome))</span></code></pre></div>
<p><img src="04-cat_files/figure-html/unnamed-chunk-4-1.png" width="80%" style="display: block; margin: auto;" /></p>
<ol start="5" style="list-style-type: decimal">
<li><p>If there was no association between the treatment and the back pain relief, about how many of the 11 “successes” would you expect to see in each group? Did the researchers observe more successes in the saline group than expected (if the drug had no effect) or fewer successes than expected? Is this in the direction conjectured by the researchers?</p></li>
<li><p>Is is <em>possible</em> that the drug has absolutely no effect on back pain? That the differences were simply due to chance or random variability? How likely is that?</p></li>
</ol>
</div>
<div id="simulation" class="section level4 unnumbered">
<h4 class="unnumbered">Simulation</h4>
<ul>
<li><p>11 red “success” cards (pain reduction); 20 black “failure” cards (no pain reduction)</p></li>
<li><p>randomly deal out (i.e. shuffle) 15 cards to the treatment group and 16 cards to the placebo group.</p></li>
<li><p>count how many people in the treatment group were successes? Repeat 5 times.</p></li>
<li><p>process</p>
<ul>
<li>what do the cards represent?</li>
<li>what does shuffling the cards represent?</li>
<li>what implicit assumption about the two groups did the shuffling of cards represent?</li>
<li>what observational units would be represented by the dots on the dotplot?</li>
<li>why would we count the number of repetitions with 9 or more “successes?”</li>
</ul></li>
<li><p>Repeat simulation using the two-way table applet:
[<a href="http://www.rossmanchance.com/applets/2021/chisqshuffle/ChiSqShuffle.htm" class="uri">http://www.rossmanchance.com/applets/2021/chisqshuffle/ChiSqShuffle.htm</a>]</p></li>
<li><p>summary</p>
<ul>
<li>How many reps?</li>
<li>How many as extreme as the true data?</li>
<li>What proportion are at least as extreme as the true data?</li>
<li>Do our data support the researchers conjecture?</li>
<li>What if the actual data had been 7 successes in the treatment group (and 4 in the placebo group)?</li>
</ul></li>
</ul>
<div class="definition">
<p><span id="def:unlabeled-div-6" class="definition"><strong>(#def:unlabeled-div-6) </strong></span><strong>p-value</strong> The p-value is the probability of seeing our results or more extreme if there is nothing interesting going on with the data. (This is the same definition of p-value that you will always use in this class and in your own research.)</p>
</div>
<p>Notice that regardless of whether or not the drug has an effect, the data will be different each time (think: new 31 people). The small p-value allows us to draw cause-and-effect conclusions, but doesn’t necessarily allow us to infer to a larger population. Why not?</p>
<table>
<thead>
<tr class="header">
<th align="center">low cutoff</th>
<th align="center">p-value</th>
<th align="center">high cutoff</th>
<th align="left">evidence</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center">p-value <span class="math inline">\(\leq\)</span></td>
<td align="center">0.001</td>
<td align="left">very strong evidence</td>
</tr>
<tr class="even">
<td align="center">0.001</td>
<td align="center"><span class="math inline">\(&lt;\)</span> p-value <span class="math inline">\(\leq\)</span></td>
<td align="center">0.01</td>
<td align="left">strong evidence</td>
</tr>
<tr class="odd">
<td align="center">0.01</td>
<td align="center"><span class="math inline">\(&lt;\)</span> p-value <span class="math inline">\(\leq\)</span></td>
<td align="center">0.05</td>
<td align="left">moderate evidence</td>
</tr>
<tr class="even">
<td align="center">0.05</td>
<td align="center"><span class="math inline">\(&lt;\)</span> p-value <span class="math inline">\(\leq\)</span></td>
<td align="center">0.10</td>
<td align="left">weak but suggestive evidence</td>
</tr>
<tr class="odd">
<td align="center">0.10</td>
<td align="center"><span class="math inline">\(&lt;\)</span> p-value</td>
<td align="center"></td>
<td align="left">little or no evidence</td>
</tr>
</tbody>
</table>
</div>
<div id="inferFET" class="section level3" number="4.1.1">
<h3 number="4.1.1"><span class="header-section-number">4.1.1</span> Simulation using R</h3>
<p>The simulation from the applet can be recreated using the <strong>infer</strong> package in R. Note the different pieces of the simulation using functions like <code>specify()</code>, <code>hypothesize()</code>, <code>generate()</code>, and <code>calculate()</code>. Also notice that this particular function works best using the difference in proportions (which we discussed in class is equivalent to recording the single count of Botox patients who had reduced back pain).</p>
<p>Step 1. Calculate the observed difference in proportion of patients with reduced back pain. Note that as with linear regression we continue to use the syntax: <code>responsevariable ~ explanatoryvariable</code>.</p>
<p>Step 2. Go through the simulation steps, just like the applet.</p>
<ul>
<li><code>specify()</code> the variables<br />
</li>
<li><code>hypothesize()</code> about the null claim<br />
</li>
<li><code>generate()</code> many permutions of the data<br />
</li>
<li><code>calculate()</code> the statistic of interest for all the different permutations</li>
</ul>
<p>Step 3. Plot a histogram representing the differences in proportions for all the many permuted tables. The plot represents the distribution of the differences in proportion under the null hypothesis.</p>
<p>Step 4. Calculate the p-value from the sampling distribution generated in Step 3.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(infer)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1.</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>diff_props <span class="ot">&lt;-</span> backpain <span class="sc">%&gt;%</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">specify</span>(outcome <span class="sc">~</span> treatment, <span class="at">success =</span> <span class="st">&quot;reduction&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;diff in props&quot;</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>diff_props  <span class="co"># print to screen to see the observed difference</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 1</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    stat</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;dbl&gt;</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 0.475</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2.</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>nulldist <span class="ot">&lt;-</span> backpain <span class="sc">%&gt;%</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">specify</span>(outcome <span class="sc">~</span> treatment, <span class="at">success =</span> <span class="st">&quot;reduction&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hypothesize</span>(<span class="at">null =</span> <span class="st">&quot;independence&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">generate</span>(<span class="at">reps =</span> <span class="dv">1000</span>, <span class="at">type =</span> <span class="st">&quot;permute&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;diff in props&quot;</span>)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3.</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a><span class="fu">visualize</span>(nulldist) <span class="sc">+</span> </span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">shade_p_value</span>(<span class="at">obs_stat =</span> diff_props, <span class="at">direction =</span> <span class="st">&quot;greater&quot;</span>)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4.</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>nulldist <span class="sc">%&gt;%</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">get_p_value</span>(<span class="at">obs_stat =</span> diff_props, <span class="at">direction =</span> <span class="st">&quot;greater&quot;</span>)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 1</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   p_value</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     &lt;dbl&gt;</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1   0.007</span></span></code></pre></div>
<p><img src="04-cat_files/figure-html/unnamed-chunk-5-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="fisher" class="section level2" number="4.2">
<h2 number="4.2"><span class="header-section-number">4.2</span> Fisher’s Exact Test</h2>
<p>(Section 6.4 in <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>, great detailed explanation!)</p>
<p>Because we have a fixed sample, we use the hypergeometric distribution to enumerate the possible ways of choosing our data or more extreme given fixed row and column totals.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>pain reduction</th>
<th>no pain reduction</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Botox</td>
<td>9 = x</td>
<td>6</td>
<td>15 = n</td>
</tr>
<tr class="even">
<td>placebo</td>
<td>2</td>
<td>14</td>
<td>16</td>
</tr>
<tr class="odd">
<td></td>
<td>11 = M</td>
<td>20 = N - M</td>
<td>31 = N</td>
</tr>
</tbody>
</table>
<p>To make it simpler, let’s say I have 5 items (N=5), and I want to choose 3 of them (n=3). How many ways can I do that?</p>
<blockquote>
<p>SSSNN, SSNSN, SSNNS, SNSSN, SNSNS, SNNSS, NSSSN, NSSNS, NSNSS, NNSSS [5!/ 3! 2!]
(S = select, N = not selected)</p>
</blockquote>
<p>So, how many different ways can I select 11 people (out of 31) to be my “pain reduction” group? That is the total number of different groups of size 11 from 31. But really, we want our groups to be of a certain breakdown. We need 2 (of 16) to have gotten the placebo and 9 (of 15) to have gotten the Botox treatment.</p>
<div class="definition">
<p><span id="def:unlabeled-div-7" class="definition"><strong>(#def:unlabeled-div-7) </strong></span><strong>Hypergeometric Probability</strong> For any <span class="math inline">\(2 \times 2\)</span> table when there are N observations with M total successes , the probability of observing x successes in a sample of size n is:</p>
</div>
<p><span class="math display">\[\begin{eqnarray*}
P(X=x) = \frac{\# \mbox{ of ways to select x successes and n-x failures}}{\# \mbox{ of ways to select n subjects}} = \frac{ { M \choose x} {N-M \choose n-x}}{{N \choose n}}\\
\end{eqnarray*}\]</span></p>
<p>Find the P(X=2)</p>
<p>We can now find EXACT probabilities associated with the following hypotheses.
<span class="math display">\[\begin{eqnarray*}
&amp;&amp;H_0: p_{pl} = p_{btx}\\
&amp;&amp;H_a: p_{pl} &lt; p_{btx}\\
&amp;&amp;p = \mbox{true probability of no pain}\\
\end{eqnarray*}\]</span></p>
<p>Is this a one- or two-sided test? Why? [Note: the conditions here include that the row and column totals are fixed – a <strong>conditional test of independence</strong>. However, the research project in the back of chapter 6 extends the permutation test to demonstrated that the probabilities hold even under alternative technical conditions.</p>
<p>Note also that we get an exact probability with no conditions needed about the sample size being big enough (we can use Fisher’s Exact Test even when true probabilities are close to 0 or 1.]</p>
</div>
<div id="chisq" class="section level2" number="4.3">
<h2 number="4.3"><span class="header-section-number">4.3</span> Testing independence of two categorical variables</h2>
<p>(Sections 6.5, 6.6, 6.7 in <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>.)</p>
<div id="chi2-tests" class="section level3" number="4.3.1">
<h3 number="4.3.1"><span class="header-section-number">4.3.1</span> <span class="math inline">\(\chi^2\)</span> tests</h3>
<p>(Section 6.6 in <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>.)</p>
<p>2x2… but also rxc (<span class="math inline">\(p_a = p_b = p_c\)</span>)</p>
<p>We can also use <span class="math inline">\(\chi^2\)</span> tests to evaluate <span class="math inline">\(r \times c\)</span> contingency tables. Our main question now will be whether there is an association between two categorical variables of interest. Note that we are now generalizing what we did with the Botox and back pain example. Are the two variables independent? If the two variables are independent, then the state of one variable is not related to the probability of the different outcomes of the other variable.</p>
<p>If the data were sampled in such a way that we have random samples of both the explanatory and response variables (e.g., cross classification study), then we typically do a test of association:</p>
<p><span class="math display">\[\begin{eqnarray*}
H_0: &amp;&amp; \mbox{ the two variables are independent}\\
H_a: &amp;&amp; \mbox{ the two variables are not independent}
\end{eqnarray*}\]</span></p>
<p>If the data are sampled in such a way that the response is measured across specified populations (as in the example below), we typically do a test of homogeneity of proportions. For example,</p>
<p><span class="math display">\[\begin{eqnarray*}
H_0: &amp;&amp; p_1 = p_2 = p_3\\
H_a: &amp;&amp; \mbox{not } H_0
\end{eqnarray*}\]</span>
where <span class="math inline">\(p=P(\mbox{success})\)</span> for each of groups 1,2,3.</p>
<p>How do we get expected frequencies? The same mathematics hold regardless of the type of test (i.e., sampling mechanism used to collect the data). If, in fact,the variables are independent, then we should be able to multiply their probabilities. If the probabilities are the same, we expect the overall proportion of each response variable to be the same as the proportion of the response variable in each explanatory group. And the math in the example below follows directly.</p>
<div class="example">
<p><span id="exm:unlabeled-div-8" class="example"><strong>(#exm:unlabeled-div-8) </strong></span>The table below show the observed distributions of ABO blood type in three random samples of African Americans living in different locations. The three datasets, collected in the 1950s by three different investigators, are reproduced in <span class="citation">(<a href="#ref-bloodtype" role="doc-biblioref">Mourant, Kopec, and Domaniewsa-Sobczak 1976</a>)</span>.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th></th>
<th>Blood</th>
<th>Type</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>A</td>
<td>B</td>
<td>AB</td>
<td>O</td>
<td>Total</td>
</tr>
<tr class="even">
<td>Location</td>
<td>(Florida)</td>
<td>122</td>
<td>117</td>
<td>19</td>
<td>244</td>
<td>502</td>
</tr>
<tr class="odd">
<td></td>
<td>(Iowa)</td>
<td>1781</td>
<td>1351</td>
<td>289</td>
<td>3301</td>
<td>6722</td>
</tr>
<tr class="even">
<td></td>
<td>(Missouri)</td>
<td>353</td>
<td>269</td>
<td>60</td>
<td>713</td>
<td>1395</td>
</tr>
<tr class="odd">
<td></td>
<td>Total</td>
<td>2256</td>
<td>1737</td>
<td>368</td>
<td>4258</td>
<td>8619</td>
</tr>
</tbody>
</table>
</div>
<div id="test-of-homogeneity-of-proportions-equivalent-mathematically-to-independence" class="section level4" number="4.3.1.1">
<h4 number="4.3.1.1"><span class="header-section-number">4.3.1.1</span> Test of Homogeneity of Proportions (equivalent mathematically to independence)</h4>
<p>If there is no difference in blood type proportions across the groups, then:</p>
<p><span class="math display">\[\begin{eqnarray*}
P(AB | FL) = P(AB | IA) = P(AB | MO) = P(AB)
\end{eqnarray*}\]</span></p>
<p>We will use <span class="math inline">\(\hat{P}(AB) = \frac{368}{8619}\)</span> as baseline for expectation (under <span class="math inline">\(H_0\)</span>) for all the groups. That is, we would expect,</p>
<p><span class="math display">\[\begin{eqnarray*}
\# \mbox{expected for AB blood and Iowa} &amp;=&amp;  \frac{368}{8619} \cdot 6722\\
\end{eqnarray*}\]</span></p>
</div>
<div id="test-of-independence-equivalent-mathematically-to-homogeneity-of-proporitions" class="section level4" number="4.3.1.2">
<h4 number="4.3.1.2"><span class="header-section-number">4.3.1.2</span> Test of Independence (equivalent mathematically to homogeneity of proporitions)</h4>
<p><span class="math display">\[\begin{eqnarray*}
P(cond1 \mbox{ &amp; } cond2 ) &amp;=&amp; P(cond1) P(cond2)  \mbox{ if variables 1 and 2 are independent}\\
P(AB \mbox{ blood &amp; Iowa}) &amp;=&amp; P(AB \mbox{ blood}) P(\mbox{Iowa}) \\
&amp;=&amp; \bigg( \frac{368}{8619}\bigg) \bigg( \frac{6722}{8619} \bigg)\\
&amp;=&amp; 0.0333\\
\# \mbox{expected for AB blood and Iowa} &amp;=&amp; 0.033 \cdot 8619\\
&amp;=&amp; \frac{368 \cdot 6722}{8619}\\
E_{i,j} &amp;=&amp; \frac{(i \mbox{ row total})(j \mbox{ col total})}{\mbox{grand total}}\\
\end{eqnarray*}\]</span></p>
<p>And the expected values under the null hypothesis…</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th></th>
<th>Blood</th>
<th>Type</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>A</td>
<td>B</td>
<td>AB</td>
<td>O</td>
<td>Total</td>
</tr>
<tr class="even">
<td>Location</td>
<td>(Florida)</td>
<td>131.4</td>
<td>101.17</td>
<td>21.43</td>
<td>248.00</td>
<td>502</td>
</tr>
<tr class="odd">
<td></td>
<td>(Iowa)</td>
<td>1759.47</td>
<td>1354.69</td>
<td>287.00</td>
<td>3320.83</td>
<td>6722</td>
</tr>
<tr class="even">
<td></td>
<td>(Missouri)</td>
<td>365.14</td>
<td>281.14</td>
<td>59.56</td>
<td>689.16</td>
<td>1395</td>
</tr>
<tr class="odd">
<td></td>
<td>Total</td>
<td>2256</td>
<td>1737</td>
<td>368</td>
<td>4258</td>
<td>8619</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\begin{eqnarray*}
X^2 &amp;=&amp; \sum_{all cells} \frac{( O - E)^2}{E}\\
&amp;=&amp; 5.65\\
\mbox{p-value} &amp;=&amp; P(\chi^2_6 \geq 5.65) \\
&amp;=&amp; 1 - pchisq(5.65, 6)\\
&amp;=&amp; 0.464
\end{eqnarray*}\]</span></p>
<p>We cannot reject the null hypothesis. Again, we have no evidence against the null hypothesis that blood types are independently distributed in the various regions.</p>
<p>How do we know if our test statistic is a big number or not? Well, it turns out that the test statistic (<span class="math inline">\(X^2\)</span>) will have an approximate <span class="math inline">\(\chi^2\)</span> distribution with degrees of freedom = <span class="math inline">\((r- 1)\cdot (c-1)\)</span>. As long as:</p>
<ul>
<li>We have a random sample from the population.<br />
</li>
<li>We expect at least 1 observation in every cell (<span class="math inline">\(E_i \geq 1 \forall i\)</span>)<br />
</li>
<li>We expect at least 5 observations in 80% of the cells (<span class="math inline">\(E_i \geq 5\)</span> for 80% of <span class="math inline">\(i\)</span>)</li>
</ul>
<p>When there are only two populations, the <span class="math inline">\(\chi^2\)</span> procedure is equivalent to the two-sided z-test for proportions. The chi-squared test statistic is the square of the z-test statistic. That is, the chi-squared test is exactly the same as the two-sided alternative for the z-test.</p>
<p>use chi-square if you have multiple populations</p>
<p>use z-test if you want one-sided tests or confidence intervals.</p>
</div>
</div>
</div>
<div id="catest" class="section level2" number="4.4">
<h2 number="4.4"><span class="header-section-number">4.4</span> Parameter Estimation</h2>
<p>(Section 6.8 in <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>.)</p>
<div class="definition">
<p><span id="def:unlabeled-div-9" class="definition"><strong>(#def:unlabeled-div-9) </strong></span><strong>Data Types</strong> Data are often classified as</p>
</div>
<ul>
<li>Categorical - each unit is assigned to a category<br />
</li>
<li>Quantitative - each observational unit is assigned a numerical value<br />
</li>
<li>(Binary - a special case of categorical with 2 categories, e.g. male/female)</li>
</ul>
<blockquote>
<p>Table 6.6 on page 193 of <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span> is excellent and worth looking at.</p>
</blockquote>
<div class="example">
<p><span id="exm:unlabeled-div-10" class="example"><strong>(#exm:unlabeled-div-10) </strong></span><strong>Popcorn &amp; Lung Disease</strong> <span class="citation"><a href="#ref-iscam" role="doc-biblioref">Chance and Rossman</a> (<a href="#ref-iscam" role="doc-biblioref">2018</a>)</span></p>
<p>How can we tell if popcorn production is related to lung disease? Consider High / Low exposure:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Airway obstructed</th>
<th>Airway not obstructed</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>low exposure</td>
<td>6</td>
<td>52</td>
<td>58</td>
</tr>
<tr class="even">
<td>high exposure</td>
<td>15</td>
<td>43</td>
<td>58</td>
</tr>
<tr class="odd">
<td></td>
<td>21</td>
<td>95</td>
<td>116</td>
</tr>
</tbody>
</table>
<p>Is 21 a lot of people? Can we compare 6 vs. 15? What should we look at? <em>proportions</em> (always a number between 0 and 1). Look at your data (graphically and numerically). Segmented bar graph (mosaic plot):</p>
<p>Is there a difference in the two groups? Look at the difference in proportions or risk:</p>
<p><span class="math display">\[\begin{eqnarray*}
6/58 = 0.103 &amp; 15/58=0.2586 &amp; \Delta = 0.156\\
p_1 = 0.65 &amp; p_2 = 0.494 &amp; \Delta = 0.156\\
p_1 = 0.001 &amp; p_2 = 0.157 &amp; \Delta = 0.156\\
\end{eqnarray*}\]</span></p>
</div>
<div id="differences-in-proportions" class="section level3" number="4.4.1">
<h3 number="4.4.1"><span class="header-section-number">4.4.1</span> Differences in Proportions</h3>
<p>It turns out that the sampling distribution of the difference in the sample proportions (of success) across two <em>independent</em> groups can be modeled by the normal distribution if we have reasonably large sample sizes (CLT).</p>
<p>To ensure the accuracy of the test, check whether np and n(1-p) is bigger than 5 in both samples is usually adequate. A more precise check is <span class="math inline">\(n_s \hat{p}_c\)</span> and <span class="math inline">\(n_s(1-\hat{p}_c)\)</span> are both greater than 5; <span class="math inline">\(n_s\)</span> is the smaller of the two sample sizes and <span class="math inline">\(\hat{p}_c\)</span>is the sample proportion when the two samples are combined into one.</p>
<p>Note:
<span class="math display">\[\begin{eqnarray*}
\hat{p}_1 - \hat{p}_2 \sim N\Bigg(p_1 - p_2, \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}\Bigg)
\end{eqnarray*}\]</span></p>
<p>When testing independence, we assume that <span class="math inline">\(p_1=p_2\)</span>, so we use the pooled estimate of the proportion to calculate the SE:
<span class="math display">\[\begin{eqnarray*}
SE(\hat{p}_1 - \hat{p}_2) = \sqrt{ \hat{p}_c(1-\hat{p}_c) \bigg(\frac{1}{n_1} + \frac{1}{n_2}\bigg)}
\end{eqnarray*}\]</span></p>
<p>So, when testing, the appropriate test statistic is:
<span class="math display">\[\begin{eqnarray*}
 Z = \frac{\hat{p}_1 - \hat{p}_2 - 0}{ \sqrt{ \hat{p}_c(1-\hat{p}_c) (\frac{1}{n_1} + \frac{1}{n_2})}}
\end{eqnarray*}\]</span></p>
</div>
<div id="ci-for-differences-in-proportions" class="section level3" number="4.4.2">
<h3 number="4.4.2"><span class="header-section-number">4.4.2</span> CI for differences in proportions</h3>
<p>We can’t pool our estimate for the SE, but everything else stays the same…</p>
<p><span class="math display">\[\begin{eqnarray*}
SE(\hat{p}_1 - \hat{p}_2) = \sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}
\end{eqnarray*}\]</span></p>
<p>The main idea here is to determine whether two categorical variables are independent. That is, does knowledge of the value of one variable tell me something about the probability of the other variable (gender and pregnancy). We’re going to talk about two different ways to approach this problem.</p>
</div>
<div id="relative-risk" class="section level3" number="4.4.3">
<h3 number="4.4.3"><span class="header-section-number">4.4.3</span> Relative Risk</h3>
<div class="definition">
<p><span id="def:unlabeled-div-11" class="definition"><strong>(#def:unlabeled-div-11) </strong></span><strong>Relative Risk</strong> The relative risk (RR) is the ratio of risks for each group. We say, “The risk of success is <strong>RR</strong> times higher for those in group 1 compared to those in group 2.”</p>
</div>
<p><span class="math display">\[\begin{eqnarray*}
\mbox{relative risk} &amp;=&amp; \frac{\mbox{risk group 1}}{\mbox{risk group 2}}\\
&amp;=&amp;  \frac{\mbox{proportion of successes in group 1}}{\mbox{proportion of successes in group 2}}\\
\mbox{RR} &amp;=&amp; \frac{p_1}{p_2} = \frac{p_1}{p_2}\\
\hat{\mbox{RR}} &amp;=&amp; \frac{\hat{p}_1}{\hat{p}_2}
\end{eqnarray*}\]</span></p>
<p><span class="math inline">\(\hat{RR}\)</span> in the popcorn example is <span class="math inline">\(\frac{15/58}{6/58} = 2.5\)</span>. We say, “The risk of airway obstruction is 2.5 times higher for those in high exposure group compared to those in the low exposure group.” What about</p>
<ul>
<li>sample size?<br />
</li>
<li>baseline risk?</li>
</ul>
<p>To create confidence intervals for relative risk, we use the fact that:</p>
<p><span class="math display">\[\begin{eqnarray*}
SE(\ln (\hat{RR})) &amp;\approx&amp; \sqrt{\frac{(1 - \hat{p}_1)}{n_1 \hat{p}_1} + \frac{(1-\hat{p}_2)}{n_2 \hat{p}_2}}
\end{eqnarray*}\]</span></p>
</div>
<div id="odds-ratios" class="section level3" number="4.4.4">
<h3 number="4.4.4"><span class="header-section-number">4.4.4</span> Odds Ratios</h3>
<p>A related concept to risk is odds. It is often used in horse racing, where “success” is typically defined as losing. So, if the odds are 3 to 1 we would expect to lose 3/4 of the time.</p>
<div class="definition">
<p><span id="def:unlabeled-div-12" class="definition"><strong>(#def:unlabeled-div-12) </strong></span><strong>Odds Ratio</strong> A related concept to risk is odds. It is often used in horse racing, where “success” is typically defined as losing. So, if the odds are 3 to 1 we would expect to lose 3/4 of the time. The odds ratio (OR) is the ratio of odds for each group. We say, “The odds of success is <strong>OR</strong> times higher for those in group 1 compared to those group 2.”</p>
</div>
<p><span class="math display">\[\begin{eqnarray*}
\mbox{odds} &amp;=&amp; \frac{\mbox{proportion of successes}}{\mbox{proportion of failures}}\\
&amp;=&amp; \frac{\mbox{number of successes}}{\mbox{number of failures}} = \theta\\
\hat{\mbox{odds}} &amp;=&amp; \hat{\theta}\\
\mbox{odds ratio} &amp;=&amp; \frac{\mbox{odds group 1}}{\mbox{odds group 2}} \\
\mbox{OR} &amp;=&amp; \frac{\theta_1}{\theta_2} = \frac{p_1/(1-p_1)}{p_2/(1-p_2)}= \frac{p_1/(1-p_1)}{p_2/(1-p_2)}\\
\hat{\mbox{OR}} &amp;=&amp; \frac{\hat{\theta}_1}{\hat{\theta}_2} = \frac{\hat{p}_1/(1-\hat{p}_1)}{\hat{p}_2/(1-\hat{p}_2)}\\
\end{eqnarray*}\]</span></p>
<p><span class="math inline">\(\hat{OR}\)</span> in the popcorn example is <span class="math inline">\(\frac{15/43}{6/52} = 3.02\)</span>. We say, “The odds of airway obstruction are 3 times higher for those in the high exposure group compared to those in the low exposure group.”</p>
<div id="or-is-more-extreme-than-rr" class="section level4" number="4.4.4.1">
<h4 number="4.4.4.1"><span class="header-section-number">4.4.4.1</span> OR is more extreme than RR</h4>
<p>Without loss of generality, assume the true <span class="math inline">\(RR &gt; 1\)</span>, implying <span class="math inline">\(p_1 / p_2 &gt; 1\)</span> and <span class="math inline">\(p_1 &gt; p_2\)</span>.</p>
<p>Note the following sequence of consequences:</p>
<p><span class="math display">\[\begin{eqnarray*}
RR = \frac{p_1}{p_2} &amp;&gt;&amp; 1\\
\frac{1 - p_1}{1 - p_2} &amp;&lt;&amp; 1\\
\frac{ 1 / (1 - p_1)}{1 / (1 - p_2)} &amp;&gt;&amp; 1\\
\frac{p_1}{p_2} \cdot \frac{ 1 / (1 - p_1)}{1 / (1 - p_2)} &amp;&gt;&amp; \frac{p_1}{p_2}\\
OR &amp;&gt;&amp; RR
\end{eqnarray*}\]</span></p>
</div>
<div id="other-considerations" class="section level4" number="4.4.4.2">
<h4 number="4.4.4.2"><span class="header-section-number">4.4.4.2</span> Other considerations:</h4>
<ul>
<li>Observational study (who worked in each place?)<br />
</li>
<li>Cross sectional (only one point in time)<br />
</li>
<li>Healthy worker effect (who stayed home sick?)<br />
</li>
<li><strong>Explanatory variable</strong> is one that is a potential explanation for any changes (here exposure level).<br />
</li>
<li><strong>Response variable</strong> is the measured outcome of interest (here airway obstruction).</li>
</ul>
<div class="example">
<p><span id="exm:unlabeled-div-13" class="example"><strong>(#exm:unlabeled-div-13) </strong></span><strong>Smoking &amp; Lung Cancer</strong> <span class="citation"><a href="#ref-iscam" role="doc-biblioref">Chance and Rossman</a> (<a href="#ref-iscam" role="doc-biblioref">2018</a>)</span></p>
<p>After World War II, evidence began mounting that there was a link between cigarette smoking and pulmonary carcinoma (lung cancer). In the 1950s, two now classic articles were published on the subject. One of these studies was conducted in the United States by <span class="citation"><a href="#ref-wynder" role="doc-biblioref">Wynder and Graham</a> (<a href="#ref-wynder" role="doc-biblioref">1950</a>)</span>. They found records from a large number (684) of patients with proven bronchiogenic carcinoma (a specific form of lung cancer) in hospitals in California, Colorado, Missouri, New Jersey, New York, Ohio, Pennsylvania, and Utah. They personally interviewed 634 of the subjects to identify their smoking habits, occupation, exposure to dust and fumes, alcohol intake, education, and cause of death of parents and siblings. Thirty-three subjects completed mailed questionnaires, and information for the other 17 was obtained from family members or close acquaintances. Of those in the study, the researchers focused on 605 male patients with the same form of lung cancer. Another 1332 hospital patients with similar age and economic distribution (including 780 males) without lung cancer were interviewed by these researchers in St. Louis and by other researchers in Boston, Cleveland, and Hines, Illinois.</p>
<p>The following two-way table replicates the counts for the 605 male patients with the same form of cancer and for the “control-group” of 780 males.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th>patients</th>
<th>controls</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>none</td>
<td><span class="math inline">\(&lt;\)</span> 1/day</td>
<td>8</td>
<td>114</td>
</tr>
<tr class="even">
<td>light</td>
<td>1-9/day</td>
<td>14</td>
<td>90</td>
</tr>
<tr class="odd">
<td>mod heavy</td>
<td>10-15/day</td>
<td>61</td>
<td>148</td>
</tr>
<tr class="even">
<td>heavy</td>
<td>16-20/day</td>
<td>213</td>
<td>278</td>
</tr>
<tr class="odd">
<td>excessive</td>
<td>21-34/day</td>
<td>187</td>
<td>90</td>
</tr>
<tr class="even">
<td>chain</td>
<td>35<span class="math inline">\(+\)</span>/day</td>
<td>122</td>
<td>60</td>
</tr>
</tbody>
</table>
<p>Given the results of the study, do you think we can generalize from the sample to the population? Explain and make it clear that you know the difference between a sample and a population.</p>
</div>
<table>
<thead>
<tr class="header">
<th></th>
<th>cancer</th>
<th>healthy</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>chain smoking</td>
<td>122</td>
<td>60</td>
<td>182</td>
</tr>
<tr class="even">
<td>no smoking</td>
<td>8</td>
<td>114</td>
<td>122</td>
</tr>
<tr class="odd">
<td></td>
<td>130</td>
<td>174</td>
<td>304</td>
</tr>
</tbody>
</table>
<ul>
<li>Causation?<br />
</li>
<li>Case-control study (605 with lung cancer, 780 without… baseline rate?)</li>
</ul>
<table>
<thead>
<tr class="header">
<th>Group A</th>
<th>Group B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>expl = smoking status</td>
<td>expl = lung cancer</td>
</tr>
<tr class="even">
<td>resp = lung cancer</td>
<td>resp = smoking status</td>
</tr>
</tbody>
</table>
<ul>
<li>If lung cancer is considered a success and no smoking is baseline:</li>
</ul>
<p><span class="math display">\[\begin{eqnarray*}
\hat{RR} &amp;=&amp; \frac{122/182}{8/122} = 10.22\\
\hat{OR} &amp;=&amp; \frac{122/60}{8/114} = 28.9\\
\end{eqnarray*}\]</span>
The risk of lung cancer is 10.22 times higher for those who smoke than for those who don’t smoke.</p>
<p>The odds of lung cancer is 28.9 times higher for those who smoke than for those who don’t smoke.</p>
<ul>
<li>If chain smoking is considered a success and healthy is baseline:</li>
</ul>
<p><span class="math display">\[\begin{eqnarray*}
\hat{RR} &amp;=&amp; \frac{122/130}{60/174} = 2.7\\
\hat{OR} &amp;=&amp; \frac{122/8}{60/114} = 28.9\\
\end{eqnarray*}\]</span>
The risk of smoking is 2.7 times higher for those who have lung cancer than for those who don’t have lung cancer.</p>
<p>The odds of smoking is 28.9 times higher for those who have lung cancer than for those who don’t have lung cancer.</p>
<p>
We know the risk of being a light smoker if you have lung cancer but we do <em>not</em> know the risk of lung cancer if you are a light smoker. Let’s say we have a <em>population</em> of 1,000,000 people:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>cancer</th>
<th>healthy</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>light smoking</td>
<td>49,000</td>
<td>51,000</td>
<td>100,000</td>
</tr>
<tr class="even">
<td>no smoking</td>
<td>1,000</td>
<td>899,000</td>
<td>900,000</td>
</tr>
<tr class="odd">
<td></td>
<td>50,000</td>
<td>950,000</td>
<td>1,000,000</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\begin{eqnarray*}
P(\mbox{light} | \mbox{lung cancer}) &amp;=&amp; \frac{49,000}{50,000} = 0.98\\
P(\mbox{lung cancer} | \mbox{light}) &amp;=&amp; \frac{49,000}{100,000} = 0.49\\
\end{eqnarray*}\]</span></p>
<ul>
<li>What is the explanatory variable?</li>
<li>What is the response variable?</li>
<li>relative risk?</li>
<li>odds ratio?</li>
</ul>
<table>
<thead>
<tr class="header">
<th>Group A</th>
<th>Group B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>expl = smoking status</td>
<td>expl = lung cancer</td>
</tr>
<tr class="even">
<td>resp = lung cancer</td>
<td>resp = smoking status</td>
</tr>
</tbody>
</table>
<ul>
<li>If lung cancer is considered a success and no smoking is baseline:</li>
</ul>
<p><span class="math display">\[\begin{eqnarray*}
RR &amp;=&amp; \frac{49/100}{1/900} = 441\\
OR &amp;=&amp; \frac{49/51}{1/899} = 863.75\\
\end{eqnarray*}\]</span></p>
<ul>
<li>If light smoking is considered a success and healthy is baseline:</li>
</ul>
<p><span class="math display">\[\begin{eqnarray*}
RR &amp;=&amp; \frac{49/50}{51/950} = 18.25\\
OR &amp;=&amp; \frac{49/1}{51/899} = 863.75\\
\end{eqnarray*}\]</span></p>
<p>OR is the same no matter which variable you choose as explanatory versus response! Though, in general, we still prefer to know baseline odds or baseline risk (which we can’t know with a case-control study).</p>
<div class="example">
<p><span id="exm:unlabeled-div-14" class="example"><strong>(#exm:unlabeled-div-14) </strong></span><strong>More on Smoking &amp; Lung Cancer</strong>, <span class="citation"><a href="#ref-iscam" role="doc-biblioref">Chance and Rossman</a> (<a href="#ref-iscam" role="doc-biblioref">2018</a>)</span><br />
Now we have a cohort prospective study. (Previously we had a case-control retrospective study). Now do we have baseline risk estimates? Yes! But be careful, we can’t conclude causation, because the study is still observational.</p>
</div>
</div>
</div>
<div id="ciOR" class="section level3" number="4.4.5">
<h3 number="4.4.5"><span class="header-section-number">4.4.5</span> Confidence Interval for OR</h3>
<p>Due to some theory that we won’t cover:</p>
<p><span class="math display">\[\begin{eqnarray*}
SE(\ln (\hat{OR})) &amp;\approx&amp; \sqrt{\frac{1}{n_1 \hat{p}_1 (1-\hat{p}_1)} + \frac{1}{n_2 \hat{p}_2 (1-\hat{p}_2)}}
\end{eqnarray*}\]</span></p>
<p>Note that your book introduces <span class="math inline">\(SE(\ln(\hat{OR}))\)</span> in the context of hypothesis testing where the null, <span class="math inline">\(H_0: p_1 = p_2\)</span>, is assumed to be true. If the null is true, you’d prefer an estimate for the proportion of success to be based on the entire sample:</p>
<p><span class="math display">\[\begin{eqnarray*}
SE(\ln (\hat{OR})) &amp;\approx&amp; \sqrt{\frac{1}{n_1 \hat{p} (1-\hat{p})} + \frac{1}{n_2 \hat{p}(1-\hat{p})}}
\end{eqnarray*}\]</span></p>
<p>So, a <span class="math inline">\((1-\alpha)100\%\)</span> CI for the <span class="math inline">\(\ln(OR)\)</span> is:
<span class="math display">\[\begin{eqnarray*}
\ln(\hat{OR}) \pm z_{1-\alpha/2} SE(\ln(\hat{OR}))
\end{eqnarray*}\]</span></p>
<p>Which gives a <span class="math inline">\((1-\alpha)100\%\)</span> CI for the <span class="math inline">\(OR\)</span>:
<span class="math display">\[\begin{eqnarray*}
(e^{\ln(\hat{OR}) - z_{1-\alpha/2} SE(\ln(\hat{OR}))}, e^{\ln(\hat{OR}) + z_{1-\alpha/2} SE(\ln(\hat{OR}))})
\end{eqnarray*}\]</span></p>
<p>Back to the example… <span class="math inline">\(OR = 28.9.\)</span>
<span class="math display">\[\begin{eqnarray*}
SE(\ln(\hat{OR})) &amp;=&amp; \sqrt{\frac{1}{182*0.67*(1-0.67)} + \frac{1}{122*0.0656*(1-0.0656)}}\\
&amp;=&amp; 0.398\\
90\% \mbox{ CI for } \ln(OR) &amp;&amp; \ln(28.9) \pm 1.645 \cdot 0.398\\
&amp;&amp; 3.366 \pm 1.645 \cdot 0.398\\
&amp;&amp; (2.71, 4.02)\\
90\% \mbox{ CI for } OR &amp;&amp; (e^{2.71}, e^{4.02})\\
&amp;&amp; (15.04, 55.47)\\
\end{eqnarray*}\]</span></p>
<p>We are 90% confident that the true <span class="math inline">\(\ln(OR)\)</span> is between 2.71 and 4.02. We are 90% confident that the true <span class="math inline">\(OR\)</span> is between 15.04 and 55.47. That is, the true odds of getting lung cancer if you smoke are somewhere between 15.04 and 55.47 times higher than if you don’t smoke, with 90% confidence.</p>
<p>Note 1: we use the theory which allows us to understand the sampling distribution for the <span class="math inline">\(\ln(\hat{OR}).\)</span> We use the <em>process</em> for creating CIs to transform back to <span class="math inline">\(OR\)</span>.</p>
<p>Note 2: We do not use the t-distribution here because we are not estimating the population standard deviation.</p>
<p>Note 3: There are not good general guidelines for checking whether the sample sizes are large enough for the normal approximation. Most authorities agree that one can get away with smaller sample sizes here than for the differences of two proportions. If the sample sizes pass the rough check discussed for <span class="math inline">\(\chi^2\)</span>, they should be large enough to support inferences based on the approximate normality of the log of the estimated odds ratio, too. <span class="citation">(<a href="#ref-sleuth" role="doc-biblioref">Ramsey and Schafer 2012, 541</a>)</span></p>
<p>For the normal approximation to hold, we need the expected counts in each cell to be at least 5. <span class="citation">(<a href="#ref-pagano" role="doc-biblioref">Pagano and Gauvreau 2000, 355</a>)</span></p>
<p>Note 4: If any of the cells are zero, many people will add 0.5 to that cell’s observed value.</p>
<p>Note 5: The OR will always be more extreme than the RR (one more reason to be careful…)</p>
<p><span class="math display">\[\begin{eqnarray*}
\mbox{assume } &amp;&amp; \frac{X_1 / n_1}{X_2 / n_2} = RR &gt; 1\\
&amp; &amp; \\
\frac{X_1}{n_1} &amp;=&amp; RR \ \ \frac{X_2}{n_2}\\
\frac{X_1}{n_1 - X_1} &amp;=&amp; RR \ \ \bigg( \frac{n_1}{n_2}  \frac{n_2 - X_2}{n_1 - X_1} \bigg) \frac{X_2}{n_2-X_2}\\
OR &amp;=&amp; RR \ \ \bigg(\frac{n_1}{n_2} \bigg) \frac{n_2 - X_2}{n_1 - X_1}\\
 &amp;=&amp; RR \ \ \bigg(\frac{1/n_2}{1/n_1} \bigg) \frac{n_2 - X_2}{n_1 - X_1}\\
 &amp;=&amp; RR  \ \ \frac{1 - X_2/n_2}{1 - X_1/n_1}\\
 &amp; &gt; &amp; RR
\end{eqnarray*}\]</span>
[<span class="math inline">\(1 - \frac{X_2}{n_2} &gt; 1 - \frac{X_1}{n_1} \rightarrow \frac{1 - \frac{X_2}{n_2}}{1 - \frac{X_1}{n_1}} &gt; 1\)</span>]</p>
<p>Note 6: <span class="math inline">\(RR \approx OR\)</span> if the risk is small (the denominator of the OR will be very similar to the denominator of the RR).</p>
</div>
</div>
<div id="studies" class="section level2" number="4.5">
<h2 number="4.5"><span class="header-section-number">4.5</span> Types of Studies</h2>
<p>(Section 6.9 of <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>.)</p>
<div class="definition">
<p><span id="def:unlabeled-div-15" class="definition"><strong>(#def:unlabeled-div-15) </strong></span><strong>Explanatory variable</strong> is one that is a potential explanation for any changes in the response variable.</p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-16" class="definition"><strong>(#def:unlabeled-div-16) </strong></span><strong>Response variable</strong> is the measured outcome of interest.</p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-17" class="definition"><strong>(#def:unlabeled-div-17) </strong></span><strong>Case-control study:</strong> identify observational units by response</p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-18" class="definition"><strong>(#def:unlabeled-div-18) </strong></span><strong>Cohort study:</strong> identify observational units by explanatory variable</p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-19" class="definition"><strong>(#def:unlabeled-div-19) </strong></span><strong>Cross-classification study:</strong> identify observational units regardless of levels of the variable.</p>
</div>
<div id="retrospective-versus-prospective-studies" class="section level3" number="4.5.1">
<h3 number="4.5.1"><span class="header-section-number">4.5.1</span> Retrospective versus Prospective Studies</h3>
<p>After much research (and asking many people who do not all agree!), I finally came across a definition of retrospective that I like. Note, however, that many many books <em>define</em> retrospective as synonymous with case-control. That is, they define a retrospective study to be one in which the observational units were chosen based on their status of the response variable. I disagree with that definition. As you see below, retrospective studies are defined based on the when the variables were <em>measured</em>. I’ve also given a quote from the Kuiper text where retrospective is defined as any study where historic data are collected (I like this definition less).</p>
<div class="definition">
<p><span id="def:unlabeled-div-20" class="definition"><strong>(#def:unlabeled-div-20) </strong></span>A <strong>prospective</strong> study watches for outcomes, such as the development of a disease, during the study period. The explanatory variables are <em>measured</em> before the response variable occurs.</p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-21" class="definition"><strong>(#def:unlabeled-div-21) </strong></span>A <strong>retrospective</strong> study looks backwards and examines exposures to suspected risk or protection factors in relation to an outcome that is established at the start of the study. The explanatory variables are <em>measured</em> after the response has happened.</p>
</div>
<blockquote>
<p>Studies can be classified further as either prospective or retrospective. We define a prospective study as one in which exposure and covariate measurements are made before the cases of illness occur. In a retrospective study these measurements are made after the cases have already occurred… Early writers referred to cohort studies as prospective studies and to case-control studies as retrospective studies because cohort studies usually begin with identification of the exposure status and then measure disease occurrence, whereas case-control studies usually begin by identifying cases and controls and then measure exposure status. The terms prospective and retrospective, however, are more usefully employed to describe the <strong>timing of disease occurrence with respect to exposure measurement</strong>. For example, case-control studies can be either prospective or retrospective. A prospective case-control study uses exposure measurements taken before disease, whereas a retrospective case-control study uses measurements taken after disease. <span class="citation">(<a href="#ref-modepi" role="doc-biblioref">Rothman and Greenland 1998, 74</a>)</span></p>
</blockquote>
<blockquote>
<p>Retrospective cohort studies also exist. In these designs past (medical) records are often used to collect data. As with prospective cohort studies, the objective is still to first establish groups based on an explanatory variable. However since these are past records the response variable can be collected at the same time. <span class="citation">(<a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar 2013, chap. 6</a>, page 24)</span></p>
</blockquote>
<p>Understanding if a study is retrospective or prospective leads to having a sense of the biases within a study.</p>
<ul>
<li>The retrospective aspect may introduce selection bias and misclassification or information bias. With retrospective studies, the temporal relationship is frequently difficult to assess.</li>
</ul>
<div id="disadvantages-of-prospective-cohort-studies" class="section level4 unnumbered">
<h4 class="unnumbered">Disadvantages of Prospective Cohort Studies</h4>
<ul>
<li>You may have to follow large numbers of subjects for a long time.<br />
</li>
<li>They can be very expensive and time consuming.<br />
</li>
<li>They are not good for rare diseases.<br />
</li>
<li>They are not good for diseases with a long latency.<br />
</li>
<li>Differential loss to follow up can introduce bias.</li>
</ul>
</div>
<div id="disadvantages-of-retrospective-cohort-studies" class="section level4 unnumbered">
<h4 class="unnumbered">Disadvantages of Retrospective Cohort Studies</h4>
<ul>
<li>As with prospective cohort studies, they are not good for very rare diseases.</li>
<li>If one uses records that were not designed for the study, the available data may be of poor quality.</li>
<li>There is frequently an absence of data on potential confounding factors if the data was recorded in the past.</li>
<li>It may be difficult to identify an appropriate exposed cohort and an appropriate comparison group.</li>
<li>Differential losses to follow up can also bias retrospective cohort studies.</li>
</ul>
<p>Disadvantages from: <a href="http://sphweb.bumc.bu.edu/otlt/MPH-Modules/EP/EP713_CohortStudies/EP713_CohortStudies5.html" class="uri">http://sphweb.bumc.bu.edu/otlt/MPH-Modules/EP/EP713_CohortStudies/EP713_CohortStudies5.html</a></p>
<div id="examples-of-studies" class="section level5 unnumbered">
<h5 class="unnumbered">Examples of studies:</h5>
<ul>
<li>cross-classification, prospective: NHANES<br />
</li>
<li>cross-classification, retrospective: death records (if exposure is measured post-hoc)<br />
</li>
<li>case-control, prospective: the investigator still <em>enrolls</em> based on outcome status, but the investigator must wait for the cases to occur<br />
</li>
<li>case-control, retrospective: at the start of the study, all cases have already occurred and the investigator goes back to measure the exposure (explanatory) variable<br />
</li>
<li>cohort, prospective: follows the selected participants to assess the proportion who develop the disease of interest<br />
</li>
<li>cohort, retrospective: the exposure and outcomes have already happened (i.e., death records)</li>
</ul>
</div>
</div>
<div id="which-test" class="section level4 unnumbered">
<h4 class="unnumbered">Which test?</h4>
<p>(Section 6.1 of <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>.)</p>
<p>It turns out that the tests above (independence, homogeneity of proportions, homogeneity of odds) are typically equivalent with respect to their conclusions. However, they each have particular conditions related to what they are testing, but that we can generally use any of them for our hypotheses of interest. However, we need to be very careful about our <strong>interpretations</strong>!</p>
<p>(No goodness of fit, section 6.11 of <span class="citation"><a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar</a> (<a href="#ref-KuiperSklar" role="doc-biblioref">2013</a>)</span>.)</p>
</div>
</div>
</div>
<div id="r-example-categorical-data-botox-and-back-pain" class="section level2" number="4.6">
<h2 number="4.6"><span class="header-section-number">4.6</span> R Example (categorical data): Botox and back pain</h2>
<div id="entering-and-visualizing-the-data" class="section level3" number="4.6.1">
<h3 number="4.6.1"><span class="header-section-number">4.6.1</span> Entering and visualizing the data</h3>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>backpain <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">treatment =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;placebo&quot;</span>, <span class="dv">16</span>), <span class="fu">rep</span>(<span class="st">&quot;Botox&quot;</span>, <span class="dv">15</span>)),</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">outcome =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;reduction&quot;</span>, <span class="dv">2</span>), <span class="fu">rep</span>(<span class="st">&quot;no reduction&quot;</span>, <span class="dv">14</span>), </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>                                 <span class="fu">rep</span>(<span class="st">&quot;reduction&quot;</span>, <span class="dv">9</span>), <span class="fu">rep</span>(<span class="st">&quot;no reduction&quot;</span>, <span class="dv">6</span>)))</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>backpain <span class="sc">%&gt;%</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>()</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          outcome</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; treatment no reduction reduction</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Botox              6         9</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   placebo           14         2</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>backpain <span class="sc">%&gt;%</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> treatment)) <span class="sc">+</span> </span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="fu">aes</span>(<span class="at">fill =</span> outcome), <span class="at">position =</span> <span class="st">&quot;fill&quot;</span>) <span class="sc">+</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;percentage&quot;</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>backpain <span class="sc">%&gt;%</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> treatment)) <span class="sc">+</span> </span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="fu">aes</span>(<span class="at">fill =</span> outcome))</span></code></pre></div>
<p><img src="04-cat_files/figure-html/unnamed-chunk-6-1.png" width="80%" style="display: block; margin: auto;" /><img src="04-cat_files/figure-html/unnamed-chunk-6-2.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="fishers-exact-test" class="section level3" number="4.6.2">
<h3 number="4.6.2"><span class="header-section-number">4.6.2</span> Fisher’s Exact Test</h3>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>backpain <span class="sc">%&gt;%</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>() <span class="sc">%&gt;%</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fisher.test</span>()</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Fisher&#39;s Exact Test for Count Data</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; data:  .</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; p-value = 0.009</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; alternative hypothesis: true odds ratio is not equal to 1</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 95 percent confidence interval:</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  0.00848 0.71071</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; sample estimates:</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; odds ratio </span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      0.104</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co"># their CI is an inversion of the HT</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co"># an approximate SE for the ln(OR) is given by:</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>se.lnOR <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">/</span>(<span class="dv">16</span><span class="sc">*</span>(<span class="dv">2</span><span class="sc">/</span><span class="dv">16</span>)<span class="sc">*</span>(<span class="dv">14</span><span class="sc">/</span><span class="dv">16</span>)) <span class="sc">+</span> <span class="dv">1</span><span class="sc">/</span>(<span class="dv">15</span><span class="sc">*</span>(<span class="dv">9</span><span class="sc">/</span><span class="dv">15</span>)<span class="sc">*</span>(<span class="dv">6</span><span class="sc">/</span><span class="dv">15</span>)))</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>se.lnOR</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.922</span></span></code></pre></div>
</div>
<div id="chi-squared-analysis" class="section level3" number="4.6.3">
<h3 number="4.6.3"><span class="header-section-number">4.6.3</span> Chi-squared Analysis</h3>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>backpain <span class="sc">%&gt;%</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">table</span>() <span class="sc">%&gt;%</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">chisq.test</span>()</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Pearson&#39;s Chi-squared test with Yates&#39; continuity correction</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; data:  .</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; X-squared = 6, df = 1, p-value = 0.02</span></span></code></pre></div>
<!--chapter:end:04-cat.Rmd-->
</div>
</div>
</div>
<div id="logistic-regression" class="section level1" number="5">
<h1 number="5"><span class="header-section-number">5</span> Logistic Regression</h1>
<div id="logmodel" class="section level2" number="5.1">
<h2 number="5.1"><span class="header-section-number">5.1</span> Motivation for Logistic Regression</h2>
<p>During investigation of the US space shuttle <em>Challenger</em> disaster, it was learned that project managers had judged the probability of mission failure to be 0.00001, whereas engineers working on the project had estimated failure probability at 0.005. The difference between these two probabilities, 0.00499 was discounted as being too small to worry about. Is a different picture provided by considering odds? How is it interpreted?</p>
<p>The logistic regression model is a <em>generalized</em> linear model. That is, a linear model as a function of the expected value of the response variable. We can now model binary response variables.
<span class="math display">\[\begin{align}
GLM: g(E[Y | X]) = \beta_0 + \beta_1 X
\end{align}\]</span>
where <span class="math inline">\(g(\cdot)\)</span> is the link function. For logistic regression, we use the logit link function:
<span class="math display">\[\begin{align}
\mbox{logit} (p) = \ln \bigg( \frac{p}{1-p} \bigg)
\end{align}\]</span></p>
<div id="ex:burnexamp" class="section level4" number="5.1.0.1">
<h4 number="5.1.0.1"><span class="header-section-number">5.1.0.1</span> Surviving Third-degree Burns</h4>
<p>These data refer to 435 adults who were treated for third-degree burns by the University of Southern California General Hospital Burn Center. The patients were grouped according to the area of third-degree burns on the body (measured in square cm). In the table below are recorded, for each midpoint of the groupings <code>log(area +1)</code>, the number of patients in the corresponding group who survived, and the number who died from the burns. <span class="citation">(<a href="#ref-burn" role="doc-biblioref">Fan, Heckman, and Wand 1995</a>)</span></p>
<table>
<thead>
<tr class="header">
<th align="center">log(area+1) midpoint</th>
<th align="center">survived</th>
<th align="center">died</th>
<th align="center">prop surv</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1.35</td>
<td align="center">13</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">1.60</td>
<td align="center">19</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">1.75</td>
<td align="center">67</td>
<td align="center">2</td>
<td align="center">0.971</td>
</tr>
<tr class="even">
<td align="center">1.85</td>
<td align="center">45</td>
<td align="center">5</td>
<td align="center">0.900</td>
</tr>
<tr class="odd">
<td align="center">1.95</td>
<td align="center">71</td>
<td align="center">8</td>
<td align="center">0.899</td>
</tr>
<tr class="even">
<td align="center">2.05</td>
<td align="center">50</td>
<td align="center">20</td>
<td align="center">0.714</td>
</tr>
<tr class="odd">
<td align="center">2.15</td>
<td align="center">35</td>
<td align="center">31</td>
<td align="center">0.530</td>
</tr>
<tr class="even">
<td align="center">2.25</td>
<td align="center">7</td>
<td align="center">49</td>
<td align="center">0.125</td>
</tr>
<tr class="odd">
<td align="center">2.35</td>
<td align="center">1</td>
<td align="center">12</td>
<td align="center">0.077</td>
</tr>
</tbody>
</table>
<p><img src="05-log_files/figure-html/unnamed-chunk-2-1.png" width="95%" style="display: block; margin: auto;" /></p>
<p>We can see that the logit transformation linearizes the relationship.</p>
<p>A first idea might be to model the relationship between the probability of success (that the patient survives) and the explanatory variable <code>log(area +1)</code> as a simple linear regression model. However, the scatterplot of the proportions of patients surviving a third-degree burn against the explanatory variable shows a distinct curved relationship between the two variables, rather than a linear one. It seems that a transformation of the data is in place.</p>
<p>The functional form relating x and the probability of success looks like it could be an <code>S</code> shape. But we’d have to do some work to figure out what the form of that <code>S</code> looks like. Below I’ve given some different relationships between x and the probability of success using <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> values that are yet to be defined. Regardless, we can see that by tuning the functional relationship of the <code>S</code> curve, we can get a good fit to the data.</p>
<p><img src="05-log_files/figure-html/unnamed-chunk-3-1.png" width="95%" style="display: block; margin: auto;" /></p>
<p>S-curves ( <code>y = exp(linear) / (1+exp(linear))</code> ) for a variety of different parameter settings. Note that the x-axis is some continuous variable <code>x</code> while the y-axis is the probability of success at that value of <code>x</code>. More on this as we move through this model.</p>
<p>Why doesn’t linear regression work here?</p>
<ul>
<li>The response isn’t normal<br />
</li>
<li>The response isn’t linear (until we transform)<br />
</li>
<li>The predicted values go outside the bounds of (0,1)<br />
</li>
<li>Note: it <em>does</em> work to think about values inside (0,1) as probabilities</li>
</ul>
</div>
<div id="the-logistic-model" class="section level3" number="5.1.1">
<h3 number="5.1.1"><span class="header-section-number">5.1.1</span> The logistic model</h3>
<p>Instead of trying to model the using <em>linear regression</em>, let’s say that we consider the relationship between the variable <span class="math inline">\(x\)</span> and the probability of success to be given by the following generalized linear model. (The logistic model is just one model, there isn’t anything magical about it. We do have good reasons for how we defined it, but that doesn’t mean there aren’t other good ways to model the relationship.)</p>
<p><span class="math display">\[\begin{align}
p(x) = \frac{e^{\beta_0 + \beta_1 x}}{1+e^{\beta_0 + \beta_1 x}}
\end{align}\]</span>
Where <span class="math inline">\(p(x)\)</span> is the probability of success (here surviving a burn). <span class="math inline">\(\beta_1\)</span> still determines the direction and <em>slope</em> of the line. <span class="math inline">\(\beta_0\)</span> now determines the location (median survival).</p>
<ul>
<li><p><strong>Note 1</strong> What is the probability of success for a patient with covariate of <span class="math inline">\(x = -\beta_0 / \beta_1\)</span>?<br />
<span class="math display">\[\begin{align}
x &amp;= - \beta_0 / \beta_1\\
\beta_0 + \beta_1 x &amp;= 0\\
e^{0} &amp;= 1\\
p(-\beta_0 / \beta_1) &amp;= p(x) = 0.5
\end{align}\]</span>
(for a given <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_0\)</span> determines the median survival value)</p></li>
<li><p><strong>Note 2</strong> If <span class="math inline">\(x=0\)</span>,
<span class="math display">\[\begin{align}
p(0) = \frac{e^{\beta_0}}{1+e^{\beta_0}}
\end{align}\]</span>
<span class="math inline">\(x=0\)</span> can often be thought of as the baseline condition, and the probability at <span class="math inline">\(x=0\)</span> takes the place of thinking about the intercept in a linear regression.</p></li>
<li><p><strong>Note 3</strong><br />
<span class="math display">\[\begin{align}
1 - p(x) = \frac{1}{1+e^{\beta_0 + \beta_1 x}}
\end{align}\]</span><br />
gives the probability of failure.
<span class="math display">\[\begin{align}
\frac{p(x)}{1-p(x)} = e^{\beta_0 + \beta_1 x}
\end{align}\]</span><br />
gives the odds of success.
<span class="math display">\[\begin{align}
\ln \bigg( \frac{p(x)}{1-p(x)} \bigg) = \beta_0 + \beta_1 x
\end{align}\]</span><br />
gives the <span class="math inline">\(\ln\)</span> odds of success .</p></li>
<li><p><strong>Note 4</strong> Every type of generalized linear model has a link function. Ours is called the <em>logit</em>. The link is the relationship between the response variable and the <em>linear</em> function in x.
<span class="math display">\[\begin{align}
\mbox{logit}(\star) = \ln \bigg( \frac{\star}{1-\star} \bigg) \ \ \ \ 0 &lt; \star &lt; 1
\end{align}\]</span></p></li>
</ul>
<div id="model-assumptions" class="section level4" number="5.1.1.1">
<h4 number="5.1.1.1"><span class="header-section-number">5.1.1.1</span> model assumptions</h4>
<p>Just like in linear regression, our <code>Y</code> response is the only random component.</p>
<p><span class="math display">\[\begin{align}
y &amp;= \begin{cases}
1 &amp; \mbox{ died}\\
0 &amp; \mbox{ survived}
\end{cases}
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
Y &amp;\sim \mbox{Bernoulli}(p)\\
P(Y=y) &amp;= p^y(1-p)^{1-y}
\end{align}\]</span></p>
<!--
%\begin{align}
%Y &\sim \mbox{Binomial}(m,p)\\
%P(Y=y) &= {m \choose y}p^y(1-p)^{m-y}\\
%E(Y/m) &= p\\
%E(Y) &= m p\\
%Var(Y) &= m p (1-p)
%\end{align}
-->
<p>When each person is at risk for a different covariate (i.e., explanatory variable), they each end up with a different probability of success.
<span class="math display">\[\begin{align}
Y_i \sim \mbox{Bernoulli} \bigg( p(x_i) = \frac{e^{\beta_0 + \beta_1 x_i}}{1+ e^{\beta_0 + \beta_1 x_i}}\bigg)
\end{align}\]</span></p>
<ul>
<li>independent trials<br />
</li>
<li>success / failure<br />
</li>
<li>probability of success is constant for a particular <span class="math inline">\(X\)</span>.<br />
</li>
<li><span class="math inline">\(E[Y|x] = p(x)\)</span> is given by the logistic function</li>
</ul>
</div>
<div id="interpreting-coefficients" class="section level4" number="5.1.1.2">
<h4 number="5.1.1.2"><span class="header-section-number">5.1.1.2</span> interpreting coefficients</h4>
<p>Let’s say the log odds of survival for given observed (log) burn areas <span class="math inline">\(x\)</span> and <span class="math inline">\(x+1\)</span> are:
<span class="math display">\[\begin{align}
\mbox{logit}(p(x)) &amp;= \beta_0 + \beta_1 x\\
\mbox{logit}(p(x+1)) &amp;= \beta_0 + \beta_1 (x+1)\\
\beta_1 &amp;= \mbox{logit}(p(x+1)) - \mbox{logit}(p(x))\\
&amp;= \ln \bigg(\frac{p(x+1)}{1-p(x+1)} \bigg) -  \ln \bigg(\frac{p(x)}{1-p(x)} \bigg)\\
&amp;= \ln \bigg( \frac{p(x+1) / [1-p(x+1)]}{p(x) / [1-p(x)]} \bigg)\\
e^{\beta_1} &amp;= \bigg( \frac{p(x+1) / [1-p(x+1)]}{p(x) / [1-p(x)]} \bigg)\\
\end{align}\]</span></p>
<p><span class="math inline">\(e^{\beta_1}\)</span> is the <em>odds ratio</em> for dying associated with a one unit increase in x. [<span class="math inline">\(\beta_1\)</span> is the change in log-odds associated with a one unit increase in x.</p>
<p><span class="math display">\[\begin{align}
\mbox{logit} (\hat{p}) = 22.708 - 10.662 \cdot \ln(\mbox{ area }+1).
\end{align}\]</span></p>
<p>(Suppose we are interested in comparing the odds of surviving third-degree burns for patients with burns corresponding to <code>log(area +1)= 1.90</code>, and patients with burns corresponding
to <code>log(area +1)= 2.00</code>. The odds ratio <span class="math inline">\(\hat{OR}_{1.90, 2.00}\)</span> is given by
<span class="math display">\[\begin{align}
\hat{OR}_{1.90, 2.00} = e^{-10.662} (1.90-2.00) = e^{1.0662} = 2.904
\end{align}\]</span>
That is, the odds of survival for a patient with <code>log(area+1)= 1.90</code> is 2.9 times higher than the odds of survival for a patient with <code>log(area+1)= 2.0</code>.)</p>
<p>What about the RR (relative risk) or difference in risks? It won’t be constant for a given <span class="math inline">\(X\)</span>, so it must be calculated as a function of <span class="math inline">\(X\)</span>.</p>
</div>
</div>
<div id="constant-or-varying-rr" class="section level3" number="5.1.2">
<h3 number="5.1.2"><span class="header-section-number">5.1.2</span> constant OR, varying RR</h3>
<p>The previous model specifies that the OR is constant for any value of <span class="math inline">\(X\)</span> which is not true about RR. Using the burn data, convince yourself that the RR isn’t constant. Try computing the RR at 1.5 versus 2.5, then again at 1 versus 2.
<span class="math display">\[\begin{align}
\mbox{logit} (\hat{p}) &amp;= 22.708 - 10.662 \cdot \ln(\mbox{ area }+1)\\
\hat{p}(x) &amp;= \frac{e^{22.708 - 10.662 x}}{1+e^{22.708 - 10.662 x}}\\
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\hat{p}(1) &amp;= 0.9999941\\
\hat{p}(1.5) &amp;= 0.9987889\\
\hat{p}(2) &amp;= 0.7996326\\
\hat{p}(2.5) &amp;= 0.01894664\\
\hat{RR}_{1, 2} &amp;= 1.250567\\
\hat{RR}_{1.5, 2.5} &amp;= 52.71587\\
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
\hat{RR} &amp;= \frac{\frac{e^{b_0 + b_1 x}}{1+e^{b_0 + b_1 x}}}{\frac{e^{b_0 + b_1 (x+1)}}{1+e^{b_0 + b_1 (x+1)}}}\\
&amp;= \frac{\frac{e^{b_0}e^{b_1 x}}{1+e^{b_0}e^{b_1 x}}}{\frac{e^{b_0} e^{b_1 x} e^{b_1}}{1+e^{b_0}e^{b_1 x} e^{b_1}}}\\
&amp;= \frac{1+e^{b_0}e^{b_1 x}e^{b_1}}{e^{b_1}(1+e^{b_0}e^{b_1 x})}\\
\end{align}\]</span>
(see log-linear model below, @ref(altmodels) )</p>
<div id="altmodels" class="section level4" number="5.1.2.1">
<h4 number="5.1.2.1"><span class="header-section-number">5.1.2.1</span> Alternative strategies for binary outcomes</h4>
<p>It is quite common to have binary outcomes (response variable) in the medical literature. However, the logit link (logistic regression) is only one of a variety of models that we can use. We see above that the logistic model imposes a constant OR for any value of <span class="math inline">\(X\)</span> (and <em>not</em> a constant RR).</p>
<ul>
<li><strong>complementary log-log</strong><br />
The complementary log-log model is used when you have a rate of, for example, infection, model by instances of contact (based on a Poisson model).
<span class="math display">\[\begin{align}
p(k) &amp;= 1-(1-\lambda)^k\\
\ln[ - \ln (1-p(k))] &amp;= \ln[-\ln(1-\lambda)] + \ln(k)\\
\ln[ - \ln (1-p(k))] &amp;= \beta_0 + 1 \cdot \ln(k)\\
\ln[ - \ln (1-p(k))] &amp;= \beta_0 + \beta_1 x\\
p(x) &amp;= 1 - \exp [ -\exp(\beta_0 + \beta_1 x) ]
\end{align}\]</span></li>
<li><strong>linear</strong><br />
The excess (or additive) risk model can modeled by using simple linear regression:
<span class="math display">\[\begin{align}
p(x) &amp;= \beta_0 + \beta_1 x
\end{align}\]</span>
which we have already seen is problematic for a variety of reasons. However, any <strong>unit increase in <span class="math inline">\(x\)</span> gives a <span class="math inline">\(\beta_1\)</span> increase in the risk</strong> (for <em>all</em> values of <span class="math inline">\(x\)</span>).</li>
<li><strong>log-linear</strong><br />
As long as we do not have a case-control study, we can model the risk using a log-linear model.
<span class="math display">\[\begin{align}
\ln (p(x)) = \beta_0 + \beta_1 x
\end{align}\]</span>
The regression coefficient, <span class="math inline">\(\beta_1\)</span>, has the interpretation of the <strong>logarithm of the relative risk associated with a unit increase in <span class="math inline">\(x\)</span></strong>. Although many software programs will fit this model, it may present numerical difficulties because of the constraint that the sum of terms on the right-hand side must be no greater than zero for the results to make sense (due to the constraint that the outcome probability p(x) must be in the interval [0,1]). As a result, convergence of standard fitting algorithms may be unreliable in some cases.</li>
</ul>
</div>
</div>
</div>
<div id="logMLE" class="section level2" number="5.2">
<h2 number="5.2"><span class="header-section-number">5.2</span> Estimating coefficients in logistic regression</h2>
<div id="maximum-likelihood-estimation" class="section level3" number="5.2.1">
<h3 number="5.2.1"><span class="header-section-number">5.2.1</span> Maximum Likelihood Estimation</h3>
<p>Recall how we estimated the coefficients for linear regression. The values of <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are those that minimize the residual sum of squares:
<span class="math display">\[\begin{align}
RSS &amp;= \sum_i (Y_i - \hat{Y}_i)^2\\
 &amp;= \sum_i (Y_i - (\beta_0 + \beta_1 X_i))^2
\end{align}\]</span>
That is, we take derivatives with respect to both <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, set them equal to zero (take second derivatives to ensure minimums), and solve to get <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>. It turns out that we’ve also <em>maximized the normal likelihood</em>.
<span class="math display">\[\begin{align}
L(\underline{y} | \beta_0, \beta_1, \underline{x}) &amp;= \prod_i \frac{1}{\sqrt{2 \pi \sigma^2}} e^{(y_i - \beta_0 - \beta_1 x_i)^2 / 2 \sigma}\\
&amp;= \bigg( \frac{1}{2 \pi \sigma^2} \bigg)^{n/2} e^{\sum_i (y_i - \beta_0 - \beta_1 x_i)^2 / 2 \sigma}\\
\end{align}\]</span></p>
<p>What does that even mean? Likelihood? Maximizing the likelihood? WHY??? The likelihood is the probability distribution of the data given <em>specific</em> values of the unknown parameters.</p>
<p>Consider a toy example where you take a sample of size 4 from a binary population (e.g., flipping a coin that has probability heads of <span class="math inline">\(p\)</span>) and get: failure, success, failure, failure (FSFF).</p>
<p>Would you guess <span class="math inline">\(p=0.49\)</span>?? No, you would guess <span class="math inline">\(p=0.25\)</span>… you <em>maximized</em> the likelihood of <strong>seeing your data</strong>.
<span class="math display">\[\begin{align}
P(FSFF| p) &amp;=  p^1 (1-p)^{4-1}\\
P(FSFF | p = 0.90) &amp;= 0.0009 \\
P(FSFF | p = 0.75) &amp;= 0.0117 \\
P(FSFF | p = 0.50) &amp;= 0.0625\\
P(FSFF | p = 0.25) &amp;= 0.105\\
P(FSFF | p = 0.15) &amp;= 0.092\\
P(FSFF | p = 0.05) &amp;= 0.043\\
\end{align}\]</span></p>
<p>Think about the example as a set of independent binary responses, <span class="math inline">\(Y_1, Y_2, \ldots Y_n\)</span>. Since each observed response is independent and follows the Bernoulli distribution, the probability of a particular outcome can be found as:
<span class="math display">\[\begin{align}
P(Y_1=y_1, Y_2=y_2, \ldots, Y_n=y_n) &amp;= P(Y_1=y_1) P(Y_2 = y_2) \cdots P(Y_n = y_n)\\
&amp;= p^{y_1}(1-p)^{1-y_1} p^{y_2}(1-p)^{1-y_2} \cdots p^{y_n}(1-p)^{1-y_n}\\
&amp;= p^{\sum_i y_i} (1-p)^{\sum_i (1-y_i)}\\
\end{align}\]</span>
where <span class="math inline">\(y_1, y_2, \ldots, y_n\)</span> represents a particular observed series of 0 or 1 outcomes and <span class="math inline">\(p\)</span> is a probability <span class="math inline">\(0 \leq p \leq 1\)</span>. Once <span class="math inline">\(y_1, y_2, \ldots, y_n\)</span> have been observed, they are fixed values. Maximum likelihood estimates are functions of sample data that are derived by finding the value of <span class="math inline">\(p\)</span> that maximizes the likelihood functions.</p>
<p>To maximize the likelihood, we use the natural log of the likelihood (because we know we’ll get the same answer):
<span class="math display">\[\begin{align}
\ln L(p) &amp;= \ln \Bigg(p^{\sum_i y_i} (1-p)^{\sum_i (1-y_i)} \Bigg)\\
&amp;= \sum_i y_i \ln(p) + (n- \sum_i y_i) \ln (1-p)\\
\frac{ \partial \ln L(p)}{\partial p} &amp;= \sum_i y_i \frac{1}{p} + (n - \sum_i y_i) \frac{-1}{(1-p)} = 0\\
0 &amp;= (1-p) \sum_i y_i + p (n-\sum_i y_i) \\
\hat{p} &amp;= \frac{ \sum_i y_i}{n}
\end{align}\]</span></p>
<p>Using the logistic regression model makes the likelihood substantially more complicated because the probability of success changes for each individual. Recall:
<span class="math display">\[\begin{align}
p_i = p(x_i) &amp;= \frac{e^{\beta_0 + \beta_1 x_i}}{1+e^{\beta_0 + \beta_1 x_i}}
\end{align}\]</span>
which gives a likelihood of:
<span class="math display">\[\begin{align}
L(\beta_0,\beta_1) &amp;= \prod_i \Bigg( \frac{e^{\beta_0 + \beta_1 x_i}}{1+e^{\beta_0 + \beta_1 x_i}} \Bigg)^{y_i} \Bigg(1-\frac{e^{\beta_0 + \beta_1 x_i}}{1+e^{\beta_0 + \beta_1 x_i}} \Bigg)^{(1- y_i)} \\
\mbox{and a log likelihood of}: &amp;\\
\ln L(\beta_0, \beta_1) &amp;= \sum_i y_i \ln\Bigg( \frac{e^{\beta_0 + \beta_1 x_i}}{1+e^{\beta_0 + \beta_1 x_i}} \Bigg) + (1-  y_i) \ln \Bigg(1-\frac{e^{\beta_0 + \beta_1 x_i}}{1+e^{\beta_0 + \beta_1 x_i}} \Bigg)\\
\end{align}\]</span></p>
<p>To find <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> we actually use numerical optimization techniques to maximize <span class="math inline">\(L(\beta_0,\beta_1)\)</span> (…Because using calculus won’t provide closed form solutions. Try taking derivatives and setting them equal to zero. What happens?)</p>
<p>Why use maximum likelihood estimates?</p>
<ul>
<li>Estimates are essentially unbiased.<br />
</li>
<li>We can estimate the SE (Wald estimates via Fisher Information).<br />
</li>
<li>The estimates have low variability.<br />
</li>
<li>The estimates have an approximately normal sampling distribution for large sample sizes because they are maximum likelihood estimates.<br />
</li>
<li>Though it is important to realize that we cannot find estimates in closed form.</li>
</ul>
</div>
</div>
<div id="loginf" class="section level2" number="5.3">
<h2 number="5.3"><span class="header-section-number">5.3</span> Formal Inference</h2>
<div id="wald-tests-intervals" class="section level3" number="5.3.1">
<h3 number="5.3.1"><span class="header-section-number">5.3.1</span> Wald Tests &amp; Intervals</h3>
<p>Because we will use maximum likelihood parameter estimates, we can also use large sample theory to find the SEs and consider the estimates to have normal distributions (for large sample sizes). However, <span class="citation">(<a href="#ref-menard" role="doc-biblioref">Menard 1995</a>)</span> warns that for large coefficients, standard error is inflated, lowering the Wald statistic (chi-square) value. <span class="citation">(<a href="#ref-agresti" role="doc-biblioref">Agresti 1996</a>)</span> states that the likelihood-ratio test is more reliable for small sample sizes than the Wald test.</p>
<p><span class="math display">\[\begin{align}
z = \frac{b_1 - \beta_1}{SE(b_1)}
\end{align}\]</span></p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>burnglm <span class="sc">%&gt;%</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glm</span>(burnresp<span class="sc">~</span>burnexpl, <span class="at">data =</span> ., <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>()</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)     22.7      2.27     10.0  1.23e-23</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 burnexpl       -10.7      1.08     -9.85 6.95e-23</span></span></code></pre></div>
<p><strong>Note:</strong> Although the model is a Bernoulli model and not really a binomial model (although the Bernoulli is a binomial with <span class="math inline">\(n=1\)</span>), the way to fit a logistic regression model in R is to use <code>family = "binomial"</code>. It just is what it is.</p>
</div>
<div id="likelihood-ratio-tests" class="section level3" number="5.3.2">
<h3 number="5.3.2"><span class="header-section-number">5.3.2</span> Likelihood Ratio Tests</h3>
<p><span class="math inline">\(\frac{L(p_0)}{L(\hat{p})}\)</span> gives us a sense of whether the null value or the observed value produces a higher likelihood. Recall:
<span class="math display">\[\begin{align}
L(\hat{\underline{p}}) &gt; L(p_0)
\end{align}\]</span>
always. [Where <span class="math inline">\(\hat{\underline{p}}\)</span> is the maximum likelihood estimate for the probability of success (here it will be a vector of probabilities, each based on the same MLE estimates of the linear parameters). ] The above inequality holds because <span class="math inline">\(\hat{\underline{p}}\)</span> maximizes the likelihood.</p>
<p>We can show that if <span class="math inline">\(H_0\)</span> is true,
<span class="math display">\[\begin{align}
-2 \ln \bigg( \frac{L(p_0)}{L(\hat{p})} \bigg) \sim \chi^2_1
\end{align}\]</span>
If we are testing only one parameter value. More generally,
<span class="math display">\[\begin{align}
-2 \ln \bigg( \frac{\max L_0}{\max L} \bigg) \sim \chi^2_\nu
\end{align}\]</span>
where <span class="math inline">\(\nu\)</span> is the number of extra parameters we estimate using the unconstrained likelihood (as compared to the constrained null likelihood).</p>
<div class="example">
<p><span id="exm:unlabeled-div-22" class="example"><strong>(#exm:unlabeled-div-22) </strong></span>Consider a data set with 147 people. 49 got cancer and 98 didn’t. Let’s test whether the true proportion of people who get cancer is <span class="math inline">\(p=0.25\)</span>.
<span class="math display">\[\begin{align}
H_0:&amp; p=0.25\\
H_1:&amp; p \ne 0.25\\
\hat{p} &amp;= \frac{49}{147}\\
-2 \ln \bigg( \frac{L(p_0)}{L(\hat{p})} \bigg) &amp;= -2 [ \ln (L(p_0)) - \ln(L(\hat{p}))]\\
&amp;= -2 \Bigg[ \ln \bigg( (0.25)^{y} (0.75)^{n-y} \bigg) - \ln \Bigg( \bigg( \frac{y}{n} \bigg)^{y} \bigg( \frac{(n-y)}{n} \bigg)^{n-y} \Bigg) \Bigg]\\
&amp;= -2 \Bigg[ \ln \bigg( (0.25)^{49} (0.75)^{98} \bigg) - \ln \Bigg( \bigg( \frac{1}{3} \bigg)^{49} \bigg( \frac{2}{3} \bigg)^{98} \Bigg) \Bigg]\\
&amp;= -2 [ \ln(0.0054) - \ln(0.0697) ] = 5.11\\
P( \chi^2_1 \geq 5.11) &amp;= 0.0238
\end{align}\]</span></p>
</div>
<p>But really, usually likelihood ratio tests are more interesting. In fact, usually, we use them to test whether the coefficients are zero:</p>
<p><span class="math display">\[\begin{align}
H_0: &amp; \beta_1 =0\\
H_1: &amp; \beta_1 \ne 0\\
p_0 &amp;= \frac{e^{\hat{b}_0}}{1 + e^{\hat{b}_0}}
\end{align}\]</span>
where <span class="math inline">\(\hat{b}_0\)</span> is the MLE from the logistic regression model which does not contain any explanatory variable, <span class="math inline">\(x\)</span>.</p>
<p><strong>Important note:</strong>
<span class="math display">\[\begin{align}
\mbox{deviance} = \mbox{constant} - 2 \ln(\mbox{likelihood})
\end{align}\]</span>
That is, the difference in log likelihoods will be the opposite difference in deviances:
<span class="math display">\[\begin{align}
\mbox{test stat} &amp;= \chi^2\\
&amp;= -2 \ln \bigg( \frac{L(\mbox{null value(s)})}{L(MLEs)} \bigg)\\
&amp;= -2 [ \ln(L(\mbox{null value(s)}) - \ln(L(MLEs)) ]\\
&amp;= \mbox{deviance}_0 - \mbox{deviance}_{model}\\
&amp;= \mbox{deviance}_{null} - \mbox{deviance}_{residual}\\
&amp;= \mbox{deviance}_{reduced} - \mbox{deviance}_{full}\\
\end{align}\]</span></p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>burnglm <span class="sc">%&gt;%</span> </span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glm</span>(burnresp<span class="sc">~</span>burnexpl, <span class="at">data =</span> ., <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() </span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 8</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1          525.     434  -168.  339.  347.     335.         433   435</span></span></code></pre></div>
<p><span class="math display">\[\begin{align}
\mbox{test stat} &amp;= G\\
&amp;= -2 \ln \bigg( \frac{L(\mbox{null value(s)})}{L(MLEs)} \bigg)\\
&amp;= -2 [ \ln(L(\mbox{null value(s)}) - \ln(L(MLEs)) ]\\
&amp;= \mbox{deviance}_0 - \mbox{deviance}_{model}\\
&amp;= \mbox{deviance}_{null} - \mbox{deviance}_{residual}\\
&amp;= \mbox{deviance}_{reduced} - \mbox{deviance}_{full}\\
\end{align}\]</span></p>
<p>So, the LRT here is (see columns of <code>null deviance</code> and <code>deviance</code>):
<span class="math display">\[\begin{align}
G &amp;= 525.39 - 335.23 = 190.16\\
p-value &amp;= P(\chi^2_1 \geq 190.16) = 0
\end{align}\]</span></p>
<div id="modeling-categorical-predictors-with-multiple-levels" class="section level4" number="5.3.2.1">
<h4 number="5.3.2.1"><span class="header-section-number">5.3.2.1</span> modeling categorical predictors with multiple levels</h4>
<div class="example">
<p><span id="exm:unlabeled-div-23" class="example"><strong>(#exm:unlabeled-div-23) </strong></span><strong>Snoring</strong> A study was undertaken to investigate whether snoring is related to a heart disease. In the survey, 2484 people were classified according to their proneness to snoring (never, occasionally, often, always) and whether or not they had the heart disease.</p>
<table>
<colgroup>
<col width="39%" />
<col width="60%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>disease (response variable)</td>
<td>Binary variable: having disease=1,</td>
</tr>
<tr class="even">
<td></td>
<td>not having disease=0</td>
</tr>
<tr class="odd">
<td>snoring (explanatory variable)</td>
<td>Categorical variable indicating level of snoring</td>
</tr>
<tr class="even">
<td></td>
<td>(never=1, occasionally=2, often=3 and always=4)</td>
</tr>
</tbody>
</table>
<p>Source: <span class="citation">(<a href="#ref-snoring" role="doc-biblioref">Norton and Dunn 1985</a>)</span></p>
<p><span class="math display">\[\begin{align}
X_1 = \begin{cases}
  1 &amp; \text{for occasionally} \\
  0 &amp; \text{otherwise} \\
\end{cases}
X_2 = \begin{cases}
  1 &amp; \text{for often} \\
  0 &amp; \text{otherwise} \\
\end{cases}
X_3 = \begin{cases}
  1 &amp; \text{for always} \\
  0 &amp; \text{otherwise} \\
\end{cases}
\end{align}\]</span></p>
<p>Our new model becomes:
<span class="math display">\[\begin{align}
\mbox{logit}(p) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3
\end{align}\]</span></p>
<p>We can use the drop-in-deviance test to test the effect of any or all of the parameters (of which there are now <em>four</em>) in the model.</p>
</div>
<p>See the birdnest example, @ref(birdexamp)</p>
</div>
</div>
</div>
<div id="multlog" class="section level2" number="5.4">
<h2 number="5.4"><span class="header-section-number">5.4</span> Multiple Logistic Regression</h2>
<div id="interaction" class="section level3" number="5.4.1">
<h3 number="5.4.1"><span class="header-section-number">5.4.1</span> Interaction</h3>
<p>Another worry when building models with multiple explanatory variables has to do with variables interacting. That is, for one level of a variable, the relationship of the main predictor on the response is different.</p>
<div class="example">
<p><span id="exm:unlabeled-div-24" class="example"><strong>(#exm:unlabeled-div-24) </strong></span>Consider a simple linear regression model on number of hours studied and exam grade. Then add class year to the model. There would probably be a different slope for each class year in order to model the two variables most effectively. For simplicity, consider only first year students and seniors.</p>
<p><span class="math display">\[\begin{align}
E[\mbox{grade seniors}| \mbox{hours studied}] &amp;= \beta_{0s} + \beta_{1s} \mbox{hrs}\\
E[\mbox{grade first years}| \mbox{hours studied}] &amp;= \beta_{0f} + \beta_{1f} \mbox{hrs}\\
E[\mbox{grade}| \mbox{hours studied}] &amp;= \beta_{0} + \beta_{1} \mbox{hrs} + \beta_2 I(\mbox{year=senior}) + \beta_{3} \mbox{hrs} I(\mbox{year = senior})\\
\beta_{0f} &amp;= \beta_{0}\\
\beta_{0s} &amp;= \beta_0 + \beta_2\\
\beta_{1f} &amp;= \beta_1\\
\beta_{1s} &amp;= \beta_1 + \beta_3
\end{align}\]</span></p>
<p>Why do we need the <span class="math inline">\(I(\mbox{year=seniors})\)</span> variable?</p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-25" class="definition"><strong>(#def:unlabeled-div-25) </strong></span><em>Interaction</em> means that the effect of an explanatory variable on the outcome differs according to the level of another explanatory variable. (Not the case with age on smoking and lung cancer above. With the smoking example, age is a significant variable, but it does not interact with lung cancer.)</p>
</div>
<!--
Recall the homework assignment where APACHE score was a significant predictor of the odds of dying for treated black patients but not for untreated.  This is interaction.  The relationship between the explanatory variable (APACHE score) and the response (survival) changes depending on a 3rd variables (treated vs. untreated).
-->
<div class="example">
<p><span id="exm:unlabeled-div-26" class="example"><strong>(#exm:unlabeled-div-26) </strong></span>The <strong>Heart and Estrogen/progestin Replacement Study (HERS)</strong> is a randomized, double-blind, placebo-controlled trial designed to test the efficacy and safety of estrogen plus progestin therapy for prevention of recurrent coronary heart disease (CHD) events in women. The participants are postmenopausal women with a uterus and with CHD. Each woman was randomly assigned to receive one tablet containing 0.625 mg conjugated estrogens plus 2.5 mg medroxyprogesterone acetate daily or an identical placebo. The results of the first large randomized clinical trial to examine the effect of hormone replacement therapy (HRT) on women with heart disease appeared in JAMA in 1998 <span class="citation">(<a href="#ref-HERS" role="doc-biblioref">Hulley et al. 1998</a>)</span>.</p>
<p>The Heart and Estrogen/Progestin Replacement Study (HERS) found that the use of estrogen plus progestin in postmenopausal women with heart disease did not prevent further heart attacks or death from coronary heart disease (CHD). This occurred despite the positive effect of treatment on lipoproteins: LDL (bad) cholesterol was reduced by 11 percent and HDL (good) cholesterol was increased by 10 percent.</p>
<p>The hormone replacement regimen also increased the risk of clots in the veins (deep vein thrombosis) and lungs (pulmonary embolism). The results of HERS are surprising in light of previous observational studies, which found lower rates of CHD in women who take postmenopausal estrogen.</p>
<p>Data available at: <a href="http://www.biostat.ucsf.edu/vgsm/data/excel/hersdata.xls" class="uri">http://www.biostat.ucsf.edu/vgsm/data/excel/hersdata.xls</a> For now, we will try to predict whether the individuals had a pre-existing medical condition (other than CHD, self reported), <code>medcond</code>. We will use the variables <code>age</code>, <code>weight</code>, <code>diabetes</code> and <code>drinkany</code>.</p>
</div>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic   p.value</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)  -1.60     0.401       -4.00 0.0000624</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 age           0.0162   0.00597      2.71 0.00664</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age <span class="sc">+</span> weight, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 3 x 5</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic   p.value</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept) -2.17      0.496       -4.37 0.0000124</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 age          0.0189    0.00613      3.09 0.00203  </span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 weight       0.00528   0.00274      1.93 0.0542</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age<span class="sc">+</span>diabetes, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 3 x 5</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic      p.value</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)  -1.89     0.408       -4.64 0.00000349  </span></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 age           0.0185   0.00603      3.07 0.00217     </span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 diabetes      0.487    0.0882       5.52 0.0000000330</span></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age<span class="sc">*</span>diabetes, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 x 5</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term         estimate std.error statistic     p.value</span></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;</span></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   -2.52     0.478       -5.26 0.000000141</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 age            0.0278   0.00707      3.93 0.0000844  </span></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 diabetes       2.83     0.914        3.10 0.00192    </span></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 age:diabetes  -0.0354   0.0137      -2.58 0.00986</span></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age<span class="sc">*</span>drinkany, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 x 5</span></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term         estimate std.error statistic p.value</span></span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)  -0.991     0.511       -1.94  0.0526</span></span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 age           0.00885   0.00759      1.17  0.244 </span></span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 drinkany     -1.44      0.831       -1.73  0.0833</span></span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 age:drinkany  0.0168    0.0124       1.36  0.175</span></span></code></pre></div>
<p>Write out a few models <em>by hand</em>, does any of the significance change with respect to interaction? Does the interpretation change with interaction? In the last model, we might want to remove all the age information. Age seems to be less important than drinking status. How do we decide? How do we model?</p>
</div>
<div id="simpsons-paradox" class="section level3" number="5.4.2">
<h3 number="5.4.2"><span class="header-section-number">5.4.2</span> Simpson’s Paradox</h3>
<p><strong>Simpson’s paradox</strong> is when the association between two variables is opposite the partial association between the same two variables after controlling for one or more other variables.</p>
<div class="example">
<p><span id="exm:unlabeled-div-27" class="example"><strong>(#exm:unlabeled-div-27) </strong></span>Back to linear regression to consider Simpson’s Paradox in the wild. Consider data on SAT scores across different states with information on educational expenditure. The correlation between SAT score and average teacher salary is negative with the combined data. However, SAT score and average teacher salary is positive after controlling for the fraction of students who take the exam. The fewer students who take the exam, the higher the SAT score. That’s because states whose public universities encourage the ACT have SAT-takers who are leaving the state for college (with their higher SAT scores).</p>
<p><img src="05-log_files/figure-html/unnamed-chunk-8-1.png" width="80%" style="display: block; margin: auto;" /><img src="05-log_files/figure-html/unnamed-chunk-8-2.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(SAT)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        state expend ratio salary frac verbal math  sat         fracgrp</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1    Alabama   4.41  17.2   31.1    8    491  538 1029    low fraction</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2     Alaska   8.96  17.6   48.0   47    445  489  934 medium fraction</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3    Arizona   4.78  19.3   32.2   27    448  496  944 medium fraction</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4   Arkansas   4.46  17.1   28.9    6    482  523 1005    low fraction</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 California   4.99  24.0   41.1   45    417  485  902 medium fraction</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6   Colorado   5.44  18.4   34.6   29    462  518  980 medium fraction</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sat <span class="sc">~</span> salary, <span class="at">data=</span>SAT) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)  1159.       57.7      20.1  5.13e-25</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 salary         -5.54      1.63     -3.39 1.39e- 3</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sat <span class="sc">~</span> salary <span class="sc">+</span> frac, <span class="at">data=</span>SAT) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 3 x 5</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   988.      31.9       31.0  6.20e-33</span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 salary          2.18     1.03       2.12 3.94e- 2</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 frac           -2.78     0.228    -12.2  4.00e-16</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sat <span class="sc">~</span> salary <span class="sc">*</span> frac, <span class="at">data=</span>SAT) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 x 5</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term         estimate std.error statistic  p.value</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept) 1082.       54.4       19.9   3.00e-24</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 salary        -0.720     1.70      -0.424 6.73e- 1</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 frac          -5.03      1.09      -4.62  3.15e- 5</span></span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 salary:frac    0.0648    0.0308     2.11  4.05e- 2</span></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sat <span class="sc">~</span> salary <span class="sc">+</span> fracgrp, <span class="at">data=</span>SAT) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 x 5</span></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term                   estimate std.error statistic  p.value</span></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)             1002.      31.8       31.5  8.55e-33</span></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 salary                     1.09     0.988      1.10 2.76e- 1</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 fracgrpmedium fraction  -112.      14.3       -7.82 5.46e-10</span></span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 fracgrphigh fraction    -150.      12.8      -11.7  2.09e-15</span></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sat <span class="sc">~</span> salary <span class="sc">*</span> fracgrp, <span class="at">data=</span>SAT) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 x 5</span></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term                           estimate std.error statistic  p.value</span></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;                             &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)                   1012.         55.8    18.1    4.85e-22</span></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 salary                           0.768       1.77    0.435  6.65e- 1</span></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 fracgrpmedium fraction        -107.        103.     -1.04   3.03e- 1</span></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 fracgrphigh fraction          -175.         79.2    -2.21   3.27e- 2</span></span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 salary:fracgrpmedium fraction   -0.0918      2.93   -0.0313 9.75e- 1</span></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 salary:fracgrphigh fraction      0.692       2.28    0.303  7.63e- 1</span></span></code></pre></div>
</div>
<!--
%Consider the following data on twenty-year vital status by smoking behavior: %(pgs 52-53 in VGSM)
%\begin{center}
%\begin{tabular}{r|cc|r}
%& smoker & nonsmoker & total\\
%\hline
%cases & 139 & 230 & 369\\
%non cases & 443 & 502 & 945\\
%\hline
%total & 582 & 502 & 1314
%\end{tabular}
%\end{center}

%Just as we have before, we can calculate the OR of cancer given the person was a smoker.  We could also break down the relationship between smoking and cancer using the age variable.

%\begin{center}
%\begin{tabular}{lccc}
%& OR & \multicolumn{2}{c}{CI}\\
%overall & 0.685 & 0.439 & 0.931\\
%18-44 & 1.777 & 0.873 & 3.615\\
%45-64 & 1.320 & 0.873 & 1.997\\
%65+ & 1.018 & 0.424 & 2.434\\
%\end{tabular}
%\end{center}

%After *adjusting* for age, smoking is no longer significant.  But more importantly, age is a variable that changes the effect of smoking on cancer.  This is referred to as Simpson's Paradox.  The effect is not due to the observational nature of the study, and so it is important to adjust for possible influential variables regardless of the study at hand.
-->
<div class="example">
<p><span id="exm:unlabeled-div-28" class="example"><strong>(#exm:unlabeled-div-28) </strong></span>Consider the example on smoking and 20-year mortality (case) from section 3.4 of <em>Regression Methods in Biostatistics</em>, pg 52-53. The study represents women participating in a health survey in Whickham, England in 1972-1972 with follow-up 20 years later <span class="citation">(<a href="#ref-Vanderpump95" role="doc-biblioref">Vanderpump et al. 1995</a>)</span>. Mortality was recorded as the response variable and self-reported smoking and age (both given in the original study) as the explanatory variables.</p>
<table>
<thead>
<tr class="header">
<th>age</th>
<th>test</th>
<th align="center">smoker</th>
<th align="center">nonsmoker</th>
<th align="center">prob smoke</th>
<th align="center">odds smoke</th>
<th align="center">empirical OR</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>all</td>
<td>case</td>
<td align="center">139</td>
<td align="center">230</td>
<td align="center">0.377</td>
<td align="center">0.604</td>
<td align="center">0.685</td>
</tr>
<tr class="even">
<td></td>
<td>control</td>
<td align="center">443</td>
<td align="center">502</td>
<td align="center">0.469</td>
<td align="center">0.882</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td>18-44</td>
<td>case</td>
<td align="center">61</td>
<td align="center">32</td>
<td align="center">0.656</td>
<td align="center">1.906</td>
<td align="center">1.627</td>
</tr>
<tr class="even">
<td></td>
<td>control</td>
<td align="center">375</td>
<td align="center">320</td>
<td align="center">0.540</td>
<td align="center">1.172</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td>45-64</td>
<td>case</td>
<td align="center">34</td>
<td align="center">66</td>
<td align="center">0.340</td>
<td align="center">0.515</td>
<td align="center">1.308</td>
</tr>
<tr class="even">
<td></td>
<td>control</td>
<td align="center">50</td>
<td align="center">127</td>
<td align="center">0.282</td>
<td align="center">0.394</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td>65+</td>
<td>case</td>
<td align="center">44</td>
<td align="center">132</td>
<td align="center">0.250</td>
<td align="center">0.333</td>
<td align="center">1.019</td>
</tr>
<tr class="even">
<td></td>
<td>control</td>
<td align="center">18</td>
<td align="center">55</td>
<td align="center">0.247</td>
<td align="center">0.327</td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>What we see is that the vast majority of the controls were young, and they had a high rate of smoking. A good chunk of the cases were older, and the rate of smoking was substantially lower in the oldest group. However, within each group, the cases were more likely to smoke than the controls.</p>
<p>After <em>adjusting</em> for age, smoking is no longer significant. But more importantly, age is a variable that reverses the effect of smoking on cancer - Simpson’s Paradox. The effect is not due to the observational nature of the study, and so it is important to adjust for possible influential variables regardless of the study at hand.</p>
<p>What would it mean to <em>adjust</em> for age in this context? It means that we have to include it in the model:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>( death <span class="sc">~</span> smoke, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   -0.781    0.0796     -9.80 1.10e-22</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 smoke         -0.379    0.126      -3.01 2.59e- 3</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>( death <span class="sc">~</span> <span class="fu">as.factor</span>(age), <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 3 x 5</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term                estimate std.error statistic  p.value</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)           -0.571     0.125     -4.56 5.01e- 6</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 as.factor(age)old      1.45      0.187      7.75 9.00e-15</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 as.factor(age)young   -1.44      0.167     -8.63 6.02e-18</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>( death <span class="sc">~</span> smoke <span class="sc">+</span> <span class="fu">as.factor</span>(age), <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 x 5</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term                estimate std.error statistic  p.value</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)           -0.668     0.135     -4.96 7.03e- 7</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 smoke                  0.312     0.154      2.03 4.25e- 2</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 as.factor(age)old      1.47      0.188      7.84 4.59e-15</span></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 as.factor(age)young   -1.52      0.173     -8.81 1.26e-18</span></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>( death <span class="sc">~</span> smoke <span class="sc">*</span> <span class="fu">as.factor</span>(age), <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 x 5</span></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term                      estimate std.error statistic  p.value</span></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;                        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)                 -0.655     0.152    -4.31  1.61e- 5</span></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 smoke                        0.269     0.269     0.999 3.18e- 1</span></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 as.factor(age)old            1.53      0.221     6.93  4.29e-12</span></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 as.factor(age)young         -1.65      0.240    -6.88  6.00e-12</span></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 smoke:as.factor(age)old     -0.251     0.420    -0.596 5.51e- 1</span></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 smoke:as.factor(age)young    0.218     0.355     0.614 5.40e- 1</span></span></code></pre></div>
<p>Using the additive model above:
<span class="math display">\[\begin{align}
\mbox{logit} (p(x_1, x_2) ) &amp;= \beta_0 + \beta_1 x_1 + \beta_2 x_2\\
OR &amp;= \mbox{odds dying if } (x_1, x_2) / \mbox{odds dying if } (x_1^*, x_2^*) = \frac{e^{\beta_0 + \beta_1 x_1 + \beta_2 x_2}}{e^{\beta_0 + \beta_1 x_1^* + \beta_2 x_2^*}}\\
x_1 &amp;= \begin{cases}
0 &amp; \mbox{ don&#39;t smoke}\\
1 &amp; \mbox{ smoke}\\
\end{cases}\\
x_2 &amp;= \begin{cases}
\mbox{young} &amp; \mbox{18-44 years old}\\
\mbox{middle} &amp; \mbox{45-64 years old}\\
\mbox{old} &amp; \mbox{65+ years old}\\
\end{cases}
\end{align}\]</span>
where we are modeling the probability of 20-year mortality using smoking status and age group.</p>
<p><strong>Note 1:</strong> We can see from above that the coefficients for each variable are significantly different from zero. That is, the variables are important in predicting odds of survival.<br />
<strong>Note 2:</strong> We can see that smoking becomes less significant as we add age into the model. That is because age and smoking status are so highly associated (think of the coin example).<br />
<strong>Note 3:</strong> We can estimate any of the OR (of dying for smoke vs not smoke) from the given coefficients:<br />
<span class="math display">\[\begin{align}
\mbox{simple model} &amp;\\
\mbox{overall OR} &amp;= e^{-0.37858 } = 0.6848332\\
&amp; \\
\mbox{additive model} &amp;\\
\mbox{young, middle, old OR} &amp;= e^{ 0.3122} = 1.3664\\
&amp; \\
\mbox{interaction model} &amp;\\
\mbox{young OR} &amp;= e^{0.2689 + 0.2177} = 1.626776\\
\mbox{middle OR} &amp;= e^{0.2689} = 1.308524\\
\mbox{old OR} &amp;= e^{0.2689 + -0.2505} = 1.018570\\
\end{align}\]</span>
What does it mean that the interaction terms are not significant in the last model?</p>
</div>
</div>
</div>
<div id="multicol" class="section level2" number="5.5">
<h2 number="5.5"><span class="header-section-number">5.5</span> Multicolinearity</h2>
<div class="example">
<p><span id="exm:unlabeled-div-29" class="example"><strong>(#exm:unlabeled-div-29) </strong></span>Consider the following data set collected from church offering plates in 62 consecutive Sundays. Also noted is whether there was enough change to buy a candy bar for $1.25.</p>
<p><img src="05-log_files/figure-html/unnamed-chunk-12-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(Candy <span class="sc">~</span> Coins, <span class="at">data =</span> Offering, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic   p.value</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   -4.14     0.996      -4.16 0.0000321</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 Coins          0.286    0.0772      3.70 0.000213</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(Candy <span class="sc">~</span> Small, <span class="at">data =</span> Offering, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic   p.value</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   -2.33     0.585      -3.98 0.0000693</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 Small          0.184    0.0576      3.19 0.00142</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(Candy <span class="sc">~</span> Coins <span class="sc">+</span> Small, <span class="at">data =</span> Offering, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 3 x 5</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic p.value</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   -17.0       7.80     -2.18  0.0296</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 Coins           3.49      1.75      1.99  0.0461</span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 Small          -3.04      1.57     -1.93  0.0531</span></span></code></pre></div>
<p>Notice that the directionality of the low coins changes when it is included in the model that already contains the number of coins total. Lesson of the story: be very very very careful interpreting coefficients when you have multiple explanatory variables.</p>
</div>
</div>
<div id="logstep" class="section level2" number="5.6">
<h2 number="5.6"><span class="header-section-number">5.6</span> Model Building</h2>
<div class="example">
<p><span id="exm:unlabeled-div-30" class="example"><strong>(#exm:unlabeled-div-30) </strong></span>Suppose that you have to take an exam that covers 100 different topics, and you do not know any of them. The rules, however, state that you can bring two classmates as consultants. Suppose also that you know which topics each of your classmates is familiar with. If you could bring only one consultant, it is easy to figure out who you would bring: it would be the one who knows the most topics (the variable most associated with the answer). Let’s say this is Sage who knows 85 topics. With two consultants you might choose Sage first, and for the second option, it seems reasonable to choose the second most knowledgeable classmate (the second most highly associated variable), for example Bruno, who knows 75 topics.</p>
<p>The problem with this strategy is that it may be that the 75 subjects Bruno knows are already included in the 85 that Sage knows, and therefore, Bruno does not provide any knowledge beyond that of Sage.</p>
<p>A better strategy is to select the second not by considering what they know regarding the entire agenda, but by looking for the person who knows more about the topics that the first does not know (the variable that best explains the residual of the equation with the variables entered). It may even happen that the best pair of consultants are not the most knowledgeable, as there may be two that complement each other perfectly in such a way that one knows 55 topics and the other knows the remaining 45, while the most knowledgeable does not complement anybody.</p>
<table>
<thead>
<tr class="header">
<th>Individual</th>
<th># topics</th>
<th>Pair</th>
<th># topics</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sage</td>
<td>85</td>
<td>Sage &amp; Bruno</td>
<td>95</td>
</tr>
<tr class="even">
<td>Bruno</td>
<td>80</td>
<td>Sage &amp; Beta</td>
<td>93</td>
</tr>
<tr class="odd">
<td>Luna</td>
<td>55</td>
<td>Sage &amp; Luna</td>
<td>92</td>
</tr>
<tr class="even">
<td>Beta</td>
<td>45</td>
<td>Bruno &amp; Beta</td>
<td>90</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>Bruno &amp; Luna</td>
<td>90</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>Beta &amp; Luna</td>
<td>100</td>
</tr>
</tbody>
</table>
<p>With forward selection, which two are chosen?<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>With backward selection, which two are chosen?<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<!-- %(Taken from American Statistician article that I refereed, August 2012.) -->
</div>
<!--
% added January 2019 ...  I need to read through, edit, etc.

#### More thoughts on Model Selection...

Question: Did females receive lower starting salaries than males?  @sleuth

model:  y = log(salary), x's: seniority, age, experience, education, sex.

In Sleuth, they first find a good model using only seniority, age, experience and education (including considerations of interactions/quadratics). Once they find a suitable model (Model 1), they then add the sex variable to this model to determine if it is significant. (H0: Model 1 vs HA: Model 1 + sex)  In other regression texts, the models considered would include the sex variable from the beginning, and work from there, but always keeping the sex variable in.  What are the pluses/minuses of these approaches?

\begin{itemize}
\item[Resp1]
It seems possible, and even likely, that sex would be associated with some of these other variables, so depending how the model selection that starts with sex included were done, it would be entirely possible to choose a model that includes sex but not one or more of the other variables, and in which sex is significant. If however, those other variables were included, sex might not explain a significant amount of variation beyond those others. Whereas the model selection that doesn't start with sex would be more likely to include those associated covariates to start with.

I do like both of those methods in that they both end up with sex in the model; one of my pet peeves is when a model selection procedure ends up removing the variable of interest and people then claim that the variable of interest doesn't matter.  But my preference is actually to try to avoid model selection as much as possible. What I tell the people I work with is that each model you build answers a different question, and so try to get them to decide ahead of time what question they are interested in. I also find Frank Harrell's comments on model selection (in his Regression Modeling Strategies book) to be particularly helpful.

In this case I really think there are two questions of interest; are there differences at all (univariate model), and are there differences after accounting for the covariates (multivariate model)? If the differences get smaller after adjusting for the covariates, then that leads to the very interesting question of why that is, and whether those differences are also part of the sex discrimination. It bugs me when people try to explain away the wage gap between men and women by saying that men just go into higher-paying jobs, when really, that's part of the problem, that jobs that have more women in them pay less. :( The point, though, is that one model may not be sufficient for a particular situation, and looking for one "best" model can be misleading.
\item[Resp2]
If you know (or are willing to assume) the covariates that you want to adjust for and their form in the model (non-linearity, interactions) and you have enough data relative to the number of covariates, then you should not do any model selection, just compare the model with the variable of interest to the model without.  Which covariates are significant or not does not matter in this case.

See here: https://stats.stackexchange.com/questions/37564/r-code-question-model-selection-based-on-individual-significance-in-regression/37609#37609 for simulation examples where screening/model selection can either include meaningless variables, or leave out important ones.
\end{itemize}
-->
<div id="formal-model-building" class="section level3" number="5.6.1">
<h3 number="5.6.1"><span class="header-section-number">5.6.1</span> Formal Model Building</h3>
<p>We are going to discuss how to add (or subtract) variables from a model. Before we do that, we can define two criteria used for suggesting an optimal model.</p>
<blockquote>
<p>AIC: Akaike’s Information Criteria = <span class="math inline">\(-2 \ln\)</span> likelihood + <span class="math inline">\(2p\)</span><br />
BIC: Bayesian Information Criteria = <span class="math inline">\(-2 \ln\)</span> likelihood <span class="math inline">\(+p \ln(n)\)</span></p>
</blockquote>
<p>Both techniques suggest choosing a model with the smallest AIC and BIC value; both adjust for the number of parameters in the model and are more likely to select models with fewer variables than the drop-in-deviance test.</p>
<div id="stepwise-regression" class="section level4" number="5.6.1.1">
<h4 number="5.6.1.1"><span class="header-section-number">5.6.1.1</span> Stepwise Regression</h4>
<p>As done previously, we can add and remove variables based on the deviance. Recall, when comparing two nested models, the differences in the deviances can be modeled by a <span class="math inline">\(\chi^2_\nu\)</span> variable where <span class="math inline">\(\nu = \Delta p\)</span>.</p>
<p>Consider the HERS data described in your book (page 30); variable description also given on the book website <a href="http://www.epibiostat.ucsf.edu/biostat/vgsm/data/hersdata.codebook.txt" class="uri">http://www.epibiostat.ucsf.edu/biostat/vgsm/data/hersdata.codebook.txt</a></p>
<p>For now, we will try to predict whether the individuals had a medical condition, <code>medcond</code> (defined as a pre-existing and self-reported medical condition). We will use the variables <code>age</code>, <code>weight</code>, <code>diabetes</code> and <code>drinkany</code>.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic   p.value</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)  -1.60     0.401       -4.00 0.0000624</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 age           0.0162   0.00597      2.71 0.00664</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age <span class="sc">+</span> weight, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 3 x 5</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic   p.value</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept) -2.17      0.496       -4.37 0.0000124</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 age          0.0189    0.00613      3.09 0.00203  </span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 weight       0.00528   0.00274      1.93 0.0542</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age<span class="sc">+</span>diabetes, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 3 x 5</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic      p.value</span></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)  -1.89     0.408       -4.64 0.00000349  </span></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 age           0.0185   0.00603      3.07 0.00217     </span></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 diabetes      0.487    0.0882       5.52 0.0000000330</span></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age<span class="sc">*</span>diabetes, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 x 5</span></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term         estimate std.error statistic     p.value</span></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;</span></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   -2.52     0.478       -5.26 0.000000141</span></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 age            0.0278   0.00707      3.93 0.0000844  </span></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 diabetes       2.83     0.914        3.10 0.00192    </span></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 age:diabetes  -0.0354   0.0137      -2.58 0.00986</span></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age<span class="sc">*</span>drinkany, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 x 5</span></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term         estimate std.error statistic p.value</span></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)  -0.991     0.511       -1.94  0.0526</span></span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 age           0.00885   0.00759      1.17  0.244 </span></span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 drinkany     -1.44      0.831       -1.73  0.0833</span></span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 age:drinkany  0.0168    0.0124       1.36  0.175</span></span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age <span class="sc">+</span> weight <span class="sc">+</span> diabetes <span class="sc">+</span> drinkany, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 x 5</span></span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic    p.value</span></span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;</span></span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept) -1.87      0.505      -3.72  0.000203  </span></span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 age          0.0184    0.00620     2.96  0.00304   </span></span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 weight       0.00143   0.00285     0.500 0.617     </span></span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 diabetes     0.432     0.0924      4.68  0.00000288</span></span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 drinkany    -0.253     0.0835     -3.03  0.00248</span></span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age , <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic   p.value</span></span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)  -1.60     0.401       -4.00 0.0000624</span></span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 age           0.0162   0.00597      2.71 0.00664</span></span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> weight , <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value</span></span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept) -0.769     0.198       -3.88 0.000106</span></span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 weight       0.00339   0.00267      1.27 0.204</span></span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> diabetes , <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value</span></span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   -0.652    0.0467    -13.9  3.18e-44</span></span>
<span id="cb26-65"><a href="#cb26-65" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 diabetes       0.468    0.0878      5.34 9.55e- 8</span></span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> drinkany, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value</span></span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb26-70"><a href="#cb26-70" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   -0.398    0.0498     -8.00 1.26e-15</span></span>
<span id="cb26-71"><a href="#cb26-71" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 drinkany      -0.330    0.0818     -4.04 5.46e- 5</span></span></code></pre></div>
</div>
<div id="forward-selection" class="section level4 unnumbered">
<h4 class="unnumbered">Forward Selection</h4>
<p>One idea is to start with an empty model and adding the best available variable at each iteration, checking for needs for transformations. We should also look at interactions which we might suspect. However, looking at all possible interactions (if only 2-way interactions, we could also consider 3-way interactions etc.), things can get out of hand quickly.</p>
<ol style="list-style-type: decimal">
<li>We start with the response variable versus all variables and find the best predictor. If there are too many, we might just look at the correlation matrix. However, we may miss out of variables that are good predictors but aren’t linearly related. Therefore, if its possible, a scatter plot matrix would be best.<br />
</li>
<li>We locate the best variable, and regress the response variable on it.<br />
</li>
<li>If the variable seems to be useful, we keep it and move on to looking for a second.<br />
</li>
<li>If not, we stop.</li>
</ol>
</div>
<div id="forward-stepwise-selection" class="section level4 unnumbered">
<h4 class="unnumbered">Forward Stepwise Selection</h4>
<p>This method follows in the same way as Forward Regression, but as each new variable enters the model, we check to see if any of the variables already in the model can now be removed. This is done by specifying two values, <span class="math inline">\(\alpha_e\)</span> as the <span class="math inline">\(\alpha\)</span> level needed to <strong>enter</strong> the model, and <span class="math inline">\(\alpha_l\)</span> as the <span class="math inline">\(\alpha\)</span> level needed to <strong>leave</strong> the model. We require that <span class="math inline">\(\alpha_e&lt;\alpha_l\)</span>, otherwise, our algorithm could cycle, we add a variable, then immediately decide to delete it, continuing ad infinitum. This is bad.</p>
<ol style="list-style-type: decimal">
<li>We start with the empty model, and add the best predictor, assuming the p-value associated with it is smaller than <span class="math inline">\(\alpha_e\)</span>.<br />
</li>
<li>Now, we find the best of the remaining variables, and add it if the p-value is smaller than <span class="math inline">\(\alpha_e\)</span>. If we add it, we also check to see if the first variable can be dropped, by calculating the p-value associated with it (which is different from the first time, because now there are two variables in the model). If its p-value is greater than <span class="math inline">\(\alpha_l\)</span>, we remove the variable.<br />
</li>
<li>We continue with this process until there are no more variables that meet either requirements. In many situations, this will help us from stopping at a less than desirable model.</li>
</ol>
<p>How do you choose the <span class="math inline">\(\alpha\)</span> values? If you set <span class="math inline">\(\alpha_e\)</span> to be very small, you might walk away with no variables in your model, or at least not many. If you set it to be large, you will wander around for a while, which is a good thing, because you will explore more models, but you may end up with variables in your model that aren’t necessary.</p>
</div>
<div id="backward-selection" class="section level4 unnumbered">
<h4 class="unnumbered">Backward Selection</h4>
<ol style="list-style-type: decimal">
<li>Start with the full model including every term (and possibly every interaction, etc.).<br />
</li>
<li>Remove the variable that is <em>least</em> significant (biggest p-value) in the model.<br />
</li>
<li>Continue removing variables until all variables are significant at the chosen <span class="math inline">\(\alpha\)</span> level.</li>
</ol>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> (age <span class="sc">+</span> diabetes <span class="sc">+</span> weight <span class="sc">+</span> drinkany)<span class="sc">^</span><span class="dv">2</span>, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 8</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1         3643.    2758 -1793. 3608. 3673.    3586.        2748  2759</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age <span class="sc">+</span> diabetes <span class="sc">+</span> weight <span class="sc">+</span> drinkany, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 8</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1         3643.    2758 -1797. 3605. 3634.    3595.        2754  2759</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(medcond <span class="sc">~</span> age <span class="sc">+</span> diabetes <span class="sc">+</span> drinkany, <span class="at">data =</span> HERS, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 x 5</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic     p.value</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)  -1.72     0.413       -4.17 0.0000300  </span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 age           0.0176   0.00605      2.90 0.00369    </span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 diabetes      0.442    0.0895       4.94 0.000000786</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 drinkany     -0.252    0.0834      -3.01 0.00257</span></span></code></pre></div>
<ul>
<li>The big model (with all of the interaction terms) has a deviance of 3585.7; the additive model has a deviance of 3594.8.</li>
</ul>
<p><span class="math display">\[\begin{align}
G &amp;= 3594.8 - 3585.7= 9.1\\
p-value &amp;= P(\chi^2_6 \geq 9.1)= 1 - pchisq(9.1, 6) = 0.1680318
\end{align}\]</span>
We cannot reject the null hypothesis, so we know that we don’t need the 6 interaction terms. Next we will check whether we need weight.</p>
<ul>
<li>The additive model has a deviance of 3594.8; the model without weight is 3597.3.</li>
</ul>
<p><span class="math display">\[\begin{align}
G &amp;= 3597.3 - 3594.8 =2.5\\
p-value &amp;= P(\chi^2_1 \geq 2.5)= 1 - pchisq(2.5, 1) = 0.1138463
\end{align}\]</span>
We cannot reject the null hypothesis, so we know that we don’t need the weight in the model either.</p>
</div>
</div>
<div id="getting-the-model-right" class="section level3" number="5.6.2">
<h3 number="5.6.2"><span class="header-section-number">5.6.2</span> Getting the Model Right</h3>
<p>In terms of selecting the variables to model a particular response, four things can happen:</p>
<ul>
<li>The logistic regression model is correct!<br />
</li>
<li>The logistic regression model is underspecified.<br />
</li>
<li>The logistic regression model contains extraneous variables.<br />
</li>
<li>The logistic regression model is overspecified.</li>
</ul>
<div id="underspecified" class="section level5 unnumbered">
<h5 class="unnumbered">Underspecified</h5>
<p>A regression model is underspecified if it is missing one or more important predictor variables. Being underspecified is the worst case scenario because the model ends up being biased and predictions are wrong for virtually every observation. (Think about Simpson’s Paradox and the need for interaction.)</p>
</div>
<div id="extraneous" class="section level5 unnumbered">
<h5 class="unnumbered">Extraneous</h5>
<p>The third type of variable situation comes when extra variables are included in the model but the variables are neither related to the response nor are they correlated with the other explanatory variables. Generally, extraneous variables are not so problematic because they produce models with unbiased coefficient estimators, unbiased predictions, and unbiased variance estimates. The worst thing that happens is that the error degrees of freedom is lowered which makes confidence intervals wider and p-values bigger (lower power). Also problematic is that the model becomes unnecessarily complicated and harder to interpret.</p>
</div>
<div id="overspecified" class="section level5 unnumbered">
<h5 class="unnumbered">Overspecified</h5>
<p>When a model is overspecified, there are one or more redundant variables. That is, the variables contain the same information as other variables (i.e., are correlated!). As we’ve seen, correlated variables cause trouble because they inflate the variance of the coefficient estimates. With correlated variables it is still possible to get unbiased prediction estimates, but the coefficients themselves are so variable that they cannot be interpreted (nor can inference be easily performed).</p>
<p>Generally: the idea is to use a model building strategy with some criteria (<span class="math inline">\(\chi^2\)</span>-tests, AIC, BIC, ROC, AUC) to find the middle ground between an underspecified model and an overspecified model.</p>
</div>
<div id="one-model-building-strategy" class="section level4" number="5.6.2.1">
<h4 number="5.6.2.1"><span class="header-section-number">5.6.2.1</span> One Model Building Strategy</h4>
<p>Taken from <a href="https://onlinecourses.science.psu.edu/stat501/node/332" class="uri">https://onlinecourses.science.psu.edu/stat501/node/332</a>.</p>
<p>Model building is definitely an “art.” Unsurprisingly, there are many approaches to model building, but here is one strategy, consisting of seven steps, that is commonly used when building a regression model.</p>
</div>
<div id="the-first-step" class="section level4 unnumbered">
<h4 class="unnumbered">The first step</h4>
<p>Decide on the type of model that is needed in order to achieve the goals of the study. In general, there are five reasons one might want to build a regression model. They are:</p>
<ul>
<li>For predictive reasons - that is, the model will be used to predict the response variable from a chosen set of predictors.<br />
</li>
<li>For theoretical reasons - that is, the researcher wants to estimate a model based on a known theoretical relationship between the response and predictors. For example, there may be a known physical relationship (with parameters to esimate) or a differential equation that models state changes.<br />
</li>
<li>For control purposes - that is, the model will be used to control a response variable by manipulating the values of the predictor variables.<br />
</li>
<li>For inferential reasons - that is, the model will be used to explore the strength of the relationships between the response and the predictors.<br />
</li>
<li>For data summary reasons - that is, the model will be used merely as a way to summarize a large set of data by a single equation.</li>
</ul>
</div>
<div id="the-second-step" class="section level4 unnumbered">
<h4 class="unnumbered">The second step</h4>
<p>Decide which explanatory variables and response variable on which to collect the data. Collect the data.</p>
</div>
<div id="the-third-step" class="section level4 unnumbered">
<h4 class="unnumbered">The third step</h4>
<p>Explore the data. That is:</p>
<ul>
<li>On a univariate basis, check for outliers, gross data errors, and missing values.<br />
</li>
<li>Study bivariate relationships to reveal other outliers, to suggest possible transformations, and to identify possible multicollinearities.</li>
</ul>
<p>I can’t possibly over-emphasize the data exploration step. There’s not a data analyst out there who hasn’t made the mistake of skipping this step and later regretting it when a data point was found in error, thereby nullifying hours of work.</p>
</div>
<div id="the-fourth-step" class="section level4 unnumbered">
<h4 class="unnumbered">The fourth step</h4>
<p>(The fourth step is very good modeling practice. It gives you a sense of whether or not you’ve overfit the model in the building process.) Randomly divide the data into a training set and a validation set:</p>
<ul>
<li>The training set, with at least 15-20 error degrees of freedom, is used to estimate the model.<br />
</li>
<li>The validation set is used for cross-validation of the fitted model.</li>
</ul>
</div>
<div id="the-fifth-step" class="section level4 unnumbered">
<h4 class="unnumbered">The fifth step</h4>
<p>Using the training set, identify several candidate models:</p>
<ul>
<li>Use best subsets regression.<br />
</li>
<li>Use stepwise regression, which of course only yields one model unless different alpha-to-remove and alpha-to-enter values are specified.</li>
</ul>
</div>
<div id="the-sixth-step" class="section level4 unnumbered">
<h4 class="unnumbered">The sixth step</h4>
<p>Select and evaluate a few “good” models:</p>
<ul>
<li>Select the models based on the criteria we learned, as well as the number and nature of the predictors.<br />
</li>
<li>Evaluate the selected models for violation of the model conditions.<br />
</li>
<li>If none of the models provide a satisfactory fit, try something else, such as collecting more data, identifying different predictors, or formulating a different type of model.</li>
</ul>
</div>
<div id="the-seventh-and-final-step" class="section level4 unnumbered">
<h4 class="unnumbered">The seventh and final step</h4>
<p>Select the final model:</p>
<ul>
<li>A large cross-validation AUC on the validation data is indicative of a good predictive model (for your population of interest).<br />
</li>
<li>Consider false positive rate, false negative rate, outliers, parsimony, relevance, and ease of measurement of predictors.</li>
</ul>
<p>And, most of all, don’t forget that there is not necessarily only one good model for a given set of data. There might be a few equally satisfactory models.</p>
</div>
<div id="another-model-building-strategy" class="section level4" number="5.6.2.2">
<h4 number="5.6.2.2"><span class="header-section-number">5.6.2.2</span> Another Model Building Strategy</h4>
<div class="figure" style="text-align: center">
<img src="figs/sleuthmodelbuild.png" alt="Another strategy for model building. Figure taken from [@sleuth]." width="90%" />
<p class="caption">
(#fig:unnamed-chunk-18)Another strategy for model building. Figure taken from <span class="citation">(<a href="#ref-sleuth" role="doc-biblioref">Ramsey and Schafer 2012</a>)</span>.
</p>
</div>
<!--
% add a bit on stepwise regression??? add1, drop1 in R

% use the binomial model for pearson residuals $\frac{Y_i - n_i \hat{p}_i}{\sqrt{n_i \hat{p}_i (1-\hat{p}_i)} and for chi-square test goodness-of-fit

% see notes from 2008 on yellow pad of paper
-->
</div>
</div>
</div>
<div id="model-assessment" class="section level2" number="5.7">
<h2 number="5.7"><span class="header-section-number">5.7</span> Model Assessment</h2>
<div id="measures-of-association" class="section level3" number="5.7.1">
<h3 number="5.7.1"><span class="header-section-number">5.7.1</span> Measures of Association</h3>
<p>With logistic regression, we don’t have residuals, so we don’t have a value like <span class="math inline">\(R^2\)</span>. We can, however, measure whether or not the estimated model is consistent with the data. That is, is the model able to discriminate between successes and failures.</p>
<p>We’d like to choose a model that produces high probabilities of success for those observations where success was recorded and low probabilities of success for those observation where failure was recorded. In other words, we want mostly <strong>concordant</strong> pairs.</p>
<p>Given a particular pair of observations where one was a success and the other was a failure, if the observation corresponding to a success has a <em>higher</em> probability of success than the observation corresponding to a failure, we call the pair <em>concordant</em>. If the observation corresponding to a success has a <em>lower</em> probability of success than the observation corresponding to a failure, we call the pair <em>discordant</em>. Tied pairs occur when the observed success has the same estimated probability as the observed failure.</p>
<div id="back-to-the-burn-data-refexburnexamp" class="section level4" number="5.7.1.1">
<h4 number="5.7.1.1"><span class="header-section-number">5.7.1.1</span> Back to the burn data @ref(ex:burnexamp):</h4>
<p>Consider looking at all the pairs of successes and failures in the burn data, we have 308 survivors and 127 deaths = 39,116 pairs of individuals.</p>
<p>One pair of individuals has burn areas of 1.75 and 2.35.
<span class="math display">\[\begin{align}
p(x=1.75) &amp;= \frac{e^{22.7083-10.6624\cdot 1.75}}{1+e^{22.7083 -10.6624\cdot 1.75}} = 0.983\\
p(x=2.35) &amp;= \frac{e^{22.7083-10.6624\cdot 2.35}}{1+e^{22.7083 -10.6624\cdot 2.35}} = 0.087
\end{align}\]</span>
The pairs would be concordant if the first individual survived and the second didn’t. The pairs would be discordant if the first individual died and the second survived.</p>
<p>Ideally the model chosen would have a large number of concordant pairs. The following metrics quantify the concordance across the entire model with respect to the observed data:</p>
<ul>
<li><span class="math inline">\(D_{xy}\)</span>: <strong>Somers’ D</strong> is the number of concordant pairs minus the number of discordant pairs divided by the total number of pairs.<br />
</li>
<li>gamma: <strong>Goodman-Kruskal gamma</strong> is the number of concordant pairs minus the number of discordant pairs divided by the total number of pairs excluding ties.<br />
</li>
<li>tau-a: <strong>Kendall’s tau-a</strong> is the number of concordant pairs minus the number of discordant pairs divided by the total number of pairs of people (including pairs who both survived or both died).</li>
</ul>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(c(&quot;Hmisc&quot;, &quot;rms&quot;))</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rms)   <span class="co"># you need this line!!</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>burn.glm <span class="ot">&lt;-</span> <span class="fu">lrm</span>(burnresp<span class="sc">~</span>burnexpl, <span class="at">data =</span> burnglm)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(burn.glm)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Logistic Regression Model</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  </span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  lrm(formula = burnresp ~ burnexpl, data = burnglm)</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  </span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                         Model Likelihood    Discrimination    Rank Discrim.    </span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                               Ratio Test           Indexes          Indexes    </span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Obs           435    LR chi2     190.15    R2       0.505    C       0.877    </span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0            127    d.f.             1    g        2.576    Dxy     0.753    </span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   1            308    Pr(&gt; chi2) &lt;0.0001    gr      13.146    gamma   0.824    </span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  max |deriv| 8e-11                          gp       0.313    tau-a   0.312    </span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                                             Brier    0.121                     </span></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  </span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;            Coef     S.E.   Wald Z Pr(&gt;|Z|)</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Intercept  22.7083 2.2661 10.02  &lt;0.0001 </span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  burnexpl  -10.6624 1.0826 -9.85  &lt;0.0001 </span></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span></code></pre></div>
<p>The summary contains the following elements:</p>
<blockquote>
<p>number of observations used in the fit, maximum absolute value of first derivative of log likelihood, model likelihood ratio chi2, d.f., P-value, <span class="math inline">\(c\)</span> index (area under ROC curve), Somers’ Dxy, Goodman-Kruskal gamma, Kendall’s tau-a rank correlations between predicted probabilities and observed response, the Nagelkerke <span class="math inline">\(R^2\)</span> index, the Brier score computed with respect to Y <span class="math inline">\(&gt;\)</span> its lowest level, the <span class="math inline">\(g\)</span>-index, <span class="math inline">\(gr\)</span> (the <span class="math inline">\(g\)</span>-index on the odds ratio scale), and <span class="math inline">\(gp\)</span> (the <span class="math inline">\(g\)</span>-index on the probability scale using the same cutoff used for the Brier score).</p>
</blockquote>
</div>
</div>
<div id="roc" class="section level3" number="5.7.2">
<h3 number="5.7.2"><span class="header-section-number">5.7.2</span> Receiver Operating Characteristic Curves</h3>
<p>Recall that logistic regression can be used to predict the outcome of a binary event (your response variable). A Receiver Operating Characteristic (ROC) Curve is a graphical representation of the relationship between</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th align="center">Truth</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="center">positive</td>
<td align="center">negative</td>
<td align="center"></td>
</tr>
<tr class="even">
<td>Predicted</td>
<td>positive</td>
<td align="center">true positive</td>
<td align="center">false positive</td>
<td align="center"><span class="math inline">\(P&#39;\)</span></td>
</tr>
<tr class="odd">
<td></td>
<td>negative</td>
<td align="center">false negative</td>
<td align="center">true negative</td>
<td align="center"><span class="math inline">\(N&#39;\)</span></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td align="center"><span class="math inline">\(P\)</span></td>
<td align="center"><span class="math inline">\(N\)</span></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<ul>
<li>type I error = FP<br />
</li>
<li>type II error = FN<br />
</li>
<li>sensitivity = power = true positive rate (TPR) = TP / P = TP / (TP+FN)<br />
</li>
<li>false positive rate (FPR) = FP / N = FP / (FP + TN)<br />
</li>
<li>specificity = 1 - FPR = TN / (FP + TN)<br />
</li>
<li>accuracy (acc) = (TP+TN) / (P+N)<br />
</li>
<li>positive predictive value (PPV) = precision = TP / (TP + FP)<br />
</li>
<li>negative predictive value (NPV) = TN / (TN + FN)<br />
</li>
<li>false discovery rate = 1 - PPV = FP / (FP + TP)</li>
</ul>
<div class="example">
<p><span id="exm:unlabeled-div-31" class="example"><strong>(#exm:unlabeled-div-31) </strong></span>For example: consider a pair of individuals with burn areas of 1.75 and 2.35.
<span class="math display">\[\begin{align}
p(x=1.75) &amp;= \frac{e^{22.7083-10.6624\cdot 1.75}}{1+e^{22.7083 -10.6624\cdot 1.75}} = 0.983\\
p(x=2.35) &amp;= \frac{e^{22.7083-10.6624\cdot 2.35}}{1+e^{22.7083 -10.6624\cdot 2.35}} = 0.087\\
x &amp;= \mbox{log area burned}
\end{align}\]</span>
What value would we assign to 1.75 or 2.35 or 15 for log(area) burned? By changing our cutoff, we can fit an entire curve. We want the curve to be as far in the upper left corner as possible (sensitivity = 1, specificity = 1). Notice that the color band represents the probability cutoff for predicting a ``success."</p>
</div>
<div class="figure" style="text-align: center">
<img src="figs/ROCcurve_burn.png" alt="ROC curve.  Color indicates the probability cutoff used to determine predictions." width="90%" />
<p class="caption">
(#fig:unnamed-chunk-20)ROC curve. Color indicates the probability cutoff used to determine predictions.
</p>
</div>
<p>A: Let’s say we use prob=0.25 as a cutoff:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th align="center">truth</th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="center">yes</td>
<td align="center">no</td>
</tr>
<tr class="even">
<td>predicted</td>
<td>yes</td>
<td align="center">300</td>
<td align="center">66</td>
</tr>
<tr class="odd">
<td></td>
<td>no</td>
<td align="center">8</td>
<td align="center">61</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td align="center">308</td>
<td align="center">127</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\begin{align}
\mbox{sensitivity} &amp;= TPR = 300/308 = 0.974\\
\mbox{specificity} &amp;= 61 / 127 = 0.480, \mbox{1 - specificity} =  FPR = 0.520\\
\end{align}\]</span></p>
<p>B: Let’s say we use prob=0.7 as a cutoff:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th align="center">truth</th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="center">yes</td>
<td align="center">no</td>
</tr>
<tr class="even">
<td>predicted</td>
<td>yes</td>
<td align="center">265</td>
<td align="center">35</td>
</tr>
<tr class="odd">
<td></td>
<td>no</td>
<td align="center">43</td>
<td align="center">92</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td align="center">308</td>
<td align="center">127</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\begin{align}
\mbox{sensitivity} &amp;= TPR = 265/308 = 0.860\\
\mbox{specificity} &amp;= 92/127 = 0.724, \mbox{1 - specificity} = FPR = 0.276\\
\end{align}\]</span></p>
<p>C: Let’s say we use prob=0.9 as a cutoff:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th align="center">truth</th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="center">yes</td>
<td align="center">no</td>
</tr>
<tr class="even">
<td>predicted</td>
<td>yes</td>
<td align="center">144</td>
<td align="center">7</td>
</tr>
<tr class="odd">
<td></td>
<td>no</td>
<td align="center">164</td>
<td align="center">120</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td align="center">308</td>
<td align="center">127</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\begin{align}
\mbox{sensitivity} &amp;= TPR = 144/308 = 0.467\\
\mbox{specificity} &amp;= 120/127 = 0.945, \mbox{1 - specificity} = FPR = 0.055\\
\end{align}\]</span></p>
<p>D: all models will go through (0,0) <span class="math inline">\(\rightarrow\)</span> predict everything negative, prob=1 as your cutoff</p>
<p>E: all models will go through (1,1) <span class="math inline">\(\rightarrow\)</span> predict everything positive, prob=0 as your cutoff</p>
<p>F: you have a model that gives perfect sensitivity (no FN!) and specificity (no FP)</p>
<p>G: random guessing. If classifier randomly guess, it should get half the positives correct and half the negatives correct. If it guesses 90% of the positives correctly, it will also guess 90% of the negatives to be positive.</p>
<p>H: is worse than random guessing. Note that the opposite classifier to (H) might be quite good!</p>
</div>
<div id="cv" class="section level3" number="5.7.3">
<h3 number="5.7.3"><span class="header-section-number">5.7.3</span> Cross Validation</h3>
<p>Before reading the notes here, look through the following visualization. Don’t worry about building the model (classification trees are not a topic for class), but check out the end where they talk about predicting on test and training data.</p>
<p><a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/" class="uri">http://www.r2d3.us/visual-intro-to-machine-learning-part-1/</a></p>
<div id="overfitting" class="section level4" number="5.7.3.1">
<h4 number="5.7.3.1"><span class="header-section-number">5.7.3.1</span> Overfitting</h4>
<p>Imagine you are preparing for your statistics exam. Helpfully, Professor Hardin has made previous exam papers and their worked answers available online. You begin by trying to answer the questions from previous papers and comparing your answers with the model answers provided. Unfortunately, you get carried away and spend all your time on memorizing the model answers to all past questions.</p>
<p>Now, if the upcoming exam completely consists of past questions, you are certain to do very well. But if the new exam asks different questions about the same material, you would be ill-prepared and get a much lower mark than with a more traditional preparation. In this case, one could say that you were <strong>overfitting</strong> the past exam papers and that the knowledge gained didn’t generalize to future exam questions.</p>
</div>
<div id="cv-model-assessment" class="section level4" number="5.7.3.2">
<h4 number="5.7.3.2"><span class="header-section-number">5.7.3.2</span> CV Model Assessment</h4>
<p>Cross validation is commonly used to perform two different tasks:<br />
1. To assess a model’s accuracy (<strong>model assessment</strong>).<br />
2. To build a model (<strong>model selection</strong>).</p>
<p>We will focus here only on model assessment.</p>
<p>Suppose that we build a classifier (logistic regression model) on a given data set. We’d like to know how well the model classifies observations, but if we test on the samples at hand, the error rate will be much lower than the model’s inherent accuracy rate. Instead, we’d like to predict <em>new</em> observations that were not used to create the model. There are various ways of creating <em>test</em> or <em>validation</em> sets of data:</p>
<ul>
<li>one training set, one test set [two drawbacks: estimate of error is highly variable because it depends on which points go into the training set; and because the training data set is smaller than the full data set, the error rate is biased in such a way that it overestimates the actual error rate of the modeling technique.]<br />
</li>
<li>leave one out cross validation (LOOCV) [LOOCV is a special case of <span class="math inline">\(k\)</span>-fold CV with <span class="math inline">\(k=n\)</span>]<br />
</li>
</ul>
<ol style="list-style-type: decimal">
<li>remove one observation<br />
</li>
<li>build the model using the remaining n-1 points<br />
</li>
<li>predict class membership for the observation which was removed<br />
</li>
<li>repeat by removing each observation one at a time (time consuming to keep building models)<br />
</li>
</ol>
<ul>
<li><span class="math inline">\(k\)</span>-fold cross validation (<span class="math inline">\(k\)</span>-fold CV)
<ul>
<li>like LOOCV except that the algorithm is run <span class="math inline">\(k\)</span> times on each group (of approximately equal size) from a partition of the data set.<br />
</li>
<li>advantage of <span class="math inline">\(k\)</span>-fold is computational<br />
</li>
<li><span class="math inline">\(k\)</span>-fold often has a better bias-variance trade-off [bias is lower with LOOCV. however, because LOOCV predicts <span class="math inline">\(n\)</span> observations from <span class="math inline">\(n\)</span> models which are all basically the same, the variability will be higher. with <span class="math inline">\(k\)</span>-fold, prediction is on <span class="math inline">\(n\)</span> values from <span class="math inline">\(k\)</span> models which are much less correlated. the effect is to average out the predicted values in such a way that there will be less variability from data set to data set.</li>
</ul></li>
</ul>
<div class="figure" style="text-align: center">
<img src="figs/CV.png" alt="4-fold CV is depicted.  Notice that the holdout group is never used as part of the coefficient estimation process." width="90%" />
<p class="caption">
(#fig:unnamed-chunk-21)4-fold CV is depicted. Notice that the holdout group is never used as part of the coefficient estimation process.
</p>
</div>
</div>
</div>
</div>
<div id="birdexamp" class="section level2" number="5.8">
<h2 number="5.8"><span class="header-section-number">5.8</span> R: Birdnest Example</h2>
<p><strong>Length of Bird Nest</strong> This example is from problem E1 in your text and includes 99 species of N. American passerine birds. Recall that the response variable is binary and represents whether there is a small opening (<code>closed=1</code>) or a large opening (<code>closed=0</code>) for the nest. The explanatory variable of interest was the length of the bird.</p>
<div id="drop-in-deviance-likelihood-ratio-test-lrt" class="section level3" number="5.8.1">
<h3 number="5.8.1"><span class="header-section-number">5.8.1</span> Drop-in-deviance (Likelihood Ratio Test, LRT)</h3>
<p><span class="math inline">\(\chi^2\)</span>: The Likelihood ratio test also tests whether the response is explained by the explanatory variable. We can output the deviance ( = K - 2 * log-likelihood) for both the full (maximum likelihood!) and reduced (null) models.
<span class="math display">\[\begin{align}
G &amp;= 2 \cdot \ln(L(MLE)) - 2 \cdot \ln(L(null))\\
&amp;= \mbox{null (restricted) deviance - residual (full model) deviance}\\
G &amp;\sim \chi^2_{\nu} \ \ \ \mbox{when the null hypothesis is true}
\end{align}\]</span>
where <span class="math inline">\(\nu\)</span> represents the difference in the number of parameters needed to estimate in the full model versus the null model.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">~</span> Length, <span class="at">data =</span> nests, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic p.value</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   0.457     0.753      0.607   0.544</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 Length       -0.0677    0.0425    -1.59    0.112</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">~</span> Length, <span class="at">data =</span> nests, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">glance</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print.data.frame</span>(<span class="at">digits=</span><span class="dv">6</span>)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   null.deviance df.null   logLik    AIC     BIC deviance df.residual nobs</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1       119.992      94 -58.4399 120.88 125.987   116.88          93   95</span></span></code></pre></div>
</div>
<div id="difference-between-tidy-and-augment-and-glance" class="section level3" number="5.8.2">
<h3 number="5.8.2"><span class="header-section-number">5.8.2</span> Difference between <code>tidy</code> and <code>augment</code> and <code>glance</code></h3>
<p>Note that <code>tidy</code> contains the same number of rows as the number of coefficients. <code>augment</code> contains the same number of rows as number of observations. <code>glance</code> always has one row (containing overall model information).</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">~</span> Length, <span class="at">data =</span> nests, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic p.value</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   0.457     0.753      0.607   0.544</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 Length       -0.0677    0.0425    -1.59    0.112</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">~</span> Length, <span class="at">data =</span> nests, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">augment</span>()</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 95 x 9</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   .rownames `Closed?` Length .fitted .resid .std.resid   .hat .sigma .cooksd</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 1                 0   20    -0.896 -0.827     -0.833 0.0137   1.12 0.00288</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 2                 1   20    -0.896  1.57       1.58  0.0137   1.11 0.0173 </span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 4                 1   20    -0.896  1.57       1.58  0.0137   1.11 0.0173 </span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 5                 1   22.5  -1.07   1.65       1.67  0.0202   1.11 0.0305 </span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 6                 0   18.5  -0.795 -0.863     -0.868 0.0116   1.12 0.00267</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 7                 1   17    -0.693  1.48       1.49  0.0110   1.12 0.0112 </span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 89 more rows</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">~</span> Length, <span class="at">data =</span> nests, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">glance</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print.data.frame</span>(<span class="at">digits=</span><span class="dv">6</span>)</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   null.deviance df.null   logLik    AIC     BIC deviance df.residual nobs</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1       119.992      94 -58.4399 120.88 125.987   116.88          93   95</span></span></code></pre></div>
</div>
<div id="looking-at-variables-in-a-few-different-ways." class="section level3" number="5.8.3">
<h3 number="5.8.3"><span class="header-section-number">5.8.3</span> Looking at variables in a few different ways.</h3>
<p>Length as a continuous explanatory variable:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">~</span> Length, <span class="at">data =</span> nests, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic p.value</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   0.457     0.753      0.607   0.544</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 Length       -0.0677    0.0425    -1.59    0.112</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">~</span> Length, <span class="at">data =</span> nests, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">glance</span>() <span class="sc">%&gt;%</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print.data.frame</span>(<span class="at">digits=</span><span class="dv">6</span>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   null.deviance df.null   logLik    AIC     BIC deviance df.residual nobs</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1       119.992      94 -58.4399 120.88 125.987   116.88          93   95</span></span></code></pre></div>
<p>Length as a categorical explanatory variables:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">~</span> <span class="fu">as.factor</span>(Length), <span class="at">data =</span> nests, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 34 x 5</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term                       estimate std.error statistic p.value</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;                         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)            19.6            10754.  1.82e- 3   0.999</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 as.factor(Length)10     0.000000432    13171.  3.28e-11   1.00 </span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 as.factor(Length)10.5   0.000000430    15208.  2.82e-11   1.00 </span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 as.factor(Length)11   -18.9            10754. -1.75e- 3   0.999</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 as.factor(Length)12   -21.2            10754. -1.97e- 3   0.998</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 as.factor(Length)12.5   0.000000431    15208.  2.83e-11   1.00 </span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 28 more rows</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">~</span> <span class="fu">as.factor</span>(Length), <span class="at">data =</span> nests, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">glance</span>() <span class="sc">%&gt;%</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print.data.frame</span>(<span class="at">digits=</span><span class="dv">6</span>)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   null.deviance df.null   logLik     AIC     BIC deviance df.residual nobs</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1       119.992      94 -36.8776 141.755 228.587  73.7552          61   95</span></span></code></pre></div>
<p>Length plus a few other explanatory variables:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">~</span> Length <span class="sc">+</span> Incubate <span class="sc">+</span>  Color, <span class="at">data =</span> nests, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 x 5</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic p.value</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   -2.64     2.06      -1.28   0.201 </span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 Length        -0.114    0.0527    -2.17   0.0302</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 Incubate       0.314    0.172      1.82   0.0684</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 Color         -0.420    0.609     -0.690  0.490</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">~</span> Length <span class="sc">+</span> Incubate <span class="sc">+</span>  Color, <span class="at">data =</span> nests, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">glance</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print.data.frame</span>(<span class="at">digits=</span><span class="dv">6</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   null.deviance df.null   logLik     AIC     BIC deviance df.residual nobs</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1       110.086      87 -51.6633 111.327 121.236  103.327          84   88</span></span></code></pre></div>
</div>
<div id="predicting-response" class="section level3" number="5.8.4">
<h3 number="5.8.4"><span class="header-section-number">5.8.4</span> Predicting Response</h3>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>bird_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">~</span> Length, <span class="at">data =</span> nests, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>bird_glm <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic p.value</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)   0.457     0.753      0.607   0.544</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 Length       -0.0677    0.0425    -1.59    0.112</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co"># predicting the linear part:</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="co"># reasonable to use the SE to create CIs</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(bird_glm, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">Length =</span> <span class="dv">47</span>), <span class="at">se.fit =</span> <span class="cn">TRUE</span>, <span class="at">type =</span> <span class="st">&quot;link&quot;</span>)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $fit</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     1 </span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -2.72 </span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $se.fit</span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1.3</span></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $residual.scale</span></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1</span></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a><span class="co"># predicting the probability of success (on the `scale` of the response variable):</span></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a><span class="co"># do NOT use the SE to create a CI for the predicted value</span></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a><span class="co"># instead, use the SE from `type=&quot;link&quot; ` and transform the interval</span></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(bird_glm, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">Length =</span> <span class="dv">47</span>), <span class="at">se.fit =</span> <span class="cn">TRUE</span>, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $fit</span></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      1 </span></span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0.0616 </span></span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $se.fit</span></span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      1 </span></span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0.0751 </span></span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $residual.scale</span></span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1</span></span></code></pre></div>
</div>
<div id="measues-of-association" class="section level3" number="5.8.5">
<h3 number="5.8.5"><span class="header-section-number">5.8.5</span> Measues of association</h3>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(c(&quot;Hmisc&quot;, &quot;rms&quot;))</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rms)   <span class="co"># you need this line!!</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>bird_lrm <span class="ot">&lt;-</span> <span class="fu">lrm</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">~</span> Length, <span class="at">data =</span> nests)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(bird_lrm)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Frequencies of Missing Values Due to Each Variable</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Closed?  Length </span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       0       4 </span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Logistic Regression Model</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  </span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  lrm(formula = `Closed?` ~ Length, data = nests)</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  </span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  </span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                        Model Likelihood    Discrimination    Rank Discrim.    </span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                              Ratio Test           Indexes          Indexes    </span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Obs            95    LR chi2      3.11    R2       0.045    C       0.638    </span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0             64    d.f.            1    g        0.455    Dxy     0.276    </span></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   1             31    Pr(&gt; chi2) 0.0777    gr       1.576    gamma   0.288    </span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  max |deriv| 2e-07                         gp       0.088    tau-a   0.123    </span></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                                            Brier    0.210                     </span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  </span></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;            Coef    S.E.   Wald Z Pr(&gt;|Z|)</span></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Intercept  0.4571 0.7530  0.61  0.5438  </span></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Length    -0.0677 0.0425 -1.59  0.1117  </span></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span></code></pre></div>
</div>
<div id="roc-curves" class="section level3" number="5.8.6">
<h3 number="5.8.6"><span class="header-section-number">5.8.6</span> ROC curves</h3>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotROC)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>nests <span class="ot">&lt;-</span> nests <span class="sc">%&gt;%</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Closed =</span> <span class="fu">as.factor</span>(<span class="fu">ifelse</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">==</span> <span class="dv">0</span>, <span class="st">&quot;no&quot;</span>, </span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>                                   <span class="fu">ifelse</span>(<span class="st">`</span><span class="at">Closed?</span><span class="st">`</span> <span class="sc">==</span> <span class="dv">1</span>, <span class="st">&quot;yes&quot;</span>, <span class="st">`</span><span class="at">Closed?</span><span class="st">`</span>))))</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>bird_glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(Closed <span class="sc">~</span> Length, <span class="at">data =</span> nests, <span class="at">family=</span><span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>bird_indiv <span class="ot">&lt;-</span> bird_glm <span class="sc">%&gt;%</span> </span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>) </span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(bird_indiv)</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 x 9</span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   .rownames Closed Length .fitted .resid .std.resid   .hat .sigma .cooksd</span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;     &lt;fct&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 1         no       20     0.290 -0.827     -0.833 0.0137   1.12 0.00288</span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 2         yes      20     0.290  1.57       1.58  0.0137   1.11 0.0173 </span></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 4         yes      20     0.290  1.57       1.58  0.0137   1.11 0.0173 </span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 5         yes      22.5   0.256  1.65       1.67  0.0202   1.11 0.0305 </span></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 6         no       18.5   0.311 -0.863     -0.868 0.0116   1.12 0.00267</span></span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 7         yes      17     0.333  1.48       1.49  0.0110   1.12 0.0112</span></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>bird_cv_plot <span class="ot">&lt;-</span> bird_indiv <span class="sc">%&gt;%</span></span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_roc</span>(<span class="fu">aes</span>(<span class="at">d =</span> Closed, <span class="at">m =</span> .fitted)) <span class="sc">+</span></span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>)</span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>bird_cv_plot</span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_auc</span>(bird_cv_plot)</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   PANEL group   AUC</span></span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1     1    -1 0.638</span></span></code></pre></div>
<p><img src="05-log_files/figure-html/unnamed-chunk-30-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="cross-validation-on-nest-data" class="section level3" number="5.8.7">
<h3 number="5.8.7"><span class="header-section-number">5.8.7</span> Cross Validation on nest data</h3>
<p>Note that the syntax here is slightly different from what we’ve seen previously. From the <strong>caret</strong> and <strong>plotROC</strong> packages:</p>
<ul>
<li><code>train()</code> to partition the data into 4 groups and run the logistic regression separately</li>
<li><code>geom_roc()</code> to plot the ROC curve for each partition</li>
</ul>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotROC)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>bird_cv <span class="ot">&lt;-</span> <span class="fu">train</span>(Closed <span class="sc">~</span> Length <span class="sc">+</span> Incubate <span class="sc">+</span> Nestling,</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> nests,</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>                 <span class="at">na.action =</span> na.omit,</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>                 <span class="at">method =</span> <span class="st">&quot;glm&quot;</span>, </span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>,</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>                 <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">4</span>,</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">savePredictions =</span> <span class="cn">TRUE</span>))</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>bird_cv</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Generalized Linear Model </span></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 99 samples</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  3 predictor</span></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  2 classes: &#39;no&#39;, &#39;yes&#39; </span></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; No pre-processing</span></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Resampling: Cross-Validated (4 fold) </span></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Summary of sample sizes: 64, 65, 65, 64 </span></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Resampling results:</span></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Accuracy  Kappa</span></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0.744     0.39</span></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>bird_cv<span class="sc">$</span>pred <span class="sc">%&gt;%</span> <span class="fu">head</span>()</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   pred obs     no    yes rowIndex parameter Resample</span></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1   no yes 0.7817 0.2183        2      none    Fold1</span></span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2   no  no 0.6644 0.3356        8      none    Fold1</span></span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3   no  no 0.9808 0.0192        9      none    Fold1</span></span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4  yes yes 0.0338 0.9662       12      none    Fold1</span></span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5  yes  no 0.1455 0.8545       14      none    Fold1</span></span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6   no  no 0.9729 0.0271       15      none    Fold1</span></span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a>bird_cv_plot <span class="ot">&lt;-</span> bird_cv<span class="sc">$</span>pred <span class="sc">%&gt;%</span></span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_roc</span>(<span class="fu">aes</span>(<span class="at">m =</span> yes, <span class="at">d =</span> obs, <span class="at">color =</span> Resample))</span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true" tabindex="-1"></a>bird_cv_plot <span class="sc">+</span>  </span>
<span id="cb37-42"><a href="#cb37-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb37-43"><a href="#cb37-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_roc</span>(<span class="fu">aes</span>(<span class="at">m =</span> yes, <span class="at">d =</span> obs), <span class="at">color =</span> <span class="st">&quot;black&quot;</span>)</span>
<span id="cb37-44"><a href="#cb37-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-45"><a href="#cb37-45" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_auc</span>(bird_cv_plot)</span>
<span id="cb37-46"><a href="#cb37-46" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   PANEL group   AUC</span></span>
<span id="cb37-47"><a href="#cb37-47" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1     1     1 0.686</span></span>
<span id="cb37-48"><a href="#cb37-48" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2     1     2 0.847</span></span>
<span id="cb37-49"><a href="#cb37-49" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3     1     3 0.806</span></span>
<span id="cb37-50"><a href="#cb37-50" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4     1     4 0.876</span></span></code></pre></div>
<p><img src="05-log_files/figure-html/unnamed-chunk-31-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>We might try the whole thing over using a model with only one variable. Do the CV values and accuracy get better?</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>bird_cv_length <span class="ot">&lt;-</span> <span class="fu">train</span>(Closed <span class="sc">~</span> Length,</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> nests,</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>                 <span class="at">na.action =</span> na.omit,</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">method =</span> <span class="st">&quot;glm&quot;</span>, </span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>                 <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>,</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>                 <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">4</span>,</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">savePredictions =</span> <span class="cn">TRUE</span>))</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>bird_cv_length</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Generalized Linear Model </span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 99 samples</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  1 predictor</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  2 classes: &#39;no&#39;, &#39;yes&#39; </span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; No pre-processing</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Resampling: Cross-Validated (4 fold) </span></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Summary of sample sizes: 72, 71, 71, 71 </span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Resampling results:</span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Accuracy  Kappa</span></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   0.684     0.04</span></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>bird_cv_length<span class="sc">$</span>pred <span class="sc">%&gt;%</span> <span class="fu">head</span>()</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   pred obs    no   yes rowIndex parameter Resample</span></span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1   no  no 0.706 0.294        1      none    Fold1</span></span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2   no yes 0.706 0.294        3      none    Fold1</span></span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3   no  no 0.620 0.380        8      none    Fold1</span></span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4   no yes 0.638 0.362       11      none    Fold1</span></span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5   no yes 0.706 0.294       14      none    Fold1</span></span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6   no  no 0.800 0.200       19      none    Fold1</span></span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true" tabindex="-1"></a>bird_cv_length_plot <span class="ot">&lt;-</span> bird_cv_length<span class="sc">$</span>pred <span class="sc">%&gt;%</span></span>
<span id="cb38-34"><a href="#cb38-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb38-35"><a href="#cb38-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_roc</span>(<span class="fu">aes</span>(<span class="at">m =</span> yes, <span class="at">d =</span> obs, <span class="at">color =</span> Resample))</span>
<span id="cb38-36"><a href="#cb38-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-37"><a href="#cb38-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-38"><a href="#cb38-38" aria-hidden="true" tabindex="-1"></a>bird_cv_length_plot <span class="sc">+</span>  </span>
<span id="cb38-39"><a href="#cb38-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb38-40"><a href="#cb38-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_roc</span>(<span class="fu">aes</span>(<span class="at">m =</span> yes, <span class="at">d =</span> obs), <span class="at">color =</span> <span class="st">&quot;black&quot;</span>)</span>
<span id="cb38-41"><a href="#cb38-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-42"><a href="#cb38-42" aria-hidden="true" tabindex="-1"></a><span class="fu">calc_auc</span>(bird_cv_length_plot)</span>
<span id="cb38-43"><a href="#cb38-43" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   PANEL group   AUC</span></span>
<span id="cb38-44"><a href="#cb38-44" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1     1     1 0.509</span></span>
<span id="cb38-45"><a href="#cb38-45" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2     1     2 0.750</span></span>
<span id="cb38-46"><a href="#cb38-46" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3     1     3 0.781</span></span>
<span id="cb38-47"><a href="#cb38-47" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4     1     4 0.574</span></span></code></pre></div>
<p><img src="05-log_files/figure-html/unnamed-chunk-32-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="drawing-interactions" class="section level3" number="5.8.8">
<h3 number="5.8.8"><span class="header-section-number">5.8.8</span> Drawing interactions</h3>
<p><a href="https://interactions.jacob-long.com/index.html" class="uri">https://interactions.jacob-long.com/index.html</a></p>
<!--chapter:end:05-log.Rmd-->
</div>
</div>
</div>
<div id="survival-analysis" class="section level1" number="6">
<h1 number="6"><span class="header-section-number">6</span> Survival Analysis</h1>
<p>To motivate the technical details which are vital to understanding survival analysis, consider the following example <span class="citation">(<a href="#ref-gerds" role="doc-biblioref">Gerds 2016</a>)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-32" class="example"><strong>(#exm:unlabeled-div-32) </strong></span>In class – experience the Titanic going down.</p>
<ul>
<li>The Titanic is sinking. How long can you hold your breath?<br />
</li>
<li>Every person is sinking and will also be their own time keeper (number of seconds the sinker can hold their breath).<br />
</li>
<li>Because the Titanic is sinking slowly, the participants go under water asynchronously (i.e., at different times).<br />
</li>
<li>Accrual period will last about a minute.<br />
</li>
<li>When I say “stop” (about another minute), everyone should end their time clocks (this is the end of the follow-up period).<br />
</li>
<li>Each participant will have a recorded time as well as an indicator as to whether or not they have died.</li>
</ul>
<p>Based on the data, we would like to calculate:<br />
1. What is the probability of surviving 40 seconds?<br />
2. What is the median survival time?<br />
3. What is the average survival time?</p>
</div>
<p>The next example is given in your text <span class="citation">(<a href="#ref-KuiperSklar" role="doc-biblioref">Kuiper and Sklar 2013</a> (chapter 9))</span> as part of the motivation for survival analysis.</p>
<div class="example">
<p><span id="exm:unlabeled-div-33" class="example"><strong>(#exm:unlabeled-div-33) </strong></span>Class chocolate melting activity</p>
<ul>
<li>Each student should be randomly assigned to a white or milk chocolate chip (flip a coin)<br />
</li>
<li>When the instructor gives approval, students should place either a white or milk chocolate chip into their mouths and record the time until it completely melts.<br />
</li>
<li>Treat the study as if it could only be done for a specified period of time (this may require some experimenting, but 60 seconds has worked well). If the actual time is less than 60 seconds, then the actual time will be complete. The student should submit the data (chip color, actual time, censoring status); 1=observed, 0=censored. Any chips that are “swallowed” prior to 60 seconds should be regarded as censored.</li>
</ul>
</div>
<p>Survival analysis is typically done with a prospective study (see censoring below) on a cohort of patients (observational or experimental) to determine some clinical outcome. We will also usually measure covariates of interest: treatment, clinical variables measured at recruitment, etc.</p>
<blockquote>
<p><strong>Key Point</strong>: the outcome of interest (death, recurrence, etc.) may <em>not</em> occur</p>
</blockquote>
<p>Possible responses:</p>
<ul>
<li><p>Outcome of interest occurs<br />
</p></li>
<li><p>Study ends<br />
</p></li>
<li><p>The individual can no longer be measured (moves away, etc.)</p></li>
<li><p><strong>response</strong> fate <em>and</em> length of follow-up<br />
</p></li>
<li><p><strong>data</strong> suppose we are following n patients<br />
<span class="math display">\[
\begin{align*}
t_i &amp;= \mbox{time the } i^{th} \mbox{ has event of interest}\\
m(t) &amp;= \mbox{number of patients for whom } t_i &gt; t \mbox{ (die
later)}\\
d(t) &amp;= \mbox{number of patients for whom } t_i \leq t \mbox{
(die sooner)}\\
\end{align*}
\]</span></p></li>
</ul>
<div id="timedata" class="section level2" number="6.1">
<h2 number="6.1"><span class="header-section-number">6.1</span> Time-to-event data</h2>
<div id="survival-function" class="section level3" number="6.1.1">
<h3 number="6.1.1"><span class="header-section-number">6.1.1</span> Survival Function</h3>
<p>The two main quantities of interest (i.e., <em>parameters</em>) are:</p>
<p><span class="math display">\[
\begin{align*}
S(t) &amp;= P(T &gt; t) = \mbox{ probability of surviving until after time } t\\
D(t) &amp;= P(T \leq t) = \mbox{ probability of dying by time } t \ (= F(t))\\
\end{align*}
\]</span> Where <span class="math inline">\(T\)</span> is a random variable representing the time to event; t is a number.</p>
<p>If <span class="math inline">\(t_i\)</span> is known for all i (no censoring), we can estimate <span class="math inline">\(S(t)\)</span> and <span class="math inline">\(D(t)\)</span> with <span class="math display">\[
\begin{align*}
\hat{S}(t)_E &amp;= m(t)/n = \mbox{ proportion alive at time } t\\
\hat{D}(t)_E &amp;= d(t)/n = \mbox{ proportion who have died by time } t\\
\end{align*}
\]</span></p>
<div id="censoring" class="section level4" number="6.1.1.1">
<h4 number="6.1.1.1"><span class="header-section-number">6.1.1.1</span> censoring</h4>
<ul>
<li><strong>right</strong> censoring: when the observation on an individual begins at a defined starting time and ends before the outcome of interest happens (this is the censoring for our model)<br />
</li>
<li><strong>left</strong> censoring: when the outcome of interest is known to have occurred before the study begins (infection of a disease, learning to count). Note that the event of interest <em>has happened</em>, unlike in right censoring where the event of interest has not happened.<br />
</li>
<li><strong>interval</strong> censoring; when the event of interest is only known to have occurred between two time points, but the precise time is not known.</li>
</ul>
<p><strong>Important Assumption</strong>: survival time must be independent of any mechanism which causes censoring (called non-informative censoring). Censoring should be random: a person who is censored has the same probability of dying as non-censored people at given explanatory variables <span class="math inline">\(\underline{X}\)</span>.</p>
<p>Said differently: within any subgroup of interest, the subjects who are censored at time <span class="math inline">\(t\)</span> should be representative of all the subjects in that subgroup who remained at risk at time <span class="math inline">\(t\)</span> with respect to their survival experience.</p>
<ul>
<li><p>Not independent</p>
<ul>
<li>Subjects who drop out because they are extremely ill<br />
</li>
<li>Subjects who drop out because of adverse effects of the treatment regimen<br />
</li>
</ul></li>
<li><p>Independent</p>
<ul>
<li>Subjects who drop out because the study ends<br />
</li>
<li>Subjects who drop out because they move away</li>
</ul></li>
</ul>
<div class="example">
<p><span id="exm:unlabeled-div-34" class="example"><strong>(#exm:unlabeled-div-34) </strong></span>Suppose we have the following melting times (in seconds) of milk chocolate chips for 7 students where the maximum time allowed for the experiment was 60 seconds:</p>
<table>
<thead>
<tr class="header">
<th align="right">Student</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
<th align="center">7</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">Time</td>
<td align="center">35</td>
<td align="center">30</td>
<td align="center">60</td>
<td align="center">45</td>
<td align="center">25</td>
<td align="center">55</td>
<td align="center">30</td>
</tr>
</tbody>
</table>
<p>To find the estimated proportion of chocolate chips that have not melted after 45 seconds we use the <strong>empirical survival function</strong>, <span class="math inline">\(\hat{S}(45)_E\)</span>. <span class="math display">\[
\begin{align*}
\hat{S}(45)_E &amp;= \frac{\mbox{number of chips that have not melted
after 45 seconds}}{\mbox{total number of chips in the sample}}\\
&amp;= 2/7 = 0.286\\
\hat{S}(t)_E &amp;= \frac{\mbox{number of individuals yet to experience
the event at time } t}{\mbox{number of individuals in the study}}\\
&amp;= \frac{\mbox{number of event times greater than } t}{\mbox{number
of individuals in the study}}\\
\end{align*}
\]</span></p>
<p>What if some of the observations are incomplete (i.e., censored)?</p>
<table>
<thead>
<tr class="header">
<th align="right">Student</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
<th align="center">7</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">Time</td>
<td align="center"><span class="math inline">\(35^+\)</span></td>
<td align="center">30</td>
<td align="center"><span class="math inline">\(60^+\)</span></td>
<td align="center">45</td>
<td align="center">25</td>
<td align="center">55</td>
<td align="center"><span class="math inline">\(30^+\)</span></td>
</tr>
</tbody>
</table>
<p>One way to deal with censored observations is to remove them from the study. We would consider our sample to be only those observations that have complete information.</p>
<table>
<thead>
<tr class="header">
<th align="right">Student</th>
<th align="center">2</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">Time</td>
<td align="center">30</td>
<td align="center">45</td>
<td align="center">25</td>
<td align="center">55</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[
\begin{align*}
\hat{S}(45)_E &amp;= \frac{\mbox{number of chips that have not melted after 45 seconds}}{\mbox{total number of chips in the sample}}\\
&amp;= 1/4 = 0.25\\
\end{align*}
\]</span></p>
</div>
<p>By treating censored observations as complete, we assume that the event times are shorter than what they actually are (thereby underestimating the true probability of survival). By removing the censored observations from the data, we lose information. By treating censored observations as complete we bias the estimate based on the remaining times; by ignoring censored observations, we reduce the power of the inferential model.</p>
</div>
</div>
</div>
<div id="KM" class="section level2" number="6.2">
<h2 number="6.2"><span class="header-section-number">6.2</span> Kaplan-Meier Curves</h2>
<p>When a data set contains incomplete observations, the best estimator of the survival function is the Kaplan-Meier estimator, <span class="math inline">\(\hat{S}(t)_{KM}\)</span>. We’ll create a few curves by hand, and then we’ll let R make them for us.</p>
<p><span class="math display">\[
\begin{align*}
t_1 &lt; t_2 &lt; \cdots &lt; t_n &amp; \ \mbox{ are the ordered completed times}\\
n_i &amp;= \mbox{number of patients known to be at risk at time (day) } t_i, \mbox{ just before } [t_i, t_{i+1})\\
d_i &amp;= \mbox{number of patients who die at time (day) } t_i, \mbox{ in } [t_i, t_{i+1})\\
\end{align*}
\]</span></p>
<p>For the patients alive at the beginning of the <span class="math inline">\(t_i^{th}\)</span> time, the probability of surviving that time is <span class="math display">\[p_i = \frac{n_i - d_i}{n_i}\]</span> The probability that a patient survives to time 2 given that they survived to time 1 is <span class="math display">\[p_2 = \frac{n_2 - d_2}{n_2}\]</span> The probability that (at the outset) a patient survives to time 2 is: <span class="math display">\[
\begin{align*}
P(T &gt; t_2) &amp;= P(T &gt; t_2 | T &gt; t_1) P(T &gt; t_1)\\
&amp;= \frac{n_1 - d_1}{n_1} \frac{n_2 - d_2}{n_2}
\end{align*}
\]</span> The probability of surviving the first t days is: <span class="math display">\[
\begin{align*}
\hat{S}(t)_{KM} &amp;= \prod_{i:t_i &lt; t} \frac{n_i - d_i}{n_i}\\
&amp;= \prod_{i:t_i &lt; t} p_i\\
\hat{D}(t)_{KM} &amp;= 1 - \hat{S}(t)_{KM}\\
\end{align*}
\]</span> If there are no deaths at time <span class="math inline">\(t_i\)</span>, then <span class="math inline">\((n_i -d_i) / n_i = 1\)</span>.</p>
<p>If there is no censoring at time <span class="math inline">\(t_i\)</span>, then <span class="math inline">\(n_i - d_i = n_{i+1}\)</span>. The Kaplan-Meier survival curve will be equivalent to the empirical survival curve:</p>
<p><span class="math display">\[
\begin{align*}
\hat{S}(t)_{KM} &amp;= \prod_{i:t_i &lt; t} \frac{n_i - d_i}{n_i}\\
&amp;= \frac{n_1 - d_1}{n_1} \frac{n_2 - d_2}{n_2} \cdots \frac{n_k - d_k}{n_k}\\
&amp;= \frac{m(t)}{n}
\end{align*}
\]</span> ::: {.example} milk chocolate times by hand.</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(t_i\)</span></th>
<th align="center"><span class="math inline">\(n_i\)</span></th>
<th align="center"><span class="math inline">\(d_i\)</span></th>
<th align="center"><span class="math inline">\(n_i - d_i\)</span></th>
<th align="center"><span class="math inline">\(\frac{n_i - d_i}{n_i}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">25</td>
<td align="center">7</td>
<td align="center">1</td>
<td align="center">6</td>
<td align="center">6/7= 0.857</td>
</tr>
<tr class="even">
<td align="center">30</td>
<td align="center">6</td>
<td align="center">1</td>
<td align="center">5</td>
<td align="center">5/6 = 0.833</td>
</tr>
<tr class="odd">
<td align="center">35</td>
<td align="center">4</td>
<td align="center">0</td>
<td align="center">4</td>
<td align="center">4/4 = 1</td>
</tr>
<tr class="even">
<td align="center">45</td>
<td align="center">3</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2/3 = 0.667</td>
</tr>
<tr class="odd">
<td align="center">55</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1/2=0.5</td>
</tr>
<tr class="even">
<td align="center">60</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1/1=1</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th align="center">time interval</th>
<th align="center"><span class="math inline">\(\hat{S}(t)_{KM}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\([0,25)\)</span></td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\([25,30)\)</span></td>
<td align="center">0.857</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\([30, 35)\)</span></td>
<td align="center">0.857 <span class="math inline">\(\cdot\)</span> 0.833 = 0.714</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\([35,45)\)</span></td>
<td align="center">0.714 <span class="math inline">\(\cdot\)</span> 1 = 0.714</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\([45,55)\)</span></td>
<td align="center">0.714 <span class="math inline">\(\cdot\)</span> 0.667 = 0.476</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\([55,60)\)</span></td>
<td align="center">0.476 <span class="math inline">\(\cdot\)</span> 0.5 = 0.238</td>
</tr>
</tbody>
</table>
<p>:::</p>
<div id="KMCI" class="section level3" number="6.2.1">
<h3 number="6.2.1"><span class="header-section-number">6.2.1</span> CI for KM curve</h3>
<p>Recall: <span class="math inline">\(\hat{S}(t)_{KM} = \prod_{k:t_k &lt; t} [ (n_k - d_k) / n_k]\)</span>.</p>
<p>Because <span class="math inline">\(\hat{S}(t)_{KM}\)</span> is just a product of counts, we can “easily” estimate the SE: <span class="math display">\[
\begin{align*}
s^2_{\hat{S}(t)_{KM}} = \hat{S}(t)_{KM}^2 \sum_{k:t_k &lt; t}
\frac{d_k}{n_k(n_k - d_k)}
\end{align*}
\]</span></p>
<p>Your book uses the above SE and normal theory which does work, particularly with large sample sizes. However, with smaller sample sizes and at the ends of the survival curve (close to zero or one), the sampling distribution of the estimated KM curve will not be normal. Additionally if we try to apply normal theory, we’ll get something meaningless because the CI will go outside the bounds of 0 and 1. Fortunately, someone figured out a transformation for us!</p>
<p><span class="math inline">\(l l \hat{S}(t) = \ln (-\ln \hat{S}(t)_{KM})\)</span> has a much more normal sampling distribution than the sampling distribution of the untransformed estimator <span class="math inline">\(\hat{S}(t)_{KM}\)</span>.</p>
<p><span class="math display">\[
\begin{align*}
\hat{\sigma}^2(t) &amp;= SE( l l \hat{S}(t))\\
&amp;= \frac{\sum_{k:t_k &lt; t} \frac{d_k}{n_k(n_k - d_k)}}{\bigg[\sum_{k:t_k &lt; t} \ln ( (n_k - d_k) / n_k) \bigg]^2}
\end{align*}
\]</span> A 95 % CI for <span class="math inline">\(\ln ( -\ln S(t))\)</span> is <span class="math display">\[ll\hat{S}(t) \pm 1.96 \hat{\sigma}(t) \ \ \ \mbox{(a function of
t!!!)}\]</span></p>
<p>A 95 % CI for <span class="math inline">\(S(t)\)</span> is <span class="math display">\[\bigg(\hat{S}(t)_{KM}^{\exp(1.96\hat{\sigma}(t))},
\hat{S}(t)_{KM}^{\exp(-1.96\hat{\sigma}(t))} \bigg)\]</span></p>
<p>We can also find a CI for <span class="math inline">\(D(t) = 1- S(t)\)</span> using:</p>
<p><span class="math display">\[
\begin{align*}
\bigg(1 - \hat{S}(t)_{KM}^{\exp(-1.96\hat{\sigma}(t))}, 1 -
\hat{S}(t)_{KM}^{\exp(1.96\hat{\sigma}(t))} \bigg)
\end{align*}
\]</span></p>
<div id="derivation-of-the-above-confidence-intervals." class="section level5 unnumbered">
<h5 class="unnumbered">Derivation of the above confidence intervals.</h5>
<p>Remember that <span class="math inline">\(\exp(a \cdot b) = (\exp(a))^b\)</span>, we’ll need that below. A CI is an interval of values that captures the true parameter in 95 of samples. Let’s say that the complementary log-log interval from above happens to catch the true value of <span class="math inline">\(S(t)\)</span>. Then,</p>
<p><span class="math display">\[
\begin{align*}
ll\hat{S}(t) - 1.96 \hat{\sigma}(t) \leq  &amp; llS(t)  \leq ll\hat{S}(t) + 1.96 \hat{\sigma}(t) \\
\exp(ll\hat{S}(t) - 1.96 \hat{\sigma}(t)) \leq  &amp; -lS(t)  \leq \exp(ll\hat{S}(t) + 1.96 \hat{\sigma}(t)) \\
-l\hat{S}(t)\exp(- 1.96 \hat{\sigma}(t))\leq  &amp;-lS(t)  \leq -l\hat{S}(t)\exp(1.96 \hat{\sigma}(t)) \\
l\hat{S}(t)\exp(- 1.96 \hat{\sigma}(t))\geq  &amp; lS(t)  \geq l\hat{S}(t)\exp(1.96 \hat{\sigma}(t)) \\
l\hat{S}(t)\exp(1.96 \hat{\sigma}(t))\leq  &amp; lS(t)  \leq l\hat{S}(t)\exp(-1.96 \hat{\sigma}(t)) \\
\exp(l\hat{S}(t)\exp(1.96 \hat{\sigma}(t))) \leq  &amp; S(t)  \leq \exp(l\hat{S}(t)\exp(-1.96 \hat{\sigma}(t))) \\
\exp(l\hat{S}(t))^{\exp(1.96 \hat{\sigma}(t))} \leq  &amp; S(t)  \leq \exp(l\hat{S}(t))^{\exp(-1.96 \hat{\sigma}(t))} \\
(\hat{S}(t))^{\exp(1.96 \hat{\sigma}(t))} \leq  &amp; S(t)  \leq (\hat{S}(t))^{\exp(-1.96 \hat{\sigma}(t))}
\end{align*}
\]</span></p>
</div>
<div id="mean-and-median-values" class="section level4" number="6.2.1.1">
<h4 number="6.2.1.1"><span class="header-section-number">6.2.1.1</span> Mean and Median values</h4>
<p><strong>Mean</strong></p>
<blockquote>
<p>Mean survival time is estimated as the area under the survival curve. The estimator is based upon the entire range of data. Some software uses only the data up to the last observed event <span class="citation">(<a href="#ref-SurvHL" role="doc-biblioref">Hosmer, Lemeshow, and May 2008</a>)</span> point out that this biases the estimate of the mean downwards, and they recommend that the entire range of data be used. A large sample method is used to estimate the variance of the mean survival time and thus to construct a confidence interval <span class="citation">(<a href="#ref-Andersen" role="doc-biblioref">Andersen et al. 1996</a>)</span>. <span class="citation">(<a href="#ref-KMmean" role="doc-biblioref">StatsDirect Limited 2016</a>)</span></p>
</blockquote>
<p>In some ways, it is easier to conceptualize the mean as the average under the curve by thinking about calculating average as horizontal bars instead of vertical bars. The jumps along the y-axis are approximately 1/n, so each horizontal bar represents one of the individual deaths. See the example here: <a href="http://blog.data-miners.com/2010/06/why-is-area-under-survival-curve-equal.html" class="uri">http://blog.data-miners.com/2010/06/why-is-area-under-survival-curve-equal.html</a></p>
<p><span class="math display">\[
\begin{align*}
\hat{\mu} = \left\{
    \begin{array}{ll}
    \sum_{i=0}^{m-1} \hat{S}(t_i)_{KM} (t_{i+1} - t_i) &amp; \mbox{if } t_n = t_m  \mbox{ (last obs is complete)}\\
    \sum_{i=0}^{m-1} \hat{S}(t_i)_{KM} (t_{i+1} - t_i) + \hat{S}(t_m)_{KM}(t_n-t_m) &amp; \mbox{if last obs is censored}
    \end{array}
\right.
\end{align*}
\]</span></p>
<p>Each entry can be rearranged to be thought of as the proportion of people who die in the interval times the width of the interval: <span class="math inline">\([\hat{S}(t_{i-1})_{KM} - \hat{S}(t_{i})_{KM}]t_i\)</span>. The difference, <span class="math inline">\([\hat{S}(t_{i-1})_{KM} - \hat{S}(t_{i})_{KM}]\)</span>, gives the proportion of individuals who die in that time interval. Therefore, our estimate is a weighted average of the time points <span class="math inline">\(t_i\)</span> where the weight is <span class="math inline">\([\hat{S}(t_{i-1})_{KM} - \hat{S}(t_{i})_{KM}]\)</span>.</p>
<p><span class="math display">\[
\begin{align*}
\hat{\mu} &amp;= \sum_{i=0}^{m-1} \hat{S}(t_i)_{KM}(t_{i+1} - t_i)\\
&amp;= \hat{S}(t_0)_{KM}(t_1 - t_0) + \hat{S}(t_1)_{KM}(t_2 - t_1) + \hat{S}(t_2)_{KM} (t_3 - t_2) + \cdots + \hat{S}(t_{m-1})_{KM} (t_m - t_{m-1}) \\
&amp;= -t_0  \hat{S}(t_0)_{KM} + t_1 ( \hat{S}(t_0)_{KM} -  \hat{S}(t_1)_{KM}) + \cdots + t_{m-1}( \hat{S}(t_{m-2})_{KM} -  \hat{S}(t_{m-1})_{KM}) + t_m  \hat{S}(t_{m-1})_{KM}\\
&amp;= 0 + t_1 ( \hat{S}(t_0)_{KM} -  \hat{S}(t_1)_{KM}) + \cdots + t_{m-1}( \hat{S}(t_{m-2})_{KM} -  \hat{S}(t_{m-1})_{KM}) + t_m ( \hat{S}(t_{m-1})_{KM} - 0)\\
&amp;= \mbox{a weighted average of the times}
\end{align*}
\]</span></p>
<p><strong>Median</strong><br />
Since the distribution of survival times tend to be positively skewed, the median is often the preferred summary measure of location of the distribution. Once the survivor function has been estimated, it is straightforward to obtain an estimate of the <em>median survival time</em>. That is, the time beyond which 50 % of the individuals in the population under study are expected to survive, and is given by the value <span class="math inline">\(t_{(50)}\)</span> such that <span class="math inline">\(S(t_{(50)}) = 0.5\)</span>.</p>
<p><span class="math display">\[
\begin{align*}
\hat{t}_{(p)} = \mbox{smallest complete event time, } t_i, \mbox{ in the sample such that } \hat{S}(t_i)_{KM} \leq 1-p/100
\end{align*}
\]</span></p>
<p><span class="math inline">\(\hat{S}(t_i)_{KM}\)</span> then gives the time at which at least p % of events have occurred. There are also ways of compute confidence intervals for percentiles. We won’t cover those here.</p>
</div>
</div>
<div id="logrank" class="section level3" number="6.2.2">
<h3 number="6.2.2"><span class="header-section-number">6.2.2</span> Log-rank Test</h3>
<p>As before, we’d like to know if two treatments produce the same probability of survival (how did we do that with logistic regression? significance of the <span class="math inline">\(\beta\)</span> coefficient). Here: <span class="math display">\[
\begin{align*}
H_0: &amp; S_1(t) = S_2(t) \ \ \ \ \ \forall t \mbox{
parameters!}\\
H_1: &amp; S_1(t) \ne S_2(t) \ \ \ \ \ \mbox{ for some } t\\
\end{align*}
\]</span></p>
<p>We want to test whether the curves are the same over all <span class="math inline">\(t\)</span> (or different at any <span class="math inline">\(t\)</span>). Let’s consider a particular time, the <span class="math inline">\(j^{th}\)</span> event time (we don’t look at the censored times, because we only consider when the curve changes / steps):</p>
<table>
<thead>
<tr class="header">
<th align="right"></th>
<th align="center">Group 1</th>
<th align="center">Group 2</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">died</td>
<td align="center"><span class="math inline">\(d_{1j}\)</span></td>
<td align="center"><span class="math inline">\(d_{2j}\)</span></td>
<td><span class="math inline">\(d_j\)</span></td>
</tr>
<tr class="even">
<td align="right">survived</td>
<td align="center"><span class="math inline">\(n_{1j} - d_{1j}\)</span></td>
<td align="center"><span class="math inline">\(n_{2j} - d_{2j}\)</span></td>
<td><span class="math inline">\(n_j - d_j\)</span></td>
</tr>
<tr class="odd">
<td align="right"></td>
<td align="center"><span class="math inline">\(n_{1j}\)</span></td>
<td align="center"><span class="math inline">\(n_{2j}\)</span></td>
<td><span class="math inline">\(n_j\)</span></td>
</tr>
</tbody>
</table>
<p>Because it’s a <span class="math inline">\(2x2\)</span> table with fixed margins, we only need to consider one group. If survival is similar for the two groups, we’d expect:</p>
<p><span class="math display">\[
\begin{align*}
d_{1j} &amp;\approx \frac{d_j}{n_j}n_{1j}\\
d_{1j} &amp;= \mbox{observed}\\
\frac{d_j}{n_j} n_{1j} &amp;= E(d_{1j} | d_j) = E_{1j} \\
var(d_{1j}) &amp;= \frac{n_{1j} n_{2j} d_j (n_j - d_j)}{n_j^2(n_j-1)}
= V_{1j}\\
\end{align*}
\]</span> where the variance is derived from the hypergeometric distribution.</p>
<p>To estimate the overall difference between the observed and expected death counts: <span class="math display">\[
\begin{align*}
\sum_j d_{1j} - \sum_j E(d_{1j} | d_j) = \sum_j d_{1j} - \sum_j
\frac{d_j}{n_j}n\_{1j}
\end{align*}
\]</span> The overall variability: <span class="math display">\[\sum_j var(d_{1j}|d_j)\]</span> The test statistic we use to compare the observed and expected frequency of deaths. (Sum over all of the death (or event) times.) <span class="math display">\[
\begin{align*}
T = \frac{(|\sum_j d_{1j} - \sum_j E(d_{1j} | d_j)| -
0.5)^2}{\sum_j var(d_{1j}|d_j)} \sim \chi^2_1
\end{align*}
\]</span></p>
<p>What if we had had <span class="math inline">\(g\)</span> groups (instead of 2)? We would have <span class="math inline">\(g-1\)</span> “death” values. Consider the test statistic above, call it <span class="math inline">\(T_1\)</span>. If we had <span class="math inline">\(g\)</span> groups, we would need to sum <span class="math inline">\(T_i, i=1,2, \ldots, g-1\)</span>. However, the variances of the <span class="math inline">\(T_i\)</span> would be correlated (because the values must sum to <span class="math inline">\(D_k\)</span>)… so the test statistic is slightly more complicated. <span class="citation">(<a href="#ref-Collett" role="doc-biblioref">Collett 2015</a>(section 2.6))</span></p>
<ul>
<li>The Wilcoxon test is very similar to the log-rank test, but it uses a different derivation for the variance, and therefore a different denominator and test statistic.<br />
</li>
<li>The log-rank test is more powerful than the Wilcoxon, but the log-rank test requires the proportional hazards assumption.<br />
</li>
<li>Wilcoxon test does not require the proportional hazards assumption, but it does require that one curve is always bigger than the other.<br />
</li>
<li>Neither work if the curves cross.<br />
</li>
<li>Other technical conditions are that the sample size should be “big enough.” The sample size is dependent on the number of deaths. No specific criteria, but the results are asymptotic, so the p-values converge to the actual probabilities as the number of deaths gets larger.</li>
</ul>
</div>
</div>
<div id="hazfunc" class="section level2" number="6.3">
<h2 number="6.3"><span class="header-section-number">6.3</span> Hazard Functions</h2>
<p>Another important idea in survival analysis is the hazard function or instantaneous death rate. Let T be the random variable representing death time. [Your text implicitly redefines <span class="math inline">\(S(t) = P(T \geq t)\)</span> which is inconsistent but not fundamentally problematic.]</p>
<p><span class="math display">\[
\begin{align*}
h(t)&amp;= \lim_{\Delta t \rightarrow 0} \frac{P(\mbox{patient dies by time } t + \Delta t | \mbox{alive at } t)}{\Delta t}\\
 &amp;= \lim_{\Delta t \rightarrow 0} \frac{P(T &lt; t + \Delta t | T \geq t)}{\Delta t}\\
 &amp;= \lim_{\Delta t \rightarrow 0} \frac{P(t \leq T &lt; t + \Delta t | T \geq t)}{\Delta t}\\
 &amp;= \lim_{\Delta t \rightarrow 0} \frac{P(t \leq T &lt; t + \Delta t )}{P(T \geq t) \Delta t}\\
 &amp;= \lim_{\Delta t \rightarrow 0} \frac{S(t) - S(t + \Delta t)}{S(t) \Delta t}\\
 &amp;= \lim_{\Delta t \rightarrow 0} -\frac{S(t + \Delta t) - S(t)}{\Delta t}\frac{1}{S(t)}\\
 &amp;= -S&#39;(t) \frac{1}{S(t)}\\
 &amp;= -\frac{d}{dt} \ln(S(t))\\
S(t) &amp;= \exp \{ - \int^t_0 h(x) dx  \}\\
\end{align*}
\]</span></p>
<p>How do different functions of <span class="math inline">\(h\)</span> affect the survival curve, <span class="math inline">\(S\)</span>?</p>
<p><span class="math display">\[
\begin{align*}
h(t) = 0 &amp;&amp;\Rightarrow \mbox{ no risk of death at time } t\\
&amp;&amp; \Rightarrow S(t) \mbox{ is flat at } t\\
h(t) \&gt; \&gt;&amp;&amp; \Rightarrow S(t) \mbox{ is rapidly declining in } t\\
h(t) =k &amp;&amp; \Rightarrow S(t) = e^{-kt}
\end{align*}
\]</span></p>
<div id="hazard-function-as-a-constant" class="section level4" number="6.3.0.1">
<h4 number="6.3.0.1"><span class="header-section-number">6.3.0.1</span> hazard function as a constant</h4>
<p>If <span class="math inline">\(h(t) =k \rightarrow S(t) = e^{-kt}\)</span>.</p>
<p>Plots of different hazard functions and their corresponding survival functions.</p>
<p><img src="06-surv_files/figure-html/unnamed-chunk-2-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="estimating-ht-ala-kaplan-meier" class="section level3" number="6.3.1">
<h3 number="6.3.1"><span class="header-section-number">6.3.1</span> Estimating <span class="math inline">\(h(t)\)</span> ala Kaplan-Meier</h3>
<p><span class="math inline">\(h(t)\)</span> is the rate at which individuals in the population experience the event in the next <em>instant</em> of time, conditional on surviving to time <span class="math inline">\(t\)</span>. The estimated hazard curve can only extend to the last complete event time, otherwise the denominator is infinitely large. Also, keep in mind that <span class="math inline">\(h(t)\)</span> is very hard to estimate, and <span class="math inline">\(\hat{h}_{KM}(t)\)</span> can be erratic.</p>
<p><span class="math display">\[
\begin{align*}
\hat{P}(t_i \leq T &lt; t_{i+1} | T \geq t_i) &amp;= \frac{d_i}{n_i} = \hat{p}_i\\
\hat{h}_{KM}(t) &amp;= \frac{\hat{p}_i}{t_{i+1} - t_i}  \ \ \ \ \ \ t_{i+1} \leq t &lt; t_i\\
\end{align*}
\]</span></p>
</div>
<div id="proportional-hazards" class="section level3" number="6.3.2">
<h3 number="6.3.2"><span class="header-section-number">6.3.2</span> Proportional Hazards</h3>
<p>Suppose that <span class="math inline">\(h_0(t)\)</span> and <span class="math inline">\(h_1(t)\)</span> are the hazard functions for patients on control and experimental treatments. The two groups have {proportional hazards} if <span class="math inline">\(h_1(t) = R h_0(t)\)</span> for some constant R: <span class="math display">\[\frac{h_1(t)}{h_0(t)} = R \ \ \ \ \ \forall t\]</span> R is called the <strong>hazard ratio</strong>. <span class="math inline">\(h_0(t)\)</span> can be anything as long as <span class="math inline">\(h_1(t)\)</span> is proportional. Note in the pictures below that no one dies between 3 and 7 days, the survival curves are flat over that interval.</p>
<p><img src="06-surv_files/figure-html/unnamed-chunk-3-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Consider the notion of risk of death: <span class="math display">\[
\begin{align*}
\mbox{risk of death by } t + \Delta t \mbox{ given alive at } t=
\left\{
\begin{array}{ll}
h_0(t) \Delta t &amp; \mbox{control}\\
h_1(t) \Delta t &amp; \mbox{experiment}
\end{array}
\right.
\end{align*}
\]</span></p>
<p><span class="math display">\[
\begin{align*}
\frac{\mbox{risk of dying for experim}}{\mbox{risk of dying control}} = \frac{h_1(t) \Delta t}{h_0(t) \Delta t} = \frac{h_1(t) }{h_0(t) } = R
\end{align*}
\]</span>Ratio of hazard functions can be thought of as the <strong>instantaneous relative risk</strong> (i.e., at a time <span class="math inline">\(t\)</span>).</p>
</div>
<div id="coxph" class="section level3" number="6.3.3">
<h3 number="6.3.3"><span class="header-section-number">6.3.3</span> Cox PH Regression Analysis</h3>
<div id="simple-proportional-hazards-model" class="section level4" number="6.3.3.1">
<h4 number="6.3.3.1"><span class="header-section-number">6.3.3.1</span> Simple proportional hazards model</h4>
<p>ASSUMING proportional hazards! Let <span class="math inline">\(h_0(t)\)</span> be the hazard function for the control group. <span class="math inline">\(x_i\)</span> =1 if the <span class="math inline">\(i^{th}\)</span> patient receives treatment; 0 if the <span class="math inline">\(i^{th}\)</span> patient receives the control. A big value of <span class="math inline">\(\beta\)</span> means that the event is more likely to happen.</p>
<p><span class="math display">\[
\begin{align*}
h_i(t) &amp;= h_0(t) e^{\beta x_i} = \left\{
\begin{array}{ll}
h_0(t) e^\beta &amp; \mbox{experim}\\
h_0(t) &amp; \mbox{control}
\end{array}
\right.\\
\mbox{inst. RR} &amp;= \frac{h_0(t) e^\beta}{h_0(t)} = e^\beta\\
S_i(t) &amp;= (S_0(t))^{e^\beta}\\
\end{align*}
\]</span> We don’t yet know how to run this model and estimate the parameters, but still, we can probably do it. Right? We run a <strong>Cox proportional hazards model</strong>, get <span class="math inline">\(b\)</span>, and estimate the HR using: <span class="math inline">\(\widehat{HR} = e^{b}\)</span>! It turns out that for large samples (as with logistic regression, the CI and tests below are again called Wald CI and tests),</p>
<p><span class="math display">\[
\begin{align*}
b \sim N: &amp; \\
&amp; 95\% \mbox{ CI for } \beta: b \pm 1.96 SE(b)\\
&amp; 95\% \mbox{ CI for } HR: (e^{b - 1.96 SE(b)}, e^{b + 1.96 SE(b)})\\
\end{align*}
\]</span> And we can test HR by using <span class="math inline">\(\beta\)</span>: <span class="math display">\[
\begin{align*}
H_0: \ &amp; \beta=0 \iff HR = 1\\
Z &amp;= \frac{b - 0 }{SE(b)}
\end{align*}
\]</span></p>
</div>
<div id="estimating-the-proportional-hazards-coefficients" class="section level4" number="6.3.3.2">
<h4 number="6.3.3.2"><span class="header-section-number">6.3.3.2</span> Estimating the proportional hazards coefficients</h4>
<p>The main point of proportional hazards is that if we have proportional hazards, then we don’t actually need to know the hazard function in order to estimate the coefficients which affect the survival function. [We divide out the hazard function.]</p>
<p>Intervals between death times convey no information about the relationship between hazard and explanatory variables (including treatment). We are also assuming that we have no ties for our death times. [Importantly, we assume that the proportional hazards assumption holds over <em>all</em> <span class="math inline">\(t\)</span>.]</p>
<p><span class="math display">\[
\begin{align*}
P(i^{th} \mbox{ indiv, w/}x_i, \mbox{ dies at } t_i | \mbox{one death at } t_i) &amp;= \frac{P(i^{th} \mbox{ indiv w/}x_i \mbox{ dies at } t_i )}{P(\mbox{at least one death at } t_i)}\\
&amp;= \frac{\mbox{hazard at } t_i}{\mbox{sum over all patients at risk at time } t_i}\\
&amp;= \frac{h_i(t_i)}{\sum_{k:t_k \geq t_i} h_k (t_i)} \\
&amp;= \frac{e^{\beta x_i}}{\sum_{k:t_k \geq t_i} e^{\beta x_k}}
\end{align*}
\]</span> As with logistic regression (and linear regression!) we’ll use maximum likelihood to estimate the parameter(s). (The product is over only patients who have death times recorded, not censored times).</p>
<p><span class="math display">\[
\begin{align*}
L(\beta) &amp;= \prod_{i=1}^r \frac{e^{\beta x_i}}{\sum_{k:t_k
\geq t_i} e^{\beta x_k}}\\
\delta_i &amp;= \left\{\begin{array}{ll}
1 &amp; \mbox{death}\\
0 &amp; \mbox{censored}
\end{array}
\right.\\
L(\beta) &amp;= \prod_{i=1}^n \Bigg( \frac{e^{\beta
x_i}}{\sum_{k:t_k \geq t_i} e^{\beta x_k}} \Bigg)^{\delta_i}\\
\ln L(\beta) &amp;= \sum_{i=1}^n \delta_i \bigg[ \beta x_i - \ln
(\sum_{k:t_k \geq t_i} e^{\beta x_k}) \bigg]
\end{align*}
\]</span> <span class="math inline">\(b\)</span> is found using numerical methods (as it was with logistic regression).</p>
<div class="example">
<p><span id="exm:unlabeled-div-35" class="example"><strong>(#exm:unlabeled-div-35) </strong></span>Consider the following data from a prostate cancer study. The study was performed as a randomized clinical trail to compare treatments for prostatic cancer, and was begun in 1967 by the Veteran’s Administration Cooperative Urological Research Group. The trial was double blind and two of the treatments used were a placebo and 1.0 mg of diethylstilbestrol (DES). The time origin of the study is the date on which a patient was randomized to a treatment, and the end-point is the death of the patient from prostate cancer. The full data set is given in <span class="citation"><a href="#ref-AndHerz" role="doc-biblioref">Andrews and Herzberg</a> (<a href="#ref-AndHerz" role="doc-biblioref">1985</a>)</span>, but the data used in this example are from patients presenting with Stage III cancer and given in <span class="citation"><a href="#ref-Collett" role="doc-biblioref">Collett</a> (<a href="#ref-Collett" role="doc-biblioref">2015</a>)</span> (page 8).</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(survival)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>prostate <span class="ot">&lt;-</span> readr<span class="sc">::</span><span class="fu">read_csv</span>(<span class="st">&quot;PROSTATE.csv&quot;</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(prostate)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 x 7</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Treatment  Time Status   Age  Haem  Size Gleason</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1         1    65      0    67  13.4    34       8</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2         2    61      0    60  14.6     4      10</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3         2    60      0    77  15.6     3       8</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4         1    58      0    64  16.2     6       9</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5         2    51      0    65  14.1    21       9</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6         1    51      0    61  13.5     8       8</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(Time,Status) <span class="sc">~</span> Treatment, <span class="at">data =</span> prostate)</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; coxph(formula = Surv(Time, Status) ~ Treatment, data = prostate)</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           coef exp(coef) se(coef)  z    p</span></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Treatment -2.0       0.1      1.1 -2 0.07</span></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Likelihood ratio test=5  on 1 df, p=0.03</span></span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; n= 38, number of events= 6</span></span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(Time,Status) <span class="sc">~</span> Treatment, <span class="at">data =</span> prostate) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 5</span></span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term      estimate std.error statistic p.value</span></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 Treatment    -1.98      1.10     -1.80  0.0717</span></span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(Time,Status) <span class="sc">~</span> Treatment, <span class="at">data =</span> prostate) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 18</span></span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       n nevent statistic.log p.value.log statistic.sc p.value.sc statistic.wald</span></span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;</span></span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1    38      6          4.55      0.0329         4.42     0.0355           3.24</span></span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 11 more variables: p.value.wald &lt;dbl&gt;, statistic.robust &lt;dbl&gt;,</span></span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   p.value.robust &lt;dbl&gt;, r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;,</span></span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   concordance &lt;dbl&gt;, std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;,</span></span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   BIC &lt;dbl&gt;, nobs &lt;int&gt;</span></span></code></pre></div>
<ul>
<li><p><strong>Note 1</strong>: There is no intercept in the model. The intercept is contained within the <span class="math inline">\(h_0(t)\)</span> parameter.<br />
</p></li>
<li><p><strong>Note 2</strong>: Nowhere have we made any assumptions about the form of <span class="math inline">\(h_0(t)\)</span>.<br />
</p></li>
<li><p><strong>Note 3</strong>: To estimate <span class="math inline">\(h_0(t)\)</span>, we use the pointwise values, just like Kaplan-Meier plots (<span class="math inline">\(\tau_j = t_{(j+1)} - t_j):\)</span> <span class="math display">\[h_0(t_j) = \frac{d_j}{n_j \tau_j}\]</span> If there are covariates, the estimation gets much more complicated.<br />
</p></li>
<li><p><strong>Note 4</strong>: The logrank statistic can be derived as the score test for the Cox proportional hazards model comparing two groups. It is therefore approximately equivalent to the likelihood ratio test statistics from that model <span class="citation">(<a href="#ref-Collett" role="doc-biblioref">Collett 2015</a> (section 3.9, page 102-106))</span>. Additionally, the log-rank test is most powerful against the alternative that the hazard of death at any given time for an individual in one group is proportional to the hazard at that time for a similar individual in the other group (i.e., the proportional hazards assumption). <span class="citation">(<a href="#ref-Collett" role="doc-biblioref">Collett 2015</a> (section 2.5.4, pg 44-45))</span> <span class="math display">\[
\begin{align*}
H_0:\ &amp;h_1(t) = h_2(t)\\
H_1:\ &amp;h_1(t) = R h_2(t)
\end{align*}
\]</span></p></li>
<li><p><strong>Note 5</strong>: You need proportional hazards to do the <em>inference</em> (otherwise your p-values are meaningless!). The technical assumptions for the Cox Proportional Hazards model are:</p>
<ul>
<li>Observations are independent (this is almost always an important assumption in all of statistical inference)<br />
</li>
<li>Proportional hazards: the hazard ratios are not dependent on time.<br />
</li>
<li>Independent censoring: the censored observations have the same survival prospects as the non-censored participants.<br />
</li>
</ul></li>
</ul>
</div>
</div>
<div id="multcoxph" class="section level4" number="6.3.3.3">
<h4 number="6.3.3.3"><span class="header-section-number">6.3.3.3</span> Cox PH Multiple Regression Analysis</h4>
<p>Extending the simple proportional hazards model to include multiple covariates.</p>
<p>Let <span class="math inline">\(x_{i1}, x_{i2}, \ldots, x_{iq}\)</span> be the <span class="math inline">\(q\)</span> covariates for person <span class="math inline">\(i\)</span>. We define the baseline hazard as: <span class="math display">\[
\begin{align*}
h_0(t) &amp;= \mbox{hazard for patients with covariates }
x_{i1}=x_{i2}=\cdots=x_{iq} = 0\\
h_i(t) &amp;= h_0(t) e^{\beta_1 x_{i1} + \beta_2 x_{i2} + \cdots +
\beta_q x_{iq}}\\
\end{align*}
\]</span> is the hazard function for the <span class="math inline">\(i^{th}\)</span> patient.</p>
<p>As before, we can consider nested models and compare their likelihoods.</p>
<p><span class="math display">\[
\begin{align*}
-2 \ln \frac{L_{\mbox{reduced model}}}{L_{\mbox{full model}}}
&amp;\sim \chi^2_{\Delta p}\\
&amp; \\
2 \bigg( \ln L_{\mbox{full model}} - \ln L_{\mbox{reduced model}} \bigg) &amp;=
\mbox{test stat}\\
\end{align*}
\]</span></p>
<div class="example">
<p><span id="exm:unlabeled-div-36" class="example"><strong>(#exm:unlabeled-div-36) </strong></span><strong>Framingham Heart Study</strong> <span class="citation">(example <a href="#ref-Dupont" role="doc-biblioref">Dupont 2009</a> (section 3.10))</span> Long-term follow-up and cardiovascular risk factor data on almost 5000 residents of the town of Framingham, MA. Recruitment started in 1948 (went for 40+ years). These data are 4699 patients who were free of coronary heart disease at their baseline exam <span class="citation">(<a href="#ref-framingham" role="doc-biblioref">Mahmood et al. 2014</a>)</span>:</p>
<table>
<thead>
<tr class="header">
<th>variable</th>
<th align="center"></th>
<th>code</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>sex</td>
<td align="center">=</td>
<td>gender coded as</td>
</tr>
<tr class="even">
<td></td>
<td align="center"></td>
<td>1=if subject is male</td>
</tr>
<tr class="odd">
<td></td>
<td align="center"></td>
<td>0= if subject is female</td>
</tr>
<tr class="even">
<td>sbp</td>
<td align="center">=</td>
<td>systolic blood pressure (SBP) in mm Hg</td>
</tr>
<tr class="odd">
<td>dbp</td>
<td align="center">=</td>
<td>diastolic blood pressure (DBP) in mm Hg</td>
</tr>
<tr class="even">
<td>scl</td>
<td align="center">=</td>
<td>serum cholesterol (SCL) in mg/100ml</td>
</tr>
<tr class="odd">
<td>chdfate</td>
<td align="center">=</td>
<td>1= if the patient develops CHD at the end of follow-up</td>
</tr>
<tr class="even">
<td></td>
<td align="center"></td>
<td>0= otherwise</td>
</tr>
<tr class="odd">
<td>followup</td>
<td align="center">=</td>
<td>the subject’s follow-up in days</td>
</tr>
<tr class="even">
<td>age</td>
<td align="center">=</td>
<td>age in years</td>
</tr>
<tr class="odd">
<td>bmi</td>
<td align="center">=</td>
<td>body mass index (BMI) =weight/height<span class="math inline">\(^2\)</span> in kg/m<span class="math inline">\(^2\)</span></td>
</tr>
<tr class="even">
<td>month</td>
<td align="center">=</td>
<td>month of year in which baseline exam occurred</td>
</tr>
<tr class="odd">
<td>id</td>
<td align="center">=</td>
<td>a patient identification variable (numbered 1 to 4699)</td>
</tr>
</tbody>
</table>
<p>We look at the K-M survival curves broken down by diastolic blood pressure. The logrank statistic comparing all 7 groups is highly significant (<span class="math inline">\(p &lt; 10^{-52}\)</span>), and the pairwise logrank tests for adjacent pairs of risk groups are also all significant (though be careful with multiple comparisons!).</p>
</div>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>heart <span class="ot">&lt;-</span> readr<span class="sc">::</span><span class="fu">read_csv</span>(<span class="st">&quot;framingham.csv&quot;</span>)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>heart <span class="ot">&lt;-</span> heart <span class="sc">%&gt;%</span> </span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">dbpf =</span> <span class="fu">case_when</span>(</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    dbp <span class="sc">&lt;=</span> <span class="dv">60</span> <span class="sc">~</span> <span class="st">&quot;under60&quot;</span>,</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    dbp <span class="sc">&lt;=</span><span class="dv">70</span> <span class="sc">~</span> <span class="st">&quot;60-70&quot;</span>,</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    dbp <span class="sc">&lt;=</span> <span class="dv">80</span> <span class="sc">~</span> <span class="st">&quot;70-80&quot;</span>,</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    dbp <span class="sc">&lt;=</span><span class="dv">90</span> <span class="sc">~</span> <span class="st">&quot;80-90&quot;</span>,</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>    dbp <span class="sc">&lt;=</span><span class="dv">100</span> <span class="sc">~</span> <span class="st">&quot;90-100&quot;</span>,</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>    dbp <span class="sc">&lt;=</span><span class="dv">110</span> <span class="sc">~</span> <span class="st">&quot;100-110&quot;</span>,</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>    <span class="cn">TRUE</span> <span class="sc">~</span> <span class="st">&quot;over110&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">dbpf =</span> <span class="fu">factor</span>(dbpf,</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>                       <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;under60&quot;</span>, <span class="st">&quot;60-70&quot;</span>, <span class="st">&quot;70-80&quot;</span>,<span class="st">&quot;80-90&quot;</span>, <span class="st">&quot;90-100&quot;</span>,<span class="st">&quot;100-110&quot;</span>,<span class="st">&quot;over110&quot;</span>)),</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>         <span class="at">sex =</span> <span class="fu">case_when</span>(</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>           sex <span class="sc">==</span> <span class="dv">1</span> <span class="sc">~</span> <span class="st">&quot;male&quot;</span>, </span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>           <span class="cn">TRUE</span> <span class="sc">~</span> <span class="st">&quot;female&quot;</span>))</span></code></pre></div>
<p><span class="math display">\[
\begin{align*}
dbp_{ij} &amp;= \left\{
\begin{array}{ll}
1 &amp; \mbox{if the } i^{th} \mbox{ patient is in DBP group } j\\
0 &amp; \mbox{otherwise}
\end{array}
\right.\\
male_i &amp;= \left\{
\begin{array}{ll}
1 &amp; \mbox{if the } i^{th} \mbox{ patient is male}\\
0 &amp; \mbox{if the } i^{th} \mbox{ patient is female}\\
\end{array}
\right.\\
\end{align*}
\]</span></p>
<ul>
<li><strong>Table 7.1</strong><br />
Using a proportional hazards model for estimating the hazard ratio associated with each blood pressure group, we get: <span class="math display">\[
\begin{align*}
h_i(t) &amp;= h_0(t) \exp \bigg\{ \beta_2 dbp_{i2} + \beta_3 dbp_{i3} + \beta_4 dbp_{i4} + \beta_5 dbp_{i5} + \beta_6 dbp_{i6} + \beta_7 dbp_{i7} \bigg\}\\ 
h_i(t) &amp;= h0(t) \exp \bigg\{ \sum_{j=2}^7 \beta_j dbp_{ij} \bigg\} 
\end{align*}
\]</span></li>
</ul>
<p>We can use the model with dbp as categorical to check whether dbp could be used as a continuous variable. Indeed, it seems that the model is linear (in ln(HR)) with respect to <code>dbp</code>. What we see (in the linearity) is that the hazard ratio for an increase in 10 dbp is constant regardless of the actual value of <code>dbp</code>. Indeed, it seems like the hazard ratio for a 10 unit increase in <code>dbp</code> is roughly <span class="math inline">\(e^{0.3}\)</span> regardless of the value of <code>dbp</code>. When the model is run on <code>dbp</code> as a continuous variable (instead of as groups) we <strong>also</strong> see that the hazard ratio associated with a 10 unit increase in <code>dbp</code> is <span class="math inline">\(e^{0.3}\)</span>.</p>
<p>One reason, however, to keep the variable broken into groups is because of the way the results are nicely laid out for each group.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(followup,chdfate) <span class="sc">~</span> dbpf, <span class="at">data =</span> heart) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 x 5</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 dbpf60-70      0.677     0.247      2.74 6.11e- 3</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 dbpf70-80      0.939     0.241      3.90 9.56e- 5</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 dbpf80-90      1.12      0.241      4.64 3.54e- 6</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 dbpf90-100     1.51      0.243      6.22 4.97e-10</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 dbpf100-110    1.84      0.254      7.23 4.86e-13</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 dbpfover110    2.25      0.271      8.29 1.18e-16</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(followup,chdfate) <span class="sc">~</span> dbp, <span class="at">data =</span> heart) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 5</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term  estimate std.error statistic  p.value</span></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 dbp     0.0316   0.00193      16.3 4.53e-60</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(followup,chdfate) <span class="sc">~</span> dbpf, <span class="at">data =</span> heart) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 18</span></span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       n nevent statistic.log p.value.log statistic.sc p.value.sc statistic.wald</span></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;</span></span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1  4699   1473          222.    4.22e-45         260.   3.44e-53           237.</span></span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 11 more variables: p.value.wald &lt;dbl&gt;, statistic.robust &lt;dbl&gt;,</span></span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   p.value.robust &lt;dbl&gt;, r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;,</span></span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   concordance &lt;dbl&gt;, std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;,</span></span>
<span id="cb41-25"><a href="#cb41-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   BIC &lt;dbl&gt;, nobs &lt;int&gt;</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="figs/table71_CHDHR.png" alt="Table 7.1 from @Collett." width="90%" />
<p class="caption">
(#fig:unnamed-chunk-7)Table 7.1 from <span class="citation"><a href="#ref-Collett" role="doc-biblioref">Collett</a> (<a href="#ref-Collett" role="doc-biblioref">2015</a>)</span>.
</p>
</div>
<ul>
<li><p><strong>Table 7.2</strong><br />
As our next step, we can consider adding gender as a <em>multiplicative effect</em> to our model. <span class="math display">\[
\begin{align*}
h_i(t) &amp;= h_0(t) \exp \bigg\{ \sum_{j=2}^7 \beta_j
dbp_{ij} + \gamma male_i \bigg\}
\end{align*}
\]</span> We say the effects are multiplicative because we are adding in the exponent, so any effect due to gender will be multiplied with the effect due to dbp. How do we tell - from the results - that interaction wasn’t modeled? Look at the hazard ratios, are they consistent when comparing one variable and keeping the other one constant? That is, check to see if the HR for two different levels of dbp is the same regardless of whether men or women are considered.</p>
<ul>
<li>The change in deviance is 133 (<span class="math inline">\(H_0: \gamma =0\)</span>), so with one degree of freedom, the p-value is very small. We do not think that <span class="math inline">\(\gamma=0\)</span>, so we need gender in the model.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(followup,chdfate) <span class="sc">~</span> sex <span class="sc">+</span> dbpf, <span class="at">data =</span> heart) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 7 x 5</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic  p.value</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 sexmale        0.606    0.0528     11.5  1.54e-30</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 dbpf60-70      0.648    0.247       2.62 8.74e- 3</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 dbpf70-80      0.888    0.241       3.69 2.27e- 4</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 dbpf80-90      1.02     0.241       4.24 2.25e- 5</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 dbpf90-100     1.40     0.243       5.76 8.48e- 9</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 dbpf100-110    1.79     0.254       7.02 2.29e-12</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 1 more row</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(followup,chdfate) <span class="sc">~</span> sex <span class="sc">+</span> dbpf, <span class="at">data =</span> heart) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 18</span></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       n nevent statistic.log p.value.log statistic.sc p.value.sc statistic.wald</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;</span></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1  4699   1473          355.    1.10e-72         397.   1.08e-81           369.</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 11 more variables: p.value.wald &lt;dbl&gt;, statistic.robust &lt;dbl&gt;,</span></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   p.value.robust &lt;dbl&gt;, r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;,</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   concordance &lt;dbl&gt;, std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;,</span></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   BIC &lt;dbl&gt;, nobs &lt;int&gt;</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="figs/table72_CHDHR.png" alt="Table 7.2 from @Collett." width="90%" />
<p class="caption">
(#fig:unnamed-chunk-9)Table 7.2 from <span class="citation"><a href="#ref-Collett" role="doc-biblioref">Collett</a> (<a href="#ref-Collett" role="doc-biblioref">2015</a>)</span>.
</p>
</div>
<ul>
<li><p><strong>Table 7.3</strong> Considering gender and dbp interacting. <span class="math display">\[
\begin{align*}
h_i(t) &amp;= h_0(t) \exp \bigg\{ \sum_{j=2}^7 \beta_j
dbp_{ij} + \gamma male_i + \sum_{j=2}^7 \delta_j dbp_{ij}
male_i \bigg\}
\end{align*}
\]</span></p>
<ul>
<li>The change in deviance is 21.23 (<span class="math inline">\(H_0: \delta_j =0\)</span>), so with six degrees of freedom, the p-value is 0.002. The evidence of interaction is statistically significant.<br />
</li>
<li>Note the marked differences between the estimates in table 7.2 and 7.3. The interactive model indicates that the effect of gender on the risk of CHD is greatest for people with low or moderate blood pressure and diminishes as blood pressure rises. Gender appears to have no effect on CHD for people with a DBP above 110 mm Hg.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(followup,chdfate) <span class="sc">~</span> sex<span class="sc">*</span>dbpf, <span class="at">data =</span> heart) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 13 x 5</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic      p.value</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 sexmale        0.864     0.471      1.83 0.0668      </span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 dbpf60-70      0.603     0.352      1.71 0.0866      </span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 dbpf70-80      0.887     0.342      2.60 0.00944     </span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 dbpf80-90      1.26      0.341      3.68 0.000230    </span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 dbpf90-100     1.55      0.347      4.46 0.00000829  </span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 dbpf100-110    2.03      0.358      5.67 0.0000000141</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 7 more rows</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(followup,chdfate) <span class="sc">~</span> sex<span class="sc">*</span>dbpf, <span class="at">data =</span> heart) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 18</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       n nevent statistic.log p.value.log statistic.sc p.value.sc statistic.wald</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;</span></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1  4699   1473          376.    2.43e-72         409.   3.29e-79           362.</span></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 11 more variables: p.value.wald &lt;dbl&gt;, statistic.robust &lt;dbl&gt;,</span></span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   p.value.robust &lt;dbl&gt;, r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;,</span></span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   concordance &lt;dbl&gt;, std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;,</span></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   BIC &lt;dbl&gt;, nobs &lt;int&gt;</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="figs/table73_CHDHR.png" alt="Table 7.3 from @Collett." width="90%" />
<p class="caption">
(#fig:unnamed-chunk-11)Table 7.3 from <span class="citation"><a href="#ref-Collett" role="doc-biblioref">Collett</a> (<a href="#ref-Collett" role="doc-biblioref">2015</a>)</span>.
</p>
</div>
<ul>
<li><p><strong>Table 7.4</strong><br />
Adjusting for confounding variables. Of particular interest is age at baseline exam. We know that age varied widely among study subjects, and both DBP and risk of CHD increase with age. We will also consider the effect of body mass index and serum cholesterol. <span class="math display">\[
\begin{align*}
h_i(t) &amp;= h_0(t) \exp \bigg\{ \sum_{j=2}^7 \beta_j dbp_{ij} + \gamma male_i + \sum_{j=2}^7 \delta_j dbp_{ij} male_i \\
&amp; \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \  \theta_1 age_i + \theta_2 bmi_i + \theta_3 scl_i \bigg\}
\end{align*}
\]</span></p>
<ul>
<li>We need <span class="math inline">\(\theta_1, \theta_2, \theta_3\)</span>, as they are all statistically significant.</li>
<li>The HR in Table 7.4 are substantially smaller than those in Table 7.3. It is important to realize that the HR in Table 7.4 compare people of the same age, body mass index, and serum cholesterol, while those of Table 7.3 compare people without regard to other variables. It is not surprising that the unadjusted HR are inflated due to the confounding variables.</li>
<li>Goal: to predict CHD <span class="math inline">\(\rightarrow\)</span> because it’s easier to measure blood pressure than cholesterol, we may just prefer to use the unadjusted model.</li>
<li>Goal: to establish a causal link <span class="math inline">\(\rightarrow\)</span> we <em>must</em> adjust for all possible confounding variables.</li>
</ul></li>
</ul>
<p>When should we transform a continuous variable into a factor variable?</p>
<ul>
<li><strong>continuous</strong> If we believe that the relationship is linear in log(HR)<br />
</li>
<li><strong>factor</strong> If the relationship is not linear. Although keep in mind that there can be lots of coefficients to estimate when we make factor variables, so we lose df.</li>
</ul>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(followup,chdfate) <span class="sc">~</span> dbpf <span class="sc">*</span> sex <span class="sc">+</span> age <span class="sc">+</span> bmi <span class="sc">+</span> scl, <span class="at">data =</span> heart) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 16 x 5</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term        estimate std.error statistic   p.value</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 dbpf60-70      0.415     0.352      1.18 0.238    </span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 dbpf70-80      0.503     0.343      1.47 0.142    </span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 dbpf80-90      0.648     0.344      1.89 0.0592   </span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 dbpf90-100     0.661     0.351      1.88 0.0599   </span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 dbpf100-110    1.13      0.363      3.12 0.00183  </span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 dbpfover110    1.66      0.377      4.40 0.0000107</span></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 10 more rows</span></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(followup,chdfate) <span class="sc">~</span> dbpf <span class="sc">*</span> sex <span class="sc">+</span> age <span class="sc">+</span> bmi <span class="sc">+</span> scl, <span class="at">data =</span> heart) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 18</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       n nevent statistic.log p.value.log statistic.sc p.value.sc statistic.wald</span></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;</span></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1  4658   1465          754.   5.12e-150         774.  2.21e-154           707.</span></span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 11 more variables: p.value.wald &lt;dbl&gt;, statistic.robust &lt;dbl&gt;,</span></span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   p.value.robust &lt;dbl&gt;, r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;,</span></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   concordance &lt;dbl&gt;, std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;,</span></span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   BIC &lt;dbl&gt;, nobs &lt;int&gt;</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="figs/table74_CHDHR.png" alt="Table 7.4 from @Collett." width="90%" />
<p class="caption">
(#fig:unnamed-chunk-13)Table 7.4 from <span class="citation"><a href="#ref-Collett" role="doc-biblioref">Collett</a> (<a href="#ref-Collett" role="doc-biblioref">2015</a>)</span>.
</p>
</div>
</div>
</div>
<div id="testingph" class="section level3" number="6.3.4">
<h3 number="6.3.4"><span class="header-section-number">6.3.4</span> Testing Proportional Hazards</h3>
<!-- Note: in my yellow notes from 2008 I've covered all the residual analysis stuff.  The notes aren't particularly organized or well thought-out.  The topic probably isn't relevant for this class. -->
<div id="proportional-hazards-via-survival-curves" class="section level4" number="6.3.4.1">
<h4 number="6.3.4.1"><span class="header-section-number">6.3.4.1</span> Proportional Hazards via survival curves:</h4>
<p>We’ve discussed that proportional hazards means that the hazard in one group is a constant multiple of the hazard in another group. What does that mean in terms of the survival function?</p>
<p><span class="math display">\[
\begin{align*}
h_1 (t) &amp;= h_0 (t) e^\beta\\
S(t) &amp;= e^{-\int_0^t h(x) dx}\\
S_0(t) &amp;= e^{-\int_0^t h_0(x) dx}\\
S_1(t) &amp;= e^{-\int_0^t h_0(x)e^\beta dx}\\
S_1(t) &amp;= e^{- e^\beta \int_0^t h_0(x) dx}\\
S_1(t) &amp;= \bigg[ e^{- \int_0^t h_0(x) dx} \bigg]^{e^\beta}\\
\ln(S_1(t)) &amp;= e^\beta \ln [e^{- \int_0^t h_0(x) dx}]\\
-\ln(S_1(t)) &amp;= e^\beta  [-\ln(S_0(t))]\\
\ln(-\ln(S_1(t))) &amp;= \beta + \ln [-\ln(S_0(t))]\\
\end{align*}
\]</span></p>
<div id="test-1-for-ph" class="section level5 unnumbered">
<h5 class="unnumbered">Test 1 for PH</h5>
<p>Therefore, the <span class="math inline">\(\ln (- \ln\)</span> survival curves) should be parallel and differ only by a y-intercept constant of <span class="math inline">\(\beta\)</span>.</p>
<p>Note that if <span class="math inline">\(h_0(t)\)</span> is a constant (i.e., <span class="math inline">\(h_i(t) = e^\beta\)</span>), then</p>
<p><span class="math display">\[
\begin{align*}
S(t) &amp;= e^{-\int_0^t h(x) dx}\\
&amp;= e^{- e^\beta t}\\
\ln S(t) &amp;= - e^\beta t\\
- \ln S(t) &amp;= e^\beta t\\
\ln(- \ln S(t)) &amp;= \beta + \ln(t)\\
\end{align*}
\]</span></p>
<p>Which is to say that if <span class="math inline">\(ln(- ln S(t))\)</span> is linear in <span class="math inline">\(\ln(t)\)</span>, then <span class="math inline">\(h_0(t)\)</span> is not only PH but also constant for all <span class="math inline">\(t\)</span>.</p>
</div>
</div>
<div id="proportional-hazards-via-a-test-for-time-dependent-covariates" class="section level4" number="6.3.4.2">
<h4 number="6.3.4.2"><span class="header-section-number">6.3.4.2</span> Proportional Hazards via a test for time dependent covariates</h4>
<p>If the PH assumption is violated, then we have:</p>
<p><span class="math display">\[\frac{h_i(t)}{h_0(t)} = g(t)\]</span> some function of <span class="math inline">\(t\)</span>. Consider the following model (the function of time is completely specified, but it is just one possibility for the dependence relationship):</p>
<p><span class="math display">\[
\begin{align*}
x_{i1}  &amp;= \left\{
\begin{array}{ll}
1 &amp; treatment\\
0 &amp; control
\end{array}
\right.\\
x_{i2} &amp;= \left\{
\begin{array}{ll}
t &amp; treatment\\
0 &amp; control\\
\end{array}
\right.\\
\end{align*}
\]</span></p>
<p>The relative hazard becomes:
<span class="math display">\[
\begin{align*}
h_i(t) &amp;= e^{\beta_1 x_{i1} + \beta_2 x_{i2}} h_0(t)\\
\frac{h_1(t)}{h_0(t)} &amp;= e^{\beta_1 +\beta_2 t}\\
\end{align*}
\]</span></p>
<p>If <span class="math inline">\(\beta_2 &lt; 0\)</span>, the relative hazard decreases with time. If <span class="math inline">\(\beta_2 &gt; 0\)</span>, the relative hazard increases with time.</p>
<div id="test-2-for-ph" class="section level5 unnumbered">
<h5 class="unnumbered">Test 2 for PH</h5>
<p>The PH test of interest will be: <span class="math display">\[H_0: \beta_2 = 0\]</span> It isn’t a Wald test, but it is the same general idea (in R: <code>cox.zph</code>). [The variable in the denominator of the likelihood (for calculating the MLE) will have different values at different times.] An alternative form of the test is to call: <span class="math inline">\(x_{i2} = t \ \ \forall t\)</span> and let <span class="math display">\[h_i(t) = e^{\beta_1 x_{i1} + \beta_2 x_{i1} x_{i2}} h_0(t).\]</span></p>
<p>If there is time dependency in the model, then the <code>coxph</code> analysis won’t be accurate.</p>
</div>
</div>
<div id="proportional-hazards-via-schoenfeld-residuals" class="section level4" number="6.3.4.3">
<h4 number="6.3.4.3"><span class="header-section-number">6.3.4.3</span> Proportional Hazards via Schoenfeld Residuals</h4>
<p>Recall: under the Cox model, the probability that any particular member <span class="math inline">\(i\)</span> fails at time <span class="math inline">\(t_j\)</span> is:</p>
<p><span class="math display">\[
\begin{align*}
P(i^{th} \mbox{ indiv w/}x_i \mbox{ dies at } t_j | \mbox{at least
one death at } t_j) &amp;= \frac{P(i^{th} \mbox{ indiv w/}x_i \mbox{
dies at } t_j )}{P(\mbox{at least one death at } t_j)}\\
&amp;= \frac{\mbox{hazard at } t_i}{\mbox{sum over all patients at risk
at time } t_j}\\
&amp;= \frac{h_i(t_j)}{\sum_{k:t_k \geq t_j} h_k (t_j)} \\
&amp;= \frac{e^{\beta x_i}}{\sum_{k:t_k \geq t_j} e^{\beta
x_k}}\\
w_j(\beta, t_j) &amp;= \frac{e^{\beta x_i}}{\sum_{k:t_k \geq t_j}
e^{\beta x_k}}
\end{align*}
\]</span></p>
<p>Using the weights above, we can calculate the average value for the <span class="math inline">\(l^{th}\)</span> covariate (i.e., explanatory variable): <span class="math display">\[\bar{x}_l (\beta,t_j) = \sum_{k: t_k \geq t_j} x_{kl}
w_j(\beta, t_j)\]</span></p>
<p>The Schoenfeld Residual for <span class="math inline">\(x_l\)</span> and any subject <span class="math inline">\(i\)</span> who is still alive at time <span class="math inline">\(t_j\)</span>, is the <em>difference</em> between the covariate <span class="math inline">\(x_{il}\)</span> for that subject and the weighted average of the covariates in the risk set: <span class="math display">\[\mbox{Schoenfeld resid }_i = x_{il} - \bar{x}_l(\beta, t_i)\]</span> Note that the calculation is for the <span class="math inline">\(i^{th}\)</span> subject which means there was a death at time <span class="math inline">\(t_i\)</span>.</p>
<div id="test-3-for-ph" class="section level5 unnumbered">
<h5 class="unnumbered">Test 3 for PH</h5>
<p>The idea is for the residual plot of (Schoenfeld residual wrt a paticular covariate on the y-axis, time on the x-axis)to be flat. What if there is a strong linear trend for the residuals? What would that say about the time dependency? Imagine a scatterplot where the residual is very positively linearly associated with time. If <span class="math inline">\(t_i &gt; &gt;\)</span> then <span class="math inline">\(x_i\)</span> is much bigger than expected; if <span class="math inline">\(t_i &lt; &lt;\)</span> then <span class="math inline">\(x_i\)</span> is much smaller than expected. That is, the covariate of interest changes over time and its effect on the risk of survival does, too.</p>
</div>
</div>
<div id="solutions-to-violations-of-ph" class="section level4" number="6.3.4.4">
<h4 number="6.3.4.4"><span class="header-section-number">6.3.4.4</span> Solutions to violations of PH</h4>
<ul>
<li><strong>crossing</strong> If the hazard functions (or survivor functions!) cross over time, the PH assumption is violated.<br />
</li>
<li><strong>help</strong> What should we do?<br />
</li>
</ul>
<ol style="list-style-type: decimal">
<li>Don’t do coxph, just fit K-M curves separately and perform a log-rank test.<br />
</li>
<li>Start at <span class="math inline">\(t^*\)</span>, the crossing point.<br />
</li>
<li>Fit different models for before <span class="math inline">\(t^*\)</span> and after <span class="math inline">\(t^*\)</span>.<br />
</li>
<li>Fit a model with a time dependent covariate.<br />
</li>
<li>Creative analysis: instead of tumor size, use % change over a set period of time.</li>
</ol>
<ul>
<li><p><strong>examples</strong> of PH violations</p>
<ul>
<li>over time, the treatment effect lessens (short term benefits)<br />
</li>
<li>tumor size at endpoint is more predictive than tumor size at entrance.<br />
</li>
<li>clinical variables that change over time (lung capacity, weight, white blood cell count)<br />
</li>
<li>exposure variables (pollution, UV rays, etc.)<br />
</li>
<li>age, temperature</li>
</ul></li>
</ul>
</div>
<div id="log-linearity" class="section level4" number="6.3.4.5">
<h4 number="6.3.4.5"><span class="header-section-number">6.3.4.5</span> Log linearity</h4>
<p>We’ve also assumed that the log of the hazard ratio is linear in the covariates. That a one unit change in any covariate has the same effect on the log of the HR (at any level of the covariate). Just like with logistic regression, this assumption is hard to check. However, we can see how the modeling performs by checking to see if quadratic (or other higher order terms) are significant in the model. Another possibility is to categorize a continuous predictor to check PH assumptions as above.</p>
</div>
</div>
</div>
<div id="othersurv" class="section level2" number="6.4">
<h2 number="6.4"><span class="header-section-number">6.4</span> Other stuff</h2>
<div id="sample-size-calculation" class="section level3" number="6.4.1">
<h3 number="6.4.1"><span class="header-section-number">6.4.1</span> Sample Size Calculation</h3>
<div id="sample-size-for-two-independent-sample-means-inference" class="section level4" number="6.4.1.1">
<h4 number="6.4.1.1"><span class="header-section-number">6.4.1.1</span> Sample Size for Two Independent Sample Means Inference</h4>
<p>Taking a step back to consider a slightly simpler inference (two sample mean), let’s say we want a size of <span class="math inline">\(\alpha=0.05\)</span> and a power of <span class="math inline">\(1-\beta=0.8\)</span>. What does that mean? How do they relate to the type I and type II errors? Draw some pictures. We’re talking about the only thing we can control: the sample size. We cannot actually control the truth of the hypotheses, the extent of the difference in in <span class="math inline">\(H_0\)</span> versus <span class="math inline">\(H_A\)</span>, or the variability of the underlying population. We <strong>can</strong> control the sample size. The larger your sample size, the easier it is to identify a true alternative hypothesis (that is, the higher the power).</p>
<p>In order to estimate the needed sample size, you need to know how often you are willing to make type I errors, how often you are willing to make type II errors, and how big of a difference between <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_A\)</span> you would like to determine. Without all three of those components, it is <strong>impossible</strong> to determine the sample size. If you read that a sample size calculation has been done, they <strong>must</strong> report the associated size, power, and difference (or their calculation will be meaningless).</p>
<p><span class="math display">\[
\begin{align*}
H_0: \ &amp;\mu_1 - \mu_2 = 0\\
H_A: \ &amp;\mu_1 - \mu_2 \ne 0
\end{align*}
\]</span></p>
<p>We have to make some assumptions. We assume that the size is 0.05, the power is 0.8, and the alternative hypothesis is <span class="math inline">\(D = \mu_1 - \mu_2\)</span>. For this case, let’s also assume that <span class="math inline">\(\sigma_1=\sigma_2=\sigma\)</span> and <span class="math inline">\(n_1=n_2=n\)</span>. Without loss of generality, let’s say <span class="math inline">\(\overline{Y}_1 - \overline{Y}_2 &gt; 0\)</span>.</p>
<p><span class="math display">\[
\begin{align*}
P\bigg(\frac{\overline{Y}_1 - \overline{Y}_2 - 0}{\sigma
\sqrt{1/n + 1/n}} &gt; 1.96 \bigg| \mu_1 - \mu_2 = 0 \bigg) &amp;=
0.025\\
P(\overline{Y}_1 - \overline{Y}_2 &gt; 1.96 \sigma \sqrt{1/n + 1/n}
\bigg| \mu_1 - \mu_2 = 0) &amp;= 0.025\\
P(\overline{Y}_1 - \overline{Y}_2 &gt; 1.96 \sigma \sqrt{1/n + 1/n}
\bigg| \mu_1 - \mu_2 = D) &amp;\geq 0.8\\
P\bigg(\frac{\overline{Y}_1 - \overline{Y}_2 - D}{\sigma
\sqrt{1/n + 1/n}} &gt; \frac{1.96 \sigma \sqrt{1/n + 1/n}-D}{\sigma
\sqrt{1/n + 1/n}} \bigg| \mu_1 - \mu_2 = D \bigg) &amp;\geq 0.8\\
P\bigg(Z &gt; \frac{1.96 \sigma \sqrt{1/n + 1/n}-D}{\sigma \sqrt{1/n
+ 1/n}} \bigg) &amp;\geq 0.8\\
\frac{1.96 \sigma \sqrt{1/n + 1/n}-D}{\sigma \sqrt{1/n + 1/n}}
&amp;\leq Z\_{0.8}\\
1.96 \sigma \sqrt{2/n} - D &amp;\leq Z\_{0.8} \sigma \sqrt{2/n}\\
2.845 \sigma \sqrt{2/n} &amp;\leq D\\
n &amp;\geq \frac{16 \sigma^2}{D^2}
\end{align*}
\]</span></p>
<p>Again, if we want to be able to find a 2 point difference in unrestricted versus deprived mean visual acuity scores, (<span class="math inline">\(\sigma=14\)</span>, equal sample sizes):</p>
<p><span class="math display">\[
\begin{align*}
n &amp;\geq \frac{16 \cdot 14^2}{4}\\
&amp;\geq 784
\end{align*}
\]</span></p>
</div>
<div id="sample-size-for-survival-model" class="section level4" number="6.4.1.2">
<h4 number="6.4.1.2"><span class="header-section-number">6.4.1.2</span> Sample Size for Survival model</h4>
<p>The sample size calculations below are derived from the inference done with a log-rank statistics comparing two groups. The total number of deaths required to detect a difference in groups with a size of <span class="math inline">\(\alpha\)</span> and a power of <span class="math inline">\(1-\beta\)</span> is <span class="math display">\[d = \frac{(z_{\alpha/2} + z_\beta)^2}{\pi_1 \pi_2 \theta^2_R}\]</span> where <span class="math inline">\(\pi_1\)</span> is the proportion of the sample in group 1, <span class="math inline">\(\pi_2\)</span> is the proportion of the sample in group 2, and <span class="math inline">\(\theta_R\)</span> is the log hazard ratio to detect.</p>
<p>(Derivation in <span class="citation"><a href="#ref-Collett" role="doc-biblioref">Collett</a> (<a href="#ref-Collett" role="doc-biblioref">2015</a>)</span> pg 256.)</p>
<p>Consider the following sample size calculator. The variables included are slightly different, but give the same general structure to the calculation. For example, the equation above calculates the number of deaths. The applet calculates the number of samples (where <span class="math inline">\(d = p_E \cdot n\)</span>). <a href="http://powerandsamplesize.com/Calculators/Test-Time-To-Event-Data/Cox-PH-Equivalence" class="uri">http://powerandsamplesize.com/Calculators/Test-Time-To-Event-Data/Cox-PH-Equivalence</a></p>
</div>
<div id="significance-level-vs.-power-vs.-sample-size" class="section level4" number="6.4.1.3">
<h4 number="6.4.1.3"><span class="header-section-number">6.4.1.3</span> Significance level vs. Power vs. Sample Size</h4>
<ul>
<li><strong>Sig level</strong> <span class="math inline">\(\alpha\)</span>: we <em>set</em> our type I error rate<br />
</li>
<li><strong>power</strong> <span class="math inline">\(1-\beta\)</span>: probability of not making a type II error. To set the power, we would need to know the sample size, significance level, and the clinically important difference that we wish to detect (effect size).<br />
</li>
<li><strong>sample size</strong> n: To set the sample size, we need <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and effect size<br />
</li>
</ul>
<ol style="list-style-type: decimal">
<li>“The trial has 90% power” is meaningless<br />
</li>
<li>“With 500 subjects per group, the trial has 90% power to detect a decrease of 10mmHg in blood pressure due to the new treatment at a 0.05 significance level.”</li>
</ol>
</div>
</div>
<div id="study-design" class="section level3" number="6.4.2">
<h3 number="6.4.2"><span class="header-section-number">6.4.2</span> Study Design</h3>
<ul>
<li><p>Randomized, controlled trial</p></li>
<li><p>Factorial design</p>
<ul>
<li>Random allocation (within a factorial design) allows for estimation of interaction between treatments<br />
</li>
<li>Physicians’ health study was factorial with aspirin (to measure myocardial infarction) and beta carotene (cancer)<br />
</li>
<li>Can include 3 or more treatments (but would need large sample sizes to measure anything)</li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th align="center">treatment A</th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="center">Yes</td>
<td align="center">No</td>
</tr>
<tr class="even">
<td></td>
<td>Yes</td>
<td align="center">Both A &amp; B</td>
<td align="center">only B</td>
</tr>
<tr class="odd">
<td><strong>treatment B</strong></td>
<td>No</td>
<td align="center">only A</td>
<td align="center">neither</td>
</tr>
</tbody>
</table>
<ul>
<li><p>Cross-over design: all participants receive <em>both</em> treatments (e.g., surgery and chemotherapy)</p>
<ul>
<li>Each patient serves as their own control (need fewer samples)<br />
</li>
<li>Often cross-over effect from the initial treatment</li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(\swarrow\)</span></th>
<th align="center"></th>
<th align="center"><span class="math inline">\(\searrow\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Group 1</td>
<td align="center"></td>
<td align="center">Group 2</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\downarrow\)</span> (1)</td>
<td align="center"></td>
<td align="center"><span class="math inline">\(\downarrow\)</span> (1)</td>
</tr>
<tr class="odd">
<td align="center">Drug A</td>
<td align="center"><span class="math inline">\(\stackrel{(2)}{\rightarrow}\)</span></td>
<td align="center">Drug B</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center"><span class="math inline">\(\stackrel{(2)}{\hookleftarrow}\)</span></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<ul>
<li><p>Noncompliance</p>
<ul>
<li>Patients will switch on their own! How do you analyze the data?<br />
</li>
<li>Analyze according to assigned treatment (intent-to-treat). Crossover does not happen randomly and is well known to be associated to outcome.<br />
</li>
<li>Can perform a secondary analysis on only those patients who stayed on treatment.<br />
</li>
<li>Example: surgery and radiation</li>
</ul></li>
</ul>
<div id="subgroup-analysis" class="section level4" number="6.4.2.1">
<h4 number="6.4.2.1"><span class="header-section-number">6.4.2.1</span> subgroup analysis</h4>
<ul>
<li><p>Refers to analyzing a subset of patients in a trial separately (e.g., gender, race, family background, etc.)<br />
</p></li>
<li><p>Important for: clinical decision making, regulatory requirements, hypothesis generation<br />
</p></li>
<li><p>Problems:</p>
<ul>
<li>insufficient power. If powered for overall treatment effect, it will be underpowered to detect similar effects in subgroups.<br />
</li>
<li>multiple comparisons. If you torture your data long enough, eventually it will confess to anything.<br />
</li>
<li>whenever possible, subgroup analysis should be defined <em>a priori</em> in the protocol</li>
</ul></li>
</ul>
</div>
<div id="some-topics-worth-investigating" class="section level4" number="6.4.2.2">
<h4 number="6.4.2.2"><span class="header-section-number">6.4.2.2</span> Some topics worth investigating</h4>
<ul>
<li>Meta Analysis <span class="citation">(<a href="#ref-crowley" role="doc-biblioref">Green, Benedetti, and Crowley 1997</a>)</span><br />
</li>
<li>General Thoughts on Clinical Trials for cancer <span class="citation">(<a href="#ref-crowley" role="doc-biblioref">Green, Benedetti, and Crowley 1997</a>)</span><br />
</li>
<li>Stratified Cox Model <span class="citation">(<a href="#ref-vittinghoff" role="doc-biblioref">Vittinghoff et al. 2012</a>)</span><br />
</li>
<li>Interim analyses / stopping rules<br />
</li>
<li>Intent-to-treat (missing data)<br />
</li>
<li>Investigating time-varying effects <span class="citation">(<a href="#ref-timevar" role="doc-biblioref">Bellera et al. 2010</a>)</span></li>
</ul>
</div>
</div>
<div id="simulating-survival-data" class="section level3" number="6.4.3">
<h3 number="6.4.3"><span class="header-section-number">6.4.3</span> Simulating survival data</h3>
<p>There is a package designed to simulate survival data, <code>simsurv</code>. It allows for complex models, but there is some difficulty with scenarios with very few events or with binary explanatory variables. Sam Brilleman spoke about the <code>simsurv</code> package at useR! 2018: <a href="https://www.youtube.com/watch?v=fJTYsncvpvI" class="uri">https://www.youtube.com/watch?v=fJTYsncvpvI</a>.</p>
</div>
</div>
<div id="Rsurv" class="section level2" number="6.5">
<h2 number="6.5"><span class="header-section-number">6.5</span> R example: ProPublica Analysis</h2>
<div id="recidivism-in-florida" class="section level3" number="6.5.1">
<h3 number="6.5.1"><span class="header-section-number">6.5.1</span> Recidivism in Florida</h3>
<blockquote>
<p>[The ProPublica] analysis of Northpointe’s tool, called COMPAS (which stands for Correctional Offender Management Profiling for Alternative Sanctions), found that black defendants were far more likely than white defendants to be incorrectly judged to be at a higher risk of recidivism, while white defendants were more likely than black defendants to be incorrectly flagged as low risk.</p>
</blockquote>
<blockquote>
<p>[ProPublica] looked at more than 10,000 criminal defendants in Broward County, Florida, and compared their predicted recidivism rates with the rate that actually occurred over a two-year period. When most defendants are booked in jail, they respond to a COMPAS questionnaire. Their answers are fed into the COMPAS software to generate several scores including predictions of “Risk of Recidivism” and “Risk of Violent Recidivism.” <span class="citation">(<a href="#ref-angwin" role="doc-biblioref">Larson et al. {May 23, 2016}</a>)</span></p>
</blockquote>
<p>The original article is here: <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" class="uri">https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing</a></p>
<p>The data analysis is here: <a href="https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm" class="uri">https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm</a></p>
<p>The GitHub repo with data and code is here: <a href="https://github.com/propublica/compas-analysis" class="uri">https://github.com/propublica/compas-analysis</a></p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(survival)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>recid <span class="ot">&lt;-</span> readr<span class="sc">::</span><span class="fu">read_csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv&quot;</span>)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>recid <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(recid, age, c_charge_degree, race, age_cat, score_text, sex, priors_count, </span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>                    days_b_screening_arrest, decile_score, is_recid, two_year_recid, </span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>                    c_jail_in, c_jail_out) <span class="sc">%&gt;%</span> </span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(days_b_screening_arrest <span class="sc">&lt;=</span> <span class="dv">30</span>) <span class="sc">%&gt;%</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(days_b_screening_arrest <span class="sc">&gt;=</span> <span class="sc">-</span><span class="dv">30</span>) <span class="sc">%&gt;%</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(is_recid <span class="sc">!=</span> <span class="sc">-</span><span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(c_charge_degree <span class="sc">!=</span> <span class="st">&quot;O&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(score_text <span class="sc">!=</span> <span class="st">&#39;N/A&#39;</span>)</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>recid <span class="ot">&lt;-</span> recid <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">length_of_stay =</span> <span class="fu">as.numeric</span>(<span class="fu">as.Date</span>(c_jail_out) <span class="sc">-</span> <span class="fu">as.Date</span>(c_jail_in))) <span class="sc">%&gt;%</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">crime_factor =</span> <span class="fu">factor</span>(c_charge_degree)) <span class="sc">%&gt;%</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">age_factor =</span> <span class="fu">as.factor</span>(age_cat)) <span class="sc">%&gt;%</span></span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a>      <span class="fu">within</span>(age_factor <span class="ot">&lt;-</span> <span class="fu">relevel</span>(age_factor, <span class="at">ref =</span> <span class="dv">1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">race_factor =</span> <span class="fu">factor</span>(race,</span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;African-American&quot;</span>, </span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Asian&quot;</span>,</span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Caucasian&quot;</span>, </span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Hispanic&quot;</span>, </span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Native American&quot;</span>,</span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Other&quot;</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a>      <span class="fu">within</span>(race_factor <span class="ot">&lt;-</span> <span class="fu">relevel</span>(race_factor, <span class="at">ref =</span> <span class="dv">3</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">gender_factor =</span> <span class="fu">factor</span>(sex, <span class="at">labels=</span> <span class="fu">c</span>(<span class="st">&quot;Female&quot;</span>,<span class="st">&quot;Male&quot;</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>      <span class="fu">within</span>(gender_factor <span class="ot">&lt;-</span> <span class="fu">relevel</span>(gender_factor, <span class="at">ref =</span> <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a>      <span class="fu">mutate</span>(<span class="at">score_factor =</span> <span class="fu">factor</span>(score_text <span class="sc">!=</span> <span class="st">&quot;Low&quot;</span>, <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;LowScore&quot;</span>,<span class="st">&quot;HighScore&quot;</span>)))</span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a>      </span></code></pre></div>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>recidKM <span class="ot">&lt;-</span> <span class="fu">filter</span>(<span class="fu">filter</span>(<span class="fu">read_csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/propublica/compas-analysis/master/cox-parsed.csv&quot;</span>), score_text <span class="sc">!=</span> <span class="st">&quot;N/A&quot;</span>), end <span class="sc">&gt;</span> start) <span class="sc">%&gt;%</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>        <span class="fu">mutate</span>(<span class="at">race_factor =</span> <span class="fu">factor</span>(race,</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;African-American&quot;</span>, </span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Asian&quot;</span>,</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Caucasian&quot;</span>, </span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Hispanic&quot;</span>, </span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Native American&quot;</span>,</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Other&quot;</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>        <span class="fu">within</span>(race_factor <span class="ot">&lt;-</span> <span class="fu">relevel</span>(race_factor, <span class="at">ref =</span> <span class="dv">3</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>        <span class="fu">mutate</span>(<span class="at">score_factor =</span> <span class="fu">factor</span>(score_text)) <span class="sc">%&gt;%</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>        <span class="fu">within</span>(score_factor <span class="ot">&lt;-</span> <span class="fu">relevel</span>(score_factor, <span class="at">ref=</span><span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>        <span class="fu">mutate</span>(<span class="at">timefollow =</span> end <span class="sc">-</span> start) <span class="sc">%&gt;%</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(race <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;African-American&quot;</span>, <span class="st">&quot;Caucasian&quot;</span>))</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>recidKMV <span class="ot">&lt;-</span> <span class="fu">filter</span>(<span class="fu">filter</span>(<span class="fu">read_csv</span>(<span class="st">&quot;https://raw.githubusercontent.com/propublica/compas-analysis/master/cox-violent-parsed.csv&quot;</span>), score_text <span class="sc">!=</span> <span class="st">&quot;N/A&quot;</span>), end <span class="sc">&gt;</span> start) <span class="sc">%&gt;%</span></span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>        <span class="fu">mutate</span>(<span class="at">race_factor =</span> <span class="fu">factor</span>(race,</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;African-American&quot;</span>, </span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Asian&quot;</span>,</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Caucasian&quot;</span>, </span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Hispanic&quot;</span>, </span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Native American&quot;</span>,</span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a>                                             <span class="st">&quot;Other&quot;</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>        <span class="fu">within</span>(race_factor <span class="ot">&lt;-</span> <span class="fu">relevel</span>(race_factor, <span class="at">ref =</span> <span class="dv">3</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a>        <span class="fu">mutate</span>(<span class="at">score_factor =</span> <span class="fu">factor</span>(score_text)) <span class="sc">%&gt;%</span></span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>        <span class="fu">within</span>(score_factor <span class="ot">&lt;-</span> <span class="fu">relevel</span>(score_factor, <span class="at">ref=</span><span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a>        <span class="fu">mutate</span>(<span class="at">timefollow =</span> end <span class="sc">-</span> start) <span class="sc">%&gt;%</span></span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>        <span class="fu">filter</span>(race <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;African-American&quot;</span>, <span class="st">&quot;Caucasian&quot;</span>))</span></code></pre></div>
</div>
<div id="kaplan-meier-survival-curve" class="section level3" number="6.5.2">
<h3 number="6.5.2"><span class="header-section-number">6.5.2</span> Kaplan-Meier survival curve</h3>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>recid.surv <span class="ot">&lt;-</span> <span class="fu">survfit</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(recid.surv, <span class="at">lty=</span><span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">xlab=</span><span class="st">&quot;time&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;survival function&quot;</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="dv">10</span>,.<span class="dv">4</span>, <span class="fu">c</span>(<span class="st">&quot;low&quot;</span>, <span class="st">&quot;high&quot;</span>, <span class="st">&quot;medium&quot;</span>),<span class="at">lty=</span><span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>)</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>survminer<span class="sc">::</span><span class="fu">ggsurvplot</span>(recid.surv, <span class="at">conf.int=</span><span class="cn">TRUE</span>, <span class="at">censor=</span>F) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Overall&quot;</span>)</span></code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-16-1.png" width="80%" style="display: block; margin: auto;" /><img src="06-surv_files/figure-html/unnamed-chunk-16-2.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsurvplot</span>(recid.surv[<span class="dv">1</span>], <span class="at">conf.int=</span><span class="cn">TRUE</span>, <span class="at">censor=</span><span class="cn">FALSE</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Low Only&quot;</span>)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsurvplot</span>(recid.surv, <span class="at">conf.int=</span><span class="cn">TRUE</span>, <span class="at">censor=</span><span class="cn">FALSE</span>, <span class="at">risk.table =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-17-1.png" width="80%" style="display: block; margin: auto;" /><img src="06-surv_files/figure-html/unnamed-chunk-17-2.png" width="80%" style="display: block; margin: auto;" /></p>
<p>different options for CI</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4747</span>)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>recidKM2 <span class="ot">&lt;-</span> recidKM <span class="sc">%&gt;%</span> <span class="fu">sample_n</span>(<span class="dv">200</span>)  <span class="co"># CI on a smaller random sample just to see the different CIs</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsurvplot</span>(<span class="fu">survfit</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM2), </span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>           <span class="at">censor=</span>F, <span class="at">conf.int=</span>F) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;No CI&quot;</span>)</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsurvplot</span>(<span class="fu">survfit</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM2,</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>                   <span class="at">conf.type=</span><span class="st">&quot;log&quot;</span>), <span class="at">censor=</span>F, <span class="at">conf.int=</span>T) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Log CI&quot;</span>)</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsurvplot</span>(<span class="fu">survfit</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM2,</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>                   <span class="at">conf.type=</span><span class="st">&quot;log-log&quot;</span>), <span class="at">censor=</span>F, <span class="at">conf.int=</span>T) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Log-Log CI&quot;</span>)</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsurvplot</span>(<span class="fu">survfit</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM2,</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>                   <span class="at">conf.type=</span><span class="st">&quot;plain&quot;</span>), <span class="at">censor=</span>F, <span class="at">conf.int=</span>T) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Plain CI&quot;</span>)</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsurvplot_facet</span>(<span class="fu">survfit</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM2), </span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data=</span>recidKM2, <span class="at">facet.by =</span> <span class="st">&quot;race&quot;</span>)</span></code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-18-1.png" width="80%" style="display: block; margin: auto;" /><img src="06-surv_files/figure-html/unnamed-chunk-18-2.png" width="80%" style="display: block; margin: auto;" /><img src="06-surv_files/figure-html/unnamed-chunk-18-3.png" width="80%" style="display: block; margin: auto;" /><img src="06-surv_files/figure-html/unnamed-chunk-18-4.png" width="80%" style="display: block; margin: auto;" /><img src="06-surv_files/figure-html/unnamed-chunk-18-5.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="log-rank-test-rho0-and-the-wilcoxon-test-rho1" class="section level3" number="6.5.3">
<h3 number="6.5.3"><span class="header-section-number">6.5.3</span> Log-rank test [rho=0] and the Wilcoxon test [rho=1]</h3>
<p>General recidivism</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu">survdiff</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM2, <span class="at">rho=</span><span class="dv">0</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; survdiff(formula = Surv(timefollow, event) ~ score_factor, data = recidKM2, </span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     rho = 0)</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                      N Observed Expected (O-E)^2/E (O-E)^2/V</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=Low    91       16     29.3      6.04     13.13</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=High   52       20     11.6      6.11      7.80</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=Medium 57       19     14.1      1.70      2.29</span></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Chisq= 14.1  on 2 degrees of freedom, p= 9e-04</span></span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a><span class="fu">survdiff</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM2, <span class="at">rho=</span><span class="dv">1</span>)</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; survdiff(formula = Surv(timefollow, event) ~ score_factor, data = recidKM2, </span></span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     rho = 1)</span></span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                      N Observed Expected (O-E)^2/E (O-E)^2/V</span></span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=Low    91     13.8    24.54      4.68     11.69</span></span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=High   52     17.0     9.99      4.88      7.21</span></span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=Medium 57     15.8    12.04      1.16      1.82</span></span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Chisq= 12.6  on 2 degrees of freedom, p= 0.002</span></span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsurvplot</span>(<span class="fu">survfit</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM2), </span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a>           <span class="at">censor=</span>F, <span class="at">conf.int=</span>F, <span class="at">pval=</span><span class="cn">TRUE</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;No CI&quot;</span>)</span></code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-19-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Violent recidivism</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4747</span>)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>recidKMV2 <span class="ot">&lt;-</span> recidKMV <span class="sc">%&gt;%</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sample_n</span>(<span class="dv">500</span>)</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>recidKMV2 <span class="sc">%&gt;%</span> <span class="fu">filter</span>(race <span class="sc">==</span> <span class="st">&quot;Caucasian&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">survdiff</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>., <span class="at">rho=</span><span class="dv">0</span>)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; survdiff(formula = Surv(timefollow, event) ~ score_factor, data = ., </span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     rho = 0)</span></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                       N Observed Expected (O-E)^2/E (O-E)^2/V</span></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=Low    112        6    6.087   0.00126   0.00392</span></span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=High    25        2    0.966   1.10625   1.24725</span></span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=Medium  46        1    1.946   0.46016   0.58870</span></span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Chisq= 1.6  on 2 degrees of freedom, p= 0.5</span></span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>recidKMV2 <span class="sc">%&gt;%</span> <span class="fu">filter</span>(race <span class="sc">==</span> <span class="st">&quot;African-American&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">survdiff</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>., <span class="at">rho=</span><span class="dv">0</span>)</span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; survdiff(formula = Surv(timefollow, event) ~ score_factor, data = ., </span></span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     rho = 0)</span></span>
<span id="cb51-23"><a href="#cb51-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb51-24"><a href="#cb51-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                       N Observed Expected (O-E)^2/E (O-E)^2/V</span></span>
<span id="cb51-25"><a href="#cb51-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=Low     94        3     4.11     0.301     0.488</span></span>
<span id="cb51-26"><a href="#cb51-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=High   131        6     3.77     1.322     2.037</span></span>
<span id="cb51-27"><a href="#cb51-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=Medium  92        2     3.12     0.401     0.560</span></span>
<span id="cb51-28"><a href="#cb51-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb51-29"><a href="#cb51-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Chisq= 2  on 2 degrees of freedom, p= 0.4</span></span>
<span id="cb51-30"><a href="#cb51-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-31"><a href="#cb51-31" aria-hidden="true" tabindex="-1"></a><span class="fu">survdiff</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKMV2, <span class="at">rho=</span><span class="dv">1</span>)</span>
<span id="cb51-32"><a href="#cb51-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb51-33"><a href="#cb51-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; survdiff(formula = Surv(timefollow, event) ~ score_factor, data = recidKMV2, </span></span>
<span id="cb51-34"><a href="#cb51-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     rho = 1)</span></span>
<span id="cb51-35"><a href="#cb51-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb51-36"><a href="#cb51-36" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                       N Observed Expected (O-E)^2/E (O-E)^2/V</span></span>
<span id="cb51-37"><a href="#cb51-37" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=Low    206     8.77     9.63    0.0771     0.158</span></span>
<span id="cb51-38"><a href="#cb51-38" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=High   156     7.78     4.87    1.7317     2.389</span></span>
<span id="cb51-39"><a href="#cb51-39" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor=Medium 138     2.96     5.00    0.8343     1.151</span></span>
<span id="cb51-40"><a href="#cb51-40" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb51-41"><a href="#cb51-41" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Chisq= 2.7  on 2 degrees of freedom, p= 0.3</span></span>
<span id="cb51-42"><a href="#cb51-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-43"><a href="#cb51-43" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsurvplot</span>(<span class="fu">survfit</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKMV2), </span>
<span id="cb51-44"><a href="#cb51-44" aria-hidden="true" tabindex="-1"></a>           <span class="at">censor=</span>F, <span class="at">conf.int=</span>T, <span class="at">pval=</span><span class="cn">TRUE</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Violent Recidivism&quot;</span>)</span>
<span id="cb51-45"><a href="#cb51-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-46"><a href="#cb51-46" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsurvplot</span>(<span class="fu">survfit</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKMV2), </span>
<span id="cb51-47"><a href="#cb51-47" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data=</span>recidKMV, <span class="at">censor =</span> <span class="cn">FALSE</span>, <span class="at">conf.int =</span> <span class="cn">TRUE</span>, <span class="at">facet.by =</span> <span class="st">&quot;race&quot;</span>) <span class="sc">+</span> </span>
<span id="cb51-48"><a href="#cb51-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Violent Recidivism&quot;</span>)</span>
<span id="cb51-49"><a href="#cb51-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-50"><a href="#cb51-50" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(recidKMV2) <span class="sc">%&gt;%</span>  <span class="co"># must be a data.frame see &quot;.&quot; below:</span></span>
<span id="cb51-51"><a href="#cb51-51" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsurvplot</span>(<span class="fu">survfit</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span> .), </span>
<span id="cb51-52"><a href="#cb51-52" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> ., <span class="at">censor =</span> <span class="cn">FALSE</span>, <span class="at">conf.int =</span> <span class="cn">TRUE</span>, <span class="at">pval=</span><span class="cn">TRUE</span>, <span class="at">facet.by =</span> <span class="st">&quot;race&quot;</span>) <span class="sc">+</span> </span>
<span id="cb51-53"><a href="#cb51-53" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Violent Recidivism&quot;</span>)</span></code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-20-1.png" width="80%" style="display: block; margin: auto;" /><img src="06-surv_files/figure-html/unnamed-chunk-20-2.png" width="80%" style="display: block; margin: auto;" /><img src="06-surv_files/figure-html/unnamed-chunk-20-3.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="cox-proportional-hazards-models" class="section level3" number="6.5.4">
<h3 number="6.5.4"><span class="header-section-number">6.5.4</span> Cox Proportional Hazards models</h3>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Just score_factor</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 2 x 5</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term               estimate std.error statistic   p.value</span></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 score_factorHigh      1.08     0.0446      24.1 7.67e-129</span></span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 score_factorMedium    0.704    0.0439      16.0 9.78e- 58</span></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 18</span></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       n nevent statistic.log p.value.log statistic.sc p.value.sc statistic.wald</span></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;</span></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 11426   3058          617.   9.39e-135         654.  1.15e-142           609.</span></span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 11 more variables: p.value.wald &lt;dbl&gt;, statistic.robust &lt;dbl&gt;,</span></span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   p.value.robust &lt;dbl&gt;, r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;,</span></span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   concordance &lt;dbl&gt;, std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;,</span></span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   BIC &lt;dbl&gt;, nobs &lt;int&gt;</span></span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a><span class="co"># score_factor and race</span></span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor <span class="sc">+</span> race, <span class="at">data=</span>recidKM) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 3 x 5</span></span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term               estimate std.error statistic   p.value</span></span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 score_factorHigh      1.03     0.0460     22.3  3.96e-110</span></span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 score_factorMedium    0.674    0.0445     15.2  7.45e- 52</span></span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 raceCaucasian        -0.170    0.0396     -4.29 1.78e-  5</span></span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor <span class="sc">+</span> race, <span class="at">data=</span>recidKM) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 18</span></span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       n nevent statistic.log p.value.log statistic.sc p.value.sc statistic.wald</span></span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;</span></span>
<span id="cb52-30"><a href="#cb52-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 11426   3058          636.   1.65e-137         671.  3.72e-145           626.</span></span>
<span id="cb52-31"><a href="#cb52-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 11 more variables: p.value.wald &lt;dbl&gt;, statistic.robust &lt;dbl&gt;,</span></span>
<span id="cb52-32"><a href="#cb52-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   p.value.robust &lt;dbl&gt;, r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;,</span></span>
<span id="cb52-33"><a href="#cb52-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   concordance &lt;dbl&gt;, std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;,</span></span>
<span id="cb52-34"><a href="#cb52-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   BIC &lt;dbl&gt;, nobs &lt;int&gt;</span></span>
<span id="cb52-35"><a href="#cb52-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-36"><a href="#cb52-36" aria-hidden="true" tabindex="-1"></a><span class="co"># score_factor, race, age, sex</span></span>
<span id="cb52-37"><a href="#cb52-37" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor <span class="sc">+</span> race <span class="sc">+</span> age <span class="sc">+</span> sex, <span class="at">data=</span>recidKM) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb52-38"><a href="#cb52-38" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 5 x 5</span></span>
<span id="cb52-39"><a href="#cb52-39" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term               estimate std.error statistic  p.value</span></span>
<span id="cb52-40"><a href="#cb52-40" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb52-41"><a href="#cb52-41" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 score_factorHigh     0.926    0.0471      19.6  7.63e-86</span></span>
<span id="cb52-42"><a href="#cb52-42" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 score_factorMedium   0.611    0.0452      13.5  1.54e-41</span></span>
<span id="cb52-43"><a href="#cb52-43" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 raceCaucasian       -0.120    0.0398      -3.01 2.63e- 3</span></span>
<span id="cb52-44"><a href="#cb52-44" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 age                 -0.0137   0.00175     -7.82 5.38e-15</span></span>
<span id="cb52-45"><a href="#cb52-45" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 sexMale              0.411    0.0502       8.19 2.53e-16</span></span>
<span id="cb52-46"><a href="#cb52-46" aria-hidden="true" tabindex="-1"></a><span class="fu">coxph</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor <span class="sc">+</span> race <span class="sc">+</span> age <span class="sc">+</span> sex, <span class="at">data=</span>recidKM) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span>
<span id="cb52-47"><a href="#cb52-47" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 18</span></span>
<span id="cb52-48"><a href="#cb52-48" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       n nevent statistic.log p.value.log statistic.sc p.value.sc statistic.wald</span></span>
<span id="cb52-49"><a href="#cb52-49" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;int&gt;  &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;          &lt;dbl&gt;</span></span>
<span id="cb52-50"><a href="#cb52-50" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 11426   3058          768.   8.91e-164         787.  7.45e-168           739.</span></span>
<span id="cb52-51"><a href="#cb52-51" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 11 more variables: p.value.wald &lt;dbl&gt;, statistic.robust &lt;dbl&gt;,</span></span>
<span id="cb52-52"><a href="#cb52-52" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   p.value.robust &lt;dbl&gt;, r.squared &lt;dbl&gt;, r.squared.max &lt;dbl&gt;,</span></span>
<span id="cb52-53"><a href="#cb52-53" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   concordance &lt;dbl&gt;, std.error.concordance &lt;dbl&gt;, logLik &lt;dbl&gt;, AIC &lt;dbl&gt;,</span></span>
<span id="cb52-54"><a href="#cb52-54" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   BIC &lt;dbl&gt;, nobs &lt;int&gt;</span></span></code></pre></div>
<p>Using the <code>rms</code> package, we can plot CIs for each of the relevant HRs for the model at hand:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>recid.data <span class="ot">&lt;-</span> recidKM <span class="sc">%&gt;%</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(timefollow, event, score_factor, race, age, sex)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>recid.final <span class="ot">&lt;-</span> rms<span class="sc">::</span><span class="fu">cph</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor <span class="sc">+</span> race <span class="sc">+</span> age <span class="sc">+</span> sex, <span class="at">data=</span>recid.data)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>ddist <span class="ot">&lt;-</span> rms<span class="sc">::</span><span class="fu">datadist</span>(recid.data)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">datadist =</span> <span class="st">&#39;ddist&#39;</span>)</span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">summary</span>(recid.final), <span class="at">log =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-22-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="checking-proportional-hazards-with-the-plot-of-ln-lnst" class="section level3" number="6.5.5">
<h3 number="6.5.5"><span class="header-section-number">6.5.5</span> Checking proportional hazards with the plot of <span class="math inline">\(\ln(-\ln(S(t)))\)</span></h3>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggsurvplot</span>(<span class="fu">survfit</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM), </span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">censor=</span>F, <span class="at">conf.int=</span>T, <span class="at">fun=</span><span class="st">&quot;cloglog&quot;</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Complementary Log-Log&quot;</span>)</span></code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-23-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>The cox.zph function will test proportionality of all the predictors in the model by creating interactions with time using the transformation of time specified in the transform option. In this example we are testing proportionality by looking at the interactions with log(time). The column rho is the Pearson product-moment correlation between the scaled Schoenfeld residuals and log(time) for each covariate. The last row contains the global test for all the interactions tested at once. A p-value less than 0.05 indicates a violation of the proportionality assumption.</p>
</div>
<div id="checking-proportional-hazards-with-cox.zph" class="section level3" number="6.5.6">
<h3 number="6.5.6"><span class="header-section-number">6.5.6</span> Checking proportional hazards with cox.zph</h3>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cox.zph</span>(<span class="fu">coxph</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM))</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;              chisq df   p</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor 0.457  2 0.8</span></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; GLOBAL       0.457  2 0.8</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="fu">cox.zph</span>(<span class="fu">coxph</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor, <span class="at">data=</span>recidKM), <span class="at">transform=</span><span class="st">&quot;log&quot;</span>)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;              chisq df    p</span></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor  3.04  2 0.22</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; GLOBAL        3.04  2 0.22</span></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a><span class="fu">cox.zph</span>(<span class="fu">coxph</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor <span class="sc">+</span> race <span class="sc">+</span> age <span class="sc">+</span> sex, <span class="at">data=</span>recidKM))</span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                chisq df      p</span></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; score_factor  0.5254  2 0.7690</span></span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; race          7.6193  1 0.0058</span></span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; age           6.7511  1 0.0094</span></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; sex           0.0387  1 0.8440</span></span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; GLOBAL       13.6196  5 0.0182</span></span></code></pre></div>
<p>Note the big p-values. We do not reject the null hypothesis, so we conclude that there is no evidence of non-proportional hazards. If for example, the model seemed to be non-proportional on time but proportional on log(time), you might consider transforming the time variable (i.e., taking the natural log) in your original model.</p>
<p>The function cox.zph creates a cox.zph object that contains a list of the scaled Schoenfeld residuals. The ordering of the residuals in the list is the same order as the predictors were entered in the cox model. So, the first element of the list corresponds to the scaled Schoenfeld residuals for married, the second element corresponds to the scaled Schoenfeld residuals for person, and so forth. The cox.zph object can be used in a plot function. By specifying a particular element of the list it is possible to generate plots of residuals for individual predictors. Leaving out the list number results in plots for all the predictors being generated at one time. In the plots a non-zero slope is evidence against proportionality. The horizontal line at y=0 has been added for reference.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggcoxzph</span>(<span class="fu">cox.zph</span>(<span class="fu">coxph</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor <span class="sc">+</span> race <span class="sc">+</span> age <span class="sc">+</span> sex, <span class="at">data=</span>recidKM))) </span></code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-25-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="coxph-diagnostics-look-into-all-the-different-arguments-of-the-function" class="section level3" number="6.5.7">
<h3 number="6.5.7"><span class="header-section-number">6.5.7</span> Coxph diagnostics … look into all the different arguments of the function!</h3>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggcoxdiagnostics</span>(<span class="fu">coxph</span>(<span class="fu">Surv</span>(timefollow,event) <span class="sc">~</span> score_factor <span class="sc">+</span> race <span class="sc">+</span> age <span class="sc">+</span> sex, <span class="at">data=</span>recidKM))</span></code></pre></div>
<p><img src="06-surv_files/figure-html/unnamed-chunk-26-1.png" width="80%" style="display: block; margin: auto;" /></p>
<!--chapter:end:06-surv.Rmd-->
</div>
</div>
</div>
<div id="multiple-comparisons" class="section level1" number="7">
<h1 number="7"><span class="header-section-number">7</span> Multiple Comparisons</h1>
<ul>
<li>What is a p-value?</li>
</ul>
<blockquote>
<p>The <strong>p-value</strong> is the probability of collecting the observed data (or data showing as great or greater difference from the null hypothesis) if the null hypothesis is true. <em>The p-value is a number calculated from the dataset.</em></p>
</blockquote>
<ul>
<li>George Cobb (2014) put the p-value into perspective:</li>
</ul>
<blockquote>
<p>Q: Why do so many colleges and grad schools teach p = .05?<br />
A: Because that’s still what the scientific community and journal editors use.</p>
</blockquote>
<blockquote>
<p>Q: Why do so many people still use p = 0.05?<br />
A: Because that’s what they were taught in college or grad school.</p>
</blockquote>
<ul>
<li>In 2014, the journal <em>Basic and Applied Social Psychology</em> banned the use of all null hypothesis significance testing procedures (NHSTP). What are the <a href="https://www.tandfonline.com/doi/full/10.1080/01973533.2015.1012991">implications for authors</a>?</li>
</ul>
<blockquote>
<p>Question 3. Are any inferential statistical procedures required?<br />
Answer to Question 3. No, because the state of the art remains uncertain. However, BASP will require strong descriptive statistics, including effect sizes. We also encourage the presentation of frequency or distributional data when this is feasible. Finally, we encourage the use of larger sample sizes than is typical in much psychology research, because as the sample size increases, descriptive statistics become increasingly stable and sampling error is less of a problem. However, we will stop short of requiring particular sample sizes, because it is possible to imagine circumstances where more typical sample sizes might be justifiable.</p>
</blockquote>
<ul>
<li>The American Statistical Association put out a <a href="https://amstat.tandfonline.com/doi/pdf/10.1080/00031305.2016.1154108">statement on p-values</a></li>
</ul>
<ol style="list-style-type: decimal">
<li>P-values can indicate how incompatible the data are with a specified statistical model.<br />
</li>
<li>P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.<br />
</li>
<li>Scientific conclusions and business or policy decisions should not be based only on whether a p- value passes a specific threshold.<br />
</li>
<li>Proper inference requires full reporting and transparency.<br />
</li>
<li>A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.<br />
</li>
<li>By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.</li>
</ol>
<ul>
<li>Other interested parties weigh in:
<ul>
<li><a href="http://www.nature.com/news/statisticians-issue-warning-over-misuse-of-p-values-1.19503">Statisticians issue warning over misuse of P values</a> (Nature, March 7, 2016)</li>
<li><a href="https://richarddmorey.medium.com/the-value-of-p-212bcfb1ed66">The value of p</a> (Richard Morey, blog entry, Jan 3, 2021)</li>
</ul></li>
</ul>
<div id="Ioannidis" class="section level2" number="7.1">
<h2 number="7.1"><span class="header-section-number">7.1</span> Why Most Published Research Findings are False</h2>
<p>The Ioannidis article <span class="citation">(<a href="#ref-Ioannidis" role="doc-biblioref">Ioannidis 2005</a>)</span>, and our related discussion, focuses on multiple testing. We’d like to understand the effect of testing in three different contexts:</p>
<ol style="list-style-type: decimal">
<li>When looking for as many possible significant findings as possible (publish or perish)</li>
<li>When bias exists in our work</li>
<li>When (many) researchers study the same effect</li>
</ol>
<div id="definitions" class="section level4" number="7.1.0.1">
<h4 number="7.1.0.1"><span class="header-section-number">7.1.0.1</span> Definitions</h4>
<ul>
<li><strong>R</strong>
<span class="math display">\[\begin{eqnarray*}
R = \frac{ \mbox{# true relationships}}{\mbox{# null relationships}} \ \ \ \mbox{ in the population}
\end{eqnarray*}\]</span></li>
<li><strong>TRUE</strong>
<span class="math display">\[\begin{eqnarray*}
P(\mbox{study is true}) &amp;=&amp; \frac{ \mbox{# true relationships}}{\mbox{# total}}\\
&amp;=&amp; \frac{ \mbox{# true relationships}}{\mbox{# true + # null}}\\
&amp;=&amp; \frac{ \mbox{R(# null relationships)}}{\mbox{R (# null) + # null}}\\
&amp;=&amp; \frac{R}{R+1}
\end{eqnarray*}\]</span></li>
<li><strong>size</strong>
<span class="math display">\[\begin{eqnarray*}
\alpha &amp;=&amp; P(\mbox{type I error})\\
&amp;=&amp; P(\mbox{reject } H_0 | H_0 \mbox{ true})\\
\end{eqnarray*}\]</span></li>
<li><strong>power</strong>
<span class="math display">\[\begin{eqnarray*}
1 - \beta &amp;=&amp; P(\mbox{reject } H_0 | H_0 \mbox{ false})\\
\beta &amp;=&amp; P(\mbox{type II error})\\
&amp;=&amp; P(\mbox{not reject } H_0 | H_0 \mbox{ false})\\
\end{eqnarray*}\]</span></li>
<li><strong>tests</strong>
<span class="math display">\[\begin{eqnarray*}
c &amp;=&amp; \mbox{# of tests run}
\end{eqnarray*}\]</span></li>
</ul>
<p>Baseball power simulation applet <span class="citation">(<a href="#ref-iscam" role="doc-biblioref">Chance and Rossman 2018</a>)</span> <a href="http://www.rossmanchance.com/applets/power.html" class="uri">http://www.rossmanchance.com/applets/power.html</a></p>
</div>
<div id="positive-predictive-value-ppv" class="section level3" number="7.1.1">
<h3 number="7.1.1"><span class="header-section-number">7.1.1</span> Positive Predictive Value (PPV)</h3>
<p>We’ll focus here on the Positive Predictive Value (PPV). That is, what is the probability that the positive result you found is actually true?</p>
<table>
<thead>
<tr class="header">
<th>Research Finding</th>
<th>Yes</th>
<th>No</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Yes</td>
<td><span class="math inline">\(c(1-\beta)R / (R+1)\)</span></td>
<td><span class="math inline">\(c \alpha / (R+1)\)</span></td>
<td><span class="math inline">\(c(R+\alpha - \beta R)/(R+1)\)</span></td>
</tr>
<tr class="even">
<td>No</td>
<td><span class="math inline">\(c \beta R / (R+1)\)</span></td>
<td><span class="math inline">\(c(1-\alpha)/(R+1)\)</span></td>
<td><span class="math inline">\(c(1-\alpha + \beta R)/(R+1)\)</span></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(cR/(R+1)\)</span></td>
<td><span class="math inline">\(c/(R+1)\)</span></td>
<td><span class="math inline">\(c\)</span></td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\begin{eqnarray*}
PPV &amp;=&amp; \frac{c(1-\beta)R / (R+1)}{c(1-\beta)R / (R+1) + c \alpha / (R+1)}\\
&amp;=&amp; \frac{c(1-\beta)R}{c(1-\beta)R + c \alpha}\\
&amp;=&amp; \frac{(1-\beta)R}{(1-\beta)R +  \alpha}\\
&amp;=&amp; \frac{1}{1 + \alpha / (1-\beta) R}\\
&amp;&amp; \\
PPV &amp;&gt;&amp; 0.5 \mbox{ more likely true}\\
\mbox{iff   } (1-\beta)R &amp;&gt;&amp; (R-\beta R + \alpha) 0.5\\
(1-\beta) R 0.5 &amp;&gt;&amp; \alpha 0.5\\
(1-\beta) R &amp;&gt;&amp; \alpha \\
&amp;&amp; \\
PPV &amp;&lt;&amp; 0.5  \mbox{ more likely false}\\
\mbox{iff   } (1-\beta) R &amp;&lt;&amp; \alpha \\
\end{eqnarray*}\]</span></p>
</div>
<div id="bias" class="section level3" number="7.1.2">
<h3 number="7.1.2"><span class="header-section-number">7.1.2</span> Bias</h3>
<ul>
<li><strong>bias</strong>
<span class="math display">\[\begin{eqnarray*}
u &amp;=&amp; \mbox{proportion of results that would not have been research findings but ended up}\\
 &amp;&amp; \mbox{reported as such because of bias}
\end{eqnarray*}\]</span></li>
</ul>
<p>Note: bias simply moves <span class="math inline">\(u\)</span>% of the findings from the <code>No</code> row to the <code>Yes</code> row.</p>
<table style="width:100%;">
<colgroup>
<col width="12%" />
<col width="25%" />
<col width="25%" />
<col width="37%" />
</colgroup>
<thead>
<tr class="header">
<th>Research Finding</th>
<th>Yes</th>
<th>No</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Yes</td>
<td><span class="math inline">\([c(1-\beta)R +uc \beta R] / (R+1)\)</span></td>
<td><span class="math inline">\([c \alpha + u c(1-\alpha)] / (R+1)\)</span></td>
<td><span class="math inline">\(c[R+\alpha - \beta R + u(1-\alpha + \beta R)]/(R+1)\)</span></td>
</tr>
<tr class="even">
<td>No</td>
<td><span class="math inline">\((1-u)c \beta R / (R+1)\)</span></td>
<td><span class="math inline">\((1-u)c(1-\alpha)/(R+1)\)</span></td>
<td><span class="math inline">\(c(1-u)(1-\alpha + \beta R)/(R+1)\)</span></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(cR/(R+1)\)</span></td>
<td><span class="math inline">\(c/(R+1)\)</span></td>
<td><span class="math inline">\(c\)</span></td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\begin{eqnarray*}
PPV &amp;=&amp; \frac{[c(1-\beta)R +uc \beta R] / (R+1)}{c[R+\alpha - \beta R + u(1-\alpha + \beta R)]/(R+1)}\\
 &amp;=&amp; \frac{[(1-\beta)R +u \beta R]}{[R+\alpha - \beta R + u(1-\alpha + \beta R)]}\\
&amp;=&amp; \frac{1}{1 + \frac{\alpha + u(1-\alpha)}{(1-\beta)R + u\beta R}}
\end{eqnarray*}\]</span></p>
<p>Note that <span class="math inline">\(PPV \uparrow\)</span> as <span class="math inline">\(u \uparrow\)</span> as long as <span class="math inline">\((1-\beta) \leq \alpha\)</span>. Or really, it is probably easier to think about if <span class="math inline">\((1-\beta) &gt; \alpha\)</span>, then <span class="math inline">\(PPV \uparrow\)</span> as <span class="math inline">\(u \downarrow\)</span>. The second sentence is more realistic, e.g., <span class="math inline">\(\beta &lt; .95\)</span> means that we have more true results in our list of significant findings as the bias goes down. [To understand the direction of the relationships, find <span class="math inline">\(\partial PPV / \partial u &lt; 0\)</span> if <span class="math inline">\((1-\beta) &gt; \alpha\)</span> (decreasing with u).]</p>
</div>
<div id="multiple-studies" class="section level3" number="7.1.3">
<h3 number="7.1.3"><span class="header-section-number">7.1.3</span> Multiple Studies</h3>
<ul>
<li><span class="math inline">\(\alpha\)</span>
<ul>
<li>If a study is null, the probability of seeing null is <span class="math inline">\((1-\alpha)\)</span></li>
<li>If 3 of us test the same thing, the probability that we will all see null is <span class="math inline">\((1-\alpha)^3\)</span></li>
<li><em>and</em> the probability that at least one of use will see significance goes from <span class="math inline">\(\alpha\)</span> to <span class="math inline">\(1 - (1-\alpha)^3\)</span></li>
<li>As <span class="math inline">\(n \uparrow\)</span> someone will definitely see significance (bad!)</li>
</ul></li>
<li><span class="math inline">\(\beta\)</span>
<ul>
<li>If a study is significant, the probability of seeing null is <span class="math inline">\(\beta\)</span></li>
<li>If 3 of us test the same thing, the probability that we’ll all see null is <span class="math inline">\(\beta^3\)</span></li>
<li><em>and</em> the probability that at least one of us will see significance goes from <span class="math inline">\((1-\beta)\)</span> to <span class="math inline">\((1-\beta^3)\)</span></li>
<li>As <span class="math inline">\(n \uparrow\)</span>, someone will definitely see significance (good!)</li>
</ul></li>
</ul>
<table>
<colgroup>
<col width="15%" />
<col width="21%" />
<col width="26%" />
<col width="35%" />
</colgroup>
<thead>
<tr class="header">
<th>Research Finding</th>
<th>Yes</th>
<th>No</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Yes</td>
<td><span class="math inline">\(c(1-\beta^n)R / (R+1)\)</span></td>
<td><span class="math inline">\(c(1-[1- \alpha]^n) / (R+1)\)</span></td>
<td><span class="math inline">\(c(R+1-[1-\alpha]^n - \beta^n R)/(R+1)\)</span></td>
</tr>
<tr class="even">
<td>No</td>
<td><span class="math inline">\(c \beta^n R / (R+1)\)</span></td>
<td><span class="math inline">\(c(1-\alpha)^n/(R+1)\)</span></td>
<td><span class="math inline">\(c([1-\alpha]^n + \beta^n R)/(R+1)\)</span></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(cR/(R+1)\)</span></td>
<td><span class="math inline">\(c/(R+1)\)</span></td>
<td><span class="math inline">\(c\)</span></td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\begin{eqnarray*}
PPV &amp;=&amp; \frac{(1-\beta^n)R}{(R+1-[1-\alpha]^n - \beta^n R)}
\end{eqnarray*}\]</span></p>
<p><span class="math inline">\(PPV \downarrow\)</span> as <span class="math inline">\(n \uparrow\)</span> unless <span class="math inline">\((1-\beta) &lt; \alpha\)</span> that is, <span class="math inline">\(\beta &gt; 0.95\)</span> !!</p>
</div>
<div id="corollaries" class="section level3" number="7.1.4">
<h3 number="7.1.4"><span class="header-section-number">7.1.4</span> Corollaries</h3>
<ul>
<li><strong>Corollary 1</strong> The smaller the studies conducted in a scientific field, the less likely the research findings are to be true. (low power)<br />
</li>
<li><strong>Corollary 2</strong> The smaller the effect sizes in a scientific field, the less likely the research findings are to be true. (also low power)<br />
</li>
<li><strong>Corollary 3</strong> The greater the number and the lesser the selection of tested relationships in a scientific field, the less likely the research findings are to be true. (pre-study odds: R; phase III trials have better odds than microarray studies)<br />
</li>
<li><strong>Corollary 4</strong> The greater the flexibility in designs, definitions, outcomes, and analytical modes in a scientific field, the less likely the research findings are to be true. (increased bias)<br />
</li>
<li><strong>Corollary 5</strong> The greater the financial and other interests and prejudices in a scientific field, the less likely the research findings are to be true. (increased bias)</li>
<li><strong>Corollary 6</strong> The hotter a scientific field (with more scientific teams involved), the less likely the research findings are to be true. (increased <span class="math inline">\(n\)</span>)</li>
</ul>
</div>
</div>
<div id="multcomp" class="section level2" number="7.2">
<h2 number="7.2"><span class="header-section-number">7.2</span> Multiple Comparisons</h2>
<p>As you might expect, if you have 10 groups, <strong>all of which come from the same population</strong>, you might wrongly conclude that some of the means are <em>significantly</em> different. If you try pairwise comparisons on all 10 groups, you’ll have <span class="math inline">\({10 \choose 2} = 45\)</span> comparisons. Out of the 45 CI, you’d expect 2.25 of them to not contain the true difference (of zero); equivalently, you’d expect 2.25 tests to reject the true <span class="math inline">\(H_0\)</span>. In an overall test of comparing all 10 groups simultaneously, you can’t use size as a performance measure anymore.</p>
<ul>
<li><strong>FWER</strong> = <span class="math inline">\(P(V\geq1)\)</span></li>
</ul>
<p>The Familywise Error Rate (FWER) is the probability of making one or more type I errors in a series of multiple tests. In the example above (with 10 comparisons), you would almost always make at least one type I error if you used a size of <span class="math inline">\(\alpha = 0.05\)</span>. So, your FWER would be close to 1. Methods exist for controlling the FWER instead of the size (<span class="math inline">\(\alpha\)</span>).</p>
<div id="bonferroni" class="section level3" number="7.2.1">
<h3 number="7.2.1"><span class="header-section-number">7.2.1</span> Bonferroni</h3>
<p>The Bonferroni method of adjusting for multiple comparisons is used to control the FWER.</p>
<p>Assume all our tests are null
<span class="math display">\[\begin{eqnarray*}
A_1 &amp;=&amp; \mbox{event reject test 1}\\
P(A_1) &amp;=&amp; \alpha^*\\
A_2 &amp;=&amp; \mbox{event reject test 2}\\
P(A_2) &amp;=&amp; \alpha^*\\
\end{eqnarray*}\]</span></p>
<p>We want to bound the probability that all our tests don’t commit a type 1 error (that is, none of them reject).
<span class="math display">\[\begin{eqnarray*}
P( A_1 \mbox{ or } A_2) &amp;=&amp; P(A_1) + P(A_2) - P(A_1 \mbox{ and } A_2)\\
&amp;=&amp; \alpha^* + \alpha^* - ???\\
&amp; \leq&amp; 2 \alpha^* \\
FWER = P(\mbox{at least one rejects}) &amp;\leq&amp; 2 \alpha^*\\
\mbox{let} &amp;&amp; P(A_1) = P(A_2) = \alpha^* = \frac{\alpha}{2}\\
FWER &amp;\leq&amp; \alpha
\end{eqnarray*}\]</span></p>
<p>That is, with <span class="math inline">\(m\)</span> tests, rejecting any test whose p-value is less than or equal to <span class="math inline">\(\alpha/m\)</span> will control the FWER at <span class="math inline">\(\alpha\)</span>. Alternatively, rejecting adjusted p-values less than <span class="math inline">\(\alpha\)</span> will also control the FWER at <span class="math inline">\(\alpha\)</span>. Where the adjusted p-values are defined as:</p>
<p><span class="math display">\[\begin{eqnarray*}
\tilde{p}_j = \min(m p_j, 1)
\end{eqnarray*}\]</span>
Reject any hypothesis such that <span class="math inline">\(\tilde{p}_j \leq \alpha\)</span>.</p>
<ul>
<li>Note that interpretations depend heavily on the number of tests (which is true about most multiple comparison adjustments).<br />
</li>
<li>Bonferroni is extremely conservative, and therefore it has very high type II error rates (low power).<br />
</li>
<li>We aren’t really interested in the situation where “all true null tests don’t get rejected.”</li>
</ul>
</div>
<div id="holm" class="section level3" number="7.2.2">
<h3 number="7.2.2"><span class="header-section-number">7.2.2</span> Holm</h3>
<p>Holm is a less conservative (than Bonferroni) method for controlling the FWER. Because each p-value is considered sequentially, the Holm adjustment is referred to as “step-up.” The intuition is that on the first step, the bound assumes up to <span class="math inline">\(m\)</span> null hypotheses. But on the second step, there are only <span class="math inline">\(m-1\)</span> null hypotheses (assuming the first p-value is rejected).</p>
<p>To control the FWER at <span class="math inline">\(\alpha\)</span>, first order the p-values as <span class="math inline">\(p_1 \leq p_2 \leq \cdots \leq p_m\)</span> and define the adjusted p-values to be:</p>
<p><span class="math display">\[\begin{eqnarray*}
\tilde{p}_j = \max_{i \leq j} [ \min((m-i+1) p_i, 1) ]
\end{eqnarray*}\]</span>
Reject any hypothesis such that <span class="math inline">\(\tilde{p}_j \leq \alpha\)</span>.</p>
<ul>
<li><strong>FDR</strong> = <span class="math inline">\(E[V/R]\)</span></li>
</ul>
<p>The FDR (false discovery rate) is the expected proportion of false discoveries out of all the discoveries.</p>
<ul>
<li><strong>PPV</strong> = <span class="math inline">\(E[S/R]\)</span></li>
</ul>
<p>Consider <span class="math inline">\(m\)</span> hypotheses:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th align="center">Null True</th>
<th align="center">Alt True</th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Research</td>
<td>not significant</td>
<td align="center"><span class="math inline">\(U\)</span></td>
<td align="center"><span class="math inline">\(T\)</span></td>
<td align="center"><span class="math inline">\(m-R\)</span></td>
</tr>
<tr class="even">
<td>Finding</td>
<td>significant</td>
<td align="center"><span class="math inline">\(V\)</span></td>
<td align="center"><span class="math inline">\(S\)</span></td>
<td align="center"><span class="math inline">\(R\)</span></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td align="center"><span class="math inline">\(m_0\)</span></td>
<td align="center"><span class="math inline">\(m-m_0\)</span></td>
<td align="center"><span class="math inline">\(m\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="benjamini-hochberg" class="section level3" number="7.2.3">
<h3 number="7.2.3"><span class="header-section-number">7.2.3</span> Benjamini-Hochberg</h3>
<p>When running experiments that have many many tests of significance, it is often more desirable to worry about the <em>number</em> of false discoveries as opposed to the probability of getting <em>one</em> false discovery. That is, we are typically comfortable with a few false positives (i.e., a very HIGH FWER) as long as the rate of false positives is low.</p>
<p>Define the estimated false discovery proportion at a cutoff t (<span class="math inline">\(\hat{FDR}(t)\)</span>) to be the number of false discoveries at a given cutoff. Again, to control the FDR at <span class="math inline">\(\alpha\)</span>, first order the p-values as <span class="math inline">\(p_1 \leq p_2 \leq \cdots \leq p_m\)</span>.</p>
<p><span class="math display">\[\begin{eqnarray*}
\hat{FDR}(t)&amp;=&amp; \frac{\# \{ p_j \leq t \mbox{ out of the null tests } \}}{ \# \{p_j \leq t\} + (1 \mbox{ if all } p_j &gt; t)}
\end{eqnarray*}\]</span>
Notice that p-values from null hypotheses will be distributed uniformly from zero to one. That means that a good estimate of the numerator is <span class="math inline">\(t\cdot\)</span> # of null tests.
<span class="math display">\[\begin{eqnarray*}
\hat{FDR}(p_j) &amp;=&amp; \frac{p_j \cdot m \cdot \pi_0}{j} &lt; \frac{p_j m}{j}
\end{eqnarray*}\]</span>
where <span class="math inline">\(\pi_0\)</span> is the proportion of tests which are truly null (<span class="math inline">\(m_0/m\)</span>). Consider the adjusted p-values,</p>
<p><span class="math display">\[\begin{eqnarray*}
\tilde{p}_j = \min [ (m/j) p_j, \tilde{p}_{j+1} ]
\end{eqnarray*}\]</span>
Reject any hypothesis such that <span class="math inline">\(\tilde{p}_j \leq \delta\)</span> to control the FDR at <span class="math inline">\(\delta\)</span>.</p>
<p>Intuition: let <span class="math inline">\(m=1000\)</span>, and suppose the <span class="math inline">\(\tilde{p}_{250} &lt; 0.4\)</span>. Show that FDR <span class="math inline">\(&lt; 0.4\)</span>.</p>
<p><span class="math inline">\(\tilde{p}_{250} &lt; 0.4\)</span> implies two different things:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(p_{250} \leq \frac{0.4\cdot 250}{1000} = 0.1\)</span></li>
<li>and <span class="math inline">\(\approx 750\)</span> null tests have p-values between 0.1 and 1.</li>
</ol>
<p>If 750 null tests have p-values between 0.1 and 1, then <span class="math inline">\(m_0 \cdot 0.9 = 750 \rightarrow m_0 = 833.33\)</span>. Therefore, the number of null hypotheses which were rejected is 833.33 - 750 = 83.33.</p>
<p><span class="math display">\[\begin{eqnarray*}
FDR = \frac{83.33}{250} = 0.33 &lt; 0.4
\end{eqnarray*}\]</span></p>
<p>More generally if <span class="math inline">\(\tilde{p}_k = \frac{p_k \cdot m}{k} \leq \delta\)</span>:
<span class="math display">\[\begin{eqnarray*}
p_k &amp;&lt;&amp; \frac{k}{m} \delta\\
\# \mbox{ null not rejected} &amp;=&amp; \mbox{length of null interval }\bigg[\frac{k}{m}\delta,1\bigg] \cdot \mbox{ total } \# \mbox{ of null}\\
(m-k) &amp;=&amp; \bigg(1-\frac{k}{m} \delta\bigg) m_0\\
m_0 &amp;=&amp; \frac{(m-k) m}{(m-k \delta)}\\
&amp; &amp;\\
FDR &amp;=&amp; \frac{\# \mbox{ null rejected}}{\# \mbox{ rejected}}\\
&amp;=&amp; \frac{\frac{m(m-k)}{(m-k\delta)} - (m-k)}{k}\\
&amp;=&amp; \frac{m^2 - mk - (m-k) (m-k \delta)}{(m-k \delta)k}\\
&amp;=&amp; \frac{k(m \delta - k \delta)}{k(m-k \delta)} = \delta\bigg(\frac{m-k}{m/\delta - k}\bigg)\\
FDR &amp;&lt;&amp; \delta
\end{eqnarray*}\]</span>
because <span class="math inline">\(m/\delta &gt; m\)</span> so <span class="math inline">\(\frac{m-k}{m/\delta -k} &lt; 1\)</span>.</p>
<p>Consider a one sample t-test. The population is normal centered at 47 with <span class="math inline">\(\sigma=3\)</span>; samples of size 20 are taken from the population. The following hypotheses are tested:
<span class="math display">\[\begin{eqnarray*}
H_0: \mu = 47\\
H_{0_1}: \mu = 40\\
H_{0_2}: \mu = 48\\
H_{0_3}: \mu = 50\\
\end{eqnarray*}\]</span>
In the null setting, the p-values are uniformly distributed from 0 to 1. When the data are not consistent with the null, there are more p-values close to zero (and even closer to zero as the data become more and more distinct from the null).</p>
<div id="distribution-of-p-values-under-different-amounts-of-divergence-from-the-null-hypothesis." class="section level4" number="7.2.3.1">
<h4 number="7.2.3.1"><span class="header-section-number">7.2.3.1</span> Distribution of p-values under different amounts of divergence from the null hypothesis.</h4>
<p><img src="07-MC_files/figure-html/unnamed-chunk-1-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>The previous example considered the situation where all the p-values came from the distribution. In reality, p-values will come from many different distributions. For simplification, consider the situation where g100% of the tests come from the null distribution, and (1-g)100% of the tests come from a distribution where the p-values are much closer to one and skewed right.</p>
</div>
<div id="distribution-of-p-values-under-differing-proportions-of-null-versus-significant-tests." class="section level4" number="7.2.3.2">
<h4 number="7.2.3.2"><span class="header-section-number">7.2.3.2</span> Distribution of p-values under differing proportions of null versus significant tests.</h4>
<p><img src="07-MC_files/figure-html/unnamed-chunk-2-1.png" width="80%" style="display: block; margin: auto;" /><img src="07-MC_files/figure-html/unnamed-chunk-2-2.png" width="80%" style="display: block; margin: auto;" /><img src="07-MC_files/figure-html/unnamed-chunk-2-3.png" width="80%" style="display: block; margin: auto;" /><img src="07-MC_files/figure-html/unnamed-chunk-2-4.png" width="80%" style="display: block; margin: auto;" /><img src="07-MC_files/figure-html/unnamed-chunk-2-5.png" width="80%" style="display: block; margin: auto;" /><img src="07-MC_files/figure-html/unnamed-chunk-2-6.png" width="80%" style="display: block; margin: auto;" /><img src="07-MC_files/figure-html/unnamed-chunk-2-7.png" width="80%" style="display: block; margin: auto;" /><img src="07-MC_files/figure-html/unnamed-chunk-2-8.png" width="80%" style="display: block; margin: auto;" /><img src="07-MC_files/figure-html/unnamed-chunk-2-9.png" width="80%" style="display: block; margin: auto;" /><img src="07-MC_files/figure-html/unnamed-chunk-2-10.png" width="80%" style="display: block; margin: auto;" /><img src="07-MC_files/figure-html/unnamed-chunk-2-11.png" width="80%" style="display: block; margin: auto;" /><img src="07-MC_files/figure-html/unnamed-chunk-2-12.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
<div id="qvals" class="section level2" number="7.3">
<h2 number="7.3"><span class="header-section-number">7.3</span> Storey &amp; q-values</h2>
<p>The previous methods allowed the larger family of tests to control either the FWER or the FDR (global measures of accuracy). However, for a given test, there was no measure to quantify FDR for a given test.</p>
<ul>
<li><strong>p-value</strong> Recall that the p-value is the smallest level of significance (P(type I error)) possible to reject <span class="math inline">\(H_0\)</span>.</li>
<li><strong>q-value</strong> Akin to the p-value, the q-value is the minimum FDR at that score which can be attained when calling the test significant.</li>
</ul>
<p>Storey defines the q-value to be the FDR associated with a given test of significance. For example, say a q-value = 0.013 for test X. Then at most 1.3% of tests with p-values at least as small as test X are false positives. In particular, let
<span class="math display">\[\begin{eqnarray*}
\hat{\pi}_0 = \frac{\# \{ p_j &gt; \lambda \} }{m(1-\lambda)} \ \ \  \mbox{ for some } \lambda
\end{eqnarray*}\]</span>
(though there are many ways to estimate <span class="math inline">\(\pi_0\)</span>.)</p>
<p>In a step-down algorithm, the q-value is defined using the p-value at hand and the next {} p-value. Additionally, the <span class="math inline">\(\pi_0\)</span> is implemented as seen in the original intuition behind FDR control.</p>
<ul>
<li><strong>step 1</strong> let
<span class="math display">\[\begin{eqnarray*}
\hat{q}(p_{m}) = \hat{\pi}_0 p_{m}
\end{eqnarray*}\]</span>
Note that <span class="math inline">\(\hat{q}(p_{m})\)</span> is the biggest q-value and $ p_{m}$ is the biggest p-value.</li>
<li><strong>step 2</strong>
<span class="math display">\[\begin{eqnarray*}
\hat{q}(p_{m-1}) = \min( \hat{\pi}_0 p_{m-1} \frac{m}{m-1}, \hat{q}( p_{m}))
\end{eqnarray*}\]</span>
If <span class="math inline">\(\hat{q}(p_{m}) = 0.7\)</span> and <span class="math inline">\(\hat{\pi}_0 p_{m-1} \frac{m}{m-1} = 0.8\)</span>, then the next smallest q-value would be 0.7 because the FDR can be as low as 0.7 (see the definition of FDR).</li>
<li><strong>step 3</strong> more generally,
<span class="math display">\[\begin{eqnarray*}
\hat{q}(p_{j}) = \min( \hat{\pi}_0 p_{j} \frac{m}{j}, \hat{q}( p_{j+1}))
\end{eqnarray*}\]</span></li>
</ul>
<p>Can a q-value be less than a p-value? Sure! If the number of null hypotheses is small and the test is powerful. For example, consider testing 1000 hypotheses with 20% null tests (<span class="math inline">\(\pi_0=0.2\)</span>). Assume 500 of the p-values are less than 0.05 (very powerful!). With 200 null we would expect 10 to be less than 0.05. So, the FDR is 10/500 = 0.02 (which is smaller than the p-value of 0.05 at the cutoff for the <span class="math inline">\(500^{th}\)</span> test).</p>
<div id="how-are-fwer-and-fdr-related" class="section level4" number="7.3.0.1">
<h4 number="7.3.0.1"><span class="header-section-number">7.3.0.1</span> How are FWER and FDR related?</h4>
<p>First note that for both FDR and FWER, the procedure is to <em>control</em> the errors not to compute or estimate the errors (except in the case of the q-value).</p>
<p>Recall that <span class="math inline">\(FDR = E[V/R]\)</span> and is defined to equal zero if R=0</p>
<p><span class="math display">\[\begin{eqnarray*}
FDR &amp;=&amp; E\bigg[\frac{V}{R} \bigg]\\
&amp;=&amp; E\bigg[\frac{V}{R} | R &gt; 0 \bigg] P(R &gt;0) + E\bigg[\frac{V}{R} | R=0 \bigg] P(R=0)\\
&amp;=&amp; E\bigg[\frac{V}{R} | R &gt; 0 \bigg] P(R &gt;0)
\end{eqnarray*}\]</span></p>
<ul>
<li><strong>case 1</strong> In the first case, consider <span class="math inline">\(V=R\)</span> such that all significant hypotheses are null.
<span class="math display">\[\begin{eqnarray*}
FDR &amp;=&amp; E\bigg[\frac{V}{R} | R &gt; 0 \bigg] P(R &gt;0)\\
&amp;=&amp; 1 P(R&gt;0) = 1 P(V \geq 1)\\
&amp;=&amp; FWER
\end{eqnarray*}\]</span></li>
<li><strong>case 2</strong> In the second case, consider <span class="math inline">\(V &lt; R\)</span> such that some of the significant hypotheses are null and some are not. (<span class="math inline">\(V/R &lt; 1\)</span>)
<span class="math display">\[\begin{eqnarray*}
FDR &amp;=&amp; E\bigg[\frac{V}{R} | R &gt; 0 \bigg] P(R &gt;0)\\
&amp;=&amp; E\bigg[\frac{V}{R} | R &gt; 0, V\geq 1 \bigg] P(R &gt;0, V \geq 1) + E\bigg[\frac{V}{R} | R &gt; 0, V=0 \bigg] P(R &gt;0, V =0)\\ 
&amp;&amp; \mbox{ (note: } V/R \equiv 0 \mbox{ if } V = 0)\\
&amp;=&amp; E\bigg[\frac{V}{R} | R &gt; 0, V\geq 1 \bigg] P(R &gt;0, V \geq 1) \\
&amp;&lt;&amp; P(V \geq 1) = FWER \ \ \mbox{ because } V/R &lt; 1
\end{eqnarray*}\]</span></li>
</ul>
<p>The proof above shows that FWER controls the FDR when not all significant tests are null. When all significant tests are null, FWER=FDR.</p>
</div>
</div>
<div id="interim-analyses" class="section level2" number="7.4">
<h2 number="7.4"><span class="header-section-number">7.4</span> Interim Analyses</h2>
<p>An important application of multiple comparisons issues comes when deciding whether or not to stop a clinical trial early due to either positive or negative results. Looking too often will create many false positives which can be quite problematic. <span class="citation">(<a href="#ref-subgroup" role="doc-biblioref">Schulz and Grimes 2005</a>)</span></p>
<p>Consider the following case studies:</p>
<ul>
<li>HIV – Indinavir was stopped early due to positive results <span class="citation">(<a href="#ref-hiv" role="doc-biblioref">Scott M. Hammer et al. 1997</a>)</span></li>
<li>HVTN 505 was stopped early due to negative results <span class="citation">(<a href="#ref-hvtn" role="doc-biblioref">Yunda Huang et al. 2015</a>)</span></li>
<li>Truvada &amp; Tenofovir were also stopped early <span class="citation">(<a href="#ref-hrt" role="doc-biblioref">Dyer 2004</a>)</span></li>
</ul>
<p>What happens when the research performs <span class="math inline">\(k\)</span> interim analyses and the research scenario is truly null?
<span class="math display">\[\begin{eqnarray*}
P( test1 &lt; \alpha \mbox{ or } test2 &lt; \alpha \mbox{ or } \ldots \mbox{ or }  testk &lt; \alpha ) &gt; \alpha
\end{eqnarray*}\]</span></p>
<p>The researcher has two options:</p>
<ol style="list-style-type: decimal">
<li>Let <span class="math inline">\(\alpha^* &lt; &lt; &lt; \alpha\)</span></li>
<li>Change <span class="math inline">\(\alpha\)</span> at each step along the way so that the total probability of a type I error is <span class="math inline">\(\alpha\)</span></li>
</ol>
<div class="figure">
<img src="alphaInterim.png" alt="" />
<p class="caption">Different <span class="math inline">\(\alpha^*\)</span> values for three different stopping criteria. Note that Peto does not control the test at an overall <span class="math inline">\(\alpha=0.05\)</span>, although it is close.</p>
</div>
<div id="pocock" class="section level3" number="7.4.1">
<h3 number="7.4.1"><span class="header-section-number">7.4.1</span> Pocock</h3>
<p>Advantages:</p>
<ul>
<li>simple</li>
<li>aggressive with respect to stopping early. that is, there is a small expected sample size (when the effect size is large)</li>
</ul>
<p>Disadvantage:</p>
<ul>
<li>low power and therefore large maximum sample size (when the effect size is small)</li>
</ul>
</div>
<div id="obrien-flemming" class="section level3" number="7.4.2">
<h3 number="7.4.2"><span class="header-section-number">7.4.2</span> O’Brien-Flemming</h3>
<p>Advantages:</p>
<ul>
<li>final <span class="math inline">\(\alpha\)</span> is close to desired <span class="math inline">\(\alpha\)</span></li>
<li>more power than Pocock, so smaller max sample size</li>
</ul>
<p>Disadvantage:</p>
<ul>
<li>less likely to stop early, so larger expected sample size</li>
</ul>
</div>
<div id="some-parting-thoughts" class="section level3" number="7.4.3">
<h3 number="7.4.3"><span class="header-section-number">7.4.3</span> Some parting thoughts</h3>
<ul>
<li>If <span class="math inline">\(H_a\)</span> is true, the effect size is likely overestimated (true in general, not just for interim analyses).</li>
<li>Symmetry: which is more important, harm or good?</li>
<li>Can split alpha into two halves and apply one method (e.g., Pocock) to stopping early for positive reasons and apply another method (e.g., O’Brien-Flemming) to stopping early for negative reasons.</li>
</ul>
<div id="advice-1" class="section level4" number="7.4.3.1">
<h4 number="7.4.3.1"><span class="header-section-number">7.4.3.1</span> Advice 1</h4>
<p>The following quote is general advice from statistical researchers doing clinical oncology. <span class="citation">(<a href="#ref-crowley" role="doc-biblioref">Green, Benedetti, and Crowley 1997</a>)</span></p>
<blockquote>
<p>Even the specifics of the most basic task of the data monitoring committee, evaluation of interim results for evidence of benefit or harm, are not necessarily obvious. Questions (and our personal answers) include:</p>
</blockquote>
<blockquote>
<ul>
<li>How often should the data monitoring committee review interim data? (The answer to this should depend on how fast additional information becomes available on a trial. we generally recommend monitoring advanced disease studies, or any other study with rapidly accumulating events, every 6 months. Yearly monitoring may be sufficient for adjuvant or slowly accruing studies.)</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>Should the primary outcome data be reviewed each time or should they be reviewed only at times of planned interim analyses? (All data, including primary outcome data, should be reviewed at each time, since the unexpected does occur.)</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>Should treatment arms be blinded to the data monitoring committee or not? (Definitely not. If A looks better than B, the decision to continue could well be different if A is the control arm instead of the experimental arm.)</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>Should a data monitoring committee decision that evidence is sufficient to close a trail be final, or should it be advisory only? (We would say advisory, but rarely overturned.)</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>If advisory, advisory to whom - the funding agency? an executive group? the investigators? (Reports should go to the individuals with ultimate responsibility for the integrity of the trial.)</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>Should a data monitoring committee be able to make major design changes to a trial? (No, the data monitoring committee may offer suggestions but design is the responsibility of the principal investigators. On the other hand, major design changes initiated by the principal investigators should be approved by the committee.)</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>Are data monitoring committee duties over when study accrual is complete, or should the data monitoring committee also decide when results are to be reported? (It should also decide when results are to be reported - additional follow-up generates additional data that still need to be monitored.)</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>How much weight should be accorded to outside information versus current information on the study being monitored? (Definitive outside information cannot be ignored - but this begs the question of what is definitive. A single trial of moderate size probably is not definitive; two large trials probably are; a meta-analysis probably is not.)</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>How much should results of secondary endpoints influence the decision to continue or not? (Not much unless toxic death is considered secondary.)</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>How scary do results have to be to stop at a time other than a planned interim analysis? (Very scary, or the purpose of interim analyses is defeated.)</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>When do accrual problems justify early closure? (When results won’t be available until after they are no longer of interest.)</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>Should confidential information ever be provided to other data monitoring committees or planning groups? (Sometimes. If study conduct will not be compromised by limited release of information, it might be reasonable to let investigators planning new trials know of potential problems or benefits to treatment arms they are considering. Risk to the ongoing trial includes leaked information or intelligent guesses as to the current status; risk to the new trial includes choosing an inappropriate arm based on early results that don’t hold up.)</li>
</ul>
</blockquote>
<blockquote>
<p>Every monitoring committee functions differently because no two people have the same ethical, scientific, or practical perspectives. This means different committees might well come up with different answers to the same monitoring issues. To ensure some balance of opinions, it is best to have a variety of knowledgeable people as members of the committee.</p>
</blockquote>
</div>
<div id="advice-2" class="section level4" number="7.4.3.2">
<h4 number="7.4.3.2"><span class="header-section-number">7.4.3.2</span> Advice 2</h4>
<p>Duncan Temple-Lang is a leader in the area of combining computer science research concepts within the context of statistics and science more generally. Recently, he was invited to participate in a workshop, <em>Training Students to Extract Value from Big Data</em>. The workshop was subsequently summarized in a manuscript of the same name and has been provided free of charge. <a href="http://www.nap.edu/catalog.php?record_id=18981" class="uri">http://www.nap.edu/catalog.php?record_id=18981</a></p>
<p><strong>Principles for the Data Science Process</strong>, Duncan Temple Lang, University of California, Davis <span class="citation">(<a href="#ref-duncanTL" role="doc-biblioref"><em>National Research Council: Training Students to Extract Value from Big Data</em> 2014</a>)</span></p>
<p>Duncan Temple Lang began by listing the core concepts of data science - items that will need to be taught: statistics and machine learning, computing and technologies, and domain knowledge of each problem. He stressed the importance of interpretation and reasoning - not only methods - in addressing data. Students who work in data science will have to have a broad set of skills - including knowledge of randomness and uncertainty, statistical methods, programming, and technology - and practical experience in them. Students tend to have had few computing and statistics classes on entering graduate school in a domain science.</p>
<p>Temple Lang then described the data analysis pipeline, outlining the steps in one example of a
data analysis and exploration process:</p>
<ol style="list-style-type: decimal">
<li><p>Asking a general question.</p></li>
<li><p>Refining the question, identifying data, and understanding data and metadata. Temple Lang
noted that the data used are usually not collected for the specific question at hand, so the original experiment and data set should be understood.</p></li>
<li><p>Access to data. This is unrelated to the science but does require computational skill.</p></li>
<li><p>Transforming to data structures.</p></li>
<li><p>Exploratory data analyses to understand the data and determine whether the results will scale.
This is a critical step; Temple Lang noted that 80 percent of a data scientist’s time can be spent in cleaning and preparing the data.</p></li>
<li><p>Dimension reduction. Temple Lang stressed that it can be difficult or impossible to automate
this step.</p></li>
<li><p>Modeling and estimation. Temple Lang noted that computer and machine learning scientists
tend to focus more on predictive models than on modeling of physical behavior or characteristics.</p></li>
<li><p>Diagnostics. This helps to understand how well the model fits the data and identifies
anomalies and aspects for further study. This step has similarities to exploratory data analysis.</p></li>
<li><p>Quantifying uncertainty. Temple Lang indicated that quantifying uncertainty with statistical
techniques is important for understanding and interpreting models and results.</p></li>
<li><p>Conveying results.</p></li>
</ol>
<p>Temple Lang stressed that the data analysis process is highly interactive and iterative and requires the presence of a human in the loop. The next step in data processing is often not clear until the results of the current step are clear, and often something unexpected is uncovered. He also emphasized the importance of abstract skills and concepts and said that people need to be exposed to authentic data analyses, not only to the methods used. Data scientists also need to have a statistical understanding, and Temple Lang described the statistical concepts that should be taught to a student:</p>
<ul>
<li>Mapping the general question to a statistical framework.</li>
<li>Understanding the scope of inference, sampling, biases, and limitations.</li>
<li>Exploratory data analyses, including missing values, data quality, cleaning, matching, and
fusing.</li>
<li>Understanding randomness, variability, and uncertainty. Temple Lang noted that many
students do not understand sampling variability.</li>
<li>Conditional dependence and heterogeneity.</li>
<li>Dimension reduction, variable selection, and sparsity.</li>
<li>Spurious relationships and multiple testing.</li>
<li>Parameter estimation versus “black box” prediction and classification.</li>
<li>Diagnostics, residuals, and comparing models.</li>
<li>Quantifying the uncertainty of a model.</li>
<li>Sampling structure and dependence for data reduction. Temple Lang noted that modeling of
data becomes complicated when variables are not independent, identically distributed.</li>
<li>Statistical accuracy versus computational complexity and efficiency.</li>
</ul>
<p>Temple Lang then briefly discussed some of the practical aspects of computing, including the
following:</p>
<ul>
<li>Accessing data.</li>
<li>Manipulating raw data.</li>
<li>Data structures and storage, including correlated data.</li>
<li>Visualization at all stages (particularly in exploratory data analyses and conveying the
results).</li>
<li>Parallel computing, which can be challenging for a new student.</li>
<li>Translating high-level descriptions to optimal programs.</li>
</ul>
<p>During the discussion, Temple Lang proposed computing statistics on visualizations to examine
data rigorously in a statistical and automated way. He explained that “scagnostics” (from scatter plot diagnostics) is a data analysis technique for graphically exploring the relationships among variables. A small set of statistical measures can characterize scatter plots, and exploratory data analysis can be conducted on the residuals.</p>
<p>(More information about scagnostics can be found in <span class="citation"><a href="#ref-scagnostics" role="doc-biblioref">Wilkinson and Wills</a> (<a href="#ref-scagnostics" role="doc-biblioref">2007</a>)</span>.)</p>
<p>A workshop participant noted the difference between a data error and a data blunder. A blunder is a large, easily noticeable mistake. The participant gave the example of shipboard observations of cloud cover; blunders, in that case, occur when the location of the ship observation is given to be on land rather than at sea. Another blunder would be a case of a ship’s changing location too quickly. The participant speculated that such blunders could be generalized to detect problematic observations, although the tools would need to be scalable to be applied to large data sets.</p>
<!--chapter:end:07-MC.Rmd-->
</div>
</div>
</div>
</div>
<div id="poisson-regression" class="section level1" number="8">
<h1 number="8"><span class="header-section-number">8</span> Poisson Regression</h1>
<div id="regPois" class="section level2" number="8.1">
<h2 number="8.1"><span class="header-section-number">8.1</span> Regression Models</h2>
<p>Consider the following example from <span class="citation"><a href="#ref-poole" role="doc-biblioref">Poole</a> (<a href="#ref-poole" role="doc-biblioref">1989</a>)</span> (described in <span class="citation"><a href="#ref-sleuth" role="doc-biblioref">Ramsey and Schafer</a> (<a href="#ref-sleuth" role="doc-biblioref">2012</a>)</span>) on age and mating success (number of successful matings) in male African Elephants.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>elephants <span class="ot">&lt;-</span> readr<span class="sc">::</span><span class="fu">read_csv</span>(<span class="st">&quot;elephants.csv&quot;</span>)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(elephants, <span class="fu">aes</span>(<span class="at">x=</span><span class="fu">jitter</span>(AGE), <span class="at">y=</span>MATINGS)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-2-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>While it does seem like there is an increasing trend in the two variables, there are some concerns with directly applying linear regression. Indeed, the example above acts as a proxy for many regression examples where the response variable is a count with particular properties:</p>
<ol style="list-style-type: decimal">
<li><p>The response variable is a count (in particular, it cannot be negative).</p></li>
<li><p>The model may or may not be linear in X.</p></li>
<li><p>The model appears to have increasing variance as a function of X.</p></li>
</ol>
<p>For the setting above, it is often preferable to use Poisson regression instead of the normal errors linear regression.</p>
<div id="the-poisson-regression-model" class="section level3" number="8.1.1">
<h3 number="8.1.1"><span class="header-section-number">8.1.1</span> The Poisson Regression Model</h3>
<p>The Poisson distribution is given by a probability function of the form:</p>
<p><span class="math display">\[P(Y = y) = \frac{e^{-\mu} \mu^y}{y!} \ \ \ \ \ y=0, 1, 2, \ldots\]</span></p>
<p>Which gives: <span class="math inline">\(E(Y) = \mu\)</span> and <span class="math inline">\(Var(Y) = \mu\)</span>. That is, the Poisson model is characterized by a mean and variance given by the same value.</p>
<p>Recall that with linear regression, <span class="math inline">\(E(Y_i) = \beta_0 + \beta_1 X_i\)</span> which might be a reasonable idea to apply to the count data; however, as seen above, if the mean of the distribution is modeled strictly as a linear function in <span class="math inline">\(X\)</span>, then the line has the potential to predict negative counts and the variability will not be a function of <span class="math inline">\(X\)</span> if normal errors regression is used.</p>
<p>An alternative the normal errors regression is to use a <span class="math inline">\(\ln\)</span> transformation to describe the relationship between the predicted value of the response and the explanatory variables of interest:</p>
<p><span class="math display">\[\ln(E(Y_i)) = \ln(\mu_i) = \beta_0 + \beta_1 X_i.\]</span>
where the observed counts come from a Poisson model: <span class="math inline">\(Y_i \sim Pois(\mu_i)\)</span> and the Poisson parameter is given as a function of the explanatory variable(s). [Note that Poisson regression contains no error term like linear regression because the Poisson distribution has inherent variability which is determined by the mean which equals the variance.]</p>
<div id="technical-conditions-1" class="section level4" number="8.1.1.1">
<h4 number="8.1.1.1"><span class="header-section-number">8.1.1.1</span> Technical Conditions</h4>
<p>Like every model, there are technical conditions associated with Poisson Regression. The closer the data (population) conform to the conditions, the more useful the model will be at describing the context at hand. Remember,
&gt; All models are wrong, but some models are useful." -George Box.</p>
<p>So, assessing whether the technical conditions are reasonable will help in determining whether the analysis performed under a particular model was a good thing to do.</p>
<ol style="list-style-type: decimal">
<li>Line: The log of the mean is a linear function of <span class="math inline">\(X\)</span>: <span class="math inline">\(\ln(\mu_i) = \beta_0 + \beta_1 X_i.\)</span></li>
<li>Independence: The observations are independent (often characterized by a simple random sample or something approximating a simple random sample).</li>
<li>Poisson: The response variable is a count.</li>
<li>Error: The mean of the response variables is equal to the variance of the response variable for each combination of explanatory variables in the model.</li>
</ol>
<div class="figure">
<img src="NormPoisReg1.jpg" alt="" />
<p class="caption">Visualizing Normal vs Poisson Error Regression from <span class="citation"><a href="#ref-bysh" role="doc-biblioref">Legler and Roback</a> (<a href="#ref-bysh" role="doc-biblioref">2019</a>)</span></p>
</div>
</div>
</div>
<div id="comparison-to-linear-regression" class="section level3" number="8.1.2">
<h3 number="8.1.2"><span class="header-section-number">8.1.2</span> Comparison to Linear Regression</h3>
<p>One question that might come to mind is whether there is any difference in the Poisson log-linear model and a normal errors regression model with a log transformation on the response??? The short answer is that yes, there is a difference.</p>
<ul>
<li><p><strong>Poisson Log-Linear:</strong> <span class="math inline">\(\ln(E(Y_i)) = \beta_0 + \beta_1 X_i, Y_i \sim Pois(e^{\beta_0 + \beta_1 X_i})\)</span></p></li>
<li><p><strong>Normal w Log Transformation:</strong> <span class="math inline">\(E(\ln(Y_i)) = \beta_0 + \beta_1 X_i, \ln(Y_i) \sim N(\beta_0 + \beta_1 X_i, \sigma^2)\)</span></p></li>
</ul>
<p>There are two main differences with the models.</p>
<ol style="list-style-type: decimal">
<li>The first is to remember that the average (i.e., expected value) of the logs is not the log of the averages. So in the Poisson model, the linear function measures the log of the average, and in the normal model, the linear function measures the average of the logs.</li>
</ol>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">47</span>)</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>example <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">rcauchy</span>(<span class="dv">10</span>))</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>example</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1]  0.0725  2.3911  0.9302  0.6237  4.2508  1.4575  2.7521 10.2177  7.3042</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [10]  0.2404</span></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="fu">log</span>(<span class="fu">mean</span>(example))</span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1.11</span></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">log</span>(example))</span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.343</span></span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li>The second difference to note across the two regression set-ups is that the variability is modeled differently. Indeed, the likelihood functions are quite different and will produce different maximum likelihood estimates of the parameter values.</li>
</ol>
<div class="figure">
<img src="NormPoisReg2.jpg" alt="" />
<p class="caption">Differences in Normal vs Poisson Error Regression from <span class="citation"><a href="#ref-bysh" role="doc-biblioref">Legler and Roback</a> (<a href="#ref-bysh" role="doc-biblioref">2019</a>)</span></p>
</div>
</div>
<div id="interpreting-poisson-regression-coefficients" class="section level3" number="8.1.3">
<h3 number="8.1.3"><span class="header-section-number">8.1.3</span> Interpreting Poisson Regression Coefficients</h3>
<p>As we’ve done with other generalized linear models (linear regression, logistic regression, even survival analysis!), in order to understand the model more completely, we look at the impact on the response variable for a one unit change in <span class="math inline">\(X\)</span>.</p>
<p>Consider <span class="math inline">\(X\)</span> and <span class="math inline">\(X+1\)</span>.</p>
<p><span class="math display">\[\frac{E(Y|X+1)}{E(Y|X)} = \frac{e^{\beta_0 + \beta_1 (X+1)}}{e^{\beta_0 + \beta_1 (X)}} = e^{\beta_1}\]</span></p>
<p>That is, <span class="math inline">\(e^{\beta_1}\)</span> represents the ratio of means for a one unit increase in <span class="math inline">\(X\)</span>. In the elephant example, for every additional year of life, we expect the elephant’s mating success, on average, to change by a factor of <span class="math inline">\(e^{\beta_1}\)</span>. [For the savvy consumer, you might note that this is an additional contrast to normal error regression on the log transformed Y where it was required to interpret the multiplicative change in <em>median</em>. Because with Poisson, the log is taken after the average, taking the inverse of the log gives the mean directly. Previously, it was necessary to use the identity: <span class="math inline">\(median(\ln(Y)) = \ln(median(Y))\)</span>.]</p>
</div>
<div id="assessing-model-validity" class="section level3" number="8.1.4">
<h3 number="8.1.4"><span class="header-section-number">8.1.4</span> Assessing Model Validity</h3>
<p>Just as with linear regression we used scatterplots to give a sense of whether or not a linear regression was appropriate, we can use exploratory data analysis (including scatterplot!) to give a sense of whether or not Poisson regression is an appropriate model. <span class="citation">(The EDA steps here are based on excellent descriptions of Poisson model building in <a href="#ref-bysh" role="doc-biblioref">Legler and Roback 2019</a>.)</span></p>
<p><strong>Technical Condition 3, Poisson:</strong> Let’s first look at the response variable. A histogram of the number of successful matings shows a right skew which is typically not acceptable for normal errors regression (although, remember, the value of the response variable is dependent on the value of the explanatory variable!)
<img src="08-PoisReg_files/figure-html/unnamed-chunk-4-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Likely, it makes more sense to look at the distribution of the response variable at each value of the explanatory variables. Because the sample size is limited, we group the age variable into 5 year increments. Looking at the plot below, again it seems as though, even when conditioning on the explanatory variable, the response is right skewed with variance dependent on the mean. It might also be good to find the sample mean per group and plot the Poisson probabilities onto each bar.</p>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-5-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><strong>Technical Condition 4, Error:</strong> To check whether the mean and variance are similar, we can calculate the values per group (with more data we would probably have more groups of the explanatory variable, and the following analysis would be done with a scatterplot of means on the x-axis and variance on the y-axis). Note that the mean and variance are reasonably similar! When the “mean=variance” condition is violated, it is almost always violated in such that the variance is even <em>bigger</em> than would have been expected by the Poisson model. Large variance is called overdispersion, and methods for measuring and accounting for overdispersion are given in the following section @ref(overdis).</p>
<pre><code>#&gt; # A tibble: 3 x 5
#&gt;   AGEgroups  mean variance stdev     n
#&gt;   &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;
#&gt; 1 (20,30]    1.08    0.992 0.996    12
#&gt; 2 (30,40]    2.71    2.85  1.69     17
#&gt; 3 (40,55]    4.25    7.84  2.80     12</code></pre>
<p><strong>Technical Condition 1, Line:</strong> The Poisson model implies that the log of the mean will be a linear function of the explanatory variable:</p>
<p><span class="math display">\[\ln(\mu_i) = \beta_0 + \beta_1 X_i,\]</span>
which means we’d really like to plot <span class="math inline">\(\mu_i\)</span> as a function of the explanatory variable. Unfortunately, <span class="math inline">\(\mu_i\)</span> is unknown, and so cannot be plotted. We can, however, plot the log of the average value of the response for a group of x values which are close to one another. In the plot below, we’ve grouped observations based on the age of the elephants being within 3 years of years of each other. It is actually quite linear! The points that don’t follow the linear relationship are based on age groups with very few observations.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>matelogmean <span class="ot">&lt;-</span> elephants <span class="sc">%&gt;%</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">agecut =</span> <span class="fu">cut</span>(AGE, <span class="at">breaks=</span><span class="fu">seq</span>(<span class="fl">26.5</span>,<span class="fl">53.5</span>,<span class="at">by=</span><span class="dv">3</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(agecut) <span class="sc">%&gt;%</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">meanmate =</span> <span class="fu">mean</span>(MATINGS), <span class="at">logmate =</span> <span class="fu">log</span>(<span class="fu">mean</span>(MATINGS)), <span class="at">n =</span> <span class="fu">n</span>() )</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>elephantsGRP <span class="ot">&lt;-</span> <span class="fu">cbind</span>(matelogmean, <span class="at">age =</span> <span class="fu">c</span>(<span class="fu">seq</span>(<span class="fl">26.5</span>,<span class="fl">52.5</span>,<span class="at">by=</span><span class="dv">3</span>)<span class="sc">+</span><span class="fl">1.5</span> ))</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>elephantsGRP</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        agecut meanmate logmate  n age</span></span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (26.5,29.5]     1.09   0.087 11  28</span></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 (29.5,32.5]     1.50   0.405  2  31</span></span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 (32.5,35.5]     2.44   0.894  9  34</span></span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 (35.5,38.5]     3.50   1.253  6  37</span></span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 (38.5,41.5]     2.00   0.693  2  40</span></span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 (41.5,44.5]     3.57   1.273  7  43</span></span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 7 (44.5,47.5]     6.00   1.792  2  46</span></span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 8 (47.5,50.5]     2.00   0.693  1  49</span></span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 9 (50.5,53.5]     9.00   2.197  1  52</span></span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-20"><a href="#cb61-20" aria-hidden="true" tabindex="-1"></a>elephantsGRP <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>age, <span class="at">y=</span>logmate)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-7-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="inferPois" class="section level2" number="8.2">
<h2 number="8.2"><span class="header-section-number">8.2</span> Inference in Poisson Regression</h2>
<p>Recall that in Poisson regression, <span class="math inline">\(E(Y_i) = \mu_i = e^{\beta_0 + \beta_1 X_i}\)</span>. Therefore, the probability function for the <span class="math inline">\(i^{th}\)</span> observation is:</p>
<p><span class="math display">\[f(y_i) = \frac{e^{-\mu_i} \mu_i^{y_i}}{y_i!} = \frac{e^{-e^{\beta_0 + \beta_1 X_i}} \bigg(e^{\beta_0 + \beta_1 X_i}\bigg)^{y_i}}{y_i!}.\]</span>
Which gives the resulting likelihood of:</p>
<p><span class="math display">\[L(\beta_0, \beta_1) = \prod_{i=1}^n f(y_i) = \prod_{i=1}^n \frac{e^{-\mu_i} \mu_i^{y_i}}{y_i!} = \prod_{i=1}^n \frac{e^{-e^{\beta_0 + \beta_1 X_i}} \bigg(e^{\beta_0 + \beta_1 X_i}\bigg)^{y_i}}{y_i!}.\]</span></p>
<p>And the log likelihood becomes:</p>
<p><span class="math display">\[\begin{eqnarray*}
l(\beta_0, \beta_1) &amp;=&amp; \ln L(\beta_0, \beta_1) = \sum_{i=1}^n \bigg(-\mu_i + y_i \ln(\mu_i) - \ln(y_i!) \bigg) \\
&amp;=&amp; \sum_{i=1}^n \bigg(-e^{\beta_0 + \beta_1 X_i} + y_i (\beta_0 + \beta_1 X_i) - \ln(y_i!) \bigg).
\end{eqnarray*}\]</span></p>
<div id="maximum-likelihood" class="section level3" number="8.2.1">
<h3 number="8.2.1"><span class="header-section-number">8.2.1</span> Maximum Likelihood</h3>
<p>As with other probabilistic models we’ve encountered, the joint likelihood of the entire sample represents the product of the individual likelihoods for each data value. The likelihood (or more typically, the <span class="math inline">\(\ln\)</span>-likelihood) is maximized to find estimates for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p>
<p>The parameter estimates maximize the <span class="math inline">\(\ln\)</span>-likelihood, and the SE of the estimates are given by the Fisher Information from the likelihood (roughly the second derivative).</p>
<p>Given <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> as estimates of the parameter values, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, we can estimate the average count value:</p>
<p><span class="math display">\[\hat{\mu}_i = e^{b_0 + b_1 X_i}\]</span></p>
<div id="residuals" class="section level4" number="8.2.1.1">
<h4 number="8.2.1.1"><span class="header-section-number">8.2.1.1</span> Residuals</h4>
<p>Note that we <em>expect</em> the residuals of a Poisson model to have larger variability for larger values of the prediction. That makes interpreting the residuals slightly different that previously for a linear regression model.</p>
<p>Pearson residual:</p>
<p><span class="math display">\[res_{pi} = \frac{y_i - \hat{\mu}_i}{\hat{\mu}_i}\]</span></p>
<p>Deviance residual:</p>
<p><span class="math display">\[\begin{eqnarray*}
res_{di} &amp;=&amp; [-\hat{\mu}_i + y_i \ln(\hat{\mu}_i) - \ln(y_i!) ] - [-y_i + y_i \ln(y_i) - \ln(y_i!) ] \\
&amp;=&amp; y_i-\hat{\mu}_i + y_i \ln\bigg(\frac{\hat{\mu}_i}{y_i}\bigg)
\end{eqnarray*}\]</span></p>
<p>Along with giving information about individual residual values, the sum of the Deviance residuals is also a way to test for goodness-of-fit of the model. Given the null hypothesis that the Poisson is the appropriate model, the test of goodness-of-fit for the Poisson model is given by:</p>
<p><span class="math display">\[\sum_{i=1}^n res_{di} \stackrel{H_0}{\sim} \chi_{n-p}^2.\]</span></p>
</div>
<div id="overdis" class="section level4" number="8.2.1.2">
<h4 number="8.2.1.2"><span class="header-section-number">8.2.1.2</span> Dealing with Overdispersion</h4>
<p>A probability structure that is given by a variance which is larger than the mean, may end up with:</p>
<p><span class="math display">\[\begin{eqnarray*}
E(Y_i) &amp;=&amp; \mu_i\\
Var(Y_i) &amp;=&amp; \phi \mu_i\\
\end{eqnarray*}\]</span></p>
<p>If we can estimate <span class="math inline">\(\phi\)</span>, then a more appropriate SE to use is adjusted by <span class="math inline">\(\phi\)</span>: <span class="math inline">\(SE_Q(\hat{\beta}) = \sqrt{\phi} SE(\hat{\beta})\)</span>. (<span class="math inline">\(Q\)</span> stands for “quasiPoisson.”)</p>
<p>When <span class="math inline">\(Y\)</span> comes from a setting where the sample size is large, then we can use normal (sums of standard normal random variables are distributed according to a <span class="math inline">\(\chi^2\)</span> distribution) theory to assess the residuals:</p>
<p><span class="math display">\[\sum_{i=1}^n res_{pi}^2 = \sum_{i=1}^n \frac{(Y_i - \mu_i)^2}{Var(Y_i)} = \sum_{i=1}^n \frac{(Y_i - \mu_i)^2}{\phi \mu_i} \sim \chi^2_{n-p}\]</span></p>
<p>The expected value of <span class="math inline">\(\chi^2_{n-p}\)</span> is <span class="math inline">\(n-p\)</span>, which gives an estimator of <span class="math inline">\(\phi\)</span> to be:</p>
<p><span class="math display">\[\hat{\phi} =  \sum_{i=1}^n \frac{(Y_i - \mu_i)^2}{\mu_i} /(n-p).\]</span></p>
<p>Note that your text uses the Deviance residual instead of the Pearson residual to estimate <span class="math inline">\(\phi\)</span>. Both are reasonable things to do.</p>
</div>
</div>
<div id="wald-tests" class="section level3" number="8.2.2">
<h3 number="8.2.2"><span class="header-section-number">8.2.2</span> Wald Tests</h3>
<p>As before, Wald tests are given by standardizing the coefficients and finding p-values using normal theory:</p>
<p><span class="math display">\[\frac{b_i - 0}{SE(b_i)} \stackrel{H_0}{\sim} N(0,1).\]</span></p>
<p>If overdispersion is expected, then the SE is adjusted and the t-distribution is used for calculating p-values:</p>
<p><span class="math display">\[\frac{b_i - 0}{SE_Q(b_i)} =  \frac{b_i - 0}{\sqrt{\hat{\phi}} SE(b_i)} \stackrel{H_0}{\sim} t_{n-p}.\]</span></p>
</div>
<div id="drop-in-deviance-tests" class="section level3" number="8.2.3">
<h3 number="8.2.3"><span class="header-section-number">8.2.3</span> Drop-in-Deviance Tests</h3>
<p>The deviance for a Poisson is reasonably straightforward and comes directly from the likelihood, it is twice the sum of the deviance residuals:</p>
<p><span class="math display">\[D = 2 \sum_{i=1}^n [Y_i \ln(Y_i / \hat{\mu_i}) - (Y_i - \hat{\mu_i})].\]</span></p>
<p>For two nested models (that is, the smaller one is obtained by forcing some of the coefficients in the larger model to be zero), a drop-in-deviance test can be calculated using:</p>
<p><span class="math display">\[D_{reduced} - D_{full} \stackrel{H_0}{\sim} \chi^2_{d}\]</span></p>
<p>where <span class="math inline">\(d\)</span> is the difference in the number of parameters estimated in the two models.</p>
<p>The drop-in-deviance test can also be adjusted for overdispersion: <span class="math inline">\(F_Q = (D_{reduced} - D_{full}) / \hat{\phi} \sim F_{d, n-p}\)</span> where <span class="math inline">\(d\)</span> is the difference in the number of parameters estimated in the two models, and <span class="math inline">\(p\)</span> is the total number of parameters estimated in the full model.</p>
</div>
</div>
<div id="r-poisson-example" class="section level2" number="8.3">
<h2 number="8.3"><span class="header-section-number">8.3</span> R Poisson Example</h2>
<p>The R example is taken from data given in the textbook. The scientific question relates to predicting the total number of observed <code>species</code> on the Galapagos archipelago related to island <code>area</code> (km<span class="math inline">\(^2\)</span>), <code>elevation</code> (m), distance (km) to the <code>nearest</code> neighbor and to the largest island (km<span class="math inline">\(^2\)</span>) in the archipelago Santa Cruz (<code>scruz</code>), and the area of the <code>adjacent</code> island (km<span class="math inline">\(^2\)</span>). We could also consider an additional response variable which is the island <code>endemic</code> species count.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>galap <span class="ot">&lt;-</span> readr<span class="sc">::</span><span class="fu">read_csv</span>(<span class="st">&quot;Galapagos.csv&quot;</span>)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(galap)</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 x 8</span></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   island      species endemics  area elevation nearest scruz adjacent</span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 Baltra           58       23 25.1        346     0.6   0.6     1.84</span></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 Bartolome        31       21  1.24       109     0.6  26.3   572.  </span></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 Caldwell          3        3  0.21       114     2.8  58.7     0.78</span></span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 Champion         25        9  0.1         46     1.9  47.4     0.18</span></span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 Coamano           2        1  0.05        77     1.9   1.9   904.  </span></span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 DaphneMajor      18       11  0.34       119     8     8       1.84</span></span></code></pre></div>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(galap, <span class="fu">aes</span>(<span class="at">y=</span>species, <span class="at">x =</span> <span class="fu">log</span>(area), <span class="at">color =</span> adjacent)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-9-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div id="glm" class="section level3" number="8.3.1">
<h3 number="8.3.1"><span class="header-section-number">8.3.1</span> glm</h3>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> <span class="fu">log</span>(elevation) <span class="sc">+</span> nearest <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;poisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 x 5</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term            estimate std.error statistic  p.value</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)     3.02     0.303         9.96  2.28e-23</span></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 log(area)       0.315    0.0185       17.1   2.20e-65</span></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 log(elevation)  0.0977   0.0604        1.62  1.06e- 1</span></span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 nearest        -0.00106  0.00169      -0.626 5.32e- 1</span></span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 scruz          -0.00314  0.000597     -5.26  1.40e- 7</span></span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 adjacent       -0.000243 0.0000281    -8.65  5.31e-18</span></span></code></pre></div>
</div>
<div id="drop-in-deviance" class="section level3" number="8.3.2">
<h3 number="8.3.2"><span class="header-section-number">8.3.2</span> drop in deviance</h3>
<p>It seems like we might not need either <code>log(elevation)</code> or <code>nearest</code>. A drop in deviance test will help:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> <span class="fu">log</span>(elevation) <span class="sc">+</span> nearest <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;poisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 8</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;</span></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1         3511.      29  -294.  600.  609.     427.          24    30</span></span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;poisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">glance</span>()</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 1 x 8</span></span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs</span></span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           &lt;dbl&gt;   &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt; &lt;int&gt;</span></span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1         3511.      29  -296.  600.  606.     431.          26    30</span></span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a><span class="fl">431.11</span> <span class="sc">-</span> <span class="fl">427.48</span></span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 3.63</span></span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pchisq</span>(<span class="fl">3.63</span>, <span class="dv">2</span>)</span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.163</span></span></code></pre></div>
<p>The relatively large p-value suggests that we do not need either of the variables <code>log(elevation)</code> or <code>nearest</code></p>
</div>
<div id="residuals-1" class="section level3" number="8.3.3">
<h3 number="8.3.3"><span class="header-section-number">8.3.3</span> residuals</h3>
<p>Keep in mind that the expectation of a Poisson model is that the residuals will be more variable for larger predicted values. The <code>broom</code> package provides <code>.resid</code>uals which are the observed value minus the fitted value. I <em>think</em> that <code>.std.resid</code> is the Pearson residual.</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;poisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">augment</span>() <span class="sc">%&gt;%</span> <span class="fu">head</span>()</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 x 10</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   species `log(area)` scruz adjacent .fitted .resid .std.resid   .hat .sigma</span></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;</span></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1      58       3.22    0.6     1.84    4.61 -4.57      -4.83  0.105    4.04</span></span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2      31       0.215  26.3   572.      3.36  0.414      0.427 0.0605   4.15</span></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3       3      -1.56   58.7     0.78    2.76 -3.96      -4.05  0.0417   4.07</span></span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4      25      -2.30   47.4     0.18    2.55  3.01       3.08  0.0413   4.11</span></span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5       2      -3.00    1.9   904.      2.27 -3.01      -3.10  0.0559   4.11</span></span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6      18      -1.08    8       1.84    3.11 -0.953     -0.986 0.0661   4.15</span></span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 1 more variable: .cooksd &lt;dbl&gt;</span></span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;poisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">augment</span>() <span class="sc">%&gt;%</span></span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span>.resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;poisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">augment</span>() <span class="sc">%&gt;%</span></span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span>.std.resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-12-1.png" width="80%" style="display: block; margin: auto;" /><img src="08-PoisReg_files/figure-html/unnamed-chunk-12-2.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="quasipoisson" class="section level3" number="8.3.4">
<h3 number="8.3.4"><span class="header-section-number">8.3.4</span> quasiPoisson</h3>
<p>Note that all of the above analyses can be done using the overdispersed quasiPoisson model.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> <span class="fu">log</span>(elevation) <span class="sc">+</span> nearest <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;quasipoisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 x 5</span></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term            estimate std.error statistic  p.value</span></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)     3.02      1.29         2.34  0.0278  </span></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 log(area)       0.315     0.0786       4.02  0.000507</span></span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 log(elevation)  0.0977    0.257        0.381 0.707   </span></span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 nearest        -0.00106   0.00720     -0.147 0.884   </span></span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 scruz          -0.00314   0.00254     -1.24  0.228   </span></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 adjacent       -0.000243  0.000120    -2.03  0.0532</span></span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;quasipoisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 x 5</span></span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   term         estimate std.error statistic  p.value</span></span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;</span></span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 (Intercept)  3.50      0.203        17.3  8.76e-16</span></span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 log(area)    0.342     0.0304       11.3  1.63e-11</span></span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 scruz       -0.00354   0.00197      -1.80 8.36e- 2</span></span>
<span id="cb67-21"><a href="#cb67-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 adjacent    -0.000221  0.000104     -2.12 4.35e- 2</span></span></code></pre></div>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;quasipoisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">augment</span>() <span class="sc">%&gt;%</span> <span class="fu">head</span>()</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 6 x 10</span></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   species `log(area)` scruz adjacent .fitted .resid .std.resid   .hat .sigma</span></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;</span></span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1      58       3.22    0.6     1.84    4.61 -4.57      -1.18  0.105    4.04</span></span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2      31       0.215  26.3   572.      3.36  0.414      0.104 0.0605   4.15</span></span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3       3      -1.56   58.7     0.78    2.76 -3.96      -0.989 0.0417   4.07</span></span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4      25      -2.30   47.4     0.18    2.55  3.01       0.752 0.0413   4.11</span></span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5       2      -3.00    1.9   904.      2.27 -3.01      -0.758 0.0559   4.11</span></span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6      18      -1.08    8       1.84    3.11 -0.953     -0.241 0.0661   4.15</span></span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 1 more variable: .cooksd &lt;dbl&gt;</span></span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;quasipoisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">augment</span>() <span class="sc">%&gt;%</span></span>
<span id="cb68-16"><a href="#cb68-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span>.resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span>
<span id="cb68-17"><a href="#cb68-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-18"><a href="#cb68-18" aria-hidden="true" tabindex="-1"></a><span class="fu">glm</span>(species <span class="sc">~</span> <span class="fu">log</span>(area) <span class="sc">+</span> scruz <span class="sc">+</span> adjacent, </span>
<span id="cb68-19"><a href="#cb68-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">data=</span> galap, <span class="at">family=</span><span class="st">&quot;quasipoisson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">augment</span>() <span class="sc">%&gt;%</span></span>
<span id="cb68-20"><a href="#cb68-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span>.std.resid)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="08-PoisReg_files/figure-html/unnamed-chunk-14-1.png" width="80%" style="display: block; margin: auto;" /><img src="08-PoisReg_files/figure-html/unnamed-chunk-14-2.png" width="80%" style="display: block; margin: auto;" /></p>
<!--chapter:end:08-PoisReg.Rmd-->
</div>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<!--chapter:end:09-references.Rmd-->
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-agresti" class="csl-entry">
Agresti, A. 1996. <em>An Introduction to Categorical Data Analysis</em>. John Wiley; Sons, New York.
</div>
<div id="ref-Andersen" class="csl-entry">
Andersen, Per K., Ornulf Borgan, Richard D. Gill, and Niels Keiding. 1996. <em>Statistical Models Based on Counting Processes</em>. Springer Series in Statistics.
</div>
<div id="ref-AndHerz" class="csl-entry">
Andrews, D. F., and A. M. Herzberg. 1985. <em>Data</em>. Springer-Verlag.
</div>
<div id="ref-timevar" class="csl-entry">
Bellera, Carine A, Gaetan MacGrogan, Marc Debled, Christine Tunon de Lara, Veronique Brouste, and Simone Mathoulin-Pelissier. 2010. <span>“Variables with Time-Varying Effects and the Cox Model: Some Statistical Concepts Illustrated with a Prognostic Factor Study in Breast Cancer.”</span> <em>BMC Medical Research Methodology</em> 10: 20. <a href="https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-10-20">https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-10-20</a>.
</div>
<div id="ref-iscam" class="csl-entry">
Chance, Beth, and Allan Rossman. 2018. <em>Investigating Statistics, Concepts, Applications, and Methods</em>. 3rd ed. <a href="http://www.rossmanchance.com/iscam3/">http://www.rossmanchance.com/iscam3/</a>.
</div>
<div id="ref-Collett" class="csl-entry">
Collett, David. 2015. <em>Modelling Survival Data in Medical Research</em>. Chapman; Hall.
</div>
<div id="ref-Dupont" class="csl-entry">
Dupont, William D. 2009. <em>Statistical Modeling for Biomedical Researchers</em>. Cambridge University Press.
</div>
<div id="ref-hrt" class="csl-entry">
Dyer, Owen. 2004. <span>“Another <span>HRT</span> Trial Is Stopped Early.”</span> <em>British Medical Journal</em>.
</div>
<div id="ref-burn" class="csl-entry">
Fan, J., N. E. Heckman, and M. P. Wand. 1995. <span>“Local Polynomial Kernel Regression for Generalized Linear Models and Quasi-Likelihood Functions.”</span> <em>Journal of the American Statistical Association</em>, 141–50. <a href="http://statmaster.sdu.dk/courses/st111">http://statmaster.sdu.dk/courses/st111</a>.
</div>
<div id="ref-botox" class="csl-entry">
Foster, L., L. Clapp, M. Erickson, and B. Jabbari. 2001. <span>“Botulinum Toxin <span>A</span> and Chronic Low Back Pain: A Randomized, Double-Blind Study.”</span> <em>Neurology</em> 56: 1290–93.
</div>
<div id="ref-gerds" class="csl-entry">
Gerds, Thomas. 2016. <span>“The <span>K</span>aplan-<span>M</span>eier Theater.”</span> <em>Teaching Statistics</em> 38: 45–49.
</div>
<div id="ref-crowley" class="csl-entry">
Green, S, J Benedetti, and J Crowley. 1997. <em>Clinical Trials in Oncology</em>.
</div>
<div id="ref-SurvHL" class="csl-entry">
Hosmer, David W., Stanley Lemeshow, and Susanne May. 2008. <em>Applied Survival Analysis: Regression Modeling of Time-to-Event Data</em>. Wiley-Interscience.
</div>
<div id="ref-HERS" class="csl-entry">
Hulley, S., D. Grady, T. Bush, C. Furberg, D. Herrington, B. Riggs, and E. Vittinghoff. 1998. <span>“Randomized Trial of Estrogen Plus Progestin for Secondary Prevention of Coronary Heart Disease in Postmenopausal Women.”</span> <em>Journal of the American Medical Association</em> 280: 605–13.
</div>
<div id="ref-Ioannidis" class="csl-entry">
Ioannidis, John. 2005. <span>“Why Most Published Research Findings Are False.”</span> <em>PLoS Medicine</em> 2: e124.
</div>
<div id="ref-KuiperSklar" class="csl-entry">
Kuiper, Shonda, and Jeff Sklar. 2013. <em>Practicing Statistics</em>. Pearson. <a href="http://web.grinnell.edu/individuals/kuipers/stat2labs/">http://web.grinnell.edu/individuals/kuipers/stat2labs/</a>.
</div>
<div id="ref-kutner" class="csl-entry">
Kutner, Nachtsheim, Neter, and Li. 2004. <em>Applied Linear Statistical Models</em>. 5th ed. McGraw-Hill.
</div>
<div id="ref-angwin" class="csl-entry">
Larson, Jeff, Surya Mattu, Lauren Kirchner, and Julia Angwin. {May 23, 2016}. <span>“Machine Bias.”</span> <em>ProPublica</em>, {May 23, 2016}. <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing</a>.
</div>
<div id="ref-bysh" class="csl-entry">
Legler, Julie, and Paul Roback. 2019. <em>Broadening Your Statistical Horizons: Generalized Linear Models and Multilevel Models</em>.
</div>
<div id="ref-Lock5" class="csl-entry">
Lock, R., P. F. Lock, K. Lock Morgan, E. Lock, and D. Lock. 2016. <em>Unlocking the Power of Data</em>. Wiley. <a href="http://www.lock5stat.com/StatKey/">http://www.lock5stat.com/StatKey/</a>.
</div>
<div id="ref-framingham" class="csl-entry">
Mahmood, Syed S, Daniel Levy, Ramachandran S Vasan, and Thomas J Wang. 2014. <span>“The Framingham Heart Study and the Epidemiology of Cardiovascular Disease: A Historical Perspective.”</span> <em>Lancet</em> 383: 999–1008. <a href="https://doi.org/10.1016/S0140-6736(13)61752-3">https://doi.org/10.1016/S0140-6736(13)61752-3</a>.
</div>
<div id="ref-menard" class="csl-entry">
Menard, S. 1995. <em>Applied Logistic Regression Analysis</em>. 2nd ed. Sage.
</div>
<div id="ref-bloodtype" class="csl-entry">
Mourant, A. E., A.c. Kopec, and K. Domaniewsa-Sobczak. 1976. <em>The Distribution of the Human Blood Groups and Other Polymorphisms</em>. Oxford University Press.
</div>
<div id="ref-duncanTL" class="csl-entry">
<em>National Research Council: Training Students to Extract Value from Big Data</em>. 2014. Washington, D.C.: The National Academies Press.
</div>
<div id="ref-snoring" class="csl-entry">
Norton, P. G., and E. V. Dunn. 1985. <span>“Snoring as a Risk Factor for Disease: An Epidemiological Survey”</span> 291: 630–32.
</div>
<div id="ref-pagano" class="csl-entry">
Pagano, M., and K. Gauvreau. 2000. <em>Principles of Biostatistics</em>. 2nd ed. Duxbury Press.
</div>
<div id="ref-poole" class="csl-entry">
Poole, J. H. 1989. <span>“Mate Guarding, Reproductive Success and Female Choice in African Elephants.”</span> <em>Animal Behavior</em>, 842–49.
</div>
<div id="ref-sleuth" class="csl-entry">
Ramsey, F., and D. Schafer. 2012. <em>The Statistical Sleuth</em>. 3rd ed. Cengage Learning.
</div>
<div id="ref-modepi" class="csl-entry">
Rothman, K., and S. Greenland. 1998. <em>Modern Epidemiology</em>. 2nd ed. LWW.
</div>
<div id="ref-subgroup" class="csl-entry">
Schulz, K, and D Grimes. 2005. <span>“Multiplicity in Randomized Trials II: Subgroup and Interim Analyses.”</span> <em>Lancet</em> 365: 1657–61.
</div>
<div id="ref-hiv" class="csl-entry">
Scott M. Hammer et al. 1997. <span>“A Controlled Trial of Two Nucleoside Analogues Plus Indinavir in Persons with Human Immunodeficiency Virus Infection and Cd4 Cell Counts of 200 Per Cubic Millimeter or Less.”</span> <em>New England Journal of Medicine</em> 337: 725–33.
</div>
<div id="ref-Sessler2011" class="csl-entry">
Sessler, D., A. Kurz, L. Saager, and J Dalton. 2011. <span>“Operation Timing and 30-Day Mortality After Elective General Surgery.”</span> <em>Anesthesia &amp; Analgesia</em> 113: 1423–28.
</div>
<div id="ref-KMmean" class="csl-entry">
StatsDirect Limited. 2016. <em>Kaplan-Meier Survival Estimates</em>. <a href="https://www.statsdirect.com/help/survival_analysis/kaplan.htm">https://www.statsdirect.com/help/survival_analysis/kaplan.htm</a>.
</div>
<div id="ref-Vanderpump95" class="csl-entry">
Vanderpump, M. P. J., W. M. G. Tunbridge, J. M. French, D. R. Appleton, D. Bates, F. Clark, J. Grimley Evans, et al. 1995. <span>“The Incidence of Thyroid Disorders in the Community: A Twenty-Year Follow-up of the Whickham Survey.”</span> <em>Clinical Endocrinology</em> 43: 55–69.
</div>
<div id="ref-vittinghoff" class="csl-entry">
Vittinghoff, Eric, David V. Glidden, Stephen C. Shiboski, and Charles E. McCulloch. 2012. <em>Regression Methods in Biostatistics</em>. Springer-Verlag.
</div>
<div id="ref-scagnostics" class="csl-entry">
Wilkinson, L., and G. Wills. 2007. <span>“Scagnostics Distributions.”</span> <em>Journal of Computational and Graphical Statistics</em> 17: 473–91.
</div>
<div id="ref-wynder" class="csl-entry">
Wynder, E., and E. Graham. 1950. <span>“Tobacco Smoking as a Possible Etiologic Factor in Bronchiogenic Carcinoma.”</span> <em>The Journal of the American Medical Association</em> 143: 329–36.
</div>
<div id="ref-hvtn" class="csl-entry">
Yunda Huang et al. 2015. <span>“Effect of <span class="nocase">rAd5-Vector</span> <span>HIV-1</span> Preventive Vaccines on <span>HIV-1</span> Acquisition: A Participant-Level Meta-Analysis of Randomized Trials”</span> 10: e0136626.
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Sage &amp; Bruno<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Beta &amp; Luna<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<!--bookdown:body:end-->
  </main>

  <div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page">
      <h2>On this page</h2>
      <div id="book-on-this-page"></div>

      <div class="book-extra">
        <ul class="list-unstyled">
          <li><a id="book-source" href="#">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="#">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
      </div>
    </nav>
  </div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5">
  <div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Methods in Biostatistics</strong>" was written by Jo Hardin. It was last built on 2021-04-12.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
