<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 6 Interval Estimates | Statistical Theory</title>
<meta name="author" content="Jo Hardin">
<meta name="description" content="Up until now, we’ve used \(\hat{\theta}\) to estimate \(\theta\). But a single numerical value gives us no information about the degree of uncertainty of the estimate. A confidence interval is a...">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content="Chapter 6 Interval Estimates | Statistical Theory">
<meta property="og:type" content="book">
<meta property="og:description" content="Up until now, we’ve used \(\hat{\theta}\) to estimate \(\theta\). But a single numerical value gives us no information about the degree of uncertainty of the estimate. A confidence interval is a...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 6 Interval Estimates | Statistical Theory">
<meta name="twitter:description" content="Up until now, we’ve used \(\hat{\theta}\) to estimate \(\theta\). But a single numerical value gives us no information about the degree of uncertainty of the estimate. A confidence interval is a...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script type="text/x-mathjax-config">
    const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
    for (let popover of popovers){
      const div = document.createElement('div');
      div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
      div.innerHTML = popover.getAttribute('data-content');
      
      // Will this work with TeX on its own line?
      var has_math = div.querySelector("span.math");
      if (has_math) {
        document.body.appendChild(div);
      	MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
      	MathJax.Hub.Queue(function(){
          popover.setAttribute('data-content', div.innerHTML);
      	})
      }
    }
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Statistical Theory</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Class Information</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="bayes.html"><span class="header-section-number">2</span> Bayesian Estimation</a></li>
<li><a class="" href="MLE.html"><span class="header-section-number">3</span> Maximum Likelihood Estimation</a></li>
<li><a class="" href="sampdist.html"><span class="header-section-number">4</span> Sampling Distributions of Estimators</a></li>
<li><a class="" href="bootdist.html"><span class="header-section-number">5</span> Bootstrap Distributions</a></li>
<li><a class="active" href="intest.html"><span class="header-section-number">6</span> Interval Estimates</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/hardin47/website">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="intest" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Interval Estimates<a class="anchor" aria-label="anchor" href="#intest"><i class="fas fa-link"></i></a>
</h1>
<p>Up until now, we’ve used <span class="math inline">\(\hat{\theta}\)</span> to estimate <span class="math inline">\(\theta\)</span>. But a single numerical value gives us no information about the degree of uncertainty of the estimate. A confidence interval is a set of values, (A,B), that we think is likely to contain <span class="math inline">\(\theta\)</span> (the true parameter). The length of the interval gives us an idea of how closely we are able to estimate <span class="math inline">\(\theta\)</span>.</p>
<div id="frequentist-confidence-intervals" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Frequentist Confidence Intervals<a class="anchor" aria-label="anchor" href="#frequentist-confidence-intervals"><i class="fas fa-link"></i></a>
</h2>
<p>A frequentist confidence interval (CI) is created in such a way that the interval itself contains the parameter some specified percentage of the time.</p>
<div id="ci-for-the-mean-mu-in-a-normal-random-sample" class="section level3" number="6.1.1">
<h3>
<span class="header-section-number">6.1.1</span> CI for the mean, <span class="math inline">\(\mu\)</span> in a normal random sample<a class="anchor" aria-label="anchor" href="#ci-for-the-mean-mu-in-a-normal-random-sample"><i class="fas fa-link"></i></a>
</h3>
<p>We know,
<span class="math display">\[\begin{eqnarray*}
\frac{\overline{X} - \mu}{s / \sqrt{n}} \sim t_{n-1}
\end{eqnarray*}\]</span></p>
<p>n.b., Your text uses <span class="math inline">\(\sigma' = s = \sqrt{\frac{\sum_{i=1}{n}(X_i - \overline{X})^2}{n-1}}.\)</span> So whenever you see <span class="math inline">\(\sigma'\)</span>, think <span class="math inline">\(s.\)</span></p>
<p>Let <span class="math inline">\(c\)</span> be some constant such that <span class="math inline">\(\int_{-c}^c f_{t_{n-1}}(x) dx = \gamma\)</span> (e.g., = 0.95). Or:</p>
<p><span class="math display">\[\begin{eqnarray*}
P(-c \leq \frac{\overline{X} - \mu}{s/\sqrt{n}} \leq c) &amp;=&amp; 0.95\\
P( \overline{X} - c s/\sqrt{n} \leq \mu \leq \overline{X} + c s/\sqrt{n} ) &amp;=&amp; 0.95\\
\end{eqnarray*}\]</span></p>
<p>What is random here? <span class="math inline">\(\overline{X}\)</span> and <span class="math inline">\(s\)</span> are both random! The probability of getting <span class="math inline">\((\overline{X}\)</span>,<span class="math inline">\(s)\)</span> such that <span class="math inline">\(\overline{X} - c s/\sqrt{n} \leq \mu \leq \overline{X} + c s/\sqrt{n}\)</span> is 0.95. What is <span class="math inline">\(c?\)</span></p>
<p>As frequentists, we don’t interpret the interval as “the probability that <span class="math inline">\(\theta\)</span> is in the interval”
<span class="math display">\[\begin{eqnarray*}
X_1, X_2, \ldots, X_n &amp;\rightarrow&amp; \mbox{random}\\
\theta &amp;\rightarrow&amp; \mbox{fixed}\\
\end{eqnarray*}\]</span></p>
<blockquote>
<p>We are 95% confident that <span class="math inline">\(\mu\)</span> is between <span class="math inline">\(\overline{X} - c s/\sqrt{n}\)</span> and <span class="math inline">\(\overline{X} + c s/\sqrt{n}\)</span></p>
</blockquote>
<p>Bayesians interpret intervals as “the probability that <span class="math inline">\(\theta\)</span> is in the interval” because Bayesians treat <span class="math inline">\(\theta\)</span> as a random variable (we would need a prior, etc…) [See the next section on Bayesian Intervals.]</p>
<div class="example">
<p><span id="exm:unlabeled-div-29" class="example"><strong>Example 6.1  </strong></span>A sample of 25 statistics students reported that they spend an average of 110 minutes per week studying statistics, with a standard deviation of 40 minutes. Find a one-sided CI such that we are 98% confident that we know the <em>lower</em> bound of the true average studying time in the population. Let’s assume that the data are reasonably independent and normally distributed.</p>
<p>We need an interval <span class="math inline">\([ A,\infty)\)</span>, such that with 98% confidence, <span class="math inline">\(\mu\)</span> is in the interval. We know:
<span class="math display">\[\begin{eqnarray*}
P(-c_1 \leq \frac{\overline{X} - \mu}{s/\sqrt{n}} \leq c_2) &amp;=&amp; 0.98\\
P( \overline{X} - c_2 s/\sqrt{n} \leq \mu \leq \overline{X} + c_1 s/\sqrt{n} ) &amp;=&amp; 0.98\\
P(-\infty \leq \frac{\overline{X} - \mu}{s/\sqrt{n}} \leq c_2) &amp;=&amp; 0.98\\
\\
\frac{\overline{X} - \mu}{s/\sqrt{n}} &amp;\sim&amp; t_{24} \rightarrow c_2 = 2.172\\
P( \overline{X} - 2.172 s/\sqrt{n} \leq \mu (\leq \infty) ) &amp;=&amp; 0.98\\
( \overline{X} - 2.172 s/\sqrt{n},\infty ) &amp;&amp; \mbox{is a 98% CI}\\
\end{eqnarray*}\]</span>
We are 98% confident that the true average studying time (in the population) is at least 92.62 minutes. Why can’t we plug in the numbers above and keep it as a probability?</p>
<p>2-sided interval: <span class="math inline">\(c=2.492=c_1=c_2\)</span>
<span class="math display">\[\begin{eqnarray*}
( \overline{X} - 2.492 s/\sqrt{n},\overline{X} + 2.492 s/\sqrt{n} ) &amp;&amp; \mbox{is a 98% CI}\\
(90.06 \mbox{ min}, 129.94 \mbox{ min}) &amp;&amp;\\
\end{eqnarray*}\]</span></p>
<p>We are 98% confident that the average number of minutes per week spent studying in the population is between 90.06 min and 129.94 min.</p>
</div>
</div>
</div>
<div id="bayesian-intervals" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> Bayesian Intervals<a class="anchor" aria-label="anchor" href="#bayesian-intervals"><i class="fas fa-link"></i></a>
</h2>
<p>Note: your book calls Bayesian intervals “posterior intervals”, so we will stick to that language. However, most people in the Bayesian literature call them <a href="https://en.wikipedia.org/wiki/Credible_interval" target="_blank">“credible intervals”</a>.</p>
<p>We’d like to say “the probability that <span class="math inline">\(\theta\)</span> is in the interval is…” As a Bayesian we can do that because Bayesians think about <span class="math inline">\(\theta\)</span> as random, and they put a distribution on <span class="math inline">\(\theta | \underline{x}\)</span>.</p>
<p>A Bayesian <em>posterior</em> or <em>credible</em> interval is given by the posterior distribution. That is, a (<span class="math inline">\(1-\alpha\)</span>)% posterior interval for <span class="math inline">\(\theta\)</span> is <span class="math display">\[\Xi^{-1}_{\alpha/2} (\theta | \underline{X}), \Xi^{-1}_{1-\alpha/2} (\theta | \underline{X})\]</span>
where <span class="math inline">\(\Xi(\theta | \underline{X})\)</span> is the posterior cumulative distribution function of <span class="math inline">\(\theta\)</span> (but maybe we should use better notation). Do not focus on the <span class="math inline">\(\Xi\)</span> cdf notation. Instead, keep in mind that the inverse cdf defines the tail probabilities associated with the posterior distribution.</p>
<div id="joint-posterior-distribution-for-mu-and-sigma-in-a-normal-distribution" class="section level3" number="6.2.1">
<h3>
<span class="header-section-number">6.2.1</span> Joint Posterior Distribution for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> in a Normal Distribution<a class="anchor" aria-label="anchor" href="#joint-posterior-distribution-for-mu-and-sigma-in-a-normal-distribution"><i class="fas fa-link"></i></a>
</h3>
<p>Remember, we found the posterior distribution of <span class="math inline">\(\mu | \underline{x}\)</span> with <em>known</em> <span class="math inline">\(\sigma\)</span>. But we don’t really ever know <span class="math inline">\(\sigma\)</span>. To find a joint posterior on <span class="math inline">\(\mu, \sigma | \underline{x}\)</span>, we need two priors.</p>
<p>Only to simplify calculations, let <span class="math inline">\(\tau = 1/\sigma^2\)</span>. <span class="math inline">\(\tau\)</span> is called the precision. The joint distribution is calculated using the product of the marginal normal distributions. Note that that the data are assumed to be a random sample (i.e., they are independent and identically distributed according to the same <span class="math inline">\(N(\mu, 1/\tau)\)</span> distribution).</p>
<p><span class="math display">\[\begin{eqnarray*}
f(x | \mu, \tau) &amp;=&amp; \Bigg( \frac{\tau}{2 \pi} \Bigg) ^{1/2} exp \bigg[ \frac{-1}{2} \tau (x-\mu)^2 \bigg]\\
f(\underline{x} | \mu, \tau) &amp;=&amp; \Bigg( \frac{\tau}{2 \pi} \Bigg) ^{n/2} exp \bigg[ \frac{-1}{2} \tau \sum_{i=1}^n (x_i-\mu)^2 \bigg]\\
\end{eqnarray*}\]</span></p>
<div class="theorem">
<p><span id="thm:unlabeled-div-30" class="theorem"><strong>Theorem 6.1  </strong></span>(<span class="citation">DeGroot and Schervish (<a href="references.html#ref-degroot" role="doc-biblioref">2011</a>)</span> Theorem 7.6.1)
Let <span class="math inline">\(X_1, X_2, \ldots X_n \sim N(\mu, 1/\tau)\)</span> and suppose you have <strong>priors</strong> on <span class="math inline">\(\mu|\tau\)</span> and <span class="math inline">\(\tau\)</span>,
<span class="math display">\[\begin{eqnarray*}
\mu|\tau &amp;\sim&amp; N(\mu_0, 1/(\lambda_0 \tau) )\\
\tau &amp;\sim&amp; \mbox{ Gamma} (\alpha_0, \beta_0)
\end{eqnarray*}\]</span></p>
<p>Then, the <strong>posteriors</strong> on <span class="math inline">\(\mu|\tau\)</span> and <span class="math inline">\(\tau\)</span> are,
<span class="math display">\[\begin{eqnarray*}
\mu | \tau, \underline{x} &amp;\sim&amp; N(\mu_1, 1/(\lambda_1 \tau) )\\
\tau \  | \ \underline{x}  &amp;\sim&amp; \mbox{ Gamma} (\alpha_1, \beta_1)
\end{eqnarray*}\]</span>
where  <span class="math inline">\(\mu_1 = \frac{\lambda_0 \mu_0 + n \overline{x}}{\lambda_0 + n}, \ \ \ \ \lambda_1 = \lambda_0 + n, \ \ \ \ \alpha_1 = \alpha_0 + \frac{n}{2}, \ \ \ \ \ \beta_1 = \beta_0 + \frac{1}{2} \sum_{i=1}^n (x_i - \overline{x})^2 + \frac{n \lambda_0 (\overline{x} - \mu_0)^2}{2(\lambda_0 +n)}.\)</span></p>
<p>Note that the prior is a joint conjugate family of distributions. <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span> have a normal-gamma distribution. Note also that <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span> are <strong>not</strong> independent.</p>
</div>
<div class="proof">
<span id="unlabeled-div-31" class="proof"><em>Proof</em>. </span><span class="math display">\[\begin{align}
f(\underline{x} | \mu, \tau) &amp;= \Bigg( \frac{\tau}{2\pi}\Bigg)^{n/2} exp \Bigg[ -\frac{1}{2} \tau \sum_{i=1}^n (x_i - \mu)^2 \Bigg] \nonumber \\
\xi_1(\mu|\tau) &amp;= \Bigg( \frac{\lambda_0 \tau}{2\pi}\Bigg)^{1/2} exp \Bigg[ -\frac{1}{2} \lambda_0 \tau (\mu - \mu_0)^2 \Bigg]  \nonumber \\
\xi_2(\tau) &amp;= \frac{\beta_0^{\alpha_0}}{\Gamma(\alpha_0)} \tau^{\alpha_0 - 1}e^{-\beta_0 \tau} \nonumber \\
\mbox{Note, } &amp; \mu  \mbox{ and $\tau$ are not independent, and } \xi(\mu, \tau) = \xi_1(\mu|\tau) \ \xi_2(\tau) \nonumber \\
\nonumber \\
\xi(\mu,\tau|\underline{x}) &amp;\propto f(\underline{x} | \mu, \tau) \ \xi_1(\mu|\tau) \ \xi_2(\tau) \nonumber \\
&amp;\propto \tau^{\alpha_0 + (n+1)/2 -1} \exp \Bigg[-\frac{\tau}{2} \Bigg(\lambda_0 [\mu-\mu_0]^2 + \sum_{i=1}^{n}(x_i -\mu)^2 \Bigg) - \beta_0 \tau \Bigg] (\#eq:one) \end{align}\]</span>
Add and subtract <span class="math inline">\(\overline{x}\)</span> inside <span class="math inline">\((x_i -\mu)^2\)</span> to get:
<span class="math display" id="eq:two">\[\begin{align}
\sum_{i=1}^n(x_i -\mu)^2 &amp;= \sum_{i=1}^n(x_i - \overline{x})^2 + n(\overline{x} -\mu)^2
\tag{6.1} \end{align}\]</span>
By adding and subtracting <span class="math inline">\(\mu_1\)</span>:
<span class="math display" id="eq:three">\[\begin{align}
n(\overline{x} -\mu)^2 + \lambda_0 (\mu - \mu_0)^2 &amp;= (\lambda_0 + n)(\mu - \mu_1)^2 + \frac{n\lambda_0(\overline{x} - \mu_0)^2}{\lambda_0 + n} \tag{6.2}
\end{align}\]</span>
Combining (@ref{eq:two}) and (@ref{eq:three}) we get:
<span class="math display" id="eq:four">\[\begin{align}
\sum_{i=1}^n(x_i -\mu)^2 + \lambda_0 (\mu - \mu_0)^2 = (\lambda_0 + n)(\mu - \mu_1)^2 + \sum_{i=1}^n(x_i - \overline{x})^2 + \frac{n\lambda_0(\overline{x} - \mu_0)^2}{\lambda_0 + n} \tag{6.3}
\end{align}\]</span>
By plugging (@ref{eq:four}) into (@ref{eq:one}) we get:
<span class="math display">\[\begin{eqnarray}
\xi(\mu, \tau | \underline{x}) &amp;\propto&amp; \Bigg\{ \tau^{1/2} exp \Bigg[ -\frac{1}{2} \lambda_1 \tau (\mu - \mu_1)^2 \Bigg] \Bigg\} (\tau^{\alpha_1 -1} e^{-\beta_1 \tau})\\
\xi(\mu, \tau | \underline{x}) &amp;=&amp; \xi_1(\mu | \tau, \underline{x}) \xi_2(\tau | \underline{x})
\end{eqnarray}\]</span>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-32" class="theorem"><strong>Theorem 6.2  </strong></span>Let <span class="math inline">\(X_1, X_2, \ldots X_n \sim N(\mu, 1/\tau)\)</span> and suppose you have priors on <span class="math inline">\(\mu|\tau\)</span> and <span class="math inline">\(\tau\)</span>,
<span class="math display">\[\begin{eqnarray*}
\mu|\tau &amp;\sim&amp; N(\mu_0, 1/(\lambda_0 \tau) )\\
\tau &amp;\sim&amp; \mbox{ Gamma} (\alpha_0, \beta_0)
\end{eqnarray*}\]</span></p>
<p>Then, the marginal posterior distribution of <span class="math inline">\(\mu\)</span> can be written as:
<span class="math display">\[\begin{eqnarray*}
\bigg(\frac{\lambda_1 \alpha_1}{\beta_1} \bigg)^{1/2} (\mu-\mu_1) \  | \ \underline{x} \sim t_{2\alpha_1}
\end{eqnarray*}\]</span>
where <span class="math inline">\(\mu_1, \lambda_1, \alpha_1,\)</span> and <span class="math inline">\(\beta_1\)</span> are given in the previous theorem.</p>
</div>
<div class="proof">
<span id="unlabeled-div-33" class="proof"><em>Proof</em>. </span>First, let
<span class="math display">\[\begin{eqnarray*}
z &amp;=&amp; (\lambda_1 \tau)^{1/2} (\mu-\mu_1) = u(\mu)\\
\mu &amp;=&amp; z (\lambda_1 \tau)^{-1/2} + \mu_1 = w(z)
\end{eqnarray*}\]</span>
We know (from the previous theorem):
<span class="math display">\[\begin{eqnarray}
\xi(\mu,\tau|\underline{x}) &amp;=&amp; \xi_1(\mu|\tau,\underline{x}) \ \ \xi_2(\tau|\underline{x})\\
\mbox{So, } \xi(z,\tau|\underline{x}) &amp;=&amp; \xi_1(w(z)|\tau,\underline{x})\ \ \Bigg| \frac{\partial w(z)}{\partial z} \Bigg| \ \ \xi_2 (\tau|\underline{x})\\
&amp;=&amp; \xi_1(z(\lambda_1 \tau)^{-1/2} + \mu_1| \tau,\underline{x}) \ \ \big| (\lambda_1 \tau)^{-1/2} \big| \ \ \xi_2 (\tau|\underline{x})\\
&amp;=&amp; \sqrt{\frac{\lambda_1 \tau}{2 \pi}} \exp \Bigg \{ \frac{-(z(\lambda_1 \tau)^{-1/2} + \mu_1 -\mu_1)^2}{2(\lambda_1 \tau)^{-1}} \Bigg\} \ \ (\lambda_1 \tau)^{-1/2} \ \ \xi_2(\tau|\underline{x})\\
&amp;=&amp; \sqrt{\frac{1}{2\pi}} \exp(-z^2/2) \ \ \xi_2(\tau|\underline{x})\\
&amp;=&amp; \Phi(z|\underline{x}) \ \ \xi_2(\tau|\underline{x})\\
\end{eqnarray}\]</span>
Which gives us:
<span class="math display">\[\begin{eqnarray*}
Z|\underline{x} &amp;\sim&amp; N(0,1) \ \ \ \ \tau| \underline{x} \sim \mbox{Gamma}(\alpha_1,\beta_1) \ \ \mbox{  (Independent!)}\\
\mbox{Let } Y &amp;=&amp; 2\beta_1\tau \rightarrow Y|\underline{x} \sim \mbox{Gamma}(\alpha_1, 1/2) \equiv \chi^2_{2\alpha_1}
\end{eqnarray*}\]</span>
So, creating a t random variable:
<span class="math display">\[\begin{eqnarray}
U = \frac{Z}{\sqrt{Y/2\alpha_1}} = \frac{(\lambda_1 \tau)^{1/2} (\mu-\mu_1)}{\sqrt{2\beta_1\tau/2\alpha_1}} = \Bigg(\frac{\lambda_1 \alpha_1}{\beta_1} \Bigg)^{1/2}(\mu-\mu_1)
\end{eqnarray}\]</span>
Which gives:
<span class="math display">\[\begin{eqnarray}
\Bigg(\frac{\lambda_1 \alpha_1}{\beta_1} \Bigg)^{1/2}(\mu-\mu_1) \  | \ \underline{x}  \sim t_{2\alpha_1}
\end{eqnarray}\]</span>
</div>
<p>Note: <span class="math inline">\(E[ U | \underline{x} ] = 0\)</span> and <span class="math inline">\(Var(U | \underline{x}) = \frac{2 \alpha_1}{2 \alpha_1 - 2} = \frac{ \alpha_1}{\alpha_1 -1}\)</span>\
<span class="math inline">\(\rightarrow E[\mu| \underline{x}] = \mu_1\)</span> and <span class="math inline">\(Var(\mu | \underline{x}) = \frac{\beta_1}{\lambda_1 \alpha_1} \frac{\alpha_1}{\alpha_1 -1} = \frac{\beta_1}{\lambda_1(\alpha_1 -1)}\)</span></p>
</div>
<div id="posterior-interval-for-the-mean-mu-in-a-normal-random-sample" class="section level3" number="6.2.2">
<h3>
<span class="header-section-number">6.2.2</span> Posterior Interval for the mean, <span class="math inline">\(\mu\)</span> in a normal random sample<a class="anchor" aria-label="anchor" href="#posterior-interval-for-the-mean-mu-in-a-normal-random-sample"><i class="fas fa-link"></i></a>
</h3>
<p>Just like with frequentist CI:
<span class="math display">\[\begin{eqnarray*}
P( -c \leq U \leq c \  | \ \underline{x} ) &amp;=&amp; 1 - \alpha\\
P( -c \leq \Bigg( \frac{\lambda_1 \alpha_1}{\beta_1} \Bigg)^{1/2} (\mu - \mu_1) \leq c \  | \ \underline{x} ) &amp;=&amp; 1 - \alpha\\
P( \mu_1 - c \Bigg(\frac{\beta_1}{\lambda_1 \alpha_1} \Bigg)^{1/2} \leq \mu \leq \mu_1 + c \Bigg(\frac{\beta_1}{\lambda_1 \alpha_1} \Bigg)^{1/2} \  | \ \underline{x} ) &amp;=&amp; 1 - \alpha\\
\end{eqnarray*}\]</span></p>
<p><span class="math inline">\(\Rightarrow\)</span>    <span class="math inline">\(\mu_1 \pm c \Bigg(\frac{\beta_1}{\lambda_1 \alpha_1} \Bigg)^{1/2}\)</span> is a <span class="math inline">\((1 - \alpha)100\%\)</span> posterior interval for <span class="math inline">\(\mu\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-34" class="example"><strong>Example 6.2  </strong></span>Let’s say we are trying to estimate the total number of soft drinks a particular vending machine will sell in a typical week. We want to find a 90% posterior interval for <span class="math inline">\(\mu\)</span>. Our prior information (e.g., from past weeks) tells us:
<span class="math display">\[\begin{eqnarray*}
\mu | \tau &amp;\sim&amp; N(750, 5 / \tau = \frac{1}{(1/5)\tau} )\\
\tau &amp;\sim&amp; gamma(1, 45)
\end{eqnarray*}\]</span>
<span class="math inline">\(\mu_0 = 750\)</span>, <span class="math inline">\(\lambda_0 = 1/5\)</span>, <span class="math inline">\(\alpha_0 = 1\)</span>, <span class="math inline">\(\beta_0=45\)</span>\
Our random sample of 10 weeks gives <span class="math inline">\(\overline{x} = 692\)</span> and <span class="math inline">\(s^2 = \frac{14400}{9} = 1600\)</span>.\
Our posterior parameters are:
<span class="math display">\[\begin{eqnarray*}
\mu_1 &amp;=&amp; \frac{\lambda_0 \mu_0 + n \overline{x}}{\lambda_0 + n} = \frac{(1/5)750 + 6920}{(1/5) + 10} = 693.14\\
\lambda_1 &amp;=&amp; \lambda_0 + n = 10.2\\
\alpha_1 &amp;=&amp; \alpha_0 + n/2 = 1+ 5 =6\\
\beta_1 &amp;=&amp; \beta_0 + \frac{1}{2} \sum_{i=1}^n (x_i - \overline{x})^2 + \frac{n \lambda_0 (\overline{x} - \mu_0)^2}{2(\lambda_0 +n)} = 45 + 14400/2 + \frac{10(1/5) (692-750)^2}{2(1/5 +10)} = 7574.8
\end{eqnarray*}\]</span></p>
<p>To find a 90% PI, find cutoff values such that <span class="math inline">\(P(-c \leq t_{2\alpha_1} \leq c) = 0.9\)</span>. <span class="math inline">\(2 \alpha_1 =12\)</span>, <span class="math inline">\(P(t_{12} \leq 1.782) = 0.95\)</span>.
<span class="math display">\[\begin{eqnarray*}
P(-1.782 \leq U \leq 1.782  \  | \ \underline{x} ) &amp;=&amp; 0.9\\
P(\mu_1 - 1.782 (\frac{\beta_1}{\lambda_1 \alpha_1})^{1/2} \leq \mu \leq \mu_1 + 1.782 (\frac{\beta_1}{\lambda_1 \alpha_1})^{1/2} \  | \ \underline{x} ) &amp;=&amp; 0.9\\
P(673.31 \leq \mu \leq 712.97 \  | \ \underline{x} ) &amp;=&amp; 0.9
\end{eqnarray*}\]</span></p>
<p>Given our prior beliefs and data, there is a 90% probability that the average number of cans sold per week is between 673.31 and 712.97 cans.</p>
</div>
<div id="improper-priors-continued" class="section level4 unnumbered">
<h4>Improper priors, continued…<a class="anchor" aria-label="anchor" href="#improper-priors-continued"><i class="fas fa-link"></i></a>
</h4>
<p>Notice that if <span class="math inline">\(\mu_0 = \beta_0 = \lambda_0 = 0\)</span> and <span class="math inline">\(\alpha_0= -1/2\)</span>, <span class="math inline">\(\mu_1 = \overline{x}\)</span>, <span class="math inline">\(\lambda_1 = n\)</span>, <span class="math inline">\(\alpha_1 = (n-1)/2\)</span>, <span class="math inline">\(\beta_1 = \sum(x_i - \overline{x})^2 / 2\)</span>. Our interval becomes:</p>
<p><span class="math display">\[\begin{eqnarray*}
\overline{x} &amp;\pm&amp; t^* \Bigg( \frac{(1/2) \sum(x_i - \overline{x})^2}{n (n-1)/2} \Bigg)^{1/2}\\
\overline{x} &amp;\pm&amp; t^* s/\sqrt{n}
\end{eqnarray*}\]</span></p>
<p>The improper prior down-weights any beliefs and gives a frequentist-like (i.e., data only) answer with a Bayesian-like interpretation.</p>
</div>
</div>
</div>
<div id="reflection-questions-5" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> <i class="fas fa-lightbulb" target="_blank"></i> Reflection Questions<a class="anchor" aria-label="anchor" href="#reflection-questions-5"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li>
</ol>
</div>
<div id="ethics-considerations-5" class="section level2" number="6.4">
<h2>
<span class="header-section-number">6.4</span> <i class="fas fa-balance-scale"></i> Ethics Considerations<a class="anchor" aria-label="anchor" href="#ethics-considerations-5"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li>
</ol>
</div>
<div id="r-code-creating-interval-estimates" class="section level2" number="6.5">
<h2>
<span class="header-section-number">6.5</span> R code: Creating Interval Estimates<a class="anchor" aria-label="anchor" href="#r-code-creating-interval-estimates"><i class="fas fa-link"></i></a>
</h2>
<div id="finding-cutoffs" class="section level3" number="6.5.1">
<h3>
<span class="header-section-number">6.5.1</span> Finding cutoffs<a class="anchor" aria-label="anchor" href="#finding-cutoffs"><i class="fas fa-link"></i></a>
</h3>
<p>Recall that the <code>q</code> in the distributional functions (e.g., <code><a href="https://rdrr.io/r/stats/Normal.html">qnorm()</a></code>, <code><a href="https://rdrr.io/r/stats/Binomial.html">qbinom()</a></code>, <code><a href="https://rdrr.io/r/stats/Uniform.html">qunif()</a></code>, <code><a href="https://rdrr.io/r/stats/Chisquare.html">qchisq()</a></code>, <code><a href="https://rdrr.io/r/stats/TDist.html">qt()</a></code>) indicates that the output is a <strong>quantile</strong>.</p>
<p>The <strong>mosiac</strong> package adds an <code>x</code> to the front of the function name which allows a figure to accompany the numerical value of the quantile. I highly recommend drawing pictures when finding quantiles or percentages.</p>
<p>One-sided 98% t-interval <span class="math inline">\((df = 24)\)</span> where 98% of the probability is to the left of the quantile of interest. Note that the t-distribution is symmetric.</p>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">mosaic</span><span class="fu">::</span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/qdist.html">xqt</a></span><span class="op">(</span><span class="fl">.98</span>, <span class="fl">24</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-intest_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;"></div>
<pre><code>## [1] 2.17</code></pre>
<p>Two-sided 98% t-interval <span class="math inline">\((df = 24)\)</span> where 98% of the area is in the center, so 99% of the area is to the left. Note that the code can be written in two different ways and provides the same quantile values. Note also that the t-distribution is symmetric.</p>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">mosaic</span><span class="fu">::</span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/qdist.html">xqt</a></span><span class="op">(</span><span class="fl">.99</span>, <span class="fl">24</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-intest_files/figure-html/unnamed-chunk-3-1.png" width="672" style="display: block; margin: auto;"></div>
<pre><code>## [1] 2.49</code></pre>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">mosaic</span><span class="fu">::</span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/qdist.html">xqt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.01</span>, <span class="fl">0.99</span><span class="op">)</span>, <span class="fl">24</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-intest_files/figure-html/unnamed-chunk-3-2.png" width="672" style="display: block; margin: auto;"></div>
<pre><code>## [1] -2.49  2.49</code></pre>
<p>Two-sided 95% chi-square interval <span class="math inline">\((df = 9)\)</span>. Note that the chi-square distribution is not symmetric.</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">mosaic</span><span class="fu">::</span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/qdist.html">xqchisq</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">0.975</span><span class="op">)</span>, <span class="fl">9</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-intest_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;"></div>
<pre><code>## [1]  2.7 19.0</code></pre>
<p>To find a 90% prediction inteval cutoff, the same R code is used:</p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">mosaic</span><span class="fu">::</span><span class="fu"><a href="https://www.mosaic-web.org/mosaic/reference/qdist.html">xqt</a></span><span class="op">(</span><span class="fl">0.95</span>, <span class="fl">12</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="06-intest_files/figure-html/unnamed-chunk-5-1.png" width="672" style="display: block; margin: auto;"></div>
<pre><code>## [1] 1.78</code></pre>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="bootdist.html"><span class="header-section-number">5</span> Bootstrap Distributions</a></div>
<div class="next"><a href="references.html">References</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#intest"><span class="header-section-number">6</span> Interval Estimates</a></li>
<li>
<a class="nav-link" href="#frequentist-confidence-intervals"><span class="header-section-number">6.1</span> Frequentist Confidence Intervals</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#ci-for-the-mean-mu-in-a-normal-random-sample"><span class="header-section-number">6.1.1</span> CI for the mean, \(\mu\) in a normal random sample</a></li></ul>
</li>
<li>
<a class="nav-link" href="#bayesian-intervals"><span class="header-section-number">6.2</span> Bayesian Intervals</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#joint-posterior-distribution-for-mu-and-sigma-in-a-normal-distribution"><span class="header-section-number">6.2.1</span> Joint Posterior Distribution for \(\mu\) and \(\sigma\) in a Normal Distribution</a></li>
<li><a class="nav-link" href="#posterior-interval-for-the-mean-mu-in-a-normal-random-sample"><span class="header-section-number">6.2.2</span> Posterior Interval for the mean, \(\mu\) in a normal random sample</a></li>
</ul>
</li>
<li><a class="nav-link" href="#reflection-questions-5"><span class="header-section-number">6.3</span>  Reflection Questions</a></li>
<li><a class="nav-link" href="#ethics-considerations-5"><span class="header-section-number">6.4</span>  Ethics Considerations</a></li>
<li>
<a class="nav-link" href="#r-code-creating-interval-estimates"><span class="header-section-number">6.5</span> R code: Creating Interval Estimates</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#finding-cutoffs"><span class="header-section-number">6.5.1</span> Finding cutoffs</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/hardin47/website/blob/master/06-intest.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/hardin47/website/edit/master/06-intest.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Statistical Theory</strong>" was written by Jo Hardin. It was last built on 2022-10-04.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
