# Expanding databases {#sec-add-db}


```{r}
#| include: false

source("_common.R")
fontawesome::fa_html_dependency()
```

As in @sec-create-db, we will use **DuckDB** so that we have access to a server into which we can expand the information in a database we've already created. Let's create a database called `SNL`.


```{r}
con_snl <- DBI::dbConnect(duckdb::duckdb(),
                             dbdir = "SNL")
```

## Existing SNL data

Building on the examples in @sec-create-db and @sec-change-db, consider the Saturday Night Live datasets available on the <a href = "https://github.com/hhllcks/snldb/" target = "_blank">snldb GitHub repo</a>. Data is scraped from <a href = "http://www.snlarchives.net" target = "_blank">http://www.snlarchives.net</a> and <a href = "http://www.imdb.com/title/tt0072562" target = "_blank">http://www.imdb.com/title/tt0072562</a> by <a href = "https://github.com/hhllcks" target = "_blank">Hendrik Hilleckes</a> and <a href = "https://github.com/colinmorris" target = "_blank">Colin Morris</a>.  Notice that there are eleven .csv files available in the <a href = "https://github.com/hhllcks/snldb/tree/master/output" target = "_blank">output folder</a>.


```{r}
#| echo: true
casts <- readr::read_csv("https://raw.githubusercontent.com/hhllcks/snldb/master/output/casts.csv")
casts <- readr::read_csv("https://raw.githubusercontent.com/hhllcks/snldb/master/output/casts.csv")
casts <- readr::read_csv("https://raw.githubusercontent.com/hhllcks/snldb/master/output/casts.csv")
casts <- readr::read_csv("https://raw.githubusercontent.com/hhllcks/snldb/master/output/casts.csv")
casts <- readr::read_csv("https://raw.githubusercontent.com/hhllcks/snldb/master/output/casts.csv")
```


```{sql}
#| connection: con_snl

USE SNL;
```

```{sql}
#| connection: con_snl

DROP TABLE IF EXISTS casts;
```

```{sql}
#| connection: con_snl

CREATE TABLE casts (
  aid VARCHAR(255) NOT NULL DEFAULT '',
  sid INTEGER NOT NULL DEFAULT 0,
  featured BOOLEAN NOT NULL DEFAULT 'false',
  first_epid INTEGER DEFAULT 0,
  last_epid INTEGER DEFAULT 0,
  update_anchor BOOLEAN NOT NULL DEFAULT 0,
  n_episodes INTEGER NOT NULL DEFAULT 0,
  season_fraction DECIMAL(21,20) NOT NULL DEFAULT 0,
  PRIMARY KEY (sid, aid)
);
```

```{sql}
#| connection: con_snl

COPY casts FROM 'data/casts.csv' HEADER;
```


```{sql}
#| connection: con_snl

SELECT MAX(sid), MIN(sid) FROM casts LIMIT 10;
```

```{sql}
#| connection: con_snl

SELECT * FROM casts LIMIT 10;
```


## Scrape to get more SNL data

what can i scrape?  which variables/tables are easy to update?

## Add the scraped data to the SNL database





## Best practice

It is always a good idea to terminate the **SQL** connection when you are done with it.

```{r}
dbDisconnect(con_snl, shutdown = TRUE)
```


## <i class="fas fa-lightbulb"></i> Reflection questions  

## <i class="fas fa-balance-scale"></i> Ethics considerations 



